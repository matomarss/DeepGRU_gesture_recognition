----------------Training initialized----------------
-----Stage 1-----
Evaluated preprocessing: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=8)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.383906
       [Training]   Prec@1 47.500000 Max 47.500000
       [Avg Loss]          1.617713
       [Validation] Prec@1 36.111111 Max 36.111111
Confusion matrix:
[[ 8  0  6 11  5 10]
 [ 2  9  4  6  7  2]
 [ 0  0 18  2 10  0]
 [ 1  0  8  0 21  0]
 [ 0  0  9  4 17  0]
 [ 6  0  0  1  0 13]]
Epoch: [1]
       [Avg Loss]          0.960663
       [Training]   Prec@1 66.000000 Max 66.000000
       [Avg Loss]          1.308157
       [Validation] Prec@1 56.666667 Max 56.666667
Confusion matrix:
[[27  0  0  0  3 10]
 [ 3 21  0  0  3  3]
 [ 0  5  9  0 16  0]
 [ 1  2  4  0 23  0]
 [ 1  3  0  0 26  0]
 [ 1  0  0  0  0 19]]
Epoch: [2]
       [Avg Loss]          0.726086
       [Training]   Prec@1 75.833333 Max 75.833333
       [Avg Loss]          1.354250
       [Validation] Prec@1 59.444444 Max 59.444444
Confusion matrix:
[[14  0  7  7  1 11]
 [ 0 22  0  2  2  4]
 [ 0  0 27  2  1  0]
 [ 2  3 10  0 15  0]
 [ 0  0  3  0 27  0]
 [ 2  1  0  0  0 17]]
Epoch: [3]
       [Avg Loss]          0.587802
       [Training]   Prec@1 79.666667 Max 79.666667
       [Avg Loss]          1.326866
       [Validation] Prec@1 62.777778 Max 62.777778
Confusion matrix:
[[17  0  9  4  0 10]
 [ 0 22  0  0  0  8]
 [ 0  0 27  1  2  0]
 [ 1  1 14  2 12  0]
 [ 0  1  4  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          0.562341
       [Training]   Prec@1 83.000000 Max 83.000000
       [Avg Loss]          1.318716
       [Validation] Prec@1 64.444444 Max 64.444444
Confusion matrix:
[[14  1  9  7  0  9]
 [ 0 26  3  1  0  0]
 [ 0  0 30  0  0  0]
 [ 1  0 23  5  1  0]
 [ 0  0  6  2 22  0]
 [ 0  0  0  1  0 19]]
Epoch: [5]
       [Avg Loss]          0.577108
       [Training]   Prec@1 80.500000 Max 83.000000
       [Avg Loss]          1.496936
       [Validation] Prec@1 60.555556 Max 64.444444
Confusion matrix:
[[14  1 11  4  1  9]
 [ 0 28  0  0  0  2]
 [ 0  0 29  1  0  0]
 [ 0  1 22  7  0  0]
 [ 0  0  8  6 16  0]
 [ 4  1  0  0  0 15]]
Epoch: [6]
       [Avg Loss]          0.518241
       [Training]   Prec@1 82.833333 Max 83.000000
       [Avg Loss]          1.900354
       [Validation] Prec@1 55.555556 Max 64.444444
Confusion matrix:
[[15  0 12  3  0 10]
 [ 1 20  0  1  4  4]
 [ 0  1 27  1  1  0]
 [ 0  3 15  3  9  0]
 [ 0  5  4  0 21  0]
 [ 4  0  1  1  0 14]]
Epoch: [7]
       [Avg Loss]          0.421672
       [Training]   Prec@1 85.166667 Max 85.166667
       [Avg Loss]          1.641516
       [Validation] Prec@1 61.111111 Max 64.444444
Confusion matrix:
[[14  0 13  2  1 10]
 [ 0 28  0  2  0  0]
 [ 0  0 29  1  0  0]
 [ 1  0 19  5  5  0]
 [ 0 10  4  0 16  0]
 [ 0  0  0  2  0 18]]
Epoch: [8]
       [Avg Loss]          0.358144
       [Training]   Prec@1 87.166667 Max 87.166667
       [Avg Loss]          1.611118
       [Validation] Prec@1 61.111111 Max 64.444444
Confusion matrix:
[[16  0 10  4  0 10]
 [ 2 20  0  7  0  1]
 [ 0  0 28  1  1  0]
 [ 2  2  9  1 16  0]
 [ 0  0  4  0 26  0]
 [ 1  0  0  0  0 19]]
Epoch: [9]
       [Avg Loss]          0.331773
       [Training]   Prec@1 88.833333 Max 88.833333
       [Avg Loss]          1.569480
       [Validation] Prec@1 66.111111 Max 66.111111
Confusion matrix:
[[18  0  8  4  0 10]
 [ 0 30  0  0  0  0]
 [ 0  1 27  0  2  0]
 [ 2  2 10  1 15  0]
 [ 0  5  1  0 24  0]
 [ 0  0  0  1  0 19]]
Epoch: [10]
       [Avg Loss]          0.257605
       [Training]   Prec@1 91.833333 Max 91.833333
       [Avg Loss]          1.569778
       [Validation] Prec@1 66.666667 Max 66.666667
Confusion matrix:
[[19  0 11  0  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 28  2  0  0]
 [ 1  0 22  1  6  0]
 [ 0  4  4  0 22  0]
 [ 0  0  0  0  0 20]]
Epoch: [11]
       [Avg Loss]          0.281837
       [Training]   Prec@1 91.166667 Max 91.833333
       [Avg Loss]          1.843641
       [Validation] Prec@1 62.777778 Max 66.666667
Confusion matrix:
[[13  0 13  4  0 10]
 [ 0 26  0  1  3  0]
 [ 0  1 27  0  2  0]
 [ 1  2 14  4  9  0]
 [ 0  1  4  0 25  0]
 [ 0  2  0  0  0 18]]
Epoch: [12]
       [Avg Loss]          0.246325
       [Training]   Prec@1 91.666667 Max 91.833333
       [Avg Loss]          1.664243
       [Validation] Prec@1 62.777778 Max 66.666667
Confusion matrix:
[[18  0  9  3  0 10]
 [ 0 30  0  0  0  0]
 [ 0  2 27  1  0  0]
 [ 3  3 10  2 12  0]
 [ 1 10  2  0 17  0]
 [ 1  0  0  0  0 19]]
Epoch: [13]
       [Avg Loss]          0.218980
       [Training]   Prec@1 94.166667 Max 94.166667
       [Avg Loss]          1.969765
       [Validation] Prec@1 63.333333 Max 66.666667
Confusion matrix:
[[18  2 10  1  0  9]
 [ 1 24  0  0  5  0]
 [ 0  0 29  0  1  0]
 [ 3  2 13  0 12  0]
 [ 0  1  4  0 25  0]
 [ 0  2  0  0  0 18]]
Epoch: [14]
       [Avg Loss]          0.208081
       [Training]   Prec@1 92.833333 Max 94.166667
       [Avg Loss]          2.039187
       [Validation] Prec@1 60.555556 Max 66.666667
Confusion matrix:
[[12  7  7  4  0 10]
 [ 0 30  0  0  0  0]
 [ 0  6 23  1  0  0]
 [ 3  4  4 10  9  0]
 [ 0 13  0  3 14  0]
 [ 0  0  0  0  0 20]]
Fold "0" complete, final accuracy: 66.66666666666667
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.531402
       [Training]   Prec@1 39.327731 Max 39.327731
       [Avg Loss]          1.530484
       [Validation] Prec@1 50.810811 Max 50.810811
Confusion matrix:
[[13 15  0  0  2  0]
 [ 0 34  1  0  0  0]
 [ 6 12  9  0  3  0]
 [15  4  2  0  6  3]
 [ 3  5  3  0 19  0]
 [ 1 10  0  0  0 19]]
Epoch: [1]
       [Avg Loss]          1.107162
       [Training]   Prec@1 61.008403 Max 61.008403
       [Avg Loss]          1.177279
       [Validation] Prec@1 56.756757 Max 56.756757
Confusion matrix:
[[20  8  0  0  0  2]
 [ 0 34  0  1  0  0]
 [ 4 16 10  0  0  0]
 [24  2  1  1  2  0]
 [ 5  3  3  0 19  0]
 [ 7  2  0  0  0 21]]
Epoch: [2]
       [Avg Loss]          0.924187
       [Training]   Prec@1 68.067227 Max 68.067227
       [Avg Loss]          0.902070
       [Validation] Prec@1 68.108108 Max 68.108108
Confusion matrix:
[[17  6  5  0  0  2]
 [ 0 24 11  0  0  0]
 [ 0  1 28  0  1  0]
 [11  0  9  8  1  1]
 [ 1  0  5  2 22  0]
 [ 0  1  1  0  1 27]]
Epoch: [3]
       [Avg Loss]          0.861027
       [Training]   Prec@1 69.915966 Max 69.915966
       [Avg Loss]          1.074812
       [Validation] Prec@1 63.243243 Max 68.108108
Confusion matrix:
[[23  6  0  0  0  1]
 [ 5 24  2  3  0  1]
 [ 2  6 22  0  0  0]
 [18  0  1  8  0  3]
 [ 7  3  0  7 13  0]
 [ 0  3  0  0  0 27]]
Epoch: [4]
       [Avg Loss]          0.753432
       [Training]   Prec@1 74.117647 Max 74.117647
       [Avg Loss]          0.807108
       [Validation] Prec@1 72.972973 Max 72.972973
Confusion matrix:
[[20  5  0  1  0  4]
 [ 0 33  2  0  0  0]
 [ 1  7 21  1  0  0]
 [ 9  0  3 18  0  0]
 [ 1  6  0  2 21  0]
 [ 3  2  0  2  1 22]]
Epoch: [5]
       [Avg Loss]          0.564059
       [Training]   Prec@1 82.689076 Max 82.689076
       [Avg Loss]          0.748026
       [Validation] Prec@1 78.918919 Max 78.918919
Confusion matrix:
[[23  5  0  1  1  0]
 [ 0 34  1  0  0  0]
 [ 1  5 24  0  0  0]
 [ 8  0  3 18  1  0]
 [ 1  1  0  4 24  0]
 [ 2  2  0  2  1 23]]
Epoch: [6]
       [Avg Loss]          0.492176
       [Training]   Prec@1 83.697479 Max 83.697479
       [Avg Loss]          0.755115
       [Validation] Prec@1 73.513514 Max 78.918919
Confusion matrix:
[[21  5  0  1  0  3]
 [ 0 34  1  0  0  0]
 [ 0  6 24  0  0  0]
 [ 7  0  3 20  0  0]
 [ 2  7  0  6 15  0]
 [ 1  3  0  4  0 22]]
Epoch: [7]
       [Avg Loss]          0.460949
       [Training]   Prec@1 83.361345 Max 83.697479
       [Avg Loss]          0.832210
       [Validation] Prec@1 75.675676 Max 78.918919
Confusion matrix:
[[23  5  0  1  1  0]
 [ 2 33  0  0  0  0]
 [ 0  6 23  1  0  0]
 [ 7  0  3 17  3  0]
 [ 2  6  0  1 21  0]
 [ 2  4  0  1  0 23]]
Epoch: [8]
       [Avg Loss]          0.423365
       [Training]   Prec@1 86.722689 Max 86.722689
       [Avg Loss]          0.684717
       [Validation] Prec@1 79.459459 Max 79.459459
Confusion matrix:
[[25  3  1  1  0  0]
 [ 1 34  0  0  0  0]
 [ 1  2 27  0  0  0]
 [ 7  0  3 19  1  0]
 [ 1  4  1  3 21  0]
 [ 2  2  0  4  1 21]]
Epoch: [9]
       [Avg Loss]          0.447517
       [Training]   Prec@1 85.210084 Max 86.722689
       [Avg Loss]          0.814964
       [Validation] Prec@1 74.054054 Max 79.459459
Confusion matrix:
[[19  9  1  0  0  1]
 [ 0 34  1  0  0  0]
 [ 0 10 20  0  0  0]
 [ 6  0  3 18  2  1]
 [ 1  7  0  0 22  0]
 [ 0  3  0  2  1 24]]
Epoch: [10]
       [Avg Loss]          0.381280
       [Training]   Prec@1 87.058824 Max 87.058824
       [Avg Loss]          0.764092
       [Validation] Prec@1 77.837838 Max 79.459459
Confusion matrix:
[[20  3  0  1  0  6]
 [ 1 33  1  0  0  0]
 [ 0  0 27  3  0  0]
 [ 6  0  3 19  0  2]
 [ 1  7  0  1 21  0]
 [ 1  4  0  1  0 24]]
Epoch: [11]
       [Avg Loss]          0.330682
       [Training]   Prec@1 89.747899 Max 89.747899
       [Avg Loss]          0.946283
       [Validation] Prec@1 74.594595 Max 79.459459
Confusion matrix:
[[20  1  0  1  0  8]
 [ 1 34  0  0  0  0]
 [ 0  4 25  1  0  0]
 [ 6  0  2 20  0  2]
 [ 5  6  0  2 17  0]
 [ 1  2  0  5  0 22]]
Epoch: [12]
       [Avg Loss]          0.383378
       [Training]   Prec@1 86.554622 Max 89.747899
       [Avg Loss]          1.235541
       [Validation] Prec@1 70.270270 Max 79.459459
Confusion matrix:
[[24  5  1  0  0  0]
 [ 0 35  0  0  0  0]
 [ 0  6 24  0  0  0]
 [15  0  3 12  0  0]
 [ 7  6  0  2 15  0]
 [ 6  3  0  0  1 20]]
Epoch: [13]
       [Avg Loss]          0.322705
       [Training]   Prec@1 89.579832 Max 89.747899
       [Avg Loss]          1.096624
       [Validation] Prec@1 74.594595 Max 79.459459
Confusion matrix:
[[26  3  0  1  0  0]
 [ 2 33  0  0  0  0]
 [ 1  3 23  3  0  0]
 [ 8  0  3 19  0  0]
 [ 5  6  0  6 13  0]
 [ 0  4  0  2  0 24]]
Epoch: [14]
       [Avg Loss]          0.318318
       [Training]   Prec@1 89.243697 Max 89.747899
       [Avg Loss]          0.849950
       [Validation] Prec@1 75.135135 Max 79.459459
Confusion matrix:
[[23  1  0  1  0  5]
 [ 4 31  0  0  0  0]
 [ 0  3 26  1  0  0]
 [10  0  3 16  1  0]
 [ 3  5  0  1 21  0]
 [ 2  2  0  4  0 22]]
Fold "1" complete, final accuracy: 79.45945945945945
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.550445
       [Training]   Prec@1 37.142857 Max 37.142857
       [Avg Loss]          1.518757
       [Validation] Prec@1 40.540541 Max 40.540541
Confusion matrix:
[[29  0  0  0  1  0]
 [31  4  0  0  0  0]
 [30  0  0  0  0  0]
 [23  0  0  5  2  0]
 [ 8  0  0  0 22  0]
 [15  0  0  0  0 15]]
Epoch: [1]
       [Avg Loss]          1.040958
       [Training]   Prec@1 63.361345 Max 63.361345
       [Avg Loss]          1.014122
       [Validation] Prec@1 69.189189 Max 69.189189
Confusion matrix:
[[20  7  0  0  0  3]
 [ 3 30  0  0  0  2]
 [ 4  2 18  4  2  0]
 [ 4 12  0  8  1  5]
 [ 6  0  0  0 24  0]
 [ 1  1  0  0  0 28]]
Epoch: [2]
       [Avg Loss]          0.781531
       [Training]   Prec@1 74.285714 Max 74.285714
       [Avg Loss]          1.102017
       [Validation] Prec@1 64.864865 Max 69.189189
Confusion matrix:
[[22  2  0  0  3  3]
 [ 4 18  1  0  0 12]
 [ 2  0 16  0 12  0]
 [ 0  7  0 10  6  7]
 [ 4  0  0  0 26  0]
 [ 2  0  0  0  0 28]]
Epoch: [3]
       [Avg Loss]          0.719696
       [Training]   Prec@1 76.470588 Max 76.470588
       [Avg Loss]          0.788136
       [Validation] Prec@1 74.054054 Max 74.054054
Confusion matrix:
[[19  2  0  0  2  7]
 [ 6 17  0  5  0  7]
 [ 0  0 24  3  3  0]
 [ 0  0  2 23  3  2]
 [ 1  0  0  0 29  0]
 [ 5  0  0  0  0 25]]
Epoch: [4]
       [Avg Loss]          0.764705
       [Training]   Prec@1 73.277311 Max 76.470588
       [Avg Loss]          0.841822
       [Validation] Prec@1 77.297297 Max 77.297297
Confusion matrix:
[[18  6  2  0  1  3]
 [ 4 23  4  0  0  4]
 [ 0  0 30  0  0  0]
 [ 0  5  2 23  0  0]
 [ 4  1  0  5 20  0]
 [ 0  1  0  0  0 29]]
Epoch: [5]
       [Avg Loss]          0.581089
       [Training]   Prec@1 79.327731 Max 79.327731
       [Avg Loss]          0.784206
       [Validation] Prec@1 75.675676 Max 77.297297
Confusion matrix:
[[14  5  0  1  3  7]
 [ 1 24  3  2  0  5]
 [ 0  0 28  2  0  0]
 [ 0  3  1 19  4  3]
 [ 0  0  0  1 29  0]
 [ 3  1  0  0  0 26]]
Epoch: [6]
       [Avg Loss]          0.496816
       [Training]   Prec@1 82.352941 Max 82.352941
       [Avg Loss]          0.787178
       [Validation] Prec@1 75.675676 Max 77.297297
Confusion matrix:
[[26  0  0  0  4  0]
 [ 5 21  0  5  0  4]
 [ 0  0 28  2  0  0]
 [ 0  0  1 23  0  6]
 [ 5  0  0  5 20  0]
 [ 7  0  0  1  0 22]]
Epoch: [7]
       [Avg Loss]          0.506340
       [Training]   Prec@1 83.025210 Max 83.025210
       [Avg Loss]          0.795162
       [Validation] Prec@1 76.216216 Max 77.297297
Confusion matrix:
[[21  0  0  5  3  1]
 [ 4 15  6  4  0  6]
 [ 0  0 30  0  0  0]
 [ 0  1  4 23  2  0]
 [ 3  0  0  3 24  0]
 [ 0  1  0  1  0 28]]
Epoch: [8]
       [Avg Loss]          0.412579
       [Training]   Prec@1 87.226891 Max 87.226891
       [Avg Loss]          0.734209
       [Validation] Prec@1 74.594595 Max 77.297297
Confusion matrix:
[[23  1  0  0  2  4]
 [ 4 22  0  4  0  5]
 [ 0  0 27  3  0  0]
 [ 0  0  2 26  0  2]
 [ 5  0  0  8 17  0]
 [ 7  0  0  0  0 23]]
Epoch: [9]
       [Avg Loss]          0.359806
       [Training]   Prec@1 87.731092 Max 87.731092
       [Avg Loss]          0.819958
       [Validation] Prec@1 79.459459 Max 79.459459
Confusion matrix:
[[22  1  1  2  3  1]
 [ 4 20  2  2  0  7]
 [ 0  0 29  1  0  0]
 [ 0  1  1 25  2  1]
 [ 3  0  0  1 26  0]
 [ 5  0  0  0  0 25]]
Epoch: [10]
       [Avg Loss]          0.341054
       [Training]   Prec@1 87.899160 Max 87.899160
       [Avg Loss]          1.005013
       [Validation] Prec@1 71.891892 Max 79.459459
Confusion matrix:
[[23  0  0  3  4  0]
 [ 9 15  5  5  0  1]
 [ 0  0 30  0  0  0]
 [ 0  0  8 22  0  0]
 [ 4  1  2  3 20  0]
 [ 6  1  0  0  0 23]]
Epoch: [11]
       [Avg Loss]          0.320201
       [Training]   Prec@1 88.907563 Max 88.907563
       [Avg Loss]          0.774573
       [Validation] Prec@1 75.675676 Max 79.459459
Confusion matrix:
[[21  0  1  1  5  2]
 [ 8 17  0  6  0  4]
 [ 0  0 26  4  0  0]
 [ 1  0  0 26  0  3]
 [ 0  0  0  3 27  0]
 [ 5  2  0  0  0 23]]
Epoch: [12]
       [Avg Loss]          0.293126
       [Training]   Prec@1 89.915966 Max 89.915966
       [Avg Loss]          0.868852
       [Validation] Prec@1 75.675676 Max 79.459459
Confusion matrix:
[[19  0  0  7  1  3]
 [ 2 20  0  5  0  8]
 [ 0  0 30  0  0  0]
 [ 0  0  3 27  0  0]
 [ 1  0  0 10 19  0]
 [ 5  0  0  0  0 25]]
Epoch: [13]
       [Avg Loss]          0.232506
       [Training]   Prec@1 92.605042 Max 92.605042
       [Avg Loss]          0.914840
       [Validation] Prec@1 74.594595 Max 79.459459
Confusion matrix:
[[21  2  0  1  3  3]
 [ 6 17  0  8  0  4]
 [ 0  0 30  0  0  0]
 [ 0  0  4 25  0  1]
 [ 4  0  0  6 20  0]
 [ 5  0  0  0  0 25]]
Epoch: [14]
       [Avg Loss]          0.236326
       [Training]   Prec@1 91.932773 Max 92.605042
       [Avg Loss]          0.981444
       [Validation] Prec@1 76.216216 Max 79.459459
Confusion matrix:
[[20  1  0  0  5  4]
 [ 4 18  4  1  4  4]
 [ 0  0 25  2  3  0]
 [ 0  1  3 22  3  1]
 [ 0  0  0  1 29  0]
 [ 2  1  0  0  0 27]]
Fold "2" complete, final accuracy: 79.45945945945945
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.516499
       [Training]   Prec@1 40.757576 Max 40.757576
       [Avg Loss]          1.453599
       [Validation] Prec@1 66.666667 Max 66.666667
Confusion matrix:
[[20  0  0  0  0  0]
 [ 2 14  0  3  0  1]
 [ 0  2  0 10  8  0]
 [ 5  0  0 11  1  3]
 [ 0  0  0  2 18  0]
 [ 1  1  0  1  0 17]]
Epoch: [1]
       [Avg Loss]          1.026458
       [Training]   Prec@1 63.787879 Max 63.787879
       [Avg Loss]          0.872350
       [Validation] Prec@1 74.166667 Max 74.166667
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0 17  0  2  1  0]
 [ 0  1 10  7  2  0]
 [ 7  0  0 11  1  1]
 [ 0  0  0  2 18  0]
 [ 4  0  0  2  0 14]]
Epoch: [2]
       [Avg Loss]          0.888741
       [Training]   Prec@1 69.393939 Max 69.393939
       [Avg Loss]          0.814380
       [Validation] Prec@1 74.166667 Max 74.166667
Confusion matrix:
[[17  0  0  0  3  0]
 [ 1 17  0  1  1  0]
 [ 0  2 11  5  2  0]
 [ 1  0  0 17  1  1]
 [ 0  3  0  3 14  0]
 [ 2  3  0  2  0 13]]
Epoch: [3]
       [Avg Loss]          0.847222
       [Training]   Prec@1 71.060606 Max 71.060606
       [Avg Loss]          0.800380
       [Validation] Prec@1 68.333333 Max 74.166667
Confusion matrix:
[[ 9  0  0  5  6  0]
 [ 0 16  0  2  0  2]
 [ 0  1 14  5  0  0]
 [ 1  0  0 17  1  1]
 [ 0  5  0  5 10  0]
 [ 0  2  0  2  0 16]]
Epoch: [4]
       [Avg Loss]          0.732437
       [Training]   Prec@1 74.545455 Max 74.545455
       [Avg Loss]          0.913101
       [Validation] Prec@1 73.333333 Max 74.166667
Confusion matrix:
[[10  0  0  1  9  0]
 [ 1 18  0  1  0  0]
 [ 0  0 15  5  0  0]
 [ 0  0  0 17  2  1]
 [ 0  3  0  0 17  0]
 [ 3  0  0  6  0 11]]
Epoch: [5]
       [Avg Loss]          0.610495
       [Training]   Prec@1 79.393939 Max 79.393939
       [Avg Loss]          0.986819
       [Validation] Prec@1 64.166667 Max 74.166667
Confusion matrix:
[[ 6  0  0  9  5  0]
 [ 0 18  0  2  0  0]
 [ 0  2 11  6  0  1]
 [ 0  0  0 19  1  0]
 [ 0  0  0  6 14  0]
 [ 2  1  0  8  0  9]]
Epoch: [6]
       [Avg Loss]          0.476290
       [Training]   Prec@1 84.545455 Max 84.545455
       [Avg Loss]          0.660978
       [Validation] Prec@1 79.166667 Max 79.166667
Confusion matrix:
[[16  0  0  3  1  0]
 [ 1 17  0  2  0  0]
 [ 3  0 13  3  0  1]
 [ 1  0  2 14  1  2]
 [ 0  0  0  2 18  0]
 [ 2  0  0  1  0 17]]
Epoch: [7]
       [Avg Loss]          0.410163
       [Training]   Prec@1 86.969697 Max 86.969697
       [Avg Loss]          0.782118
       [Validation] Prec@1 73.333333 Max 79.166667
Confusion matrix:
[[12  0  0  4  4  0]
 [ 0 18  0  1  1  0]
 [ 1  0 12  7  0  0]
 [ 0  0  0 17  2  1]
 [ 0  0  0  1 19  0]
 [ 3  3  0  4  0 10]]
Epoch: [8]
       [Avg Loss]          0.424535
       [Training]   Prec@1 86.060606 Max 86.969697
       [Avg Loss]          0.875793
       [Validation] Prec@1 72.500000 Max 79.166667
Confusion matrix:
[[ 6  0  0  6  8  0]
 [ 0 18  0  1  1  0]
 [ 2  0 12  6  0  0]
 [ 0  0  0 16  3  1]
 [ 0  0  0  0 20  0]
 [ 2  1  0  2  0 15]]
Epoch: [9]
       [Avg Loss]          0.369226
       [Training]   Prec@1 88.636364 Max 88.636364
       [Avg Loss]          1.272800
       [Validation] Prec@1 65.833333 Max 79.166667
Confusion matrix:
[[ 6  1  0  5  8  0]
 [ 0 16  0  1  2  1]
 [ 2  1 11  5  0  1]
 [ 0  0  0 16  3  1]
 [ 0  0  0  0 20  0]
 [ 1  2  0  7  0 10]]
Epoch: [10]
       [Avg Loss]          0.330398
       [Training]   Prec@1 88.636364 Max 88.636364
       [Avg Loss]          0.785156
       [Validation] Prec@1 77.500000 Max 79.166667
Confusion matrix:
[[14  0  0  3  3  0]
 [ 0 18  0  1  1  0]
 [ 4  0 11  5  0  0]
 [ 2  0  0 16  1  1]
 [ 0  0  0  0 20  0]
 [ 2  3  0  1  0 14]]
Epoch: [11]
       [Avg Loss]          0.327032
       [Training]   Prec@1 89.848485 Max 89.848485
       [Avg Loss]          1.900173
       [Validation] Prec@1 61.666667 Max 79.166667
Confusion matrix:
[[ 7  0  0  5  8  0]
 [ 0 18  0  0  2  0]
 [ 4  0 11  4  0  1]
 [ 1  0  2  9  8  0]
 [ 0  0  0  0 20  0]
 [ 0  2  0  7  2  9]]
Epoch: [12]
       [Avg Loss]          0.284350
       [Training]   Prec@1 90.151515 Max 90.151515
       [Avg Loss]          1.190845
       [Validation] Prec@1 70.833333 Max 79.166667
Confusion matrix:
[[13  0  0  6  1  0]
 [ 0 18  0  1  0  1]
 [ 1  0 13  6  0  0]
 [ 1  0  0 17  0  2]
 [ 0  0  0 11  9  0]
 [ 1  3  0  1  0 15]]
Epoch: [13]
       [Avg Loss]          0.383015
       [Training]   Prec@1 86.363636 Max 90.151515
       [Avg Loss]          1.316826
       [Validation] Prec@1 69.166667 Max 79.166667
Confusion matrix:
[[ 5  0  0  6  9  0]
 [ 0 16  0  1  3  0]
 [ 1  0 14  5  0  0]
 [ 0  0  3 16  1  0]
 [ 0  0  0  1 19  0]
 [ 2  1  0  4  0 13]]
Epoch: [14]
       [Avg Loss]          0.353198
       [Training]   Prec@1 87.878788 Max 90.151515
       [Avg Loss]          0.677166
       [Validation] Prec@1 79.166667 Max 79.166667
Confusion matrix:
[[13  0  0  7  0  0]
 [ 0 18  0  1  1  0]
 [ 2  1 15  2  0  0]
 [ 2  0  0 14  4  0]
 [ 1  0  0  0 19  0]
 [ 1  2  0  1  0 16]]
Fold "3" complete, final accuracy: 79.16666666666667
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.514121
       [Training]   Prec@1 39.253731 Max 39.253731
       [Avg Loss]          1.485078
       [Validation] Prec@1 52.727273 Max 52.727273
Confusion matrix:
[[17  0  2  0  0  1]
 [ 3  3  7  0  7  0]
 [10  0 10  0  0  0]
 [ 0  2  6  0  9  3]
 [ 0  0  0  0 10  0]
 [ 1  1  0  0  0 18]]
Epoch: [1]
       [Avg Loss]          1.023841
       [Training]   Prec@1 64.626866 Max 64.626866
       [Avg Loss]          1.673873
       [Validation] Prec@1 42.727273 Max 52.727273
Confusion matrix:
[[19  1  0  0  0  0]
 [10  9  1  0  0  0]
 [ 9  4  7  0  0  0]
 [ 1 16  3  0  0  0]
 [ 0  0  3  0  7  0]
 [14  1  0  0  0  5]]
Epoch: [2]
       [Avg Loss]          0.812238
       [Training]   Prec@1 71.940299 Max 71.940299
       [Avg Loss]          1.536080
       [Validation] Prec@1 50.909091 Max 52.727273
Confusion matrix:
[[14  1  1  0  4  0]
 [ 6  1  4  6  3  0]
 [ 9  0 11  0  0  0]
 [ 0  5  4 11  0  0]
 [ 0  0  2  3  5  0]
 [ 6  0  0  0  0 14]]
Epoch: [3]
       [Avg Loss]          0.640479
       [Training]   Prec@1 78.805970 Max 78.805970
       [Avg Loss]          1.829021
       [Validation] Prec@1 52.727273 Max 52.727273
Confusion matrix:
[[14  0  1  1  4  0]
 [ 7  6  4  0  3  0]
 [ 9  0  7  1  3  0]
 [ 0  5 11  4  0  0]
 [ 0  0  0  0 10  0]
 [ 0  2  0  1  0 17]]
Epoch: [4]
       [Avg Loss]          0.488066
       [Training]   Prec@1 82.835821 Max 82.835821
       [Avg Loss]          1.321799
       [Validation] Prec@1 61.818182 Max 61.818182
Confusion matrix:
[[17  1  1  1  0  0]
 [ 7  5  3  5  0  0]
 [ 5  0 15  0  0  0]
 [ 0  5 10  5  0  0]
 [ 0  0  3  0  7  0]
 [ 0  0  0  1  0 19]]
Epoch: [5]
       [Avg Loss]          0.484093
       [Training]   Prec@1 82.985075 Max 82.985075
       [Avg Loss]          1.621853
       [Validation] Prec@1 54.545455 Max 61.818182
Confusion matrix:
[[ 7  5  3  0  5  0]
 [ 8  6  2  4  0  0]
 [ 7  0 11  0  1  1]
 [ 0  5  5 10  0  0]
 [ 0  0  0  0 10  0]
 [ 1  1  0  2  0 16]]
Epoch: [6]
       [Avg Loss]          0.423851
       [Training]   Prec@1 84.328358 Max 84.328358
       [Avg Loss]          1.241954
       [Validation] Prec@1 64.545455 Max 64.545455
Confusion matrix:
[[16  1  1  1  1  0]
 [10  1  0  9  0  0]
 [ 5  0 12  2  0  1]
 [ 0  4  2 14  0  0]
 [ 0  0  0  1  9  0]
 [ 0  0  0  1  0 19]]
Epoch: [7]
       [Avg Loss]          0.397967
       [Training]   Prec@1 86.716418 Max 86.716418
       [Avg Loss]          1.671699
       [Validation] Prec@1 60.909091 Max 64.545455
Confusion matrix:
[[16  0  1  2  1  0]
 [10  6  0  4  0  0]
 [ 8  0 10  2  0  0]
 [ 0  3  8  9  0  0]
 [ 0  0  0  3  7  0]
 [ 0  0  0  1  0 19]]
Epoch: [8]
       [Avg Loss]          0.348896
       [Training]   Prec@1 87.313433 Max 87.313433
       [Avg Loss]          1.972489
       [Validation] Prec@1 50.909091 Max 64.545455
Confusion matrix:
[[13  1  0  2  4  0]
 [ 9  3  0  8  0  0]
 [ 8  0  9  3  0  0]
 [ 0  4  5 11  0  0]
 [ 0  0  4  0  6  0]
 [ 5  0  0  1  0 14]]
Epoch: [9]
       [Avg Loss]          0.291484
       [Training]   Prec@1 89.552239 Max 89.552239
       [Avg Loss]          1.387870
       [Validation] Prec@1 61.818182 Max 64.545455
Confusion matrix:
[[19  0  1  0  0  0]
 [ 9  9  0  2  0  0]
 [ 5  0  4 11  0  0]
 [ 0  5  6  9  0  0]
 [ 0  0  0  1  9  0]
 [ 1  0  0  1  0 18]]
Epoch: [10]
       [Avg Loss]          0.283953
       [Training]   Prec@1 92.238806 Max 92.238806
       [Avg Loss]          1.552920
       [Validation] Prec@1 54.545455 Max 64.545455
Confusion matrix:
[[18  2  0  0  0  0]
 [ 8  6  1  3  2  0]
 [ 7  0  4  7  2  0]
 [ 0  4 10  6  0  0]
 [ 0  0  0  0 10  0]
 [ 4  0  0  0  0 16]]
Epoch: [11]
       [Avg Loss]          0.267889
       [Training]   Prec@1 90.000000 Max 92.238806
       [Avg Loss]          1.938860
       [Validation] Prec@1 53.636364 Max 64.545455
Confusion matrix:
[[18  0  1  1  0  0]
 [10  0  0 10  0  0]
 [ 7  0  0 13  0  0]
 [ 0  2  0 18  0  0]
 [ 0  0  0  4  6  0]
 [ 1  1  0  1  0 17]]
Epoch: [12]
       [Avg Loss]          0.273387
       [Training]   Prec@1 91.044776 Max 92.238806
       [Avg Loss]          1.394140
       [Validation] Prec@1 58.181818 Max 64.545455
Confusion matrix:
[[14  2  1  3  0  0]
 [ 4  8  1  2  5  0]
 [ 6  0 14  0  0  0]
 [ 0  6 11  3  0  0]
 [ 0  0  0  0 10  0]
 [ 5  0  0  0  0 15]]
Epoch: [13]
       [Avg Loss]          0.251385
       [Training]   Prec@1 91.044776 Max 92.238806
       [Avg Loss]          1.697054
       [Validation] Prec@1 51.818182 Max 64.545455
Confusion matrix:
[[17  1  1  1  0  0]
 [ 1  3  0  7  9  0]
 [ 2  0  6 10  2  0]
 [ 0  6  7  7  0  0]
 [ 0  0  0  0 10  0]
 [ 5  1  0  0  0 14]]
Epoch: [14]
       [Avg Loss]          0.214779
       [Training]   Prec@1 93.432836 Max 93.432836
       [Avg Loss]          1.937440
       [Validation] Prec@1 56.363636 Max 64.545455
Confusion matrix:
[[17  1  0  1  0  1]
 [ 9  3  4  4  0  0]
 [ 6  0 10  2  0  2]
 [ 0  2 12  6  0  0]
 [ 0  0  1  2  7  0]
 [ 0  1  0  0  0 19]]
Fold "4" complete, final accuracy: 64.54545454545455

-----------------------------------------------------------------------
Training for stage 1 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=8)")
Average accuracy is: 73.85954135954135


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 2-----
Evaluated preprocessing: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=8)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.370719
       [Training]   Prec@1 47.500000 Max 47.500000
       [Avg Loss]          1.537844
       [Validation] Prec@1 55.000000 Max 55.000000
Confusion matrix:
[[10  0  0  6 14 10]
 [ 0 20  0  5  5  0]
 [ 0  0 24  1  5  0]
 [ 0  0  8  0 22  0]
 [ 0  0  3  0 27  0]
 [ 0  0  0  2  0 18]]
Epoch: [1]
       [Avg Loss]          0.868755
       [Training]   Prec@1 70.166667 Max 70.166667
       [Avg Loss]          1.016801
       [Validation] Prec@1 73.333333 Max 73.333333
Confusion matrix:
[[26  0  0  4  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 26  3  1  0]
 [ 2  3 12  4  9  0]
 [ 1  0  2  1 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          0.779332
       [Training]   Prec@1 75.500000 Max 75.500000
       [Avg Loss]          1.230341
       [Validation] Prec@1 65.555556 Max 73.333333
Confusion matrix:
[[20  0  2  7  1 10]
 [ 0 28  0  2  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 19  0 10  0]
 [ 0  0  8  2 20  0]
 [ 0  0  0  0  0 20]]
Epoch: [3]
       [Avg Loss]          0.689612
       [Training]   Prec@1 77.666667 Max 77.666667
       [Avg Loss]          1.490469
       [Validation] Prec@1 62.222222 Max 73.333333
Confusion matrix:
[[15  0  4  0 11 10]
 [ 0 29  0  1  0  0]
 [ 0  0 30  0  0  0]
 [ 1  0 24  0  5  0]
 [ 0  0 11  0 19  0]
 [ 1  0  0  0  0 19]]
Epoch: [4]
       [Avg Loss]          0.662754
       [Training]   Prec@1 76.833333 Max 77.666667
       [Avg Loss]          1.442012
       [Validation] Prec@1 63.888889 Max 73.333333
Confusion matrix:
[[20  0  1  6  3 10]
 [ 1 24  0  5  0  0]
 [ 0  1 27  0  2  0]
 [ 1  2 14  4  9  0]
 [ 1  1  3  4 21  0]
 [ 0  0  0  1  0 19]]
Epoch: [5]
       [Avg Loss]          0.540699
       [Training]   Prec@1 81.333333 Max 81.333333
       [Avg Loss]          1.448488
       [Validation] Prec@1 66.111111 Max 73.333333
Confusion matrix:
[[19  0  0 11  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 20  0 10  0]
 [ 1  1  4  4 20  0]
 [ 0  0  4  0 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [6]
       [Avg Loss]          0.571611
       [Training]   Prec@1 81.000000 Max 81.333333
       [Avg Loss]          1.507050
       [Validation] Prec@1 63.888889 Max 73.333333
Confusion matrix:
[[19  0  5  6  0 10]
 [ 0 27  0  3  0  0]
 [ 0  0 29  0  1  0]
 [ 1  3 17  1  8  0]
 [ 0  0  9  1 20  0]
 [ 0  0  0  1  0 19]]
Epoch: [7]
       [Avg Loss]          0.465794
       [Training]   Prec@1 84.500000 Max 84.500000
       [Avg Loss]          1.765681
       [Validation] Prec@1 67.222222 Max 73.333333
Confusion matrix:
[[21  0  1  3  5 10]
 [ 0 30  0  0  0  0]
 [ 0  2 25  0  3  0]
 [ 1  2  9  0 18  0]
 [ 0  1  3  0 26  0]
 [ 0  0  0  1  0 19]]
Epoch: [8]
       [Avg Loss]          0.439099
       [Training]   Prec@1 86.500000 Max 86.500000
       [Avg Loss]          1.710089
       [Validation] Prec@1 58.888889 Max 73.333333
Confusion matrix:
[[18  0  3  2  7 10]
 [ 1 29  0  0  0  0]
 [ 0  1 15  0 14  0]
 [ 1  3  9  2 15  0]
 [ 0  0  5  2 23  0]
 [ 0  0  0  1  0 19]]
Epoch: [9]
       [Avg Loss]          0.357228
       [Training]   Prec@1 87.166667 Max 87.166667
       [Avg Loss]          1.545744
       [Validation] Prec@1 58.888889 Max 73.333333
Confusion matrix:
[[14  0  3 13  0 10]
 [ 0 29  1  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  1 22  5  1  0]
 [ 0  0 17  3 10  0]
 [ 1  0  0  1  0 18]]
Epoch: [10]
       [Avg Loss]          0.417503
       [Training]   Prec@1 85.833333 Max 87.166667
       [Avg Loss]          1.490845
       [Validation] Prec@1 61.111111 Max 73.333333
Confusion matrix:
[[24  3  0  3  0 10]
 [ 0 30  0  0  0  0]
 [ 0  3 26  1  0  0]
 [ 2  4 22  2  0  0]
 [ 4  6  8  3  9  0]
 [ 0  0  0  1  0 19]]
Epoch: [11]
       [Avg Loss]          0.393512
       [Training]   Prec@1 88.000000 Max 88.000000
       [Avg Loss]          1.744156
       [Validation] Prec@1 65.000000 Max 73.333333
Confusion matrix:
[[22  4  1  3  0 10]
 [ 0 29  0  0  1  0]
 [ 0  1 20  0  9  0]
 [ 1  2  5  1 21  0]
 [ 0  4  0  0 26  0]
 [ 0  0  0  1  0 19]]
Epoch: [12]
       [Avg Loss]          0.259120
       [Training]   Prec@1 92.666667 Max 92.666667
       [Avg Loss]          1.541709
       [Validation] Prec@1 68.333333 Max 73.333333
Confusion matrix:
[[20  0  0  7  3 10]
 [ 0 29  0  0  1  0]
 [ 0  0 28  0  2  0]
 [ 1  1  6  4 18  0]
 [ 0  3  2  1 24  0]
 [ 0  0  0  2  0 18]]
Epoch: [13]
       [Avg Loss]          0.279889
       [Training]   Prec@1 89.666667 Max 92.666667
       [Avg Loss]          1.846929
       [Validation] Prec@1 60.555556 Max 73.333333
Confusion matrix:
[[14  8  4  4  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 2  3 23  2  0  0]
 [ 0  4 11  1 14  0]
 [ 0  0  0  1  0 19]]
Epoch: [14]
       [Avg Loss]          0.286796
       [Training]   Prec@1 91.833333 Max 92.666667
       [Avg Loss]          1.499915
       [Validation] Prec@1 71.111111 Max 73.333333
Confusion matrix:
[[28  0  1  1  0 10]
 [ 1 29  0  0  0  0]
 [ 0  0 28  2  0  0]
 [ 2  3 18  3  4  0]
 [ 3  1  4  1 21  0]
 [ 0  0  0  1  0 19]]
Fold "0" complete, final accuracy: 73.33333333333333
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.409964
       [Training]   Prec@1 45.546218 Max 45.546218
       [Avg Loss]          1.379606
       [Validation] Prec@1 64.324324 Max 64.324324
Confusion matrix:
[[19  5  0  0  1  5]
 [ 0 30  5  0  0  0]
 [ 0  4 21  0  5  0]
 [ 0  1  9  5 12  3]
 [ 0  1  9  0 20  0]
 [ 0  3  1  2  0 24]]
Epoch: [1]
       [Avg Loss]          0.986505
       [Training]   Prec@1 66.218487 Max 66.218487
       [Avg Loss]          1.069509
       [Validation] Prec@1 62.702703 Max 64.324324
Confusion matrix:
[[20  1  0  0  0  9]
 [ 1 34  0  0  0  0]
 [ 0 12 13  2  3  0]
 [18  2  2  8  0  0]
 [ 6  2  2  6 14  0]
 [ 1  0  0  1  1 27]]
Epoch: [2]
       [Avg Loss]          0.897876
       [Training]   Prec@1 69.411765 Max 69.411765
       [Avg Loss]          1.133128
       [Validation] Prec@1 58.918919 Max 64.324324
Confusion matrix:
[[ 8 10 12  0  0  0]
 [ 0 26  7  2  0  0]
 [ 0  5 23  0  2  0]
 [ 9  5  8  6  2  0]
 [ 0  1  6  2 21  0]
 [ 1  1  1  2  0 25]]
Epoch: [3]
       [Avg Loss]          0.915270
       [Training]   Prec@1 68.235294 Max 69.411765
       [Avg Loss]          1.413775
       [Validation] Prec@1 51.891892 Max 64.324324
Confusion matrix:
[[20  3  0  0  0  7]
 [ 0 30  0  1  0  4]
 [ 0 10 20  0  0  0]
 [12  1  3 11  0  3]
 [13  2 10  4  1  0]
 [ 2  0  1 13  0 14]]
Epoch: [4]
       [Avg Loss]          0.770234
       [Training]   Prec@1 72.941176 Max 72.941176
       [Avg Loss]          0.836734
       [Validation] Prec@1 67.027027 Max 67.027027
Confusion matrix:
[[20 10  0  0  0  0]
 [ 1 32  2  0  0  0]
 [ 0  4 18  0  8  0]
 [ 7  2  2 11  8  0]
 [ 0  1  6  3 20  0]
 [ 4  2  1  0  0 23]]
Epoch: [5]
       [Avg Loss]          0.712288
       [Training]   Prec@1 75.462185 Max 75.462185
       [Avg Loss]          0.948896
       [Validation] Prec@1 63.783784 Max 67.027027
Confusion matrix:
[[20  4  0  0  0  6]
 [ 1 33  1  0  0  0]
 [ 0  8 22  0  0  0]
 [14  2  2 11  0  1]
 [ 0  2  4  9 15  0]
 [ 5  1  1  6  0 17]]
Epoch: [6]
       [Avg Loss]          0.659792
       [Training]   Prec@1 77.478992 Max 77.478992
       [Avg Loss]          1.183653
       [Validation] Prec@1 56.216216 Max 67.027027
Confusion matrix:
[[17  9  4  0  0  0]
 [ 0 24 10  1  0  0]
 [ 0  2 28  0  0  0]
 [13  2  6  8  1  0]
 [ 2  0  8  5 15  0]
 [ 6  1  2  9  0 12]]
Epoch: [7]
       [Avg Loss]          0.598754
       [Training]   Prec@1 78.655462 Max 78.655462
       [Avg Loss]          0.880508
       [Validation] Prec@1 71.351351 Max 71.351351
Confusion matrix:
[[19  3  0  1  0  7]
 [ 1 34  0  0  0  0]
 [ 0  8 20  0  2  0]
 [ 7  0  2 16  4  1]
 [ 1  1  1  5 22  0]
 [ 0  1  1  7  0 21]]
Epoch: [8]
       [Avg Loss]          0.529887
       [Training]   Prec@1 82.016807 Max 82.016807
       [Avg Loss]          0.878619
       [Validation] Prec@1 67.027027 Max 71.351351
Confusion matrix:
[[16  4  4  0  0  6]
 [ 0 32  3  0  0  0]
 [ 0  4 22  0  4  0]
 [ 8  1  7 12  1  1]
 [ 0  2  6  4 18  0]
 [ 0  2  1  3  0 24]]
Epoch: [9]
       [Avg Loss]          0.485202
       [Training]   Prec@1 82.689076 Max 82.689076
       [Avg Loss]          0.941379
       [Validation] Prec@1 65.405405 Max 71.351351
Confusion matrix:
[[21  9  0  0  0  0]
 [ 1 34  0  0  0  0]
 [ 0  9 20  0  1  0]
 [14  0  3 12  0  1]
 [ 1  3  3  9 14  0]
 [ 2  2  0  6  0 20]]
Epoch: [10]
       [Avg Loss]          0.472200
       [Training]   Prec@1 84.201681 Max 84.201681
       [Avg Loss]          1.104563
       [Validation] Prec@1 62.162162 Max 71.351351
Confusion matrix:
[[16  3  4  0  0  7]
 [ 1 33  1  0  0  0]
 [ 0  5 25  0  0  0]
 [ 9  0  6 11  0  4]
 [11  2  2  5 10  0]
 [ 1  2  1  6  0 20]]
Epoch: [11]
       [Avg Loss]          0.384356
       [Training]   Prec@1 86.722689 Max 86.722689
       [Avg Loss]          0.889309
       [Validation] Prec@1 69.729730 Max 71.351351
Confusion matrix:
[[23  4  1  0  0  2]
 [ 1 33  1  0  0  0]
 [ 0  3 26  1  0  0]
 [ 6  0  7 13  4  0]
 [ 1  3  5  2 19  0]
 [ 6  4  0  5  0 15]]
Epoch: [12]
       [Avg Loss]          0.427787
       [Training]   Prec@1 84.705882 Max 86.722689
       [Avg Loss]          1.042347
       [Validation] Prec@1 69.729730 Max 71.351351
Confusion matrix:
[[23  4  2  0  0  1]
 [ 0 31  4  0  0  0]
 [ 0  0 30  0  0  0]
 [ 7  1  9 11  0  2]
 [ 2  6  8  1 13  0]
 [ 1  2  0  6  0 21]]
Epoch: [13]
       [Avg Loss]          0.516450
       [Training]   Prec@1 82.689076 Max 86.722689
       [Avg Loss]          1.046996
       [Validation] Prec@1 70.270270 Max 71.351351
Confusion matrix:
[[23  2  0  0  0  5]
 [ 1 34  0  0  0  0]
 [ 1  7 22  0  0  0]
 [10  0  3  8  8  1]
 [ 3  1  1  3 22  0]
 [ 3  0  0  6  0 21]]
Epoch: [14]
       [Avg Loss]          0.464595
       [Training]   Prec@1 83.529412 Max 86.722689
       [Avg Loss]          0.911257
       [Validation] Prec@1 72.972973 Max 72.972973
Confusion matrix:
[[19 10  0  1  0  0]
 [ 0 34  1  0  0  0]
 [ 0  1 28  0  1  0]
 [ 8  1  2 16  0  3]
 [ 4  3  1  4 18  0]
 [ 1  2  0  7  0 20]]
Fold "1" complete, final accuracy: 72.97297297297297
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.396190
       [Training]   Prec@1 47.899160 Max 47.899160
       [Avg Loss]          1.451039
       [Validation] Prec@1 57.837838 Max 57.837838
Confusion matrix:
[[25  2  0  0  3  0]
 [ 8 26  0  0  0  1]
 [10  0  1  4 15  0]
 [15  4  0  8  3  0]
 [12  0  0  0 18  0]
 [ 1  0  0  0  0 29]]
Epoch: [1]
       [Avg Loss]          1.018838
       [Training]   Prec@1 62.689076 Max 62.689076
       [Avg Loss]          1.077171
       [Validation] Prec@1 63.783784 Max 63.783784
Confusion matrix:
[[23  5  0  0  0  2]
 [ 1 30  2  0  0  2]
 [12  0  5 12  1  0]
 [ 0  7  3 17  1  2]
 [ 6  0  3  3 18  0]
 [ 0  5  0  0  0 25]]
Epoch: [2]
       [Avg Loss]          0.911711
       [Training]   Prec@1 68.907563 Max 68.907563
       [Avg Loss]          0.934731
       [Validation] Prec@1 67.567568 Max 67.567568
Confusion matrix:
[[22  5  0  0  1  2]
 [ 9 24  1  0  0  1]
 [ 2  0 21  1  5  1]
 [ 0  8  2 15  3  2]
 [ 0  0  6  0 24  0]
 [11  0  0  0  0 19]]
Epoch: [3]
       [Avg Loss]          0.897770
       [Training]   Prec@1 68.403361 Max 68.907563
       [Avg Loss]          0.924155
       [Validation] Prec@1 74.054054 Max 74.054054
Confusion matrix:
[[21  4  5  0  0  0]
 [ 4 26  2  1  0  2]
 [ 1  0 23  1  5  0]
 [ 1  6  1 18  1  3]
 [ 2  0  7  2 19  0]
 [ 0  0  0  0  0 30]]
Epoch: [4]
       [Avg Loss]          0.768214
       [Training]   Prec@1 73.277311 Max 73.277311
       [Avg Loss]          1.095539
       [Validation] Prec@1 63.243243 Max 74.054054
Confusion matrix:
[[22  3  3  0  2  0]
 [ 1 16 10  0  0  8]
 [ 1  0 23  0  6  0]
 [ 1  1  8 12  7  1]
 [ 8  0  7  1 14  0]
 [ 0  0  0  0  0 30]]
Epoch: [5]
       [Avg Loss]          0.717665
       [Training]   Prec@1 75.126050 Max 75.126050
       [Avg Loss]          1.087949
       [Validation] Prec@1 65.405405 Max 74.054054
Confusion matrix:
[[20  2  3  0  3  2]
 [ 5 27  2  1  0  0]
 [ 2  0 22  3  3  0]
 [ 0  2  5 18  1  4]
 [ 5  0  0  9 16  0]
 [11  1  0  0  0 18]]
Epoch: [6]
       [Avg Loss]          0.691569
       [Training]   Prec@1 76.974790 Max 76.974790
       [Avg Loss]          0.905822
       [Validation] Prec@1 71.351351 Max 74.054054
Confusion matrix:
[[18  5  2  1  4  0]
 [ 1 27  3  0  0  4]
 [ 0  0  8  3 19  0]
 [ 0  3  3 20  3  1]
 [ 1  0  0  0 29  0]
 [ 0  0  0  0  0 30]]
Epoch: [7]
       [Avg Loss]          0.603090
       [Training]   Prec@1 80.672269 Max 80.672269
       [Avg Loss]          0.978612
       [Validation] Prec@1 72.972973 Max 74.054054
Confusion matrix:
[[23  1  2  0  4  0]
 [ 4 22  6  0  0  3]
 [ 2  0 20  1  7  0]
 [ 0  2  6 20  1  1]
 [ 1  0  0  9 20  0]
 [ 0  0  0  0  0 30]]
Epoch: [8]
       [Avg Loss]          0.568939
       [Training]   Prec@1 77.647059 Max 80.672269
       [Avg Loss]          0.958388
       [Validation] Prec@1 72.432432 Max 74.054054
Confusion matrix:
[[22  7  0  0  1  0]
 [ 5 27  1  0  0  2]
 [ 2  0 18  6  4  0]
 [ 0  3  4 16  1  6]
 [ 1  0  0  8 21  0]
 [ 0  0  0  0  0 30]]
Epoch: [9]
       [Avg Loss]          0.609950
       [Training]   Prec@1 80.000000 Max 80.672269
       [Avg Loss]          1.132365
       [Validation] Prec@1 70.270270 Max 74.054054
Confusion matrix:
[[21  4  3  1  1  0]
 [ 3 20  4  0  0  8]
 [ 1  0 19  3  7  0]
 [ 0  0  4 14 10  2]
 [ 0  0  0  4 26  0]
 [ 0  0  0  0  0 30]]
Epoch: [10]
       [Avg Loss]          0.502627
       [Training]   Prec@1 83.697479 Max 83.697479
       [Avg Loss]          0.715835
       [Validation] Prec@1 77.297297 Max 77.297297
Confusion matrix:
[[22  2  3  1  2  0]
 [ 5 23  2  1  2  2]
 [ 3  0 24  2  1  0]
 [ 0  1  1 25  1  2]
 [ 2  0  4  5 19  0]
 [ 0  0  0  0  0 30]]
Epoch: [11]
       [Avg Loss]          0.490685
       [Training]   Prec@1 82.689076 Max 83.697479
       [Avg Loss]          1.151607
       [Validation] Prec@1 68.108108 Max 77.297297
Confusion matrix:
[[24  2  2  0  2  0]
 [ 5 21  4  1  1  3]
 [ 5  0  9  7  9  0]
 [ 0  0  5 20  3  2]
 [ 2  0  0  6 22  0]
 [ 0  0  0  0  0 30]]
Epoch: [12]
       [Avg Loss]          0.446307
       [Training]   Prec@1 85.210084 Max 85.210084
       [Avg Loss]          1.131776
       [Validation] Prec@1 63.243243 Max 77.297297
Confusion matrix:
[[17  1  2  1  6  3]
 [ 6 21  3  0  1  4]
 [ 3  0 10 10  6  1]
 [ 0  7  1 16  0  6]
 [ 0  0  0  7 23  0]
 [ 0  0  0  0  0 30]]
Epoch: [13]
       [Avg Loss]          0.399205
       [Training]   Prec@1 87.899160 Max 87.899160
       [Avg Loss]          0.928461
       [Validation] Prec@1 70.270270 Max 77.297297
Confusion matrix:
[[20  7  1  1  1  0]
 [ 3 25  0  2  0  5]
 [ 1  0 13 11  5  0]
 [ 0  1  2 22  3  2]
 [ 3  1  0  5 21  0]
 [ 0  0  0  1  0 29]]
Epoch: [14]
       [Avg Loss]          0.331585
       [Training]   Prec@1 89.579832 Max 89.579832
       [Avg Loss]          1.008445
       [Validation] Prec@1 71.891892 Max 77.297297
Confusion matrix:
[[15  3  1  6  4  1]
 [ 1 27  2  0  0  5]
 [ 1  0 20  1  8  0]
 [ 0  6  2 15  3  4]
 [ 0  0  4  0 26  0]
 [ 0  0  0  0  0 30]]
Fold "2" complete, final accuracy: 77.29729729729729
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.391891
       [Training]   Prec@1 46.363636 Max 46.363636
       [Avg Loss]          1.278061
       [Validation] Prec@1 69.166667 Max 69.166667
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 18  0  2  0  0]
 [ 1  0  0  5 14  0]
 [ 7  1  0  9  3  0]
 [ 0  0  0  0 20  0]
 [ 0  3  0  1  0 16]]
Epoch: [1]
       [Avg Loss]          0.945362
       [Training]   Prec@1 68.333333 Max 68.333333
       [Avg Loss]          0.966104
       [Validation] Prec@1 69.166667 Max 69.166667
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 16  0  3  0  1]
 [ 0  1  2 13  4  0]
 [ 2  0  1 11  5  1]
 [ 0  0  0  1 19  0]
 [ 2  1  0  2  0 15]]
Epoch: [2]
       [Avg Loss]          0.801831
       [Training]   Prec@1 73.939394 Max 73.939394
       [Avg Loss]          1.020284
       [Validation] Prec@1 65.833333 Max 69.166667
Confusion matrix:
[[17  0  0  0  3  0]
 [ 0 19  0  0  1  0]
 [ 0  1 18  1  0  0]
 [ 1  1  1  8  9  0]
 [ 0  0 15  0  5  0]
 [ 2  0  0  5  1 12]]
Epoch: [3]
       [Avg Loss]          0.786216
       [Training]   Prec@1 74.848485 Max 74.848485
       [Avg Loss]          1.073607
       [Validation] Prec@1 59.166667 Max 69.166667
Confusion matrix:
[[10  0  5  5  0  0]
 [ 1 14  0  4  0  1]
 [ 0  1  6 13  0  0]
 [ 1  0  0 18  0  1]
 [ 0  0  1 10  9  0]
 [ 1  1  0  4  0 14]]
Epoch: [4]
       [Avg Loss]          0.797175
       [Training]   Prec@1 72.727273 Max 74.848485
       [Avg Loss]          0.660304
       [Validation] Prec@1 76.666667 Max 76.666667
Confusion matrix:
[[18  0  0  0  2  0]
 [ 0 19  0  1  0  0]
 [ 0  2 10  5  3  0]
 [ 2  0  0  7 10  1]
 [ 0  0  0  0 20  0]
 [ 0  2  0  0  0 18]]
Epoch: [5]
       [Avg Loss]          0.719814
       [Training]   Prec@1 76.060606 Max 76.060606
       [Avg Loss]          0.734303
       [Validation] Prec@1 71.666667 Max 76.666667
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0 18  0  1  0  1]
 [ 1  1  5 13  0  0]
 [ 1  0  0 18  1  0]
 [ 0  0  2  8 10  0]
 [ 0  2  0  2  0 16]]
Epoch: [6]
       [Avg Loss]          0.588129
       [Training]   Prec@1 78.030303 Max 78.030303
       [Avg Loss]          0.683018
       [Validation] Prec@1 78.333333 Max 78.333333
Confusion matrix:
[[18  0  0  2  0  0]
 [ 0 19  0  1  0  0]
 [ 0  1  9  9  1  0]
 [ 1  0  0 15  4  0]
 [ 0  0  0  3 17  0]
 [ 0  2  0  2  0 16]]
Epoch: [7]
       [Avg Loss]          0.622785
       [Training]   Prec@1 80.454545 Max 80.454545
       [Avg Loss]          0.750936
       [Validation] Prec@1 71.666667 Max 78.333333
Confusion matrix:
[[18  0  0  0  2  0]
 [ 0 15  1  4  0  0]
 [ 0  0 12  8  0  0]
 [ 1  0  0 18  1  0]
 [ 0  0  8  3  9  0]
 [ 0  2  0  4  0 14]]
Epoch: [8]
       [Avg Loss]          0.590288
       [Training]   Prec@1 80.000000 Max 80.454545
       [Avg Loss]          0.809654
       [Validation] Prec@1 70.833333 Max 78.333333
Confusion matrix:
[[14  0  0  6  0  0]
 [ 0 19  0  1  0  0]
 [ 0  1  7 12  0  0]
 [ 1  0  0 18  0  1]
 [ 0  0  6  4 10  0]
 [ 0  2  0  1  0 17]]
Epoch: [9]
       [Avg Loss]          0.506933
       [Training]   Prec@1 82.424242 Max 82.424242
       [Avg Loss]          0.838335
       [Validation] Prec@1 72.500000 Max 78.333333
Confusion matrix:
[[18  0  0  2  0  0]
 [ 0 19  0  1  0  0]
 [ 1  2  3 13  1  0]
 [ 1  0  0 19  0  0]
 [ 0  0  3  4 13  0]
 [ 0  2  0  3  0 15]]
Epoch: [10]
       [Avg Loss]          0.454757
       [Training]   Prec@1 83.636364 Max 83.636364
       [Avg Loss]          0.587544
       [Validation] Prec@1 81.666667 Max 81.666667
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0 19  0  1  0  0]
 [ 0  2  8  7  3  0]
 [ 1  0  0 18  0  1]
 [ 0  0  0  0 20  0]
 [ 2  1  0  3  0 14]]
Epoch: [11]
       [Avg Loss]          0.418189
       [Training]   Prec@1 86.515152 Max 86.515152
       [Avg Loss]          0.609663
       [Validation] Prec@1 83.333333 Max 83.333333
Confusion matrix:
[[16  0  0  3  1  0]
 [ 0 19  0  1  0  0]
 [ 0  2 14  4  0  0]
 [ 0  0  0 19  1  0]
 [ 0  0  1  0 19  0]
 [ 0  2  0  5  0 13]]
Epoch: [12]
       [Avg Loss]          0.325914
       [Training]   Prec@1 89.393939 Max 89.393939
       [Avg Loss]          1.150358
       [Validation] Prec@1 70.833333 Max 83.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 19  0  1  0  0]
 [ 0  3  5 12  0  0]
 [ 2  0  0 17  0  1]
 [ 0  0  1 10  9  0]
 [ 0  2  0  3  0 15]]
Epoch: [13]
       [Avg Loss]          0.404646
       [Training]   Prec@1 86.363636 Max 89.393939
       [Avg Loss]          0.559527
       [Validation] Prec@1 83.333333 Max 83.333333
Confusion matrix:
[[17  0  0  2  1  0]
 [ 0 16  0  4  0  0]
 [ 0  0 14  5  1  0]
 [ 1  0  1 18  0  0]
 [ 0  0  1  0 19  0]
 [ 0  2  0  2  0 16]]
Epoch: [14]
       [Avg Loss]          0.328260
       [Training]   Prec@1 89.393939 Max 89.393939
       [Avg Loss]          0.617634
       [Validation] Prec@1 79.166667 Max 83.333333
Confusion matrix:
[[17  0  0  3  0  0]
 [ 0 17  0  1  0  2]
 [ 0  1 12  7  0  0]
 [ 0  0  2 16  2  0]
 [ 0  0  0  1 19  0]
 [ 2  2  0  2  0 14]]
Fold "3" complete, final accuracy: 83.33333333333333
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.378555
       [Training]   Prec@1 49.253731 Max 49.253731
       [Avg Loss]          1.489067
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[13  2  1  0  0  4]
 [ 5  6  3  0  6  0]
 [ 8  0  5  0  7  0]
 [ 0  6  0 13  1  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [1]
       [Avg Loss]          0.974095
       [Training]   Prec@1 66.268657 Max 66.268657
       [Avg Loss]          1.748024
       [Validation] Prec@1 44.545455 Max 60.000000
Confusion matrix:
[[11  5  3  0  1  0]
 [ 0  9  1  0 10  0]
 [ 7  0 12  0  1  0]
 [ 0  8  2  1  9  0]
 [ 0  0  0  0 10  0]
 [11  3  0  0  0  6]]
Epoch: [2]
       [Avg Loss]          1.044314
       [Training]   Prec@1 61.194030 Max 66.268657
       [Avg Loss]          1.341845
       [Validation] Prec@1 54.545455 Max 60.000000
Confusion matrix:
[[15  2  2  0  0  1]
 [ 0  6 14  0  0  0]
 [ 8  0 12  0  0  0]
 [ 0  5  7  8  0  0]
 [ 0  0 10  0  0  0]
 [ 0  0  0  1  0 19]]
Epoch: [3]
       [Avg Loss]          0.878437
       [Training]   Prec@1 69.701493 Max 69.701493
       [Avg Loss]          1.780398
       [Validation] Prec@1 57.272727 Max 60.000000
Confusion matrix:
[[15  1  1  3  0  0]
 [ 8  8  1  0  3  0]
 [10  0  5  0  5  0]
 [ 0  6  1 10  3  0]
 [ 0  0  0  0 10  0]
 [ 0  4  0  1  0 15]]
Epoch: [4]
       [Avg Loss]          0.740792
       [Training]   Prec@1 74.029851 Max 74.029851
       [Avg Loss]          1.473295
       [Validation] Prec@1 61.818182 Max 61.818182
Confusion matrix:
[[14  4  2  0  0  0]
 [ 1  7  2  1  9  0]
 [ 8  0  8  0  4  0]
 [ 0  7  0 13  0  0]
 [ 0  0  0  0 10  0]
 [ 3  0  0  1  0 16]]
Epoch: [5]
       [Avg Loss]          0.635510
       [Training]   Prec@1 77.611940 Max 77.611940
       [Avg Loss]          1.596200
       [Validation] Prec@1 50.909091 Max 61.818182
Confusion matrix:
[[14  4  0  2  0  0]
 [ 7  6  1  3  3  0]
 [10  0  6  0  4  0]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 9  2  0  3  0  6]]
Epoch: [6]
       [Avg Loss]          0.567796
       [Training]   Prec@1 82.089552 Max 82.089552
       [Avg Loss]          1.543621
       [Validation] Prec@1 59.090909 Max 61.818182
Confusion matrix:
[[15  1  1  1  1  1]
 [ 0  3  2  7  8  0]
 [ 8  0  4  1  7  0]
 [ 0  5  1 13  1  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [7]
       [Avg Loss]          0.539701
       [Training]   Prec@1 82.238806 Max 82.238806
       [Avg Loss]          1.836201
       [Validation] Prec@1 50.909091 Max 61.818182
Confusion matrix:
[[13  3  2  2  0  0]
 [ 7  3  0  6  3  1]
 [ 9  0  0  0 10  1]
 [ 0  1  0 18  1  0]
 [ 0  0  0  0 10  0]
 [ 4  3  0  1  0 12]]
Epoch: [8]
       [Avg Loss]          0.579351
       [Training]   Prec@1 79.402985 Max 82.238806
       [Avg Loss]          1.890202
       [Validation] Prec@1 43.636364 Max 61.818182
Confusion matrix:
[[15  1  1  0  1  2]
 [ 8  3  2  5  1  1]
 [ 9  0  0  1 10  0]
 [ 0  5  1 12  2  0]
 [ 0  0  0  0 10  0]
 [11  0  0  1  0  8]]
Epoch: [9]
       [Avg Loss]          0.515733
       [Training]   Prec@1 82.686567 Max 82.686567
       [Avg Loss]          1.756245
       [Validation] Prec@1 50.909091 Max 61.818182
Confusion matrix:
[[14  4  1  0  1  0]
 [ 7  1  1  7  4  0]
 [ 8  0  2  1  8  1]
 [ 0  0  0 11  9  0]
 [ 0  0  0  0 10  0]
 [ 0  2  0  0  0 18]]
Epoch: [10]
       [Avg Loss]          0.379931
       [Training]   Prec@1 86.417910 Max 86.417910
       [Avg Loss]          1.723351
       [Validation] Prec@1 54.545455 Max 61.818182
Confusion matrix:
[[12  4  3  0  1  0]
 [ 0  2  0  7 10  1]
 [ 8  0  4  0  7  1]
 [ 0  4  0 15  1  0]
 [ 0  0  0  0 10  0]
 [ 3  0  0  0  0 17]]
Epoch: [11]
       [Avg Loss]          0.408584
       [Training]   Prec@1 87.164179 Max 87.164179
       [Avg Loss]          1.686935
       [Validation] Prec@1 55.454545 Max 61.818182
Confusion matrix:
[[15  0  1  1  2  1]
 [ 1  3  0  5 11  0]
 [ 7  0  0  1 11  1]
 [ 0  5  0 14  1  0]
 [ 0  0  0  0 10  0]
 [ 1  0  0  0  0 19]]
Epoch: [12]
       [Avg Loss]          0.321980
       [Training]   Prec@1 87.910448 Max 87.910448
       [Avg Loss]          1.613227
       [Validation] Prec@1 63.636364 Max 63.636364
Confusion matrix:
[[12  4  3  0  1  0]
 [ 1  3  1  8  7  0]
 [ 8  0  5  1  5  1]
 [ 0  0  0 20  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [13]
       [Avg Loss]          0.299186
       [Training]   Prec@1 90.298507 Max 90.298507
       [Avg Loss]          2.163195
       [Validation] Prec@1 46.363636 Max 63.636364
Confusion matrix:
[[15  1  3  1  0  0]
 [ 8  4  0  7  0  1]
 [ 8  0  2  6  3  1]
 [ 0  4  0 16  0  0]
 [ 0  0  0  3  7  0]
 [ 9  3  0  1  0  7]]
Epoch: [14]
       [Avg Loss]          0.322195
       [Training]   Prec@1 90.000000 Max 90.298507
       [Avg Loss]          2.010207
       [Validation] Prec@1 51.818182 Max 63.636364
Confusion matrix:
[[15  1  2  1  1  0]
 [ 1  1  0  7 11  0]
 [ 8  0  3  0  8  1]
 [ 0  2  0 10  8  0]
 [ 0  0  0  0 10  0]
 [ 1  0  0  1  0 18]]
Fold "4" complete, final accuracy: 63.63636363636363

-----------------------------------------------------------------------
Training for stage 2 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=8)")
Average accuracy is: 74.1146601146601


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 3-----
Evaluated preprocessing: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=8)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.510529
       [Training]   Prec@1 38.666667 Max 38.666667
       [Avg Loss]          1.729081
       [Validation] Prec@1 32.222222 Max 32.222222
Confusion matrix:
[[29  0  0  3  1  7]
 [15  0  0 15  0  0]
 [ 3  0  3 24  0  0]
 [17  0  0 12  1  0]
 [14  0  0 10  6  0]
 [ 9  0  0  3  0  8]]
Epoch: [1]
       [Avg Loss]          1.064023
       [Training]   Prec@1 59.166667 Max 59.166667
       [Avg Loss]          1.425884
       [Validation] Prec@1 48.888889 Max 48.888889
Confusion matrix:
[[31  0  0  0  6  3]
 [ 0 12  0  9  9  0]
 [ 0  0  7  0 23  0]
 [ 1  1  2  1 25  0]
 [ 1  0  0  0 29  0]
 [10  0  0  2  0  8]]
Epoch: [2]
       [Avg Loss]          0.895195
       [Training]   Prec@1 69.166667 Max 69.166667
       [Avg Loss]          1.470664
       [Validation] Prec@1 44.444444 Max 48.888889
Confusion matrix:
[[ 9  0  0 11  0 20]
 [ 0 15  0  8  0  7]
 [ 0  0 10 11  9  0]
 [ 1  1  5 10 13  0]
 [ 0  5  0  9 16  0]
 [ 0  0  0  0  0 20]]
Epoch: [3]
       [Avg Loss]          0.924531
       [Training]   Prec@1 66.333333 Max 69.166667
       [Avg Loss]          1.744601
       [Validation] Prec@1 50.000000 Max 50.000000
Confusion matrix:
[[11  0 11  3  5 10]
 [ 0 16  8  2  4  0]
 [ 0  0 27  0  3  0]
 [ 0  1 17  0 12  0]
 [ 0  0  9  0 21  0]
 [ 0  4  0  1  0 15]]
Epoch: [4]
       [Avg Loss]          0.815887
       [Training]   Prec@1 71.333333 Max 71.333333
       [Avg Loss]          1.545366
       [Validation] Prec@1 56.111111 Max 56.111111
Confusion matrix:
[[15  1  3  6  6  9]
 [ 0 28  0  2  0  0]
 [ 0  1 29  0  0  0]
 [ 1  2 15  0 12  0]
 [ 0  3  8  1 18  0]
 [ 0  7  0  2  0 11]]
Epoch: [5]
       [Avg Loss]          0.821033
       [Training]   Prec@1 69.500000 Max 71.333333
       [Avg Loss]          1.869101
       [Validation] Prec@1 48.888889 Max 56.111111
Confusion matrix:
[[29  0  1  0  0 10]
 [11 12  0  0  0  7]
 [ 1  9 19  0  1  0]
 [15  3 11  0  1  0]
 [15  0  6  0  9  0]
 [ 1  0  0  0  0 19]]
Epoch: [6]
       [Avg Loss]          0.772758
       [Training]   Prec@1 71.666667 Max 71.666667
       [Avg Loss]          2.595779
       [Validation] Prec@1 33.333333 Max 56.111111
Confusion matrix:
[[ 0  1 18 12  9  0]
 [ 0 22  1  6  1  0]
 [ 0  1 28  1  0  0]
 [ 0  2 22  0  6  0]
 [ 0  2 17  1 10  0]
 [ 0  8  2 10  0  0]]
Epoch: [7]
       [Avg Loss]          0.800719
       [Training]   Prec@1 71.333333 Max 71.666667
       [Avg Loss]          2.827889
       [Validation] Prec@1 31.111111 Max 56.111111
Confusion matrix:
[[ 9  0  2  4 18  7]
 [ 0  1  6  3 20  0]
 [ 0  0  9  0 21  0]
 [ 0  0  4  0 26  0]
 [ 0  0  3  0 27  0]
 [ 3  0  0  7  0 10]]
Epoch: [8]
       [Avg Loss]          0.706131
       [Training]   Prec@1 74.000000 Max 74.000000
       [Avg Loss]          1.869887
       [Validation] Prec@1 49.444444 Max 56.111111
Confusion matrix:
[[15  0  8  7  0 10]
 [ 0 25  1  3  0  1]
 [ 1  0 28  1  0  0]
 [ 1  2 21  2  4  0]
 [ 0  1 15  8  6  0]
 [ 4  0  1  2  0 13]]
Epoch: [9]
       [Avg Loss]          0.673636
       [Training]   Prec@1 74.333333 Max 74.333333
       [Avg Loss]          1.766985
       [Validation] Prec@1 60.555556 Max 60.555556
Confusion matrix:
[[22  0  0  6  2 10]
 [ 0 26  0  1  1  2]
 [ 0  5 14  0 11  0]
 [ 1  4  0  0 25  0]
 [ 0  3  0  0 27  0]
 [ 0  0  0  0  0 20]]
Epoch: [10]
       [Avg Loss]          0.597020
       [Training]   Prec@1 80.500000 Max 80.500000
       [Avg Loss]          1.522330
       [Validation] Prec@1 55.555556 Max 60.555556
Confusion matrix:
[[19  2  7  0  3  9]
 [ 0 26  0  0  4  0]
 [ 0  1 26  1  2  0]
 [ 0  3 16  0 11  0]
 [ 0  5  4  0 21  0]
 [ 6  3  0  3  0  8]]
Epoch: [11]
       [Avg Loss]          0.556388
       [Training]   Prec@1 80.666667 Max 80.666667
       [Avg Loss]          2.037503
       [Validation] Prec@1 44.444444 Max 60.555556
Confusion matrix:
[[23  0  0  6  1 10]
 [ 5 14  0  5  6  0]
 [ 5  1  8  3 13  0]
 [ 3  1  0  0 26  0]
 [ 8  0  0  0 22  0]
 [ 5  0  0  2  0 13]]
Epoch: [12]
       [Avg Loss]          0.526356
       [Training]   Prec@1 79.500000 Max 80.666667
       [Avg Loss]          1.992062
       [Validation] Prec@1 55.555556 Max 60.555556
Confusion matrix:
[[14  0 10  1  5 10]
 [ 0 16  0 12  2  0]
 [ 0  0 28  0  2  0]
 [ 0  0 16  2 12  0]
 [ 0  2  6  0 22  0]
 [ 0  0  0  2  0 18]]
Epoch: [13]
       [Avg Loss]          0.522821
       [Training]   Prec@1 81.833333 Max 81.833333
       [Avg Loss]          1.791723
       [Validation] Prec@1 57.222222 Max 60.555556
Confusion matrix:
[[16  2  7  4  2  9]
 [ 0 26  0  2  2  0]
 [ 0  1 27  0  2  0]
 [ 1  4 13  1 11  0]
 [ 0  7  4  0 19  0]
 [ 1  1  0  4  0 14]]
Epoch: [14]
       [Avg Loss]          0.505099
       [Training]   Prec@1 82.833333 Max 82.833333
       [Avg Loss]          1.918251
       [Validation] Prec@1 56.111111 Max 60.555556
Confusion matrix:
[[19  8  3  1  0  9]
 [ 0 27  0  0  2  1]
 [ 0  3 20  2  5  0]
 [ 1  3  1  0 25  0]
 [ 4  5  0  0 21  0]
 [ 2  3  0  1  0 14]]
Fold "0" complete, final accuracy: 60.55555555555556
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.578348
       [Training]   Prec@1 39.831933 Max 39.831933
       [Avg Loss]          1.725379
       [Validation] Prec@1 39.459459 Max 39.459459
Confusion matrix:
[[ 0 22  8  0  0  0]
 [ 0 33  2  0  0  0]
 [ 0 12 17  0  1  0]
 [ 0 10  5  4 11  0]
 [ 0  5  6  0 19  0]
 [ 0 27  0  3  0  0]]
Epoch: [1]
       [Avg Loss]          1.241647
       [Training]   Prec@1 51.932773 Max 51.932773
       [Avg Loss]          1.582834
       [Validation] Prec@1 42.162162 Max 42.162162
Confusion matrix:
[[20  0  0  0  0 10]
 [ 3 27  0  1  0  4]
 [20 10  0  0  0  0]
 [21  0  0  2  0  7]
 [24  0  0  2  0  4]
 [ 1  0  0  0  0 29]]
Epoch: [2]
       [Avg Loss]          1.134340
       [Training]   Prec@1 58.823529 Max 58.823529
       [Avg Loss]          1.369226
       [Validation] Prec@1 47.027027 Max 47.027027
Confusion matrix:
[[29  0  0  0  0  1]
 [16  9 10  0  0  0]
 [ 7  2 20  0  1  0]
 [29  0  0  1  0  0]
 [17  0  2  0 11  0]
 [13  0  0  0  0 17]]
Epoch: [3]
       [Avg Loss]          1.101585
       [Training]   Prec@1 60.504202 Max 60.504202
       [Avg Loss]          1.259308
       [Validation] Prec@1 54.594595 Max 54.594595
Confusion matrix:
[[16 11  3  0  0  0]
 [ 0 26  9  0  0  0]
 [ 0  2 28  0  0  0]
 [11  2 10  6  1  0]
 [ 1  0 19  0 10  0]
 [ 1  7  2  5  0 15]]
Epoch: [4]
       [Avg Loss]          1.014380
       [Training]   Prec@1 63.025210 Max 63.025210
       [Avg Loss]          1.167219
       [Validation] Prec@1 52.972973 Max 54.594595
Confusion matrix:
[[19  0  1  5  0  5]
 [ 5 11 16  1  0  2]
 [ 0  1 24  3  2  0]
 [ 0  0  6 16  8  0]
 [ 0  0  5 12 13  0]
 [ 1  0  1 13  0 15]]
Epoch: [5]
       [Avg Loss]          0.918757
       [Training]   Prec@1 69.243697 Max 69.243697
       [Avg Loss]          1.184537
       [Validation] Prec@1 58.378378 Max 58.378378
Confusion matrix:
[[24  2  2  0  0  2]
 [ 0 26  7  2  0  0]
 [ 0  2 27  0  1  0]
 [13  0  7  6  4  0]
 [ 7  0  5  3 15  0]
 [16  1  2  1  0 10]]
Epoch: [6]
       [Avg Loss]          0.855685
       [Training]   Prec@1 70.252101 Max 70.252101
       [Avg Loss]          1.091639
       [Validation] Prec@1 66.486486 Max 66.486486
Confusion matrix:
[[14 10  5  1  0  0]
 [ 0 32  2  1  0  0]
 [ 0  3 25  2  0  0]
 [ 3  1  6 17  0  3]
 [ 0  1  7  9 13  0]
 [ 0  7  1  0  0 22]]
Epoch: [7]
       [Avg Loss]          0.891406
       [Training]   Prec@1 67.394958 Max 70.252101
       [Avg Loss]          1.225262
       [Validation] Prec@1 54.594595 Max 66.486486
Confusion matrix:
[[ 6  0  1  7  0 16]
 [ 0 23  3  2  0  7]
 [ 0  3 19  8  0  0]
 [ 0  0  1 25  0  4]
 [ 0  0  2 23  5  0]
 [ 0  0  0  7  0 23]]
Epoch: [8]
       [Avg Loss]          0.792132
       [Training]   Prec@1 72.941176 Max 72.941176
       [Avg Loss]          0.891987
       [Validation] Prec@1 65.945946 Max 66.486486
Confusion matrix:
[[20  6  3  0  0  1]
 [ 0 32  3  0  0  0]
 [ 0  4 24  0  2  0]
 [ 2  1  8 10  8  1]
 [ 0  0  5  6 19  0]
 [ 5  4  0  4  0 17]]
Epoch: [9]
       [Avg Loss]          0.775100
       [Training]   Prec@1 71.260504 Max 72.941176
       [Avg Loss]          1.416631
       [Validation] Prec@1 57.837838 Max 66.486486
Confusion matrix:
[[17  0  0  1  0 12]
 [ 0 25  0  0  0 10]
 [ 2 10 16  1  0  1]
 [ 9  1  1 12  0  7]
 [ 9  7  0  4  8  2]
 [ 1  0  0  0  0 29]]
Epoch: [10]
       [Avg Loss]          0.750698
       [Training]   Prec@1 72.436975 Max 72.941176
       [Avg Loss]          1.027482
       [Validation] Prec@1 60.000000 Max 66.486486
Confusion matrix:
[[22  0  7  0  1  0]
 [ 1 16 18  0  0  0]
 [ 0  2 26  0  2  0]
 [ 2  0 13  9  6  0]
 [ 4  0  8  3 15  0]
 [ 5  1  1  0  0 23]]
Epoch: [11]
       [Avg Loss]          0.667838
       [Training]   Prec@1 76.806723 Max 76.806723
       [Avg Loss]          1.066599
       [Validation] Prec@1 65.405405 Max 66.486486
Confusion matrix:
[[28  0  2  0  0  0]
 [ 4 26  3  2  0  0]
 [ 3  2 24  0  1  0]
 [15  0  2 13  0  0]
 [ 9  0  2  9 10  0]
 [ 6  1  0  3  0 20]]
Epoch: [12]
       [Avg Loss]          0.701164
       [Training]   Prec@1 75.630252 Max 76.806723
       [Avg Loss]          1.135664
       [Validation] Prec@1 65.405405 Max 66.486486
Confusion matrix:
[[16  7  3  1  0  3]
 [ 0 33  2  0  0  0]
 [ 1  6 21  2  0  0]
 [ 3  1  6 15  0  5]
 [ 1  6  2 11 10  0]
 [ 0  4  0  0  0 26]]
Epoch: [13]
       [Avg Loss]          0.593825
       [Training]   Prec@1 77.815126 Max 77.815126
       [Avg Loss]          0.926345
       [Validation] Prec@1 67.567568 Max 67.567568
Confusion matrix:
[[20  0  3  0  0  7]
 [ 3 29  1  0  0  2]
 [ 0  6 24  0  0  0]
 [ 1  1  8 15  1  4]
 [ 1  5  6  8 10  0]
 [ 0  3  0  0  0 27]]
Epoch: [14]
       [Avg Loss]          0.593113
       [Training]   Prec@1 80.168067 Max 80.168067
       [Avg Loss]          0.882245
       [Validation] Prec@1 70.270270 Max 70.270270
Confusion matrix:
[[23  0  2  0  0  5]
 [ 2 28  4  0  0  1]
 [ 1  2 27  0  0  0]
 [ 5  0  5 18  0  2]
 [ 7  5  4  4 10  0]
 [ 0  3  0  3  0 24]]
Fold "1" complete, final accuracy: 70.27027027027027
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.614145
       [Training]   Prec@1 36.470588 Max 36.470588
       [Avg Loss]          1.756369
       [Validation] Prec@1 16.216216 Max 16.216216
Confusion matrix:
[[30  0  0  0  0  0]
 [35  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.282511
       [Training]   Prec@1 51.092437 Max 51.092437
       [Avg Loss]          1.576562
       [Validation] Prec@1 28.648649 Max 28.648649
Confusion matrix:
[[30  0  0  0  0  0]
 [35  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [ 7  0  0  0  0 23]]
Epoch: [2]
       [Avg Loss]          1.052348
       [Training]   Prec@1 62.521008 Max 62.521008
       [Avg Loss]          1.795238
       [Validation] Prec@1 26.486486 Max 28.648649
Confusion matrix:
[[29  0  0  0  1  0]
 [35  0  0  0  0  0]
 [30  0  0  0  0  0]
 [25  0  0  4  1  0]
 [14  0  0  0 16  0]
 [30  0  0  0  0  0]]
Epoch: [3]
       [Avg Loss]          0.962712
       [Training]   Prec@1 64.369748 Max 64.369748
       [Avg Loss]          0.947960
       [Validation] Prec@1 70.810811 Max 70.810811
Confusion matrix:
[[18  7  3  0  0  2]
 [ 1 27  3  0  0  4]
 [ 1  0 29  0  0  0]
 [ 2  7  8  8  2  3]
 [ 4  0  6  0 20  0]
 [ 0  1  0  0  0 29]]
Epoch: [4]
       [Avg Loss]          0.907218
       [Training]   Prec@1 66.890756 Max 66.890756
       [Avg Loss]          1.068689
       [Validation] Prec@1 67.567568 Max 70.810811
Confusion matrix:
[[19 11  0  0  0  0]
 [ 2 30  1  0  0  2]
 [ 2  1 21  0  6  0]
 [ 0 11  2 11  6  0]
 [ 0  4  0  0 26  0]
 [ 5  7  0  0  0 18]]
Epoch: [5]
       [Avg Loss]          0.800234
       [Training]   Prec@1 70.588235 Max 70.588235
       [Avg Loss]          1.166166
       [Validation] Prec@1 57.837838 Max 70.810811
Confusion matrix:
[[18  4  0  0  0  8]
 [ 2 24  1  0  0  8]
 [ 5  2  3 17  0  3]
 [ 0  6  1 12  0 11]
 [ 9  1  0  0 20  0]
 [ 0  0  0  0  0 30]]
Epoch: [6]
       [Avg Loss]          0.805394
       [Training]   Prec@1 71.596639 Max 71.596639
       [Avg Loss]          1.000929
       [Validation] Prec@1 71.891892 Max 71.891892
Confusion matrix:
[[16  6  3  2  3  0]
 [ 1 28  1  3  1  1]
 [ 0  0 13  3 14  0]
 [ 2  0  0 22  4  2]
 [ 0  0  0  0 30  0]
 [ 0  6  0  0  0 24]]
Epoch: [7]
       [Avg Loss]          0.822064
       [Training]   Prec@1 71.260504 Max 71.596639
       [Avg Loss]          1.534136
       [Validation] Prec@1 55.675676 Max 71.891892
Confusion matrix:
[[12  1 10  4  3  0]
 [ 0  9 23  2  0  1]
 [ 0  0 22  1  7  0]
 [ 0  0 12  4 14  0]
 [ 0  0  0  0 30  0]
 [ 1  3  0  0  0 26]]
Epoch: [8]
       [Avg Loss]          0.768279
       [Training]   Prec@1 73.277311 Max 73.277311
       [Avg Loss]          1.586751
       [Validation] Prec@1 54.054054 Max 71.891892
Confusion matrix:
[[24  4  0  0  0  2]
 [ 7 24  1  1  0  2]
 [16  0  8  4  1  1]
 [ 7  3  1 11  0  8]
 [13  0  0  0 17  0]
 [14  0  0  0  0 16]]
Epoch: [9]
       [Avg Loss]          0.794680
       [Training]   Prec@1 70.924370 Max 73.277311
       [Avg Loss]          1.098530
       [Validation] Prec@1 67.027027 Max 71.891892
Confusion matrix:
[[15  9  0  0  0  6]
 [ 0 27  1  0  0  7]
 [ 0  0 19  6  5  0]
 [ 0 11  0  5 14  0]
 [ 0  1  0  0 29  0]
 [ 0  1  0  0  0 29]]
Epoch: [10]
       [Avg Loss]          0.723359
       [Training]   Prec@1 72.436975 Max 73.277311
       [Avg Loss]          0.950374
       [Validation] Prec@1 68.108108 Max 71.891892
Confusion matrix:
[[15 14  0  0  0  1]
 [ 1 32  1  0  0  1]
 [ 0  0 25  5  0  0]
 [ 0  9  4 13  0  4]
 [ 0  2  3  8 17  0]
 [ 3  3  0  0  0 24]]
Epoch: [11]
       [Avg Loss]          0.705318
       [Training]   Prec@1 75.126050 Max 75.126050
       [Avg Loss]          1.068906
       [Validation] Prec@1 59.459459 Max 71.891892
Confusion matrix:
[[17  4  7  2  0  0]
 [ 0 10 14  8  0  3]
 [ 0  0 23  7  0  0]
 [ 2  0  6 18  2  2]
 [ 4  0  0  4 22  0]
 [ 9  1  0  0  0 20]]
Epoch: [12]
       [Avg Loss]          0.650404
       [Training]   Prec@1 75.630252 Max 75.630252
       [Avg Loss]          1.367207
       [Validation] Prec@1 54.054054 Max 71.891892
Confusion matrix:
[[ 7  1  5 10  7  0]
 [ 2 10 14  6  2  1]
 [ 0  0 20  0 10  0]
 [ 0  0  8 14  8  0]
 [ 0  0  0  0 30  0]
 [ 9  2  0  0  0 19]]
Epoch: [13]
       [Avg Loss]          0.655045
       [Training]   Prec@1 75.462185 Max 75.630252
       [Avg Loss]          0.940631
       [Validation] Prec@1 70.810811 Max 71.891892
Confusion matrix:
[[22  7  0  0  0  1]
 [ 2 30  1  0  0  2]
 [ 0  0  8 12  9  1]
 [ 0  8  0 17  4  1]
 [ 3  0  0  1 26  0]
 [ 0  2  0  0  0 28]]
Epoch: [14]
       [Avg Loss]          0.596065
       [Training]   Prec@1 77.310924 Max 77.310924
       [Avg Loss]          1.259825
       [Validation] Prec@1 60.000000 Max 71.891892
Confusion matrix:
[[16  4  0  0  0 10]
 [ 2 13  4  3  0 13]
 [ 0  0 13 16  0  1]
 [ 0  0  1 19  1  9]
 [ 7  0  0  3 20  0]
 [ 0  0  0  0  0 30]]
Fold "2" complete, final accuracy: 71.89189189189189
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.634512
       [Training]   Prec@1 36.666667 Max 36.666667
       [Avg Loss]          1.686952
       [Validation] Prec@1 33.333333 Max 33.333333
Confusion matrix:
[[ 2  0  0 18  0  0]
 [ 6  6  0  8  0  0]
 [ 0  0  0 20  0  0]
 [ 0  0  0 20  0  0]
 [ 0  0  0 20  0  0]
 [ 2  1  0  5  0 12]]
Epoch: [1]
       [Avg Loss]          1.282673
       [Training]   Prec@1 50.606061 Max 50.606061
       [Avg Loss]          1.362206
       [Validation] Prec@1 61.666667 Max 61.666667
Confusion matrix:
[[19  1  0  0  0  0]
 [ 0 18  2  0  0  0]
 [ 0  3 17  0  0  0]
 [10  3  3  3  0  1]
 [ 0 10 10  0  0  0]
 [ 0  3  0  0  0 17]]
Epoch: [2]
       [Avg Loss]          1.089953
       [Training]   Prec@1 58.333333 Max 58.333333
       [Avg Loss]          1.652753
       [Validation] Prec@1 28.333333 Max 61.666667
Confusion matrix:
[[ 0  0  0  0 20  0]
 [ 0 14  0  3  3  0]
 [ 0  0  2  1 17  0]
 [ 0  0  0  2 18  0]
 [ 0  0  4  0 16  0]
 [ 0  5  0 13  2  0]]
Epoch: [3]
       [Avg Loss]          1.045554
       [Training]   Prec@1 62.424242 Max 62.424242
       [Avg Loss]          0.977627
       [Validation] Prec@1 68.333333 Max 68.333333
Confusion matrix:
[[15  1  4  0  0  0]
 [ 0 15  0  4  0  1]
 [ 0  0 20  0  0  0]
 [ 4  0  0 14  1  1]
 [ 0  0 17  0  3  0]
 [ 1  3  0  1  0 15]]
Epoch: [4]
       [Avg Loss]          1.021781
       [Training]   Prec@1 62.878788 Max 62.878788
       [Avg Loss]          0.802835
       [Validation] Prec@1 73.333333 Max 73.333333
Confusion matrix:
[[ 9  0  0 11  0  0]
 [ 0 15  0  5  0  0]
 [ 0  0 15  5  0  0]
 [ 0  0  1 19  0  0]
 [ 0  0  1  1 18  0]
 [ 1  1  0  6  0 12]]
Epoch: [5]
       [Avg Loss]          0.918340
       [Training]   Prec@1 66.969697 Max 66.969697
       [Avg Loss]          1.278543
       [Validation] Prec@1 57.500000 Max 73.333333
Confusion matrix:
[[19  0  0  0  1  0]
 [ 4 11  0  3  2  0]
 [ 0  0  6  3 11  0]
 [ 6  0  0 11  3  0]
 [ 0  0  0  0 20  0]
 [16  0  0  2  0  2]]
Epoch: [6]
       [Avg Loss]          0.870387
       [Training]   Prec@1 67.727273 Max 67.727273
       [Avg Loss]          1.202831
       [Validation] Prec@1 55.000000 Max 73.333333
Confusion matrix:
[[ 9  0  0 10  0  1]
 [ 0 15  0  4  0  1]
 [ 0  3  7 10  0  0]
 [ 0  0  0 15  0  5]
 [ 0  0  0 17  3  0]
 [ 2  0  0  1  0 17]]
Epoch: [7]
       [Avg Loss]          0.892831
       [Training]   Prec@1 67.727273 Max 67.727273
       [Avg Loss]          1.154945
       [Validation] Prec@1 53.333333 Max 73.333333
Confusion matrix:
[[ 7  0  0  5  8  0]
 [ 0 16  0  4  0  0]
 [ 0  4  3 13  0  0]
 [ 1  0  0 16  2  1]
 [ 0  1  6  6  7  0]
 [ 1  0  0  4  0 15]]
Epoch: [8]
       [Avg Loss]          0.818293
       [Training]   Prec@1 71.515152 Max 71.515152
       [Avg Loss]          1.272586
       [Validation] Prec@1 54.166667 Max 73.333333
Confusion matrix:
[[ 6  0  0 14  0  0]
 [ 0 14  0  5  0  1]
 [ 0  1  5 14  0  0]
 [ 0  0  0 19  1  0]
 [ 0  0  0 11  9  0]
 [ 2  0  0  6  0 12]]
Epoch: [9]
       [Avg Loss]          0.771605
       [Training]   Prec@1 72.121212 Max 72.121212
       [Avg Loss]          0.708666
       [Validation] Prec@1 71.666667 Max 73.333333
Confusion matrix:
[[16  0  0  4  0  0]
 [ 1 16  0  2  0  1]
 [ 0  2 13  5  0  0]
 [ 3  0  0 15  1  1]
 [ 0  0  5  2 13  0]
 [ 6  0  0  1  0 13]]
Epoch: [10]
       [Avg Loss]          0.736136
       [Training]   Prec@1 73.181818 Max 73.181818
       [Avg Loss]          1.357784
       [Validation] Prec@1 47.500000 Max 73.333333
Confusion matrix:
[[ 2  0  0  2  0 16]
 [ 0 18  0  2  0  0]
 [ 0  0  5 15  0  0]
 [ 0  0  0 13  0  7]
 [ 0  6  0 10  4  0]
 [ 0  4  0  1  0 15]]
Epoch: [11]
       [Avg Loss]          0.700020
       [Training]   Prec@1 75.606061 Max 75.606061
       [Avg Loss]          1.504358
       [Validation] Prec@1 50.000000 Max 73.333333
Confusion matrix:
[[15  0  0  1  4  0]
 [13  3  0  1  2  1]
 [ 2  0  9  4  5  0]
 [ 4  0  0 12  4  0]
 [ 0  0  0  0 20  0]
 [12  0  0  7  0  1]]
Epoch: [12]
       [Avg Loss]          0.637029
       [Training]   Prec@1 76.818182 Max 76.818182
       [Avg Loss]          1.316116
       [Validation] Prec@1 66.666667 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 1 19  0  0  0  0]
 [ 0  5  6  9  0  0]
 [ 2  1  0 14  1  2]
 [ 0 10  0  3  7  0]
 [ 1  4  0  1  0 14]]
Epoch: [13]
       [Avg Loss]          0.639591
       [Training]   Prec@1 75.757576 Max 76.818182
       [Avg Loss]          1.343103
       [Validation] Prec@1 58.333333 Max 73.333333
Confusion matrix:
[[ 4  0  0  2 14  0]
 [ 0 18  0  2  0  0]
 [ 0  0 12  8  0  0]
 [ 0  0  0 16  4  0]
 [ 0  0  0  3 17  0]
 [ 9  2  0  6  0  3]]
Epoch: [14]
       [Avg Loss]          0.512826
       [Training]   Prec@1 80.909091 Max 80.909091
       [Avg Loss]          0.607404
       [Validation] Prec@1 79.166667 Max 79.166667
Confusion matrix:
[[14  1  0  5  0  0]
 [ 1 18  0  1  0  0]
 [ 0  1 16  3  0  0]
 [ 2  0  2 14  1  1]
 [ 0  0  0  1 19  0]
 [ 1  4  0  1  0 14]]
Fold "3" complete, final accuracy: 79.16666666666667
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.573521
       [Training]   Prec@1 37.014925 Max 37.014925
       [Avg Loss]          1.741702
       [Validation] Prec@1 22.727273 Max 22.727273
Confusion matrix:
[[ 0  0  5  5 10  0]
 [ 0  0 13  0  7  0]
 [ 0  0 15  1  4  0]
 [ 0  0  9  0 11  0]
 [ 0  0  0  0 10  0]
 [10  0  1  9  0  0]]
Epoch: [1]
       [Avg Loss]          1.176646
       [Training]   Prec@1 54.179104 Max 54.179104
       [Avg Loss]          1.720043
       [Validation] Prec@1 35.454545 Max 35.454545
Confusion matrix:
[[18  0  1  0  1  0]
 [ 6  1 10  0  3  0]
 [ 8  0 12  0  0  0]
 [ 0  5 10  2  3  0]
 [ 0  0  4  0  6  0]
 [19  0  1  0  0  0]]
Epoch: [2]
       [Avg Loss]          1.050139
       [Training]   Prec@1 60.895522 Max 60.895522
       [Avg Loss]          1.306069
       [Validation] Prec@1 57.272727 Max 57.272727
Confusion matrix:
[[13  5  2  0  0  0]
 [ 9  7  4  0  0  0]
 [ 7  0 12  0  0  1]
 [ 0  8  8  3  0  1]
 [ 0  0  0  0 10  0]
 [ 0  2  0  0  0 18]]
Epoch: [3]
       [Avg Loss]          0.878215
       [Training]   Prec@1 69.104478 Max 69.104478
       [Avg Loss]          1.562329
       [Validation] Prec@1 48.181818 Max 57.272727
Confusion matrix:
[[ 9  6  1  0  4  0]
 [ 5  9  2  0  4  0]
 [ 7  0 12  0  0  1]
 [ 0 12  6  2  0  0]
 [ 0  0  3  0  7  0]
 [ 0  6  0  0  0 14]]
Epoch: [4]
       [Avg Loss]          0.778813
       [Training]   Prec@1 72.388060 Max 72.388060
       [Avg Loss]          1.876748
       [Validation] Prec@1 61.818182 Max 61.818182
Confusion matrix:
[[19  1  0  0  0  0]
 [10  6  0  2  2  0]
 [ 9  0  5  0  5  1]
 [ 0  7  1 12  0  0]
 [ 4  0  0  0  6  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.744093
       [Training]   Prec@1 74.328358 Max 74.328358
       [Avg Loss]          1.863845
       [Validation] Prec@1 51.818182 Max 61.818182
Confusion matrix:
[[ 5  4  4  0  7  0]
 [ 1  6  5  0  8  0]
 [ 3  0 13  2  0  2]
 [ 0  5 10  5  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1  1  0  0 18]]
Epoch: [6]
       [Avg Loss]          0.681943
       [Training]   Prec@1 76.119403 Max 76.119403
       [Avg Loss]          2.144822
       [Validation] Prec@1 40.909091 Max 61.818182
Confusion matrix:
[[ 9  0  5  0  6  0]
 [ 1  5  5  0  9  0]
 [ 6  0 13  1  0  0]
 [ 0  5 11  4  0  0]
 [ 0  0  0  0 10  0]
 [11  2  3  0  0  4]]
Epoch: [7]
       [Avg Loss]          0.730027
       [Training]   Prec@1 74.328358 Max 76.119403
       [Avg Loss]          1.928451
       [Validation] Prec@1 58.181818 Max 61.818182
Confusion matrix:
[[19  0  1  0  0  0]
 [10  5  3  1  1  0]
 [10  0  8  0  2  0]
 [ 0  3  4 13  0  0]
 [ 5  0  0  0  5  0]
 [ 5  0  0  1  0 14]]
Epoch: [8]
       [Avg Loss]          0.713050
       [Training]   Prec@1 74.776119 Max 76.119403
       [Avg Loss]          1.981442
       [Validation] Prec@1 50.909091 Max 61.818182
Confusion matrix:
[[13  0  1  0  5  1]
 [ 5  6  2  2  5  0]
 [ 9  0  8  0  3  0]
 [ 0  5  6  9  0  0]
 [ 0  0  0  0 10  0]
 [ 9  0  0  1  0 10]]
Epoch: [9]
       [Avg Loss]          0.668048
       [Training]   Prec@1 76.716418 Max 76.716418
       [Avg Loss]          1.764923
       [Validation] Prec@1 59.090909 Max 61.818182
Confusion matrix:
[[18  0  1  1  0  0]
 [ 9  6  5  0  0  0]
 [ 8  0 12  0  0  0]
 [ 0  4  9  7  0  0]
 [ 0  0  0  4  6  0]
 [ 2  0  1  1  0 16]]
Epoch: [10]
       [Avg Loss]          0.603823
       [Training]   Prec@1 78.656716 Max 78.656716
       [Avg Loss]          2.443339
       [Validation] Prec@1 43.636364 Max 61.818182
Confusion matrix:
[[ 0  4  1  1 14  0]
 [ 1  6  1  2 10  0]
 [ 2  0  7  1  8  2]
 [ 0  5  2 13  0  0]
 [ 0  0  0  0 10  0]
 [ 0  8  0  0  0 12]]
Epoch: [11]
       [Avg Loss]          0.556249
       [Training]   Prec@1 82.686567 Max 82.686567
       [Avg Loss]          1.891862
       [Validation] Prec@1 54.545455 Max 61.818182
Confusion matrix:
[[17  0  1  2  0  0]
 [10  6  1  2  1  0]
 [10  0  9  0  1  0]
 [ 0  4  3 13  0  0]
 [ 0  0  0  5  5  0]
 [ 5  0  0  5  0 10]]
Epoch: [12]
       [Avg Loss]          0.573307
       [Training]   Prec@1 79.701493 Max 82.686567
       [Avg Loss]          1.937299
       [Validation] Prec@1 56.363636 Max 61.818182
Confusion matrix:
[[20  0  0  0  0  0]
 [ 8  5  1  2  4  0]
 [10  0 10  0  0  0]
 [ 2  1  5 12  0  0]
 [ 5  0  0  0  5  0]
 [10  0  0  0  0 10]]
Epoch: [13]
       [Avg Loss]          0.508726
       [Training]   Prec@1 81.343284 Max 82.686567
       [Avg Loss]          1.893357
       [Validation] Prec@1 51.818182 Max 61.818182
Confusion matrix:
[[10  3  6  1  0  0]
 [ 1 13  6  0  0  0]
 [ 5  0 13  1  0  1]
 [ 0  5 13  2  0  0]
 [ 0  0  9  1  0  0]
 [ 0  0  1  0  0 19]]
Epoch: [14]
       [Avg Loss]          0.545989
       [Training]   Prec@1 80.298507 Max 82.686567
       [Avg Loss]          1.982495
       [Validation] Prec@1 49.090909 Max 61.818182
Confusion matrix:
[[14  0  0  3  3  0]
 [10  3  0  1  6  0]
 [ 8  0  4  3  5  0]
 [ 0  1  0 15  4  0]
 [ 0  0  0  3  7  0]
 [ 0  0  0  9  0 11]]
Fold "4" complete, final accuracy: 61.81818181818182

-----------------------------------------------------------------------
Training for stage 3 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=8)")
Average accuracy is: 68.74051324051325


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 4-----
Evaluated preprocessing: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=8)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.500666
       [Training]   Prec@1 42.833333 Max 42.833333
       [Avg Loss]          1.727494
       [Validation] Prec@1 33.333333 Max 33.333333
Confusion matrix:
[[ 0 10  0 30  0  0]
 [ 0 30  0  0  0  0]
 [ 0  0  0 30  0  0]
 [ 0  1  0 29  0  0]
 [ 0  1  0 29  0  0]
 [ 0 19  0  0  0  1]]
Epoch: [1]
       [Avg Loss]          1.072531
       [Training]   Prec@1 62.666667 Max 62.666667
       [Avg Loss]          1.442952
       [Validation] Prec@1 41.111111 Max 41.111111
Confusion matrix:
[[26  1  0  3  0 10]
 [ 0 19  0 11  0  0]
 [ 0 23  3  4  0  0]
 [ 2 19  3  6  0  0]
 [ 0  9  4 16  1  0]
 [ 0  0  0  1  0 19]]
Epoch: [2]
       [Avg Loss]          0.988295
       [Training]   Prec@1 66.666667 Max 66.666667
       [Avg Loss]          1.229822
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[27  0  0  2  2  9]
 [ 0 22  0  8  0  0]
 [ 0  0 21  0  9  0]
 [ 2  0  8  0 20  0]
 [ 1  0  2  0 27  0]
 [ 8  0  0  1  0 11]]
Epoch: [3]
       [Avg Loss]          0.840917
       [Training]   Prec@1 70.833333 Max 70.833333
       [Avg Loss]          2.126646
       [Validation] Prec@1 42.777778 Max 60.000000
Confusion matrix:
[[ 0  0 25  0  5 10]
 [ 0 16  7  1  6  0]
 [ 0  0 23  0  7  0]
 [ 0  0 10  0 20  0]
 [ 0  0  4  0 26  0]
 [ 6  2  0  0  0 12]]
Epoch: [4]
       [Avg Loss]          0.881241
       [Training]   Prec@1 70.333333 Max 70.833333
       [Avg Loss]          1.532435
       [Validation] Prec@1 47.777778 Max 60.000000
Confusion matrix:
[[ 5  0  1 16  8 10]
 [ 0 25  0  3  2  0]
 [ 0  0 12  0 18  0]
 [ 0  1  5  0 24  0]
 [ 0  0  3  0 27  0]
 [ 0  2  0  1  0 17]]
Epoch: [5]
       [Avg Loss]          0.826401
       [Training]   Prec@1 70.333333 Max 70.833333
       [Avg Loss]          1.441527
       [Validation] Prec@1 43.888889 Max 60.000000
Confusion matrix:
[[27  0  0  4  0  9]
 [ 8 18  0  3  0  1]
 [ 2  4 14 10  0  0]
 [11  2  7 10  0  0]
 [ 4  0  5 21  0  0]
 [10  0  0  0  0 10]]
Epoch: [6]
       [Avg Loss]          0.816033
       [Training]   Prec@1 72.833333 Max 72.833333
       [Avg Loss]          2.504300
       [Validation] Prec@1 57.222222 Max 60.000000
Confusion matrix:
[[ 5  0 19  1  5 10]
 [ 0 27  0  2  1  0]
 [ 0  0 29  0  1  0]
 [ 0  0 11  0 19  0]
 [ 0  0  6  0 24  0]
 [ 0  1  0  1  0 18]]
Epoch: [7]
       [Avg Loss]          0.751541
       [Training]   Prec@1 73.000000 Max 73.000000
       [Avg Loss]          1.700222
       [Validation] Prec@1 63.888889 Max 63.888889
Confusion matrix:
[[26  0  5  0  1  8]
 [ 0 26  0  2  2  0]
 [ 0  0 30  0  0  0]
 [ 0  2 15  0 13  0]
 [ 0  0  6  0 24  0]
 [ 9  1  0  1  0  9]]
Epoch: [8]
       [Avg Loss]          0.667223
       [Training]   Prec@1 76.666667 Max 76.666667
       [Avg Loss]          1.774421
       [Validation] Prec@1 51.666667 Max 63.888889
Confusion matrix:
[[27  0  0  3  0 10]
 [ 8 21  0  0  0  1]
 [ 0  2 28  0  0  0]
 [ 7  2 17  4  0  0]
 [ 4  1 15 10  0  0]
 [ 7  0  0  0  0 13]]
Epoch: [9]
       [Avg Loss]          0.718759
       [Training]   Prec@1 74.833333 Max 76.666667
       [Avg Loss]          1.477224
       [Validation] Prec@1 55.000000 Max 63.888889
Confusion matrix:
[[22  0  2  6  0 10]
 [ 3 21  0  6  0  0]
 [ 0  0 30  0  0  0]
 [ 3  1 18  0  8  0]
 [ 0  0 15  1 14  0]
 [ 8  0  0  0  0 12]]
Epoch: [10]
       [Avg Loss]          0.645901
       [Training]   Prec@1 76.666667 Max 76.666667
       [Avg Loss]          1.670911
       [Validation] Prec@1 47.222222 Max 63.888889
Confusion matrix:
[[16  3  0  5  6 10]
 [ 0 28  0  2  0  0]
 [ 0  5  3  0 22  0]
 [ 1  3  2  0 24  0]
 [ 0  3  1  0 26  0]
 [ 6  1  0  1  0 12]]
Epoch: [11]
       [Avg Loss]          0.621825
       [Training]   Prec@1 77.833333 Max 77.833333
       [Avg Loss]          2.134542
       [Validation] Prec@1 47.777778 Max 63.888889
Confusion matrix:
[[25  0  5  0  0 10]
 [ 6 10  7  7  0  0]
 [ 0  0 30  0  0  0]
 [ 2  0 26  0  2  0]
 [ 0  0 17  1 12  0]
 [ 4  0  6  1  0  9]]
Epoch: [12]
       [Avg Loss]          0.600837
       [Training]   Prec@1 78.500000 Max 78.500000
       [Avg Loss]          2.515363
       [Validation] Prec@1 40.555556 Max 63.888889
Confusion matrix:
[[21  0  1  2  6 10]
 [ 0  8  0 21  1  0]
 [ 0  0  0  0 30  0]
 [ 1  2  0  0 27  0]
 [ 0  0  3  0 27  0]
 [ 1  0  0  2  0 17]]
Epoch: [13]
       [Avg Loss]          0.616349
       [Training]   Prec@1 78.500000 Max 78.500000
       [Avg Loss]          1.993074
       [Validation] Prec@1 48.888889 Max 63.888889
Confusion matrix:
[[11  0  8  9  2 10]
 [ 0 21  2  3  4  0]
 [ 0  0 30  0  0  0]
 [ 0  1 13  0 16  0]
 [ 0  0  9  0 21  0]
 [ 6  0  4  5  0  5]]
Epoch: [14]
       [Avg Loss]          0.580972
       [Training]   Prec@1 78.666667 Max 78.666667
       [Avg Loss]          1.264505
       [Validation] Prec@1 57.777778 Max 63.888889
Confusion matrix:
[[18  0  2 10  0 10]
 [ 0 29  0  1  0  0]
 [ 0  0 29  1  0  0]
 [ 2  2 11 10  5  0]
 [ 0  0 19  5  6  0]
 [ 8  0  0  0  0 12]]
Fold "0" complete, final accuracy: 63.888888888888886
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.541107
       [Training]   Prec@1 41.008403 Max 41.008403
       [Avg Loss]          1.701225
       [Validation] Prec@1 26.486486 Max 26.486486
Confusion matrix:
[[ 0 10  0  5 15  0]
 [ 0  6 11  0 18  0]
 [ 0  1  1  2 26  0]
 [ 0  0  4  5 21  0]
 [ 0  0  3  0 27  0]
 [ 0  7  3  7  3 10]]
Epoch: [1]
       [Avg Loss]          1.126549
       [Training]   Prec@1 60.336134 Max 60.336134
       [Avg Loss]          1.422310
       [Validation] Prec@1 43.243243 Max 43.243243
Confusion matrix:
[[ 4  1 10  0  0 15]
 [ 0 34  0  0  0  1]
 [ 0 21  9  0  0  0]
 [ 8  7  2  3  0 10]
 [ 0 15  8  5  1  1]
 [ 0  1  0  0  0 29]]
Epoch: [2]
       [Avg Loss]          0.998194
       [Training]   Prec@1 69.075630 Max 69.075630
       [Avg Loss]          1.137896
       [Validation] Prec@1 66.486486 Max 66.486486
Confusion matrix:
[[20  3  0  0  0  7]
 [ 1 26  5  2  0  1]
 [ 2  2 26  0  0  0]
 [15  1  4  6  2  2]
 [ 1  0  8  2 19  0]
 [ 3  0  1  0  0 26]]
Epoch: [3]
       [Avg Loss]          1.002101
       [Training]   Prec@1 64.873950 Max 69.075630
       [Avg Loss]          1.007857
       [Validation] Prec@1 63.783784 Max 66.486486
Confusion matrix:
[[19  1  1  0  0  9]
 [ 1 23  6  0  0  5]
 [ 0  4 25  0  1  0]
 [ 7  1  8  6  6  2]
 [ 0  0  7  4 19  0]
 [ 1  0  1  2  0 26]]
Epoch: [4]
       [Avg Loss]          0.924452
       [Training]   Prec@1 68.571429 Max 69.075630
       [Avg Loss]          1.115732
       [Validation] Prec@1 62.702703 Max 66.486486
Confusion matrix:
[[19  3  0  1  0  7]
 [ 1 29  4  1  0  0]
 [ 0  3 23  0  4  0]
 [11  1  7  9  2  0]
 [ 3  0  5  5 17  0]
 [ 2  1  2  6  0 19]]
Epoch: [5]
       [Avg Loss]          0.785681
       [Training]   Prec@1 73.781513 Max 73.781513
       [Avg Loss]          1.535650
       [Validation] Prec@1 63.783784 Max 66.486486
Confusion matrix:
[[17  2  3  0  0  8]
 [ 0 33  2  0  0  0]
 [ 0 10 15  0  5  0]
 [ 3  2  6  7 11  1]
 [ 0  0  1  8 21  0]
 [ 3  1  0  1  0 25]]
Epoch: [6]
       [Avg Loss]          0.897639
       [Training]   Prec@1 69.915966 Max 73.781513
       [Avg Loss]          1.009536
       [Validation] Prec@1 65.945946 Max 66.486486
Confusion matrix:
[[15  3  0  5  0  7]
 [ 1 33  1  0  0  0]
 [ 1  8 19  2  0  0]
 [ 4  2  3 20  0  1]
 [ 0  2  2 15 11  0]
 [ 2  2  1  1  0 24]]
Epoch: [7]
       [Avg Loss]          0.868964
       [Training]   Prec@1 67.899160 Max 73.781513
       [Avg Loss]          1.081091
       [Validation] Prec@1 63.783784 Max 66.486486
Confusion matrix:
[[19  2  0  1  0  8]
 [ 1 32  1  1  0  0]
 [ 0  8 18  4  0  0]
 [ 7  1  4 18  0  0]
 [ 1  0  2 16 11  0]
 [ 0  2  0  8  0 20]]
Epoch: [8]
       [Avg Loss]          0.808590
       [Training]   Prec@1 74.453782 Max 74.453782
       [Avg Loss]          1.206545
       [Validation] Prec@1 59.459459 Max 66.486486
Confusion matrix:
[[18  1  2  0  0  9]
 [ 2 23  2  8  0  0]
 [ 0  3 26  1  0  0]
 [12  0  7  8  3  0]
 [ 2  0  6  5 17  0]
 [ 8  0  1  3  0 18]]
Epoch: [9]
       [Avg Loss]          0.753862
       [Training]   Prec@1 73.781513 Max 74.453782
       [Avg Loss]          1.040442
       [Validation] Prec@1 63.243243 Max 66.486486
Confusion matrix:
[[11  1  7  2  0  9]
 [ 3 32  0  0  0  0]
 [ 0  9 21  0  0  0]
 [ 4  3  6 15  1  1]
 [ 0  2  5  6 17  0]
 [ 0  1  2  6  0 21]]
Epoch: [10]
       [Avg Loss]          0.692832
       [Training]   Prec@1 76.806723 Max 76.806723
       [Avg Loss]          1.259944
       [Validation] Prec@1 62.162162 Max 66.486486
Confusion matrix:
[[19  5  1  0  0  5]
 [ 0 35  0  0  0  0]
 [ 0 15 15  0  0  0]
 [16  4  2  4  1  3]
 [ 5  7  1  0 17  0]
 [ 1  4  0  0  0 25]]
Epoch: [11]
       [Avg Loss]          0.649236
       [Training]   Prec@1 78.151261 Max 78.151261
       [Avg Loss]          1.263079
       [Validation] Prec@1 61.081081 Max 66.486486
Confusion matrix:
[[19  2  3  0  0  6]
 [ 5 26  3  1  0  0]
 [ 0  2 28  0  0  0]
 [11  2  2 14  0  1]
 [ 3  2  5 12  8  0]
 [ 1  0  2  9  0 18]]
Epoch: [12]
       [Avg Loss]          0.738646
       [Training]   Prec@1 76.134454 Max 78.151261
       [Avg Loss]          1.215136
       [Validation] Prec@1 65.405405 Max 66.486486
Confusion matrix:
[[18  3  2  0  0  7]
 [ 1 32  1  0  0  1]
 [ 0  9 21  0  0  0]
 [11  1  7  5  0  6]
 [ 0  4  3  5 18  0]
 [ 1  2  0  0  0 27]]
Epoch: [13]
       [Avg Loss]          0.669189
       [Training]   Prec@1 76.470588 Max 78.151261
       [Avg Loss]          1.121391
       [Validation] Prec@1 60.540541 Max 66.486486
Confusion matrix:
[[19  2  0  1  0  8]
 [ 3 32  0  0  0  0]
 [ 2 10 14  4  0  0]
 [ 6  1  1 21  1  0]
 [ 0  2  1 14 13  0]
 [ 4  2  1 10  0 13]]
Epoch: [14]
       [Avg Loss]          0.618027
       [Training]   Prec@1 80.000000 Max 80.000000
       [Avg Loss]          0.996698
       [Validation] Prec@1 63.243243 Max 66.486486
Confusion matrix:
[[14 11  0  1  0  4]
 [ 2 33  0  0  0  0]
 [ 0  9 21  0  0  0]
 [ 3  1  4 10 10  2]
 [ 0  2  3  6 19  0]
 [ 1  2  0  7  0 20]]
Fold "1" complete, final accuracy: 66.48648648648648
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.564665
       [Training]   Prec@1 39.159664 Max 39.159664
       [Avg Loss]          1.682441
       [Validation] Prec@1 40.540541 Max 40.540541
Confusion matrix:
[[23  4  3  0  0  0]
 [ 5 16 14  0  0  0]
 [ 6  0 24  0  0  0]
 [17  0 13  0  0  0]
 [19  0  5  6  0  0]
 [18  0  0  0  0 12]]
Epoch: [1]
       [Avg Loss]          1.140293
       [Training]   Prec@1 58.487395 Max 58.487395
       [Avg Loss]          1.389531
       [Validation] Prec@1 46.486486 Max 46.486486
Confusion matrix:
[[10  1 12  7  0  0]
 [ 2 10 23  0  0  0]
 [ 0  0 26  2  2  0]
 [ 4  0 12  9  5  0]
 [ 3  0  4  4 19  0]
 [18  0  0  0  0 12]]
Epoch: [2]
       [Avg Loss]          0.982117
       [Training]   Prec@1 65.546218 Max 65.546218
       [Avg Loss]          1.063975
       [Validation] Prec@1 67.567568 Max 67.567568
Confusion matrix:
[[12  5  9  4  0  0]
 [ 4 15 14  0  0  2]
 [ 0  0 25  5  0  0]
 [ 0  0 10 19  0  1]
 [ 2  0  0  4 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [3]
       [Avg Loss]          0.924224
       [Training]   Prec@1 68.907563 Max 68.907563
       [Avg Loss]          1.183971
       [Validation] Prec@1 64.324324 Max 67.567568
Confusion matrix:
[[21  6  3  0  0  0]
 [ 5 27  2  0  0  1]
 [ 0  1 29  0  0  0]
 [ 1  6  8 14  0  1]
 [ 0  0 25  4  1  0]
 [ 3  0  0  0  0 27]]
Epoch: [4]
       [Avg Loss]          0.828196
       [Training]   Prec@1 71.932773 Max 71.932773
       [Avg Loss]          1.102166
       [Validation] Prec@1 58.918919 Max 67.567568
Confusion matrix:
[[18  2  5  0  1  4]
 [ 1 12 16  1  0  5]
 [ 2  0 18  2  8  0]
 [ 8  0  8  7  7  0]
 [ 6  0  0  0 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [5]
       [Avg Loss]          0.824842
       [Training]   Prec@1 70.420168 Max 71.932773
       [Avg Loss]          1.109755
       [Validation] Prec@1 67.567568 Max 67.567568
Confusion matrix:
[[22  6  1  1  0  0]
 [ 1 28  0  2  0  4]
 [ 0  6  9 15  0  0]
 [ 0  9  0 19  1  1]
 [ 0  3  0 10 17  0]
 [ 0  0  0  0  0 30]]
Epoch: [6]
       [Avg Loss]          0.838220
       [Training]   Prec@1 69.411765 Max 71.932773
       [Avg Loss]          1.273055
       [Validation] Prec@1 65.405405 Max 67.567568
Confusion matrix:
[[17  6  4  0  0  3]
 [ 2 25  1  1  0  6]
 [ 0  0 12 17  1  0]
 [ 2  7  0 16  2  3]
 [ 2  0  0  7 21  0]
 [ 0  0  0  0  0 30]]
Epoch: [7]
       [Avg Loss]          0.849320
       [Training]   Prec@1 70.588235 Max 71.932773
       [Avg Loss]          1.024893
       [Validation] Prec@1 78.378378 Max 78.378378
Confusion matrix:
[[21  2  6  0  0  1]
 [ 1 30  2  0  0  2]
 [ 0  0 28  2  0  0]
 [ 2  2  6 16  4  0]
 [ 5  0  2  3 20  0]
 [ 0  0  0  0  0 30]]
Epoch: [8]
       [Avg Loss]          0.748030
       [Training]   Prec@1 73.109244 Max 73.109244
       [Avg Loss]          1.394385
       [Validation] Prec@1 60.540541 Max 78.378378
Confusion matrix:
[[22  5  0  1  0  2]
 [ 6 19  3  2  0  5]
 [ 4  0  5 20  0  1]
 [ 2  0  0 26  1  1]
 [ 7  0  0  9 14  0]
 [ 4  0  0  0  0 26]]
Epoch: [9]
       [Avg Loss]          0.821493
       [Training]   Prec@1 71.428571 Max 73.109244
       [Avg Loss]          1.387583
       [Validation] Prec@1 62.702703 Max 78.378378
Confusion matrix:
[[10  7  4  9  0  0]
 [ 0 24  4  0  0  7]
 [ 0  6 24  0  0  0]
 [ 0 12  1  9  8  0]
 [ 0  1 10  0 19  0]
 [ 0  0  0  0  0 30]]
Epoch: [10]
       [Avg Loss]          0.809865
       [Training]   Prec@1 69.915966 Max 73.109244
       [Avg Loss]          0.940959
       [Validation] Prec@1 68.108108 Max 78.378378
Confusion matrix:
[[11  7  3  8  1  0]
 [ 0 18 12  5  0  0]
 [ 0  0 25  5  0  0]
 [ 0  0  5 20  5  0]
 [ 0  0  0  2 28  0]
 [ 1  3  0  2  0 24]]
Epoch: [11]
       [Avg Loss]          0.794189
       [Training]   Prec@1 69.243697 Max 73.109244
       [Avg Loss]          1.318364
       [Validation] Prec@1 65.945946 Max 78.378378
Confusion matrix:
[[23  5  2  0  0  0]
 [ 8 19  5  0  0  3]
 [ 0  0 24  6  0  0]
 [ 8  5  2 13  1  1]
 [ 9  0  0  7 14  0]
 [ 1  0  0  0  0 29]]
Epoch: [12]
       [Avg Loss]          0.672804
       [Training]   Prec@1 75.294118 Max 75.294118
       [Avg Loss]          0.872747
       [Validation] Prec@1 77.837838 Max 78.378378
Confusion matrix:
[[23  5  2  0  0  0]
 [ 5 25  2  1  0  2]
 [ 0  0 18  8  4  0]
 [ 0  4  0 20  4  2]
 [ 0  0  0  2 28  0]
 [ 0  0  0  0  0 30]]
Epoch: [13]
       [Avg Loss]          0.665100
       [Training]   Prec@1 76.302521 Max 76.302521
       [Avg Loss]          1.008323
       [Validation] Prec@1 76.216216 Max 78.378378
Confusion matrix:
[[23  5  2  0  0  0]
 [ 4 25  2  1  0  3]
 [ 0  0 23  7  0  0]
 [ 2  2  0 22  4  0]
 [ 1  0  0  8 21  0]
 [ 3  0  0  0  0 27]]
Epoch: [14]
       [Avg Loss]          0.674777
       [Training]   Prec@1 77.310924 Max 77.310924
       [Avg Loss]          1.132259
       [Validation] Prec@1 71.351351 Max 78.378378
Confusion matrix:
[[23  4  3  0  0  0]
 [ 5 14  8  3  0  5]
 [ 0  0 23  7  0  0]
 [ 1  0  4 21  1  3]
 [ 4  0  0  5 21  0]
 [ 0  0  0  0  0 30]]
Fold "2" complete, final accuracy: 78.37837837837837
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.564319
       [Training]   Prec@1 39.696970 Max 39.696970
       [Avg Loss]          1.672309
       [Validation] Prec@1 30.833333 Max 30.833333
Confusion matrix:
[[ 0  0  0 20  0  0]
 [ 0  7  0 13  0  0]
 [ 0  0  0 20  0  0]
 [ 0  0  0 20  0  0]
 [ 0  0  0 20  0  0]
 [ 0  1  0  9  0 10]]
Epoch: [1]
       [Avg Loss]          1.183675
       [Training]   Prec@1 57.727273 Max 57.727273
       [Avg Loss]          1.315638
       [Validation] Prec@1 46.666667 Max 46.666667
Confusion matrix:
[[ 4  0  3 13  0  0]
 [ 0 17  0  3  0  0]
 [ 0  3  1 16  0  0]
 [ 0  0  1 19  0  0]
 [ 0  0  0 20  0  0]
 [ 0  3  0  2  0 15]]
Epoch: [2]
       [Avg Loss]          1.045391
       [Training]   Prec@1 63.333333 Max 63.333333
       [Avg Loss]          1.383324
       [Validation] Prec@1 47.500000 Max 47.500000
Confusion matrix:
[[ 0  1 15  0  4  0]
 [ 0 20  0  0  0  0]
 [ 0  9 11  0  0  0]
 [ 0  5  5  7  3  0]
 [ 0  6  6  0  8  0]
 [ 0  9  0  0  0 11]]
Epoch: [3]
       [Avg Loss]          1.125891
       [Training]   Prec@1 59.545455 Max 63.333333
       [Avg Loss]          1.146475
       [Validation] Prec@1 60.833333 Max 60.833333
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0  0  0  4  0 16]
 [ 0  0  0 20  0  0]
 [ 1  0  0 17  0  2]
 [ 0  0  0  3 17  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          1.006882
       [Training]   Prec@1 64.242424 Max 64.242424
       [Avg Loss]          0.876873
       [Validation] Prec@1 64.166667 Max 64.166667
Confusion matrix:
[[ 9  0  0 11  0  0]
 [ 0 12  0  8  0  0]
 [ 0  1  4  8  7  0]
 [ 0  0  0 20  0  0]
 [ 0  0  0  2 18  0]
 [ 1  0  0  5  0 14]]
Epoch: [5]
       [Avg Loss]          0.867702
       [Training]   Prec@1 71.515152 Max 71.515152
       [Avg Loss]          0.782304
       [Validation] Prec@1 70.833333 Max 70.833333
Confusion matrix:
[[16  0  3  0  1  0]
 [ 0 16  1  3  0  0]
 [ 0  0 11  0  9  0]
 [ 5  0  2 12  1  0]
 [ 0  0  0  0 20  0]
 [ 6  3  0  1  0 10]]
Epoch: [6]
       [Avg Loss]          0.867565
       [Training]   Prec@1 69.545455 Max 71.515152
       [Avg Loss]          0.795077
       [Validation] Prec@1 70.833333 Max 70.833333
Confusion matrix:
[[15  0  0  5  0  0]
 [ 0 13  0  7  0  0]
 [ 0  2  4  8  6  0]
 [ 1  0  1 17  0  1]
 [ 0  0  0  0 20  0]
 [ 0  2  0  2  0 16]]
Epoch: [7]
       [Avg Loss]          0.879410
       [Training]   Prec@1 70.000000 Max 71.515152
       [Avg Loss]          1.393535
       [Validation] Prec@1 50.833333 Max 70.833333
Confusion matrix:
[[14  0  0  0  0  6]
 [ 0 18  0  0  0  2]
 [ 0 16  2  2  0  0]
 [ 0  3  0 10  0  7]
 [ 0 11  0  9  0  0]
 [ 0  3  0  0  0 17]]
Epoch: [8]
       [Avg Loss]          0.843081
       [Training]   Prec@1 71.969697 Max 71.969697
       [Avg Loss]          0.946920
       [Validation] Prec@1 67.500000 Max 70.833333
Confusion matrix:
[[ 8  0  0  8  4  0]
 [ 0 16  0  4  0  0]
 [ 0  2  7  2  9  0]
 [ 1  0  1 17  1  0]
 [ 0  0  0  0 20  0]
 [ 0  3  0  4  0 13]]
Epoch: [9]
       [Avg Loss]          0.814523
       [Training]   Prec@1 72.272727 Max 72.272727
       [Avg Loss]          1.419759
       [Validation] Prec@1 61.666667 Max 70.833333
Confusion matrix:
[[ 3  1  9  2  5  0]
 [ 0 17  0  2  1  0]
 [ 0  1 11  0  8  0]
 [ 0  2  2 13  3  0]
 [ 0  0  0  0 20  0]
 [ 6  3  0  1  0 10]]
Epoch: [10]
       [Avg Loss]          0.825990
       [Training]   Prec@1 71.818182 Max 72.272727
       [Avg Loss]          0.706620
       [Validation] Prec@1 74.166667 Max 74.166667
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0  9  0  4  0  7]
 [ 0  0 14  5  1  0]
 [ 3  0  0 15  0  2]
 [ 0  0  0  6 14  0]
 [ 1  1  0  1  0 17]]
Epoch: [11]
       [Avg Loss]          0.812243
       [Training]   Prec@1 71.212121 Max 72.272727
       [Avg Loss]          1.043800
       [Validation] Prec@1 65.000000 Max 74.166667
Confusion matrix:
[[11  0  8  1  0  0]
 [ 0  5  0 11  0  4]
 [ 0  0 14  5  1  0]
 [ 1  0  1 13  0  5]
 [ 0  0  0  3 17  0]
 [ 0  0  0  2  0 18]]
Epoch: [12]
       [Avg Loss]          0.779319
       [Training]   Prec@1 72.121212 Max 72.272727
       [Avg Loss]          1.030767
       [Validation] Prec@1 65.833333 Max 74.166667
Confusion matrix:
[[12  0  0  7  1  0]
 [ 0 19  0  1  0  0]
 [ 0  6  2  9  3  0]
 [ 1  0  0 18  1  0]
 [ 0  6  0  0 14  0]
 [ 1  5  0  0  0 14]]
Epoch: [13]
       [Avg Loss]          0.751211
       [Training]   Prec@1 72.727273 Max 72.727273
       [Avg Loss]          0.970108
       [Validation] Prec@1 71.666667 Max 74.166667
Confusion matrix:
[[12  0  0  6  2  0]
 [ 2 13  0  1  4  0]
 [ 0  0 12  2  6  0]
 [ 1  0  2 15  2  0]
 [ 0  0  0  0 20  0]
 [ 2  1  0  3  0 14]]
Epoch: [14]
       [Avg Loss]          0.695893
       [Training]   Prec@1 76.212121 Max 76.212121
       [Avg Loss]          0.838463
       [Validation] Prec@1 71.666667 Max 74.166667
Confusion matrix:
[[20  0  0  0  0  0]
 [ 2 17  0  1  0  0]
 [ 0  0 15  4  1  0]
 [ 7  0  3 10  0  0]
 [ 0  0  4  2 14  0]
 [ 7  2  0  1  0 10]]
Fold "3" complete, final accuracy: 74.16666666666667
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.484028
       [Training]   Prec@1 41.791045 Max 41.791045
       [Avg Loss]          1.713387
       [Validation] Prec@1 30.909091 Max 30.909091
Confusion matrix:
[[ 0  0  3 16  1  0]
 [ 0  0 10  1  9  0]
 [ 0  0 10 10  0  0]
 [ 0  0  8 12  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  2 16  0  2]]
Epoch: [1]
       [Avg Loss]          1.122558
       [Training]   Prec@1 59.850746 Max 59.850746
       [Avg Loss]          1.916803
       [Validation] Prec@1 28.181818 Max 30.909091
Confusion matrix:
[[15  0  1  1  0  3]
 [10  0  2  3  0  5]
 [12  0  0  8  0  0]
 [ 8  3  1  6  0  2]
 [10  0  0  0  0  0]
 [10  0  0  0  0 10]]
Epoch: [2]
       [Avg Loss]          1.027825
       [Training]   Prec@1 64.179104 Max 64.179104
       [Avg Loss]          1.358365
       [Validation] Prec@1 49.090909 Max 49.090909
Confusion matrix:
[[12  5  3  0  0  0]
 [ 6  0 10  0  4  0]
 [ 8  0 10  0  2  0]
 [ 0  5 13  2  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [3]
       [Avg Loss]          0.925221
       [Training]   Prec@1 68.507463 Max 68.507463
       [Avg Loss]          1.829296
       [Validation] Prec@1 47.272727 Max 49.090909
Confusion matrix:
[[ 7  7  2  0  4  0]
 [ 0 12  5  0  3  0]
 [ 5  0 13  0  0  2]
 [ 0 18  2  0  0  0]
 [ 0  0  7  0  3  0]
 [ 0  3  0  0  0 17]]
Epoch: [4]
       [Avg Loss]          1.002747
       [Training]   Prec@1 65.074627 Max 68.507463
       [Avg Loss]          2.083014
       [Validation] Prec@1 40.000000 Max 49.090909
Confusion matrix:
[[ 1  2  0 12  5  0]
 [ 0  0  0  7 13  0]
 [ 6  0  0  0 13  1]
 [ 0  0  0 16  4  0]
 [ 0  0  0  0 10  0]
 [ 0  2  0  1  0 17]]
Epoch: [5]
       [Avg Loss]          0.899196
       [Training]   Prec@1 67.462687 Max 68.507463
       [Avg Loss]          1.728926
       [Validation] Prec@1 50.000000 Max 50.000000
Confusion matrix:
[[ 8  5  3  0  4  0]
 [ 4  7  3  0  6  0]
 [ 7  0  7  0  5  1]
 [ 0  8  8  4  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [6]
       [Avg Loss]          0.863465
       [Training]   Prec@1 70.298507 Max 70.298507
       [Avg Loss]          1.704755
       [Validation] Prec@1 56.363636 Max 56.363636
Confusion matrix:
[[12  3  5  0  0  0]
 [ 4  6  4  0  6  0]
 [ 8  0 12  0  0  0]
 [ 0  5 11  4  0  0]
 [ 0  0  0  0 10  0]
 [ 0  2  0  0  0 18]]
Epoch: [7]
       [Avg Loss]          0.764977
       [Training]   Prec@1 73.880597 Max 73.880597
       [Avg Loss]          1.534154
       [Validation] Prec@1 50.909091 Max 56.363636
Confusion matrix:
[[ 8  3  4  1  4  0]
 [ 4  6  4  0  6  0]
 [ 9  0  5  1  5  0]
 [ 0  5  2  8  5  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [8]
       [Avg Loss]          0.708501
       [Training]   Prec@1 73.432836 Max 73.880597
       [Avg Loss]          1.775348
       [Validation] Prec@1 62.727273 Max 62.727273
Confusion matrix:
[[14  4  0  0  0  2]
 [10  6  3  1  0  0]
 [11  0  9  0  0  0]
 [ 0  5  0 15  0  0]
 [ 5  0  0  0  5  0]
 [ 0  0  0  0  0 20]]
Epoch: [9]
       [Avg Loss]          0.687432
       [Training]   Prec@1 75.671642 Max 75.671642
       [Avg Loss]          2.297176
       [Validation] Prec@1 50.000000 Max 62.727273
Confusion matrix:
[[ 9  5  1  1  4  0]
 [ 6  6  4  0  4  0]
 [ 9  0  5  0  6  0]
 [ 0  5  3  6  6  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [10]
       [Avg Loss]          0.690944
       [Training]   Prec@1 74.029851 Max 75.671642
       [Avg Loss]          1.737369
       [Validation] Prec@1 66.363636 Max 66.363636
Confusion matrix:
[[12  4  2  1  0  1]
 [ 6  7  2  1  4  0]
 [ 9  0  9  1  1  0]
 [ 0  5  0 15  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [11]
       [Avg Loss]          0.704945
       [Training]   Prec@1 75.373134 Max 75.671642
       [Avg Loss]          2.071810
       [Validation] Prec@1 66.363636 Max 66.363636
Confusion matrix:
[[15  3  1  1  0  0]
 [10  7  2  1  0  0]
 [11  0  9  0  0  0]
 [ 0  6  0 14  0  0]
 [ 1  0  0  0  9  0]
 [ 0  1  0  0  0 19]]
Epoch: [12]
       [Avg Loss]          0.691055
       [Training]   Prec@1 75.223881 Max 75.671642
       [Avg Loss]          1.688379
       [Validation] Prec@1 63.636364 Max 66.363636
Confusion matrix:
[[12  4  3  1  0  0]
 [ 9  6  3  1  1  0]
 [ 9  0  9  1  1  0]
 [ 0  5  0 15  0  0]
 [ 0  0  0  0 10  0]
 [ 0  2  0  0  0 18]]
Epoch: [13]
       [Avg Loss]          0.626003
       [Training]   Prec@1 76.716418 Max 76.716418
       [Avg Loss]          1.849358
       [Validation] Prec@1 59.090909 Max 66.363636
Confusion matrix:
[[12  6  2  0  0  0]
 [ 7 11  2  0  0  0]
 [ 8  0  5  1  5  1]
 [ 0 11  0  9  0  0]
 [ 0  0  0  1  9  0]
 [ 0  1  0  0  0 19]]
Epoch: [14]
       [Avg Loss]          0.667885
       [Training]   Prec@1 78.208955 Max 78.208955
       [Avg Loss]          2.285460
       [Validation] Prec@1 47.272727 Max 66.363636
Confusion matrix:
[[ 7  5  1  2  5  0]
 [ 4  6  2  2  6  0]
 [ 9  0  0  0 11  0]
 [ 0  2  0 11  7  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  1  0 18]]
Fold "4" complete, final accuracy: 66.36363636363636

-----------------------------------------------------------------------
Training for stage 4 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=8)")
Average accuracy is: 69.85681135681136


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 5-----
Evaluated preprocessing: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=5)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.492439
       [Training]   Prec@1 39.166667 Max 39.166667
       [Avg Loss]          1.628661
       [Validation] Prec@1 47.777778 Max 47.777778
Confusion matrix:
[[25  0  0  1  4 10]
 [20  3  0  0  0  7]
 [ 2  0 25  0  3  0]
 [ 1  0 17  0 12  0]
 [ 1  0 11  1 17  0]
 [ 4  0  0  0  0 16]]
Epoch: [1]
       [Avg Loss]          1.181926
       [Training]   Prec@1 54.500000 Max 54.500000
       [Avg Loss]          1.544270
       [Validation] Prec@1 37.777778 Max 47.777778
Confusion matrix:
[[10  0 12  1 10  7]
 [16  7  2  1  4  0]
 [ 0  0 29  0  1  0]
 [ 1  3 20  0  6  0]
 [ 0  2 14  1 13  0]
 [10  0  0  1  0  9]]
Epoch: [2]
       [Avg Loss]          1.008007
       [Training]   Prec@1 63.500000 Max 63.500000
       [Avg Loss]          1.717488
       [Validation] Prec@1 46.111111 Max 47.777778
Confusion matrix:
[[20  0  4  3  3 10]
 [11  7  1  4  0  7]
 [ 3  1 20  1  5  0]
 [ 1  2 11  0 16  0]
 [ 2  0  7  1 20  0]
 [ 4  0  0  0  0 16]]
Epoch: [3]
       [Avg Loss]          0.892047
       [Training]   Prec@1 67.666667 Max 67.666667
       [Avg Loss]          2.007803
       [Validation] Prec@1 39.444444 Max 47.777778
Confusion matrix:
[[11  3  1  0 15 10]
 [10  9  0  2  5  4]
 [ 3  4 17  0  6  0]
 [ 1  3  5  0 21  0]
 [ 0  5  1  0 24  0]
 [ 6  0  0  4  0 10]]
Epoch: [4]
       [Avg Loss]          0.747633
       [Training]   Prec@1 72.833333 Max 72.833333
       [Avg Loss]          1.800404
       [Validation] Prec@1 51.111111 Max 51.111111
Confusion matrix:
[[19  2  4  1  4 10]
 [12  8  0  0  0 10]
 [ 3  1 25  0  1  0]
 [ 2  2 11  1 14  0]
 [ 0  3  7  0 20  0]
 [ 1  0  0  0  0 19]]
Epoch: [5]
       [Avg Loss]          0.712445
       [Training]   Prec@1 76.833333 Max 76.833333
       [Avg Loss]          1.408395
       [Validation] Prec@1 55.555556 Max 55.555556
Confusion matrix:
[[19  1  7  4  0  9]
 [ 4 24  0  0  1  1]
 [ 1  1 27  1  0  0]
 [ 4  5  8  4  9  0]
 [ 0  6  4  3 17  0]
 [ 0  8  0  3  0  9]]
Epoch: [6]
       [Avg Loss]          0.579991
       [Training]   Prec@1 80.666667 Max 80.666667
       [Avg Loss]          2.116324
       [Validation] Prec@1 48.333333 Max 55.555556
Confusion matrix:
[[10  1  5  0 14 10]
 [ 4 10  0  0 10  6]
 [ 0  0 23  0  7  0]
 [ 1  0  5  0 24  0]
 [ 0  4  1  0 25  0]
 [ 1  0  0  0  0 19]]
Epoch: [7]
       [Avg Loss]          0.596614
       [Training]   Prec@1 78.500000 Max 80.666667
       [Avg Loss]          1.242266
       [Validation] Prec@1 61.111111 Max 61.111111
Confusion matrix:
[[18  1  4  6  2  9]
 [ 3 23  0  0  4  0]
 [ 3  0 25  2  0  0]
 [ 3  2 10  8  7  0]
 [ 1  0  4  1 24  0]
 [ 8  0  0  0  0 12]]
Epoch: [8]
       [Avg Loss]          0.523224
       [Training]   Prec@1 81.833333 Max 81.833333
       [Avg Loss]          1.703315
       [Validation] Prec@1 52.777778 Max 61.111111
Confusion matrix:
[[15  1  9  3  3  9]
 [ 9 14  0  0  1  6]
 [ 0  0 27  0  3  0]
 [ 0  2 14  2 12  0]
 [ 0  0  4  1 25  0]
 [ 7  0  0  1  0 12]]
Epoch: [9]
       [Avg Loss]          0.421315
       [Training]   Prec@1 85.500000 Max 85.500000
       [Avg Loss]          1.606776
       [Validation] Prec@1 56.666667 Max 61.111111
Confusion matrix:
[[12  3  7  3  6  9]
 [ 3 21  0  0  3  3]
 [ 0  1 27  0  2  0]
 [ 0  0 11  1 18  0]
 [ 0  6  0  0 24  0]
 [ 2  1  0  0  0 17]]
Epoch: [10]
       [Avg Loss]          0.373185
       [Training]   Prec@1 86.000000 Max 86.000000
       [Avg Loss]          1.734726
       [Validation] Prec@1 52.222222 Max 61.111111
Confusion matrix:
[[16  1  8  5  1  9]
 [ 6 16  0  0  5  3]
 [ 0  0 29  1  0  0]
 [ 0  2 14  4 10  0]
 [ 0  0  6  3 21  0]
 [10  0  0  2  0  8]]
Epoch: [11]
       [Avg Loss]          0.311511
       [Training]   Prec@1 90.166667 Max 90.166667
       [Avg Loss]          1.513791
       [Validation] Prec@1 57.222222 Max 61.111111
Confusion matrix:
[[14  4  6  1  6  9]
 [ 1 22  0  0  5  2]
 [ 0  2 26  1  1  0]
 [ 1  2  9  0 18  0]
 [ 0  6  1  0 23  0]
 [ 1  1  0  0  0 18]]
Epoch: [12]
       [Avg Loss]          0.246349
       [Training]   Prec@1 92.333333 Max 92.333333
       [Avg Loss]          1.372784
       [Validation] Prec@1 61.111111 Max 61.111111
Confusion matrix:
[[18  2  9  2  0  9]
 [ 2 23  0  0  4  1]
 [ 0  2 26  1  1  0]
 [ 1  0  9  9 11  0]
 [ 0  7  0  3 20  0]
 [ 1  4  0  1  0 14]]
Epoch: [13]
       [Avg Loss]          0.268474
       [Training]   Prec@1 92.000000 Max 92.333333
       [Avg Loss]          2.088016
       [Validation] Prec@1 52.222222 Max 61.111111
Confusion matrix:
[[13  1  5  3  9  9]
 [ 2 12  0  0  5 11]
 [ 1  1 25  0  3  0]
 [ 1  1  3  2 23  0]
 [ 0  4  0  1 25  0]
 [ 1  2  0  0  0 17]]
Epoch: [14]
       [Avg Loss]          0.259786
       [Training]   Prec@1 90.666667 Max 92.333333
       [Avg Loss]          1.742984
       [Validation] Prec@1 54.444444 Max 61.111111
Confusion matrix:
[[20  1  9  1  0  9]
 [ 1 21  0  0  4  4]
 [ 1  0 28  0  1  0]
 [ 0  2 14  1 13  0]
 [ 2  8  1  1 18  0]
 [ 6  3  0  1  0 10]]
Fold "0" complete, final accuracy: 61.111111111111114
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.642315
       [Training]   Prec@1 33.949580 Max 33.949580
       [Avg Loss]          1.536118
       [Validation] Prec@1 55.135135 Max 55.135135
Confusion matrix:
[[11 19  0  0  0  0]
 [ 1 29  4  0  1  0]
 [ 1 12 16  0  1  0]
 [ 5  4  2  5 11  3]
 [ 2  5  1  0 22  0]
 [ 0 11  0  0  0 19]]
Epoch: [1]
       [Avg Loss]          1.268599
       [Training]   Prec@1 53.781513 Max 53.781513
       [Avg Loss]          1.330501
       [Validation] Prec@1 52.432432 Max 55.135135
Confusion matrix:
[[18  1  0  0  0 11]
 [ 6 21  1  0  0  7]
 [ 0 11 19  0  0  0]
 [ 8  3  1  6 10  2]
 [10  2  7  5  5  1]
 [ 1  1  0  0  0 28]]
Epoch: [2]
       [Avg Loss]          1.140871
       [Training]   Prec@1 57.983193 Max 57.983193
       [Avg Loss]          1.038365
       [Validation] Prec@1 67.027027 Max 67.027027
Confusion matrix:
[[20  8  1  1  0  0]
 [ 4 28  3  0  0  0]
 [ 3  4 23  0  0  0]
 [ 9  0  2 14  5  0]
 [ 2  7  2  2 17  0]
 [ 2  4  0  2  0 22]]
Epoch: [3]
       [Avg Loss]          0.893958
       [Training]   Prec@1 68.739496 Max 68.739496
       [Avg Loss]          0.981102
       [Validation] Prec@1 67.567568 Max 67.567568
Confusion matrix:
[[19  7  1  2  0  1]
 [ 1 28  6  0  0  0]
 [ 2  1 27  0  0  0]
 [ 7  0  2 12  5  4]
 [ 1  7  0 10 12  0]
 [ 0  3  0  0  0 27]]
Epoch: [4]
       [Avg Loss]          0.779159
       [Training]   Prec@1 72.773109 Max 72.773109
       [Avg Loss]          1.251135
       [Validation] Prec@1 58.378378 Max 67.567568
Confusion matrix:
[[22  6  2  0  0  0]
 [ 3 31  1  0  0  0]
 [ 0  5 25  0  0  0]
 [ 8  0  2  9 11  0]
 [ 1  7  0  4 18  0]
 [19  7  0  1  0  3]]
Epoch: [5]
       [Avg Loss]          0.797762
       [Training]   Prec@1 69.915966 Max 72.773109
       [Avg Loss]          1.074760
       [Validation] Prec@1 62.162162 Max 67.567568
Confusion matrix:
[[15  2  0  1  0 12]
 [ 1 29  1  0  0  4]
 [ 0  4 26  0  0  0]
 [ 5  0  6 17  0  2]
 [ 2  7  8 11  2  0]
 [ 0  2  0  2  0 26]]
Epoch: [6]
       [Avg Loss]          0.719692
       [Training]   Prec@1 75.126050 Max 75.126050
       [Avg Loss]          1.111322
       [Validation] Prec@1 67.567568 Max 67.567568
Confusion matrix:
[[15 13  0  1  0  1]
 [ 0 34  1  0  0  0]
 [ 2  3 24  0  1  0]
 [ 7  0  2 14  1  6]
 [ 4  7  0  7 12  0]
 [ 0  4  0  0  0 26]]
Epoch: [7]
       [Avg Loss]          0.617914
       [Training]   Prec@1 79.327731 Max 79.327731
       [Avg Loss]          0.942730
       [Validation] Prec@1 71.351351 Max 71.351351
Confusion matrix:
[[24  2  0  0  0  4]
 [ 3 31  0  1  0  0]
 [ 0  3 26  0  1  0]
 [ 7  0  3 10  8  2]
 [ 3  7  1  3 16  0]
 [ 1  3  0  1  0 25]]
Epoch: [8]
       [Avg Loss]          0.536379
       [Training]   Prec@1 82.521008 Max 82.521008
       [Avg Loss]          0.942116
       [Validation] Prec@1 70.270270 Max 71.351351
Confusion matrix:
[[22  4  1  1  0  2]
 [ 2 33  0  0  0  0]
 [ 0  4 25  1  0  0]
 [ 5  0  3 10 10  2]
 [ 2  8  0  4 16  0]
 [ 0  4  0  2  0 24]]
Epoch: [9]
       [Avg Loss]          0.475084
       [Training]   Prec@1 84.537815 Max 84.537815
       [Avg Loss]          1.136864
       [Validation] Prec@1 70.270270 Max 71.351351
Confusion matrix:
[[17  9  1  1  0  2]
 [ 0 35  0  0  0  0]
 [ 0  4 25  1  0  0]
 [ 6  0  3 18  1  2]
 [ 5  9  0  5 11  0]
 [ 0  5  0  1  0 24]]
Epoch: [10]
       [Avg Loss]          0.429557
       [Training]   Prec@1 85.714286 Max 85.714286
       [Avg Loss]          1.071685
       [Validation] Prec@1 69.189189 Max 71.351351
Confusion matrix:
[[26  3  1  0  0  0]
 [ 2 31  1  0  1  0]
 [ 0  3 27  0  0  0]
 [ 7  0  3 15  4  1]
 [ 6  8  0  6 10  0]
 [ 6  4  0  1  0 19]]
Epoch: [11]
       [Avg Loss]          0.388073
       [Training]   Prec@1 86.722689 Max 86.722689
       [Avg Loss]          1.202441
       [Validation] Prec@1 65.945946 Max 71.351351
Confusion matrix:
[[20  3  0  0  0  7]
 [ 3 30  0  1  0  1]
 [ 1  5 24  0  0  0]
 [ 6  0  3 13  6  2]
 [ 6  8  0  5 11  0]
 [ 0  3  0  3  0 24]]
Epoch: [12]
       [Avg Loss]          0.325208
       [Training]   Prec@1 87.899160 Max 87.899160
       [Avg Loss]          1.279799
       [Validation] Prec@1 65.405405 Max 71.351351
Confusion matrix:
[[20  4  1  0  0  5]
 [ 3 31  0  1  0  0]
 [ 1  3 23  3  0  0]
 [ 7  0  2 11  8  2]
 [ 8 10  0  2 10  0]
 [ 0  4  0  0  0 26]]
Epoch: [13]
       [Avg Loss]          0.309800
       [Training]   Prec@1 88.571429 Max 88.571429
       [Avg Loss]          1.327793
       [Validation] Prec@1 66.486486 Max 71.351351
Confusion matrix:
[[18  4  0  1  1  6]
 [ 0 35  0  0  0  0]
 [ 0  4 26  0  0  0]
 [ 5  0  3 12  8  2]
 [ 1  8  0 11 10  0]
 [ 0  4  0  4  0 22]]
Epoch: [14]
       [Avg Loss]          0.363999
       [Training]   Prec@1 85.546218 Max 88.571429
       [Avg Loss]          1.268727
       [Validation] Prec@1 68.648649 Max 71.351351
Confusion matrix:
[[22  4  0  0  1  3]
 [ 0 35  0  0  0  0]
 [ 0  4 25  0  1  0]
 [ 4  3  3  8 10  2]
 [ 3  8  0  3 16  0]
 [ 4  3  0  2  0 21]]
Fold "1" complete, final accuracy: 71.35135135135135
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.661670
       [Training]   Prec@1 32.773109 Max 32.773109
       [Avg Loss]          1.558218
       [Validation] Prec@1 46.486486 Max 46.486486
Confusion matrix:
[[ 4 23  0  0  0  3]
 [ 0 31  2  0  1  1]
 [ 1  6  5  0 18  0]
 [ 6  7  0  2 13  2]
 [ 0  0  5  0 25  0]
 [ 0 11  0  0  0 19]]
Epoch: [1]
       [Avg Loss]          1.368604
       [Training]   Prec@1 46.554622 Max 46.554622
       [Avg Loss]          1.221800
       [Validation] Prec@1 57.837838 Max 57.837838
Confusion matrix:
[[19  5  0  0  0  6]
 [ 7 13  1  0  0 14]
 [ 3  1  9  2 15  0]
 [ 7  2  0 13  6  2]
 [ 1  2  1  3 23  0]
 [ 0  0  0  0  0 30]]
Epoch: [2]
       [Avg Loss]          1.211485
       [Training]   Prec@1 55.630252 Max 55.630252
       [Avg Loss]          1.106758
       [Validation] Prec@1 62.162162 Max 62.162162
Confusion matrix:
[[22  5  0  0  0  3]
 [ 3 27  0  0  0  5]
 [10  2  4  4 10  0]
 [ 5  3  0 13  7  2]
 [ 2  6  0  2 20  0]
 [ 0  1  0  0  0 29]]
Epoch: [3]
       [Avg Loss]          1.096069
       [Training]   Prec@1 62.016807 Max 62.016807
       [Avg Loss]          1.018624
       [Validation] Prec@1 60.000000 Max 62.162162
Confusion matrix:
[[15  4  0  0  0 11]
 [ 1 17  5  1  0 11]
 [ 2  0 18  0 10  0]
 [ 1  2  1 13  7  6]
 [ 3  3  3  2 19  0]
 [ 0  1  0  0  0 29]]
Epoch: [4]
       [Avg Loss]          1.013513
       [Training]   Prec@1 65.378151 Max 65.378151
       [Avg Loss]          0.838035
       [Validation] Prec@1 71.351351 Max 71.351351
Confusion matrix:
[[22  6  0  0  0  2]
 [ 7 24  2  1  0  1]
 [ 0  0 21  5  4  0]
 [ 0  2  0 23  5  0]
 [ 0  7  0  4 19  0]
 [ 4  3  0  0  0 23]]
Epoch: [5]
       [Avg Loss]          0.841259
       [Training]   Prec@1 69.243697 Max 69.243697
       [Avg Loss]          0.867670
       [Validation] Prec@1 68.108108 Max 71.351351
Confusion matrix:
[[11  8  0  0  0 11]
 [ 0 27  0  3  0  5]
 [ 2  0 23  2  3  0]
 [ 1  0  1 14 10  4]
 [ 0  4  0  3 23  0]
 [ 0  2  0  0  0 28]]
Epoch: [6]
       [Avg Loss]          0.737770
       [Training]   Prec@1 75.798319 Max 75.798319
       [Avg Loss]          0.793862
       [Validation] Prec@1 75.135135 Max 75.135135
Confusion matrix:
[[19  6  0  1  2  2]
 [ 6 19  3  3  0  4]
 [ 1  0 27  1  1  0]
 [ 0  0  2 19  9  0]
 [ 0  3  0  1 26  0]
 [ 0  1  0  0  0 29]]
Epoch: [7]
       [Avg Loss]          0.609475
       [Training]   Prec@1 78.487395 Max 78.487395
       [Avg Loss]          0.760843
       [Validation] Prec@1 77.297297 Max 77.297297
Confusion matrix:
[[23  4  0  0  1  2]
 [ 7 20  1  3  0  4]
 [ 0  0 29  1  0  0]
 [ 0  1  5 23  1  0]
 [ 0  6  0  5 19  0]
 [ 0  1  0  0  0 29]]
Epoch: [8]
       [Avg Loss]          0.538443
       [Training]   Prec@1 82.689076 Max 82.689076
       [Avg Loss]          0.828570
       [Validation] Prec@1 73.513514 Max 77.297297
Confusion matrix:
[[15  8  0  1  1  5]
 [ 3 20  3  5  0  4]
 [ 0  0 30  0  0  0]
 [ 0  0  3 27  0  0]
 [ 0  5  0  9 16  0]
 [ 0  2  0  0  0 28]]
Epoch: [9]
       [Avg Loss]          0.494196
       [Training]   Prec@1 83.193277 Max 83.193277
       [Avg Loss]          0.945748
       [Validation] Prec@1 71.351351 Max 77.297297
Confusion matrix:
[[18  2  0  4  0  6]
 [ 6 14  3  6  0  6]
 [ 0  0 30  0  0  0]
 [ 0  0  6 23  1  0]
 [ 2  0  0 10 18  0]
 [ 0  1  0  0  0 29]]
Epoch: [10]
       [Avg Loss]          0.422289
       [Training]   Prec@1 86.722689 Max 86.722689
       [Avg Loss]          0.846166
       [Validation] Prec@1 72.432432 Max 77.297297
Confusion matrix:
[[20  4  0  1  0  5]
 [ 7 25  0  0  0  3]
 [ 0  2 26  1  1  0]
 [ 0  6  2 20  0  2]
 [ 1  8  0  3 18  0]
 [ 4  1  0  0  0 25]]
Epoch: [11]
       [Avg Loss]          0.393990
       [Training]   Prec@1 87.226891 Max 87.226891
       [Avg Loss]          0.760306
       [Validation] Prec@1 77.837838 Max 77.837838
Confusion matrix:
[[20  4  0  1  1  4]
 [ 6 22  0  2  0  5]
 [ 0  0 30  0  0  0]
 [ 0  0  4 24  2  0]
 [ 0  5  0  5 20  0]
 [ 1  1  0  0  0 28]]
Epoch: [12]
       [Avg Loss]          0.390359
       [Training]   Prec@1 85.882353 Max 87.226891
       [Avg Loss]          0.993419
       [Validation] Prec@1 70.270270 Max 77.837838
Confusion matrix:
[[16  1  0  1  4  8]
 [ 7 16  1  5  0  6]
 [ 1  0 27  0  2  0]
 [ 0  0  2 21  7  0]
 [ 0  2  0  3 25  0]
 [ 4  1  0  0  0 25]]
Epoch: [13]
       [Avg Loss]          0.387764
       [Training]   Prec@1 86.218487 Max 87.226891
       [Avg Loss]          0.830490
       [Validation] Prec@1 74.054054 Max 77.837838
Confusion matrix:
[[14  7  0  1  2  6]
 [ 3 23  0  3  1  5]
 [ 1  0 28  0  1  0]
 [ 0  0  3 26  1  0]
 [ 0  4  0  4 22  0]
 [ 1  5  0  0  0 24]]
Epoch: [14]
       [Avg Loss]          0.357273
       [Training]   Prec@1 88.235294 Max 88.235294
       [Avg Loss]          1.399892
       [Validation] Prec@1 62.702703 Max 77.837838
Confusion matrix:
[[20  3  0  3  0  4]
 [ 6 12  6  7  1  3]
 [ 1  0 29  0  0  0]
 [ 1  0  5 24  0  0]
 [ 0  8  0  7 15  0]
 [ 8  5  1  0  0 16]]
Fold "2" complete, final accuracy: 77.83783783783784
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.526178
       [Training]   Prec@1 40.000000 Max 40.000000
       [Avg Loss]          1.464505
       [Validation] Prec@1 52.500000 Max 52.500000
Confusion matrix:
[[ 7  0  0  4  9  0]
 [ 4 12  0  2  2  0]
 [ 1  0  1  0 18  0]
 [ 3  0  0 10  7  0]
 [ 0  0  0  0 20  0]
 [ 0  5  0  2  0 13]]
Epoch: [1]
       [Avg Loss]          1.283225
       [Training]   Prec@1 50.454545 Max 50.454545
       [Avg Loss]          1.233801
       [Validation] Prec@1 55.000000 Max 55.000000
Confusion matrix:
[[20  0  0  0  0  0]
 [13  2  0  0  0  5]
 [14  0  2  1  3  0]
 [ 9  0  0  9  1  1]
 [ 2  0  0  1 17  0]
 [ 3  0  0  1  0 16]]
Epoch: [2]
       [Avg Loss]          1.135581
       [Training]   Prec@1 58.030303 Max 58.030303
       [Avg Loss]          0.978493
       [Validation] Prec@1 69.166667 Max 69.166667
Confusion matrix:
[[15  2  0  3  0  0]
 [ 3 16  0  1  0  0]
 [ 2  1 10  2  5  0]
 [ 1  0  1  9  7  2]
 [ 1  1  0  0 18  0]
 [ 2  3  0  0  0 15]]
Epoch: [3]
       [Avg Loss]          0.986178
       [Training]   Prec@1 63.787879 Max 63.787879
       [Avg Loss]          0.982017
       [Validation] Prec@1 64.166667 Max 69.166667
Confusion matrix:
[[18  0  0  2  0  0]
 [ 6 14  0  0  0  0]
 [ 2  0 15  3  0  0]
 [ 4  0  3 10  2  1]
 [ 3  0  3  4 10  0]
 [ 8  2  0  0  0 10]]
Epoch: [4]
       [Avg Loss]          0.813999
       [Training]   Prec@1 72.121212 Max 72.121212
       [Avg Loss]          1.385553
       [Validation] Prec@1 55.833333 Max 69.166667
Confusion matrix:
[[ 1  4  0 11  4  0]
 [ 0 18  0  1  1  0]
 [ 1  1  7  6  5  0]
 [ 0  0  0 16  4  0]
 [ 0  1  0  4 15  0]
 [ 1  5  0  4  0 10]]
Epoch: [5]
       [Avg Loss]          0.731278
       [Training]   Prec@1 74.242424 Max 74.242424
       [Avg Loss]          0.835382
       [Validation] Prec@1 74.166667 Max 74.166667
Confusion matrix:
[[12  0  0  7  1  0]
 [ 2 14  0  1  0  3]
 [ 3  1 12  3  1  0]
 [ 0  1  0 16  2  1]
 [ 0  2  0  0 18  0]
 [ 0  2  0  1  0 17]]
Epoch: [6]
       [Avg Loss]          0.682148
       [Training]   Prec@1 77.121212 Max 77.121212
       [Avg Loss]          1.448331
       [Validation] Prec@1 60.833333 Max 74.166667
Confusion matrix:
[[10  0  0  7  3  0]
 [ 1 16  0  1  1  1]
 [ 6  0 11  3  0  0]
 [ 1  0  0 14  4  1]
 [ 4  6  0  0 10  0]
 [ 4  2  0  2  0 12]]
Epoch: [7]
       [Avg Loss]          0.579558
       [Training]   Prec@1 80.606061 Max 80.606061
       [Avg Loss]          0.799977
       [Validation] Prec@1 75.000000 Max 75.000000
Confusion matrix:
[[14  1  0  5  0  0]
 [ 1 17  0  1  0  1]
 [ 6  0 12  2  0  0]
 [ 0  0  0 16  3  1]
 [ 1  0  0  1 18  0]
 [ 2  3  0  2  0 13]]
Epoch: [8]
       [Avg Loss]          0.504736
       [Training]   Prec@1 83.636364 Max 83.636364
       [Avg Loss]          0.992142
       [Validation] Prec@1 69.166667 Max 75.000000
Confusion matrix:
[[10  4  0  2  4  0]
 [ 1 18  0  0  0  1]
 [ 6  0 11  3  0  0]
 [ 2  0  0 13  5  0]
 [ 0  3  0  0 17  0]
 [ 2  3  0  1  0 14]]
Epoch: [9]
       [Avg Loss]          0.471954
       [Training]   Prec@1 83.787879 Max 83.787879
       [Avg Loss]          1.147645
       [Validation] Prec@1 65.833333 Max 75.000000
Confusion matrix:
[[ 5  0  0 15  0  0]
 [ 1 17  0  1  1  0]
 [ 0  0 14  6  0  0]
 [ 0  0  0 18  2  0]
 [ 0  0  0  9 11  0]
 [ 1  3  0  2  0 14]]
Epoch: [10]
       [Avg Loss]          0.505783
       [Training]   Prec@1 82.121212 Max 83.787879
       [Avg Loss]          1.173484
       [Validation] Prec@1 69.166667 Max 75.000000
Confusion matrix:
[[10  1  0  9  0  0]
 [ 1 18  0  0  1  0]
 [ 3  2 10  5  0  0]
 [ 0  2  0 14  2  2]
 [ 0  2  0  2 16  0]
 [ 0  3  0  2  0 15]]
Epoch: [11]
       [Avg Loss]          0.444319
       [Training]   Prec@1 83.636364 Max 83.787879
       [Avg Loss]          1.066407
       [Validation] Prec@1 73.333333 Max 75.000000
Confusion matrix:
[[ 6  0  0 13  1  0]
 [ 0 19  0  1  0  0]
 [ 0  0 16  4  0  0]
 [ 0  0  0 19  1  0]
 [ 1  2  0  1 16  0]
 [ 3  3  0  2  0 12]]
Epoch: [12]
       [Avg Loss]          0.358402
       [Training]   Prec@1 87.272727 Max 87.272727
       [Avg Loss]          1.148420
       [Validation] Prec@1 70.000000 Max 75.000000
Confusion matrix:
[[ 9  1  0 10  0  0]
 [ 1 13  0  0  5  1]
 [ 3  0 14  3  0  0]
 [ 0  0  2 16  1  1]
 [ 0  0  0  1 19  0]
 [ 2  3  0  2  0 13]]
Epoch: [13]
       [Avg Loss]          0.317481
       [Training]   Prec@1 89.545455 Max 89.545455
       [Avg Loss]          1.185947
       [Validation] Prec@1 65.833333 Max 75.000000
Confusion matrix:
[[13  0  0  7  0  0]
 [ 0 19  0  1  0  0]
 [ 6  0 12  2  0  0]
 [ 1  0  0 16  2  1]
 [ 3  2  0  6  9  0]
 [ 5  3  0  2  0 10]]
Epoch: [14]
       [Avg Loss]          0.321410
       [Training]   Prec@1 90.303030 Max 90.303030
       [Avg Loss]          1.224081
       [Validation] Prec@1 65.833333 Max 75.000000
Confusion matrix:
[[12  0  0  8  0  0]
 [ 1 17  0  1  1  0]
 [ 0  0 13  7  0  0]
 [ 0  0  0 18  2  0]
 [ 0  3  0  8  9  0]
 [ 4  4  0  2  0 10]]
Fold "3" complete, final accuracy: 75.0
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.536961
       [Training]   Prec@1 37.313433 Max 37.313433
       [Avg Loss]          1.565256
       [Validation] Prec@1 39.090909 Max 39.090909
Confusion matrix:
[[ 3 14  0  0  3  0]
 [ 0 10  1  0  9  0]
 [ 0  9  0  0 10  1]
 [ 4  6  0  1  9  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [1]
       [Avg Loss]          1.213343
       [Training]   Prec@1 52.238806 Max 52.238806
       [Avg Loss]          1.478954
       [Validation] Prec@1 48.181818 Max 48.181818
Confusion matrix:
[[16  1  2  0  1  0]
 [ 0  1  7  0 12  0]
 [ 6  1  8  0  5  0]
 [ 1  4  4  0 10  1]
 [ 0  0  0  0 10  0]
 [ 0  2  0  0  0 18]]
Epoch: [2]
       [Avg Loss]          1.028720
       [Training]   Prec@1 61.791045 Max 61.791045
       [Avg Loss]          1.450291
       [Validation] Prec@1 52.727273 Max 52.727273
Confusion matrix:
[[17  0  1  0  2  0]
 [ 0  4  4  0 12  0]
 [ 5  1  8  0  6  0]
 [ 1  0  9  2  4  4]
 [ 0  0  0  0 10  0]
 [ 3  0  0  0  0 17]]
Epoch: [3]
       [Avg Loss]          0.961203
       [Training]   Prec@1 67.910448 Max 67.910448
       [Avg Loss]          1.036933
       [Validation] Prec@1 67.272727 Max 67.272727
Confusion matrix:
[[15  1  0  0  3  1]
 [ 0 13  1  0  6  0]
 [ 4  3 12  0  1  0]
 [ 0  3  3  4  6  4]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          0.851755
       [Training]   Prec@1 71.194030 Max 71.194030
       [Avg Loss]          1.374918
       [Validation] Prec@1 61.818182 Max 67.272727
Confusion matrix:
[[17  0  1  2  0  0]
 [ 0  5  2  0 13  0]
 [ 5  1 13  1  0  0]
 [ 4  0  3  7  2  4]
 [ 0  0  4  0  6  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.743472
       [Training]   Prec@1 72.835821 Max 72.835821
       [Avg Loss]          1.529032
       [Validation] Prec@1 46.363636 Max 67.272727
Confusion matrix:
[[18  0  0  1  1  0]
 [ 2  8  0  0 10  0]
 [ 6  2  2  0 10  0]
 [ 9  1  2  6  0  2]
 [ 0  0  0  0 10  0]
 [13  0  0  0  0  7]]
Epoch: [6]
       [Avg Loss]          0.646369
       [Training]   Prec@1 76.417910 Max 76.417910
       [Avg Loss]          1.134168
       [Validation] Prec@1 62.727273 Max 67.272727
Confusion matrix:
[[16  0  1  3  0  0]
 [ 0  6  4  0 10  0]
 [ 4  1 15  0  0  0]
 [ 0  1  9  8  0  2]
 [ 0  0  4  0  6  0]
 [ 0  0  0  2  0 18]]
Epoch: [7]
       [Avg Loss]          0.665459
       [Training]   Prec@1 77.761194 Max 77.761194
       [Avg Loss]          1.194904
       [Validation] Prec@1 60.000000 Max 67.272727
Confusion matrix:
[[16  0  1  3  0  0]
 [ 0  9  0  0 11  0]
 [ 1  1 12  6  0  0]
 [ 0  2  3 11  3  1]
 [ 0  0  0  4  6  0]
 [ 8  0  0  0  0 12]]
Epoch: [8]
       [Avg Loss]          0.475505
       [Training]   Prec@1 84.179104 Max 84.179104
       [Avg Loss]          1.266543
       [Validation] Prec@1 60.000000 Max 67.272727
Confusion matrix:
[[15  3  1  1  0  0]
 [ 1 10  2  3  4  0]
 [ 2  2 14  0  1  1]
 [ 4  0  6  7  0  3]
 [ 0  0  4  6  0  0]
 [ 0  0  0  0  0 20]]
Epoch: [9]
       [Avg Loss]          0.440423
       [Training]   Prec@1 85.373134 Max 85.373134
       [Avg Loss]          1.334878
       [Validation] Prec@1 63.636364 Max 67.272727
Confusion matrix:
[[14  2  1  2  1  0]
 [ 6  8  0  0  6  0]
 [ 2  2 12  4  0  0]
 [ 2  2  3 11  0  2]
 [ 0  0  0  5  5  0]
 [ 0  0  0  0  0 20]]
Epoch: [10]
       [Avg Loss]          0.396058
       [Training]   Prec@1 86.119403 Max 86.119403
       [Avg Loss]          1.095658
       [Validation] Prec@1 70.000000 Max 70.000000
Confusion matrix:
[[18  1  0  1  0  0]
 [ 0 11  0  0  9  0]
 [ 1  0 15  3  0  1]
 [ 0  1  5  9  2  3]
 [ 0  0  2  3  5  0]
 [ 0  0  0  1  0 19]]
Epoch: [11]
       [Avg Loss]          0.371631
       [Training]   Prec@1 87.313433 Max 87.313433
       [Avg Loss]          1.348524
       [Validation] Prec@1 56.363636 Max 70.000000
Confusion matrix:
[[17  0  0  3  0  0]
 [ 8  8  0  0  4  0]
 [ 8  0  5  7  0  0]
 [ 0  1  2 15  0  2]
 [ 0  0  0  4  6  0]
 [ 6  0  0  3  0 11]]
Epoch: [12]
       [Avg Loss]          0.375931
       [Training]   Prec@1 86.865672 Max 87.313433
       [Avg Loss]          1.137084
       [Validation] Prec@1 71.818182 Max 71.818182
Confusion matrix:
[[13  4  2  1  0  0]
 [ 0 15  0  1  4  0]
 [ 0  2 18  0  0  0]
 [ 1  0  3 14  0  2]
 [ 0  0  0 10  0  0]
 [ 0  0  0  1  0 19]]
Epoch: [13]
       [Avg Loss]          0.308689
       [Training]   Prec@1 90.000000 Max 90.000000
       [Avg Loss]          1.352437
       [Validation] Prec@1 63.636364 Max 71.818182
Confusion matrix:
[[16  2  0  2  0  0]
 [ 0  8  0  0 12  0]
 [ 3  1 12  3  0  1]
 [ 1  0  2 14  1  2]
 [ 0  0  0  9  1  0]
 [ 1  0  0  0  0 19]]
Epoch: [14]
       [Avg Loss]          0.311525
       [Training]   Prec@1 90.298507 Max 90.298507
       [Avg Loss]          1.378256
       [Validation] Prec@1 66.363636 Max 71.818182
Confusion matrix:
[[12  2  0  5  0  1]
 [ 0  8  0  0 12  0]
 [ 2  2 15  1  0  0]
 [ 0  2  3 15  0  0]
 [ 0  0  0  7  3  0]
 [ 0  0  0  0  0 20]]
Fold "4" complete, final accuracy: 71.81818181818181

-----------------------------------------------------------------------
Training for stage 5 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=5)")
Average accuracy is: 71.42369642369643


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 6-----
Evaluated preprocessing: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=5)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.446512
       [Training]   Prec@1 44.666667 Max 44.666667
       [Avg Loss]          1.447167
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[23  0  0  0  7 10]
 [ 0 26  3  1  0  0]
 [ 0  0 30  0  0  0]
 [ 1  0 19  0 10  0]
 [ 0  0 19  0 11  0]
 [ 1  0  0  1  0 18]]
Epoch: [1]
       [Avg Loss]          0.968268
       [Training]   Prec@1 64.666667 Max 64.666667
       [Avg Loss]          1.377382
       [Validation] Prec@1 55.000000 Max 60.000000
Confusion matrix:
[[10  0  1 11  8 10]
 [ 0 29  1  0  0  0]
 [ 0  0 26  0  4  0]
 [ 1  1  9  0 19  0]
 [ 0  0  6  0 24  0]
 [10  0  0  0  0 10]]
Epoch: [2]
       [Avg Loss]          0.879269
       [Training]   Prec@1 69.500000 Max 69.500000
       [Avg Loss]          1.426816
       [Validation] Prec@1 58.333333 Max 60.000000
Confusion matrix:
[[19  0  3  0  8 10]
 [ 0 21  2  4  0  3]
 [ 0  0 30  0  0  0]
 [ 1  1 18  0 10  0]
 [ 0  0  6  2 22  0]
 [ 7  0  0  0  0 13]]
Epoch: [3]
       [Avg Loss]          0.801676
       [Training]   Prec@1 70.666667 Max 70.666667
       [Avg Loss]          1.496642
       [Validation] Prec@1 67.777778 Max 67.777778
Confusion matrix:
[[26  0  1  1  2 10]
 [ 0 30  0  0  0  0]
 [ 0  2 25  0  3  0]
 [ 2  2 11  0 15  0]
 [ 0  0  7  2 21  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          0.803907
       [Training]   Prec@1 70.833333 Max 70.833333
       [Avg Loss]          1.563837
       [Validation] Prec@1 54.444444 Max 67.777778
Confusion matrix:
[[19  0  5  6  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  1 28  0  0  0]
 [ 0  0 29  1  0  0]
 [ 0  0  0  1  0 19]]
Epoch: [5]
       [Avg Loss]          0.780814
       [Training]   Prec@1 71.500000 Max 71.500000
       [Avg Loss]          1.792518
       [Validation] Prec@1 47.777778 Max 67.777778
Confusion matrix:
[[16  0  0  7  8  9]
 [ 1 25  1  3  0  0]
 [ 0  0 13  0 17  0]
 [ 1  0  7  0 22  0]
 [ 3  0  0  1 26  0]
 [10  0  0  4  0  6]]
Epoch: [6]
       [Avg Loss]          0.744424
       [Training]   Prec@1 72.833333 Max 72.833333
       [Avg Loss]          1.532581
       [Validation] Prec@1 62.777778 Max 67.777778
Confusion matrix:
[[23  0  2  1  4 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 2  1 25  0  2  0]
 [ 0  0 12  1 17  0]
 [ 6  0  0  1  0 13]]
Epoch: [7]
       [Avg Loss]          0.626980
       [Training]   Prec@1 78.166667 Max 78.166667
       [Avg Loss]          1.436211
       [Validation] Prec@1 51.666667 Max 67.777778
Confusion matrix:
[[24  0  0  6  0 10]
 [ 1 29  0  0  0  0]
 [ 0  3 21  6  0  0]
 [ 1  1 20  8  0  0]
 [ 4  2 14  8  2  0]
 [10  0  0  1  0  9]]
Epoch: [8]
       [Avg Loss]          0.735288
       [Training]   Prec@1 74.166667 Max 78.166667
       [Avg Loss]          1.777695
       [Validation] Prec@1 62.222222 Max 67.777778
Confusion matrix:
[[17  0  1  0 12 10]
 [ 0 29  0  0  0  1]
 [ 0  0 26  0  4  0]
 [ 1  1  7  0 21  0]
 [ 0  0  4  1 25  0]
 [ 5  0  0  0  0 15]]
Epoch: [9]
       [Avg Loss]          0.596401
       [Training]   Prec@1 80.666667 Max 80.666667
       [Avg Loss]          1.700723
       [Validation] Prec@1 56.666667 Max 67.777778
Confusion matrix:
[[22  0  3  2  3 10]
 [ 0 26  2  1  0  1]
 [ 0  0 30  0  0  0]
 [ 1  1 24  0  4  0]
 [ 0  0 15  1 14  0]
 [ 9  0  0  1  0 10]]
Epoch: [10]
       [Avg Loss]          0.550341
       [Training]   Prec@1 81.000000 Max 81.000000
       [Avg Loss]          1.631164
       [Validation] Prec@1 56.111111 Max 67.777778
Confusion matrix:
[[22  1  4  2  1 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 2  2 24  0  2  0]
 [ 1  6 12  1 10  0]
 [10  0  0  1  0  9]]
Epoch: [11]
       [Avg Loss]          0.487856
       [Training]   Prec@1 82.000000 Max 82.000000
       [Avg Loss]          1.642432
       [Validation] Prec@1 62.777778 Max 67.777778
Confusion matrix:
[[22  1  2  0  5 10]
 [ 0 28  0  2  0  0]
 [ 0  0 28  0  2  0]
 [ 1  1 13  1 14  0]
 [ 1  3  0  2 24  0]
 [ 9  0  0  1  0 10]]
Epoch: [12]
       [Avg Loss]          0.472219
       [Training]   Prec@1 82.833333 Max 82.833333
       [Avg Loss]          1.835120
       [Validation] Prec@1 52.777778 Max 67.777778
Confusion matrix:
[[21  0  6  3  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 12  0 18  0]
 [ 0  1  8  2 19  0]
 [ 2  3  0  4 21  0]
 [ 8  2  0  1  0  9]]
Epoch: [13]
       [Avg Loss]          0.444897
       [Training]   Prec@1 85.166667 Max 85.166667
       [Avg Loss]          1.614210
       [Validation] Prec@1 65.000000 Max 67.777778
Confusion matrix:
[[25  0  1  1  3 10]
 [ 0 28  1  1  0  0]
 [ 0  0 28  0  2  0]
 [ 1  1  9  0 19  0]
 [ 0  4  0  1 25  0]
 [ 8  0  0  1  0 11]]
Epoch: [14]
       [Avg Loss]          0.421207
       [Training]   Prec@1 87.000000 Max 87.000000
       [Avg Loss]          1.514217
       [Validation] Prec@1 62.222222 Max 67.777778
Confusion matrix:
[[24  0  4  2  0 10]
 [ 0 29  0  1  0  0]
 [ 0  0 30  0  0  0]
 [ 2  1 18  4  5  0]
 [ 2  3  2  7 16  0]
 [10  0  0  1  0  9]]
Fold "0" complete, final accuracy: 67.77777777777777
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.465052
       [Training]   Prec@1 44.369748 Max 44.369748
       [Avg Loss]          1.391540
       [Validation] Prec@1 50.810811 Max 50.810811
Confusion matrix:
[[20  5  0  0  0  5]
 [ 1 23 11  0  0  0]
 [ 0  2 10  0 18  0]
 [12  0  9  0  5  4]
 [ 3  0  9  0 18  0]
 [ 2  3  2  0  0 23]]
Epoch: [1]
       [Avg Loss]          1.232727
       [Training]   Prec@1 56.974790 Max 56.974790
       [Avg Loss]          1.338015
       [Validation] Prec@1 46.486486 Max 50.810811
Confusion matrix:
[[19  3  0  1  0  7]
 [ 1 12  7 13  0  2]
 [ 0  1 27  2  0  0]
 [13  0 11  3  0  3]
 [ 2  0 17  5  6  0]
 [ 8  1  2  0  0 19]]
Epoch: [2]
       [Avg Loss]          1.105522
       [Training]   Prec@1 57.983193 Max 57.983193
       [Avg Loss]          1.426033
       [Validation] Prec@1 56.216216 Max 56.216216
Confusion matrix:
[[20  4  0  0  0  6]
 [ 1 34  0  0  0  0]
 [ 0  9 21  0  0  0]
 [17  3  4  3  1  2]
 [ 6  3  6  3 12  0]
 [12  2  2  0  0 14]]
Epoch: [3]
       [Avg Loss]          1.030782
       [Training]   Prec@1 62.016807 Max 62.016807
       [Avg Loss]          1.119245
       [Validation] Prec@1 63.783784 Max 63.783784
Confusion matrix:
[[18  1  0  2  0  9]
 [ 1 25  5  2  0  2]
 [ 0  2 28  0  0  0]
 [ 9  0  6  5  6  4]
 [ 1  0  8  4 17  0]
 [ 4  0  1  0  0 25]]
Epoch: [4]
       [Avg Loss]          0.992417
       [Training]   Prec@1 65.546218 Max 65.546218
       [Avg Loss]          1.203617
       [Validation] Prec@1 57.837838 Max 63.783784
Confusion matrix:
[[20  3  0  0  0  7]
 [ 1 32  0  2  0  0]
 [ 0  6 14  7  3  0]
 [16  3  1  6  2  2]
 [ 4  2  1  6 17  0]
 [ 8  2  0  2  0 18]]
Epoch: [5]
       [Avg Loss]          0.968387
       [Training]   Prec@1 66.050420 Max 66.050420
       [Avg Loss]          1.209315
       [Validation] Prec@1 54.594595 Max 63.783784
Confusion matrix:
[[20  3  0  0  0  7]
 [ 1 32  2  0  0  0]
 [ 0  5 25  0  0  0]
 [13  2  8  5  1  1]
 [ 3  2 19  6  0  0]
 [ 7  2  1  1  0 19]]
Epoch: [6]
       [Avg Loss]          0.963681
       [Training]   Prec@1 64.201681 Max 66.050420
       [Avg Loss]          1.268758
       [Validation] Prec@1 58.378378 Max 63.783784
Confusion matrix:
[[20  2  0  0  0  8]
 [ 1 32  1  1  0  0]
 [ 0  4 22  0  4  0]
 [16  2  2  7  2  1]
 [ 4  2  2  7 15  0]
 [13  1  2  2  0 12]]
Epoch: [7]
       [Avg Loss]          0.850256
       [Training]   Prec@1 71.428571 Max 71.428571
       [Avg Loss]          1.202171
       [Validation] Prec@1 64.324324 Max 64.324324
Confusion matrix:
[[20  4  0  0  0  6]
 [ 0 31  0  4  0  0]
 [ 0  4 20  6  0  0]
 [12  0  1 15  2  0]
 [ 5  1  3  7 14  0]
 [ 5  2  0  4  0 19]]
Epoch: [8]
       [Avg Loss]          0.778837
       [Training]   Prec@1 72.773109 Max 72.773109
       [Avg Loss]          1.327316
       [Validation] Prec@1 62.702703 Max 64.324324
Confusion matrix:
[[20  1  0  0  0  9]
 [ 0 30  1  2  0  2]
 [ 0  4 14  1 11  0]
 [10  1  3  9  2  5]
 [ 5  1  3  5 16  0]
 [ 2  0  1  0  0 27]]
Epoch: [9]
       [Avg Loss]          0.778753
       [Training]   Prec@1 73.277311 Max 73.277311
       [Avg Loss]          1.417023
       [Validation] Prec@1 60.000000 Max 64.324324
Confusion matrix:
[[20  4  0  0  0  6]
 [ 0 34  0  1  0  0]
 [ 0  9 18  3  0  0]
 [17  1  1 10  1  0]
 [ 5  3  1  8 13  0]
 [ 7  1  3  3  0 16]]
Epoch: [10]
       [Avg Loss]          0.718907
       [Training]   Prec@1 75.630252 Max 75.630252
       [Avg Loss]          1.351164
       [Validation] Prec@1 56.756757 Max 64.324324
Confusion matrix:
[[20  4  0  0  0  6]
 [ 0 32  0  3  0  0]
 [ 0  7 13  2  8  0]
 [17  1  1  9  2  0]
 [ 4  2  4  4 16  0]
 [10  1  0  4  0 15]]
Epoch: [11]
       [Avg Loss]          0.747504
       [Training]   Prec@1 75.630252 Max 75.630252
       [Avg Loss]          1.314411
       [Validation] Prec@1 62.702703 Max 64.324324
Confusion matrix:
[[20  1  0  0  0  9]
 [ 0 27  4  1  0  3]
 [ 0  1 28  1  0  0]
 [15  1  4  6  1  3]
 [ 5  2  5  6 12  0]
 [ 5  0  1  1  0 23]]
Epoch: [12]
       [Avg Loss]          0.730777
       [Training]   Prec@1 72.941176 Max 75.630252
       [Avg Loss]          1.184270
       [Validation] Prec@1 65.945946 Max 65.945946
Confusion matrix:
[[18  2  1  1  0  8]
 [ 0 32  1  1  0  1]
 [ 0  3 27  0  0  0]
 [ 7  1  1 14  7  0]
 [ 0  2  7  5 16  0]
 [10  0  1  4  0 15]]
Epoch: [13]
       [Avg Loss]          0.656881
       [Training]   Prec@1 77.478992 Max 77.478992
       [Avg Loss]          1.594111
       [Validation] Prec@1 55.675676 Max 65.945946
Confusion matrix:
[[20  1  0  0  0  9]
 [ 0 30  0  0  0  5]
 [ 0  5 15  9  0  1]
 [18  1  1  4  0  6]
 [ 9  2  3  6 10  0]
 [ 3  0  1  2  0 24]]
Epoch: [14]
       [Avg Loss]          0.723631
       [Training]   Prec@1 75.294118 Max 77.478992
       [Avg Loss]          1.363612
       [Validation] Prec@1 61.081081 Max 65.945946
Confusion matrix:
[[19  3  0  0  1  7]
 [ 0 28  1  6  0  0]
 [ 0  1 22  1  6  0]
 [ 5  1  1  9 13  1]
 [ 0  1  3  6 20  0]
 [11  0  3  1  0 15]]
Fold "1" complete, final accuracy: 65.94594594594595
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.423176
       [Training]   Prec@1 44.201681 Max 44.201681
       [Avg Loss]          1.372482
       [Validation] Prec@1 64.324324 Max 64.324324
Confusion matrix:
[[12  5  1 12  0  0]
 [ 2 28  1  1  0  3]
 [ 0  0 22  7  1  0]
 [ 5 10  1  5  5  4]
 [ 1  0  7  0 22  0]
 [ 0  0  0  0  0 30]]
Epoch: [1]
       [Avg Loss]          1.182694
       [Training]   Prec@1 56.974790 Max 56.974790
       [Avg Loss]          1.149047
       [Validation] Prec@1 55.135135 Max 64.324324
Confusion matrix:
[[16  5  1  8  0  0]
 [ 2 20  1  1  0 11]
 [ 1  0  7  9 13  0]
 [11  5  3  3  3  5]
 [ 4  0  0  0 26  0]
 [ 0  0  0  0  0 30]]
Epoch: [2]
       [Avg Loss]          1.065942
       [Training]   Prec@1 61.344538 Max 61.344538
       [Avg Loss]          1.123244
       [Validation] Prec@1 69.729730 Max 69.729730
Confusion matrix:
[[13  5  3  7  1  1]
 [ 2 27  1  0  0  5]
 [ 0  0 26  4  0  0]
 [ 6  8  0 10  2  4]
 [ 2  0  1  4 23  0]
 [ 0  0  0  0  0 30]]
Epoch: [3]
       [Avg Loss]          1.039320
       [Training]   Prec@1 62.689076 Max 62.689076
       [Avg Loss]          0.972707
       [Validation] Prec@1 69.189189 Max 69.729730
Confusion matrix:
[[16  7  1  5  1  0]
 [ 5 27  1  0  0  2]
 [ 3  0 22  1  4  0]
 [ 7  5  4  8  4  2]
 [ 0  0  0  0 30  0]
 [ 1  2  0  2  0 25]]
Epoch: [4]
       [Avg Loss]          0.979379
       [Training]   Prec@1 67.058824 Max 67.058824
       [Avg Loss]          1.080646
       [Validation] Prec@1 68.648649 Max 69.729730
Confusion matrix:
[[20  5  3  1  1  0]
 [ 3 28  2  0  0  2]
 [ 4  0 24  1  1  0]
 [15  1  5  3  2  4]
 [ 2  0  5  0 23  0]
 [ 1  0  0  0  0 29]]
Epoch: [5]
       [Avg Loss]          0.883578
       [Training]   Prec@1 68.739496 Max 68.739496
       [Avg Loss]          1.104285
       [Validation] Prec@1 66.486486 Max 69.729730
Confusion matrix:
[[14  5  4  7  0  0]
 [ 2 29  1  0  0  3]
 [ 2  1 23  4  0  0]
 [ 2  8  1 11  5  3]
 [ 1  0 11  1 17  0]
 [ 1  0  0  0  0 29]]
Epoch: [6]
       [Avg Loss]          0.897553
       [Training]   Prec@1 67.731092 Max 68.739496
       [Avg Loss]          1.057514
       [Validation] Prec@1 64.864865 Max 69.729730
Confusion matrix:
[[16  6  0  6  2  0]
 [ 3 26  1  0  0  5]
 [ 2  1 16  8  3  0]
 [ 5  7  1  6  9  2]
 [ 0  0  4  0 26  0]
 [ 0  0  0  0  0 30]]
Epoch: [7]
       [Avg Loss]          0.889501
       [Training]   Prec@1 68.403361 Max 68.739496
       [Avg Loss]          1.084518
       [Validation] Prec@1 64.864865 Max 69.729730
Confusion matrix:
[[14  6  2  7  1  0]
 [ 1 28  1  0  0  5]
 [ 2  3 22  1  2  0]
 [ 6  8  1  4  8  3]
 [ 0  0  6  0 24  0]
 [ 2  0  0  0  0 28]]
Epoch: [8]
       [Avg Loss]          0.915873
       [Training]   Prec@1 68.235294 Max 68.739496
       [Avg Loss]          1.093457
       [Validation] Prec@1 59.459459 Max 69.729730
Confusion matrix:
[[ 5  4  4 16  0  1]
 [ 0 29  1  3  0  2]
 [ 1  0 19  8  2  0]
 [ 5  3  3 17  1  1]
 [ 5  0  4  3 18  0]
 [ 0  6  0  2  0 22]]
Epoch: [9]
       [Avg Loss]          0.837913
       [Training]   Prec@1 70.252101 Max 70.252101
       [Avg Loss]          1.177061
       [Validation] Prec@1 55.675676 Max 69.729730
Confusion matrix:
[[ 9  6  2 13  0  0]
 [ 7 27  1  0  0  0]
 [ 2  0 24  2  2  0]
 [11  8  0  8  2  1]
 [ 6  0  1  2 21  0]
 [16  0  0  0  0 14]]
Epoch: [10]
       [Avg Loss]          0.735675
       [Training]   Prec@1 73.445378 Max 73.445378
       [Avg Loss]          1.069971
       [Validation] Prec@1 64.324324 Max 69.729730
Confusion matrix:
[[13  3  3 11  0  0]
 [ 3 25  2  1  0  4]
 [ 5  0 14  6  5  0]
 [ 1  5  3 12  6  3]
 [ 1  0  1  2 26  0]
 [ 1  0  0  0  0 29]]
Epoch: [11]
       [Avg Loss]          0.661258
       [Training]   Prec@1 79.159664 Max 79.159664
       [Avg Loss]          0.964137
       [Validation] Prec@1 69.189189 Max 69.729730
Confusion matrix:
[[21  5  3  0  1  0]
 [ 5 27  2  1  0  0]
 [ 4  0 24  1  1  0]
 [ 6  5  2 10  3  4]
 [ 1  0  1  5 23  0]
 [ 6  1  0  0  0 23]]
Epoch: [12]
       [Avg Loss]          0.640599
       [Training]   Prec@1 76.974790 Max 79.159664
       [Avg Loss]          1.081510
       [Validation] Prec@1 66.486486 Max 69.729730
Confusion matrix:
[[12  4  2 12  0  0]
 [ 2 28  1  0  0  4]
 [ 1  0 16 12  1  0]
 [ 2  7  1 14  5  1]
 [ 0  0  0  4 26  0]
 [ 0  1  0  2  0 27]]
Epoch: [13]
       [Avg Loss]          0.631081
       [Training]   Prec@1 79.495798 Max 79.495798
       [Avg Loss]          1.230689
       [Validation] Prec@1 72.432432 Max 72.432432
Confusion matrix:
[[17  4  4  2  2  1]
 [ 2 22  3  0  0  8]
 [ 1  0 28  1  0  0]
 [ 2  4  2 11  7  4]
 [ 0  0  0  3 27  0]
 [ 1  0  0  0  0 29]]
Epoch: [14]
       [Avg Loss]          0.636362
       [Training]   Prec@1 78.319328 Max 79.495798
       [Avg Loss]          1.263514
       [Validation] Prec@1 64.324324 Max 72.432432
Confusion matrix:
[[18  4  1  7  0  0]
 [ 6 21  2  1  0  5]
 [ 7  0 16  7  0  0]
 [ 1  3  3 19  1  3]
 [ 4  0  3  4 19  0]
 [ 3  0  0  1  0 26]]
Fold "2" complete, final accuracy: 72.43243243243244
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.406331
       [Training]   Prec@1 48.636364 Max 48.636364
       [Avg Loss]          1.331476
       [Validation] Prec@1 68.333333 Max 68.333333
Confusion matrix:
[[19  0  0  0  1  0]
 [ 0 17  0  2  0  1]
 [ 1  5  5  2  7  0]
 [ 5  0  0  8  5  2]
 [ 0  0  0  5 15  0]
 [ 0  2  0  0  0 18]]
Epoch: [1]
       [Avg Loss]          1.090731
       [Training]   Prec@1 61.969697 Max 61.969697
       [Avg Loss]          0.874054
       [Validation] Prec@1 70.833333 Max 70.833333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 20  0  0  0  0]
 [ 0  1 13  4  2  0]
 [ 4  2  3  9  0  2]
 [ 0  0  4 11  5  0]
 [ 1  1  0  0  0 18]]
Epoch: [2]
       [Avg Loss]          1.011467
       [Training]   Prec@1 64.090909 Max 64.090909
       [Avg Loss]          0.906199
       [Validation] Prec@1 68.333333 Max 70.833333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 18  0  2  0  0]
 [ 1  1  5 12  1  0]
 [ 3  0  0 15  0  2]
 [ 0  0  0 15  5  0]
 [ 0  0  0  1  0 19]]
Epoch: [3]
       [Avg Loss]          1.023352
       [Training]   Prec@1 66.666667 Max 66.666667
       [Avg Loss]          0.603466
       [Validation] Prec@1 80.833333 Max 80.833333
Confusion matrix:
[[16  0  0  4  0  0]
 [ 0 17  1  1  0  1]
 [ 0  1 16  0  3  0]
 [ 3  1  0 13  1  2]
 [ 0  0  1  2 17  0]
 [ 0  2  0  0  0 18]]
Epoch: [4]
       [Avg Loss]          0.865932
       [Training]   Prec@1 68.333333 Max 68.333333
       [Avg Loss]          0.939315
       [Validation] Prec@1 62.500000 Max 80.833333
Confusion matrix:
[[18  0  0  2  0  0]
 [ 0 16  0  1  0  3]
 [ 1  4 10  5  0  0]
 [ 4  1  3 12  0  0]
 [ 0  0  9 11  0  0]
 [ 0  1  0  0  0 19]]
Epoch: [5]
       [Avg Loss]          0.993115
       [Training]   Prec@1 63.484848 Max 68.333333
       [Avg Loss]          1.050511
       [Validation] Prec@1 65.000000 Max 80.833333
Confusion matrix:
[[17  0  0  0  3  0]
 [ 1 12  0  0  0  7]
 [ 0  3  2  8  7  0]
 [ 5  1  0  9  3  2]
 [ 0  0  0  1 19  0]
 [ 0  1  0  0  0 19]]
Epoch: [6]
       [Avg Loss]          0.929660
       [Training]   Prec@1 67.878788 Max 68.333333
       [Avg Loss]          0.926788
       [Validation] Prec@1 69.166667 Max 80.833333
Confusion matrix:
[[18  0  1  0  1  0]
 [ 0 10  0 10  0  0]
 [ 0  0 16  4  0  0]
 [ 4  0  1 15  0  0]
 [ 0  0  6  6  8  0]
 [ 0  2  0  2  0 16]]
Epoch: [7]
       [Avg Loss]          0.893239
       [Training]   Prec@1 69.848485 Max 69.848485
       [Avg Loss]          0.609546
       [Validation] Prec@1 78.333333 Max 80.833333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 18  1  1  0  0]
 [ 0  0 15  5  0  0]
 [ 1  1  1 14  2  1]
 [ 0  0  6  4 10  0]
 [ 0  2  0  1  0 17]]
Epoch: [8]
       [Avg Loss]          0.768828
       [Training]   Prec@1 71.666667 Max 71.666667
       [Avg Loss]          0.777331
       [Validation] Prec@1 70.000000 Max 80.833333
Confusion matrix:
[[17  0  0  3  0  0]
 [ 0 15  0  0  0  5]
 [ 1  1  4  3 11  0]
 [ 3  1  2  9  4  1]
 [ 0  0  0  0 20  0]
 [ 0  1  0  0  0 19]]
Epoch: [9]
       [Avg Loss]          0.715609
       [Training]   Prec@1 74.696970 Max 74.696970
       [Avg Loss]          0.589498
       [Validation] Prec@1 77.500000 Max 80.833333
Confusion matrix:
[[19  0  0  1  0  0]
 [ 1 19  0  0  0  0]
 [ 0  0 14  4  2  0]
 [ 4  1  2 11  1  1]
 [ 0  0  1  6 13  0]
 [ 0  3  0  0  0 17]]
Epoch: [10]
       [Avg Loss]          0.696503
       [Training]   Prec@1 75.909091 Max 75.909091
       [Avg Loss]          0.749562
       [Validation] Prec@1 77.500000 Max 80.833333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 20  0  0  0  0]
 [ 0  1 19  0  0  0]
 [ 4  1  4  9  1  1]
 [ 0  0  8  2 10  0]
 [ 0  4  0  1  0 15]]
Epoch: [11]
       [Avg Loss]          0.673097
       [Training]   Prec@1 75.303030 Max 75.909091
       [Avg Loss]          0.769127
       [Validation] Prec@1 73.333333 Max 80.833333
Confusion matrix:
[[15  0  0  4  1  0]
 [ 1 15  1  0  0  3]
 [ 0  0 20  0  0  0]
 [ 3  1  0 14  0  2]
 [ 0  0  8  7  5  0]
 [ 0  1  0  0  0 19]]
Epoch: [12]
       [Avg Loss]          0.711161
       [Training]   Prec@1 75.454545 Max 75.909091
       [Avg Loss]          1.055485
       [Validation] Prec@1 65.000000 Max 80.833333
Confusion matrix:
[[19  0  1  0  0  0]
 [ 0 20  0  0  0  0]
 [ 0  1  6 13  0  0]
 [ 5  1  0 12  1  1]
 [ 0  0  0 12  8  0]
 [ 3  4  0  0  0 13]]
Epoch: [13]
       [Avg Loss]          0.606786
       [Training]   Prec@1 79.242424 Max 79.242424
       [Avg Loss]          0.449570
       [Validation] Prec@1 82.500000 Max 82.500000
Confusion matrix:
[[19  0  0  1  0  0]
 [ 1 18  0  0  0  1]
 [ 0  0 17  3  0  0]
 [ 1  1  0 14  1  3]
 [ 0  0  2  6 12  0]
 [ 0  1  0  0  0 19]]
Epoch: [14]
       [Avg Loss]          0.556221
       [Training]   Prec@1 81.818182 Max 81.818182
       [Avg Loss]          0.617054
       [Validation] Prec@1 81.666667 Max 82.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 17  3  0  0]
 [ 4  0  2 14  0  0]
 [ 0  0  1  6 13  0]
 [ 0  2  0  3  0 15]]
Fold "3" complete, final accuracy: 82.5
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.355863
       [Training]   Prec@1 48.507463 Max 48.507463
       [Avg Loss]          1.536661
       [Validation] Prec@1 54.545455 Max 54.545455
Confusion matrix:
[[13  4  2  0  0  1]
 [ 3  8  4  0  5  0]
 [ 6  0 13  0  0  1]
 [ 0  9  6  0  3  2]
 [ 0  0  0  0 10  0]
 [ 0  4  0  0  0 16]]
Epoch: [1]
       [Avg Loss]          1.055131
       [Training]   Prec@1 60.597015 Max 60.597015
       [Avg Loss]          1.618227
       [Validation] Prec@1 57.272727 Max 57.272727
Confusion matrix:
[[11  5  3  0  1  0]
 [ 0  7  8  0  5  0]
 [ 8  0 11  0  0  1]
 [ 0  6  2 12  0  0]
 [ 0  0  1  0  9  0]
 [ 0  7  0  0  0 13]]
Epoch: [2]
       [Avg Loss]          0.934655
       [Training]   Prec@1 65.522388 Max 65.522388
       [Avg Loss]          1.588680
       [Validation] Prec@1 53.636364 Max 57.272727
Confusion matrix:
[[ 9  2  1  1  4  3]
 [ 0 11  6  0  3  0]
 [ 6  0 12  1  0  1]
 [ 0 12  2  5  1  0]
 [ 0  0  7  0  3  0]
 [ 0  1  0  0  0 19]]
Epoch: [3]
       [Avg Loss]          0.950809
       [Training]   Prec@1 65.970149 Max 65.970149
       [Avg Loss]          2.012890
       [Validation] Prec@1 47.272727 Max 57.272727
Confusion matrix:
[[13  1  0  2  3  1]
 [ 3  7  2  2  6  0]
 [ 8  0  0  1 11  0]
 [ 0  5  0 13  2  0]
 [ 0  0  0  0 10  0]
 [10  1  0  0  0  9]]
Epoch: [4]
       [Avg Loss]          0.909363
       [Training]   Prec@1 67.164179 Max 67.164179
       [Avg Loss]          1.495574
       [Validation] Prec@1 56.363636 Max 57.272727
Confusion matrix:
[[10  4  2  4  0  0]
 [ 0  2  1  9  7  1]
 [ 6  0  6  2  5  1]
 [ 0  2  0 15  3  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [5]
       [Avg Loss]          0.869177
       [Training]   Prec@1 70.149254 Max 70.149254
       [Avg Loss]          1.372685
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[14  2  1  1  0  2]
 [ 0  8  7  2  2  1]
 [ 7  0 12  0  0  1]
 [ 0  9  0 11  0  0]
 [ 0  0  4  0  6  0]
 [ 4  1  0  0  0 15]]
Epoch: [6]
       [Avg Loss]          0.788197
       [Training]   Prec@1 71.343284 Max 71.343284
       [Avg Loss]          1.429059
       [Validation] Prec@1 55.454545 Max 60.000000
Confusion matrix:
[[ 2  4  3 11  0  0]
 [ 0  6  8  1  4  1]
 [ 6  0 11  1  1  1]
 [ 0  5  1 14  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  1  0 18]]
Epoch: [7]
       [Avg Loss]          0.695755
       [Training]   Prec@1 75.522388 Max 75.522388
       [Avg Loss]          1.571413
       [Validation] Prec@1 63.636364 Max 63.636364
Confusion matrix:
[[13  3  1  2  0  1]
 [ 4  7  3  2  3  1]
 [ 8  0 11  0  0  1]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 1  4  0  0  0 15]]
Epoch: [8]
       [Avg Loss]          0.635863
       [Training]   Prec@1 78.955224 Max 78.955224
       [Avg Loss]          1.498905
       [Validation] Prec@1 61.818182 Max 63.636364
Confusion matrix:
[[ 9  3  2  6  0  0]
 [ 0  7  3  6  3  1]
 [ 7  1 11  1  0  0]
 [ 0  5  0 15  0  0]
 [ 0  0  0  0 10  0]
 [ 1  2  0  1  0 16]]
Epoch: [9]
       [Avg Loss]          0.574301
       [Training]   Prec@1 80.447761 Max 80.447761
       [Avg Loss]          1.489330
       [Validation] Prec@1 64.545455 Max 64.545455
Confusion matrix:
[[12  2  0  6  0  0]
 [ 0  7  2  5  5  1]
 [ 6  0  9  1  3  1]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [10]
       [Avg Loss]          0.607811
       [Training]   Prec@1 78.208955 Max 80.447761
       [Avg Loss]          1.837222
       [Validation] Prec@1 56.363636 Max 64.545455
Confusion matrix:
[[13  5  0  2  0  0]
 [ 1  7  3  2  6  1]
 [ 9  0 11  0  0  0]
 [ 0  6  0 14  0  0]
 [ 0  0  7  0  3  0]
 [ 5  1  0  0  0 14]]
Epoch: [11]
       [Avg Loss]          0.515428
       [Training]   Prec@1 81.940299 Max 81.940299
       [Avg Loss]          1.530533
       [Validation] Prec@1 57.272727 Max 64.545455
Confusion matrix:
[[12  4  1  3  0  0]
 [ 0  6  3  5  5  1]
 [ 7  0 11  1  0  1]
 [ 0  2  0 18  0  0]
 [ 0  0  1  1  8  0]
 [ 9  1  0  2  0  8]]
Epoch: [12]
       [Avg Loss]          0.472356
       [Training]   Prec@1 83.134328 Max 83.134328
       [Avg Loss]          1.610240
       [Validation] Prec@1 60.909091 Max 64.545455
Confusion matrix:
[[14  3  1  2  0  0]
 [ 0  7  2  3  7  1]
 [ 8  0  6  1  5  0]
 [ 0  5  0 15  0  0]
 [ 0  0  0  0 10  0]
 [ 2  2  0  1  0 15]]
Epoch: [13]
       [Avg Loss]          0.529155
       [Training]   Prec@1 81.044776 Max 83.134328
       [Avg Loss]          1.734936
       [Validation] Prec@1 54.545455 Max 64.545455
Confusion matrix:
[[12  4  1  3  0  0]
 [ 1  7  4  5  2  1]
 [ 8  0 11  1  0  0]
 [ 0  5  0 15  0  0]
 [ 0  0  5  2  3  0]
 [ 6  1  0  1  0 12]]
Epoch: [14]
       [Avg Loss]          0.486935
       [Training]   Prec@1 82.835821 Max 83.134328
       [Avg Loss]          1.628153
       [Validation] Prec@1 59.090909 Max 64.545455
Confusion matrix:
[[13  3  1  2  1  0]
 [ 0  7  6  1  5  1]
 [ 7  0 11  1  0  1]
 [ 0  6  0 14  0  0]
 [ 0  0  6  0  4  0]
 [ 2  1  0  1  0 16]]
Fold "4" complete, final accuracy: 64.54545454545455

-----------------------------------------------------------------------
Training for stage 6 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=5)")
Average accuracy is: 70.64032214032214


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 7-----
Evaluated preprocessing: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=5)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.533352
       [Training]   Prec@1 40.000000 Max 40.000000
       [Avg Loss]          1.755669
       [Validation] Prec@1 20.000000 Max 20.000000
Confusion matrix:
[[ 6  0 31  3  0  0]
 [14  0 16  0  0  0]
 [ 0  0 30  0  0  0]
 [ 2  0 28  0  0  0]
 [ 0  0 30  0  0  0]
 [ 8  0  3  9  0  0]]
Epoch: [1]
       [Avg Loss]          1.185800
       [Training]   Prec@1 56.000000 Max 56.000000
       [Avg Loss]          1.722519
       [Validation] Prec@1 27.777778 Max 27.777778
Confusion matrix:
[[ 8  0  1  0 31  0]
 [ 1  1 10  0 18  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 30  0]
 [ 7  0  4  1  2  6]]
Epoch: [2]
       [Avg Loss]          1.102585
       [Training]   Prec@1 59.333333 Max 59.333333
       [Avg Loss]          1.775780
       [Validation] Prec@1 21.111111 Max 27.777778
Confusion matrix:
[[ 2 30  0  0  0  8]
 [ 3 23  0  2  0  2]
 [ 0 29  1  0  0  0]
 [ 0 27  0  0  3  0]
 [ 0 24  3  0  3  0]
 [ 5  6  0  0  0  9]]
Epoch: [3]
       [Avg Loss]          1.039051
       [Training]   Prec@1 60.166667 Max 60.166667
       [Avg Loss]          1.698516
       [Validation] Prec@1 31.666667 Max 31.666667
Confusion matrix:
[[29  0  6  0  0  5]
 [27  0  0  2  0  1]
 [11  4 14  0  1  0]
 [ 5  5 11  0  9  0]
 [12  1 10  1  6  0]
 [11  0  0  1  0  8]]
Epoch: [4]
       [Avg Loss]          1.004324
       [Training]   Prec@1 62.166667 Max 62.166667
       [Avg Loss]          2.481514
       [Validation] Prec@1 21.666667 Max 31.666667
Confusion matrix:
[[22  0  0  8  0 10]
 [20  0  0  7  0  3]
 [28  0  0  2  0  0]
 [27  0  0  3  0  0]
 [24  0  0  6  0  0]
 [ 4  0  0  2  0 14]]
Epoch: [5]
       [Avg Loss]          1.024172
       [Training]   Prec@1 62.333333 Max 62.333333
       [Avg Loss]          1.912456
       [Validation] Prec@1 30.000000 Max 31.666667
Confusion matrix:
[[18  0  0 11  1 10]
 [14  1  0  3  0 12]
 [ 6  9  7  6  2  0]
 [ 6  3  6  5 10  0]
 [ 6  4  2 15  3  0]
 [ 0  0  0  0  0 20]]
Epoch: [6]
       [Avg Loss]          0.894864
       [Training]   Prec@1 66.000000 Max 66.000000
       [Avg Loss]          2.732065
       [Validation] Prec@1 35.555556 Max 35.555556
Confusion matrix:
[[ 1  0  2  3 25  9]
 [ 5  7  4  5  7  2]
 [ 0  0 17  0 13  0]
 [ 0  2  7  0 21  0]
 [ 0  0  6  0 24  0]
 [ 3  0  0  2  0 15]]
Epoch: [7]
       [Avg Loss]          0.927617
       [Training]   Prec@1 67.333333 Max 67.333333
       [Avg Loss]          2.107981
       [Validation] Prec@1 39.444444 Max 39.444444
Confusion matrix:
[[19  6  6  0  0  9]
 [ 9 19  0  0  0  2]
 [ 1  7 22  0  0  0]
 [ 3 10 15  0  2  0]
 [ 6  5 18  1  0  0]
 [ 0  9  0  0  0 11]]
Epoch: [8]
       [Avg Loss]          0.856225
       [Training]   Prec@1 68.166667 Max 68.166667
       [Avg Loss]          2.511799
       [Validation] Prec@1 30.000000 Max 39.444444
Confusion matrix:
[[ 0  0 12  6 14  8]
 [ 3  4  9  8  6  0]
 [ 0  0 23  0  7  0]
 [ 0  0 10  0 20  0]
 [ 0  0 10  1 19  0]
 [ 7  0  0  5  0  8]]
Epoch: [9]
       [Avg Loss]          0.796161
       [Training]   Prec@1 71.333333 Max 71.333333
       [Avg Loss]          2.040071
       [Validation] Prec@1 44.444444 Max 44.444444
Confusion matrix:
[[18  7  2  2  2  9]
 [ 6 18  0  0  0  6]
 [ 0  8 20  1  1  0]
 [ 2  5 14  0  9  0]
 [ 2  5 15  1  7  0]
 [ 0  3  0  0  0 17]]
Epoch: [10]
       [Avg Loss]          0.816400
       [Training]   Prec@1 70.000000 Max 71.333333
       [Avg Loss]          2.215147
       [Validation] Prec@1 38.888889 Max 44.444444
Confusion matrix:
[[ 3  1 13  6  8  9]
 [ 4 11  3  4  3  5]
 [ 0  0 25  0  5  0]
 [ 0  0 16  0 14  0]
 [ 0  0 16  1 13  0]
 [ 0  0  0  2  0 18]]
Epoch: [11]
       [Avg Loss]          0.762415
       [Training]   Prec@1 71.166667 Max 71.333333
       [Avg Loss]          2.058425
       [Validation] Prec@1 34.444444 Max 44.444444
Confusion matrix:
[[ 2  2 21  1  6  8]
 [ 8 18  3  0  1  0]
 [ 0  0 28  0  2  0]
 [ 0  1 19  0 10  0]
 [ 0  0 20  0 10  0]
 [ 9  0  1  6  0  4]]
Epoch: [12]
       [Avg Loss]          0.712535
       [Training]   Prec@1 74.166667 Max 74.166667
       [Avg Loss]          2.615938
       [Validation] Prec@1 32.777778 Max 44.444444
Confusion matrix:
[[ 5 25  0  0  0 10]
 [ 3 22  0  0  0  5]
 [ 0 20  9  1  0  0]
 [ 2  8 14  1  5  0]
 [ 0 23  2  0  5  0]
 [ 1  2  0  0  0 17]]
Epoch: [13]
       [Avg Loss]          0.728846
       [Training]   Prec@1 73.000000 Max 74.166667
       [Avg Loss]          2.356006
       [Validation] Prec@1 40.000000 Max 44.444444
Confusion matrix:
[[ 4 15  4  4  4  9]
 [ 4 20  0  0  0  6]
 [ 0  5 19  0  6  0]
 [ 0  5 11  0 14  0]
 [ 0 13  4  2 11  0]
 [ 0  2  0  0  0 18]]
Epoch: [14]
       [Avg Loss]          0.699486
       [Training]   Prec@1 73.333333 Max 74.166667
       [Avg Loss]          1.731021
       [Validation] Prec@1 42.222222 Max 44.444444
Confusion matrix:
[[21  1  4  5  0  9]
 [15  9  2  0  0  4]
 [ 1  1 26  1  1  0]
 [ 0  0 18  2 10  0]
 [ 1  4 13  5  7  0]
 [ 7  0  0  2  0 11]]
Fold "0" complete, final accuracy: 44.44444444444444
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.684394
       [Training]   Prec@1 32.941176 Max 32.941176
       [Avg Loss]          1.741149
       [Validation] Prec@1 27.027027 Max 27.027027
Confusion matrix:
[[ 0 18 12  0  0  0]
 [ 0 28  7  0  0  0]
 [ 0 14 13  0  3  0]
 [ 1  4 15  0 10  0]
 [ 5  3 13  0  9  0]
 [ 7 16  7  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.382249
       [Training]   Prec@1 46.890756 Max 46.890756
       [Avg Loss]          1.472444
       [Validation] Prec@1 49.189189 Max 49.189189
Confusion matrix:
[[12  9  6  0  0  3]
 [ 8 17 10  0  0  0]
 [ 0  2 24  0  4  0]
 [ 3  0  9  1 11  6]
 [16  0  2  0 12  0]
 [ 4  1  0  0  0 25]]
Epoch: [2]
       [Avg Loss]          1.252594
       [Training]   Prec@1 52.941176 Max 52.941176
       [Avg Loss]          1.364759
       [Validation] Prec@1 44.324324 Max 49.189189
Confusion matrix:
[[29  1  0  0  0  0]
 [26  8  1  0  0  0]
 [19  2  9  0  0  0]
 [15  0  0  8  7  0]
 [15  0  1  4 10  0]
 [10  1  0  1  0 18]]
Epoch: [3]
       [Avg Loss]          1.164587
       [Training]   Prec@1 55.462185 Max 55.462185
       [Avg Loss]          1.200429
       [Validation] Prec@1 54.054054 Max 54.054054
Confusion matrix:
[[16 10  0  3  0  1]
 [ 6 28  1  0  0  0]
 [ 5  6 14  1  4  0]
 [11  0  1  5 10  3]
 [12  0  1  6 11  0]
 [ 1  3  0  0  0 26]]
Epoch: [4]
       [Avg Loss]          1.079991
       [Training]   Prec@1 59.831933 Max 59.831933
       [Avg Loss]          1.537947
       [Validation] Prec@1 44.864865 Max 54.054054
Confusion matrix:
[[12 18  0  0  0  0]
 [ 1 34  0  0  0  0]
 [ 3 14  0  0 13  0]
 [13  3  0  6  6  2]
 [11  7  0  0 12  0]
 [ 1  9  0  1  0 19]]
Epoch: [5]
       [Avg Loss]          1.076381
       [Training]   Prec@1 60.672269 Max 60.672269
       [Avg Loss]          1.407879
       [Validation] Prec@1 54.054054 Max 54.054054
Confusion matrix:
[[11 16  0  0  0  3]
 [ 0 35  0  0  0  0]
 [ 1 17 11  0  1  0]
 [ 8  3  3  7  7  2]
 [ 5  8  2  4 11  0]
 [ 0  4  0  1  0 25]]
Epoch: [6]
       [Avg Loss]          1.016497
       [Training]   Prec@1 60.672269 Max 60.672269
       [Avg Loss]          1.324603
       [Validation] Prec@1 57.837838 Max 57.837838
Confusion matrix:
[[18  2  0  1  0  9]
 [ 1 33  0  0  0  1]
 [ 4 11 14  1  0  0]
 [ 9  2  1 12  0  6]
 [10  7  2  8  3  0]
 [ 1  2  0  0  0 27]]
Epoch: [7]
       [Avg Loss]          0.945367
       [Training]   Prec@1 65.546218 Max 65.546218
       [Avg Loss]          1.187549
       [Validation] Prec@1 55.675676 Max 57.837838
Confusion matrix:
[[ 4  7  1  9  0  9]
 [ 0 35  0  0  0  0]
 [ 2  9 16  3  0  0]
 [ 2  1  3 16  6  2]
 [ 0  0  1 18 11  0]
 [ 0  4  0  5  0 21]]
Epoch: [8]
       [Avg Loss]          0.836378
       [Training]   Prec@1 71.932773 Max 71.932773
       [Avg Loss]          1.289389
       [Validation] Prec@1 58.378378 Max 58.378378
Confusion matrix:
[[11  5  0  2  0 12]
 [ 0 34  0  0  0  1]
 [ 1 12 13  2  2  0]
 [ 5  1  2  9 10  3]
 [ 2  7  1  5 14  1]
 [ 0  3  0  0  0 27]]
Epoch: [9]
       [Avg Loss]          0.843140
       [Training]   Prec@1 71.596639 Max 71.932773
       [Avg Loss]          1.960045
       [Validation] Prec@1 50.810811 Max 58.378378
Confusion matrix:
[[ 5  2 23  0  0  0]
 [ 0 20 15  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 14  8  6  2]
 [ 0  3  9  8 10  0]
 [ 2  3  1  3  0 21]]
Epoch: [10]
       [Avg Loss]          0.870886
       [Training]   Prec@1 68.739496 Max 71.932773
       [Avg Loss]          1.619935
       [Validation] Prec@1 48.108108 Max 58.378378
Confusion matrix:
[[ 4 20  0  0  0  6]
 [ 0 35  0  0  0  0]
 [ 3 16  6  5  0  0]
 [ 6  4  1 14  0  5]
 [ 7 10  1  6  5  1]
 [ 0  5  0  0  0 25]]
Epoch: [11]
       [Avg Loss]          0.814182
       [Training]   Prec@1 69.243697 Max 71.932773
       [Avg Loss]          1.336545
       [Validation] Prec@1 55.675676 Max 58.378378
Confusion matrix:
[[18  0  9  1  2  0]
 [ 8 13 10  3  1  0]
 [ 0  0 28  0  2  0]
 [ 1  0 10  8 11  0]
 [ 1  0  2  8 19  0]
 [ 1  2  1  9  0 17]]
Epoch: [12]
       [Avg Loss]          0.726501
       [Training]   Prec@1 74.453782 Max 74.453782
       [Avg Loss]          1.012774
       [Validation] Prec@1 63.783784 Max 63.783784
Confusion matrix:
[[13  9  2  1  0  5]
 [ 0 35  0  0  0  0]
 [ 0  6 24  0  0  0]
 [ 2  2  5 10  9  2]
 [ 2  6  3  5 14  0]
 [ 1  5  0  2  0 22]]
Epoch: [13]
       [Avg Loss]          0.648069
       [Training]   Prec@1 78.319328 Max 78.319328
       [Avg Loss]          1.191978
       [Validation] Prec@1 61.081081 Max 63.783784
Confusion matrix:
[[16  0  8  0  0  6]
 [ 1 26  8  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  0 15  5  4  5]
 [ 3  2  6  9 10  0]
 [ 2  2  0  0  0 26]]
Epoch: [14]
       [Avg Loss]          0.632116
       [Training]   Prec@1 78.823529 Max 78.823529
       [Avg Loss]          1.148141
       [Validation] Prec@1 62.702703 Max 63.783784
Confusion matrix:
[[19  4  5  1  0  1]
 [ 0 34  1  0  0  0]
 [ 0  2 26  0  2  0]
 [ 1  0 10  6 11  2]
 [ 2  5  3  5 15  0]
 [ 6  3  1  4  0 16]]
Fold "1" complete, final accuracy: 63.78378378378378
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.688670
       [Training]   Prec@1 31.428571 Max 31.428571
       [Avg Loss]          1.720114
       [Validation] Prec@1 17.837838 Max 17.837838
Confusion matrix:
[[ 3  0  0  0 27  0]
 [ 4  0  0  0 31  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 30  0]
 [11  1  0  0 18  0]]
Epoch: [1]
       [Avg Loss]          1.425096
       [Training]   Prec@1 43.865546 Max 43.865546
       [Avg Loss]          1.572248
       [Validation] Prec@1 39.459459 Max 39.459459
Confusion matrix:
[[ 2  0  0 12 16  0]
 [ 9  0  0  4 21  1]
 [ 0  0  0 10 20  0]
 [ 0  0  0 26  4  0]
 [ 0  0  0  2 28  0]
 [13  0  0  0  0 17]]
Epoch: [2]
       [Avg Loss]          1.314564
       [Training]   Prec@1 49.243697 Max 49.243697
       [Avg Loss]          1.491490
       [Validation] Prec@1 30.810811 Max 39.459459
Confusion matrix:
[[ 9 21  0  0  0  0]
 [ 1 34  0  0  0  0]
 [16 13  1  0  0  0]
 [ 6 10  0 10  0  4]
 [ 5 18  6  0  1  0]
 [ 5 23  0  0  0  2]]
Epoch: [3]
       [Avg Loss]          1.223510
       [Training]   Prec@1 50.084034 Max 50.084034
       [Avg Loss]          1.100902
       [Validation] Prec@1 58.918919 Max 58.918919
Confusion matrix:
[[23  0  1  0  0  6]
 [16  3  4  0  0 12]
 [ 1  0 17  3  9  0]
 [ 8  0  1 10  4  7]
 [ 4  0  0  0 26  0]
 [ 0  0  0  0  0 30]]
Epoch: [4]
       [Avg Loss]          1.191395
       [Training]   Prec@1 54.957983 Max 54.957983
       [Avg Loss]          1.515588
       [Validation] Prec@1 42.702703 Max 58.918919
Confusion matrix:
[[19  0  7  0  4  0]
 [ 5  6 12  0 11  1]
 [ 0  0 10  0 20  0]
 [ 0  0  0  6 24  0]
 [ 0  0  0  0 30  0]
 [12 10  0  0  0  8]]
Epoch: [5]
       [Avg Loss]          1.107594
       [Training]   Prec@1 56.638655 Max 56.638655
       [Avg Loss]          1.368087
       [Validation] Prec@1 47.567568 Max 58.918919
Confusion matrix:
[[13 11  0  0  0  6]
 [ 4 23  0  0  0  8]
 [23  5  1  0  0  1]
 [ 9  2  0 11  0  8]
 [ 4  7  6  3 10  0]
 [ 0  0  0  0  0 30]]
Epoch: [6]
       [Avg Loss]          1.078903
       [Training]   Prec@1 59.663866 Max 59.663866
       [Avg Loss]          1.240393
       [Validation] Prec@1 52.972973 Max 58.918919
Confusion matrix:
[[ 8 13  5  1  3  0]
 [ 2 23  8  0  1  1]
 [ 0  0 25  0  5  0]
 [ 1  0 18  4  7  0]
 [ 0  0 12  0 18  0]
 [ 0 10  0  0  0 20]]
Epoch: [7]
       [Avg Loss]          1.066870
       [Training]   Prec@1 60.336134 Max 60.336134
       [Avg Loss]          1.329947
       [Validation] Prec@1 56.216216 Max 58.918919
Confusion matrix:
[[19  0  1  6  3  1]
 [10 13  0  4  3  5]
 [ 0  0  5  3 22  0]
 [ 0  0  0  9 21  0]
 [ 0  0  0  0 30  0]
 [ 1  1  0  0  0 28]]
Epoch: [8]
       [Avg Loss]          0.968236
       [Training]   Prec@1 65.714286 Max 65.714286
       [Avg Loss]          0.957261
       [Validation] Prec@1 60.540541 Max 60.540541
Confusion matrix:
[[17  8  0  0  0  5]
 [ 4 24  0  0  0  7]
 [10  1 19  0  0  0]
 [ 8  2  3 11  5  1]
 [ 5  6  7  0 12  0]
 [ 0  1  0  0  0 29]]
Epoch: [9]
       [Avg Loss]          0.887127
       [Training]   Prec@1 68.403361 Max 68.403361
       [Avg Loss]          0.929518
       [Validation] Prec@1 65.405405 Max 65.405405
Confusion matrix:
[[23  5  1  0  0  1]
 [ 7 23  3  0  0  2]
 [ 5  0 19  6  0  0]
 [ 7  2  0 12  6  3]
 [ 2  1  3  5 19  0]
 [ 1  4  0  0  0 25]]
Epoch: [10]
       [Avg Loss]          0.845590
       [Training]   Prec@1 68.067227 Max 68.403361
       [Avg Loss]          1.225798
       [Validation] Prec@1 54.054054 Max 65.405405
Confusion matrix:
[[30  0  0  0  0  0]
 [29  3  0  0  0  3]
 [ 9  0  5 16  0  0]
 [ 8  0  0 20  2  0]
 [11  0  0  5 14  0]
 [ 2  0  0  0  0 28]]
Epoch: [11]
       [Avg Loss]          0.751922
       [Training]   Prec@1 75.294118 Max 75.294118
       [Avg Loss]          0.954783
       [Validation] Prec@1 69.189189 Max 69.189189
Confusion matrix:
[[23  3  2  0  2  0]
 [ 8 16  7  2  0  2]
 [ 1  0 18  0 11  0]
 [ 0  2  1 16 11  0]
 [ 0  0  0  0 30  0]
 [ 2  3  0  0  0 25]]
Epoch: [12]
       [Avg Loss]          0.772139
       [Training]   Prec@1 71.092437 Max 75.294118
       [Avg Loss]          0.856093
       [Validation] Prec@1 69.729730 Max 69.729730
Confusion matrix:
[[23  3  0  0  1  3]
 [ 8 22  1  0  0  4]
 [ 3  1 15  5  6  0]
 [ 5  0  0 13 12  0]
 [ 1  0  0  1 28  0]
 [ 0  2  0  0  0 28]]
Epoch: [13]
       [Avg Loss]          0.672256
       [Training]   Prec@1 75.630252 Max 75.630252
       [Avg Loss]          0.924264
       [Validation] Prec@1 71.351351 Max 71.351351
Confusion matrix:
[[20  2  1  3  3  1]
 [ 4 19  2  3  3  4]
 [ 0  0 23  6  1  0]
 [ 0  1  3 19  7  0]
 [ 0  0  2  0 28  0]
 [ 1  6  0  0  0 23]]
Epoch: [14]
       [Avg Loss]          0.738699
       [Training]   Prec@1 72.773109 Max 75.630252
       [Avg Loss]          1.183327
       [Validation] Prec@1 53.513514 Max 71.351351
Confusion matrix:
[[22  7  0  1  0  0]
 [ 6 27  1  1  0  0]
 [11  1  9  9  0  0]
 [13  1  0 12  4  0]
 [11  2  0  1 16  0]
 [ 5 12  0  0  0 13]]
Fold "2" complete, final accuracy: 71.35135135135135
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.613213
       [Training]   Prec@1 37.121212 Max 37.121212
       [Avg Loss]          1.695334
       [Validation] Prec@1 30.000000 Max 30.000000
Confusion matrix:
[[15  5  0  0  0  0]
 [ 4 16  0  0  0  0]
 [15  5  0  0  0  0]
 [19  1  0  0  0  0]
 [20  0  0  0  0  0]
 [ 5 10  0  0  0  5]]
Epoch: [1]
       [Avg Loss]          1.353791
       [Training]   Prec@1 46.818182 Max 46.818182
       [Avg Loss]          1.891233
       [Validation] Prec@1 16.666667 Max 30.000000
Confusion matrix:
[[ 0  0  0  0  0 20]
 [ 0  0  0  0  0 20]
 [ 4  0  0  0  0 16]
 [ 0  0  0  0  0 20]
 [ 3  0  0  0  0 17]
 [ 0  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          1.314477
       [Training]   Prec@1 48.484848 Max 48.484848
       [Avg Loss]          1.503156
       [Validation] Prec@1 30.833333 Max 30.833333
Confusion matrix:
[[ 0  0  3  0 17  0]
 [ 7  0  5  0  8  0]
 [ 0  0 14  0  6  0]
 [ 1  0  2  5 12  0]
 [ 0  0  2  0 18  0]
 [16  1  0  3  0  0]]
Epoch: [3]
       [Avg Loss]          1.216470
       [Training]   Prec@1 50.151515 Max 50.151515
       [Avg Loss]          1.019940
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[15  0  1  4  0  0]
 [11  6  0  1  0  2]
 [ 3  0 14  0  3  0]
 [ 2  0  2 15  0  1]
 [ 4  0 10  0  6  0]
 [ 1  2  0  1  0 16]]
Epoch: [4]
       [Avg Loss]          1.090594
       [Training]   Prec@1 56.212121 Max 56.212121
       [Avg Loss]          1.149331
       [Validation] Prec@1 56.666667 Max 60.000000
Confusion matrix:
[[16  4  0  0  0  0]
 [ 6 11  0  1  0  2]
 [ 8  1  0  4  7  0]
 [ 6  0  0 13  0  1]
 [ 1  4  0  1 14  0]
 [ 3  3  0  0  0 14]]
Epoch: [5]
       [Avg Loss]          1.082937
       [Training]   Prec@1 60.151515 Max 60.151515
       [Avg Loss]          1.316748
       [Validation] Prec@1 50.833333 Max 60.000000
Confusion matrix:
[[15  0  0  4  1  0]
 [ 8  9  0  1  0  2]
 [ 5  1  0 12  2  0]
 [ 3  0  0 14  3  0]
 [10  0  0  0 10  0]
 [ 6  0  0  1  0 13]]
Epoch: [6]
       [Avg Loss]          0.991717
       [Training]   Prec@1 61.363636 Max 61.363636
       [Avg Loss]          1.166860
       [Validation] Prec@1 58.333333 Max 60.000000
Confusion matrix:
[[15  4  0  1  0  0]
 [ 1 19  0  0  0  0]
 [ 3  2 12  3  0  0]
 [ 4  0  2 13  0  1]
 [ 0 10 10  0  0  0]
 [ 6  3  0  0  0 11]]
Epoch: [7]
       [Avg Loss]          0.940294
       [Training]   Prec@1 65.606061 Max 65.606061
       [Avg Loss]          1.054600
       [Validation] Prec@1 62.500000 Max 62.500000
Confusion matrix:
[[13  0  2  5  0  0]
 [ 2 16  0  1  0  1]
 [ 3  0  9  4  4  0]
 [ 1  0  0 18  1  0]
 [ 2  2  0  2 14  0]
 [ 6  3  1  5  0  5]]
Epoch: [8]
       [Avg Loss]          0.853680
       [Training]   Prec@1 68.939394 Max 68.939394
       [Avg Loss]          1.338895
       [Validation] Prec@1 59.166667 Max 62.500000
Confusion matrix:
[[ 6  0  0  6  8  0]
 [ 1 17  0  1  1  0]
 [ 2  0  1  9  8  0]
 [ 0  0  0 16  4  0]
 [ 0  0  0  1 19  0]
 [ 4  4  0  0  0 12]]
Epoch: [9]
       [Avg Loss]          0.828318
       [Training]   Prec@1 69.696970 Max 69.696970
       [Avg Loss]          0.992738
       [Validation] Prec@1 70.833333 Max 70.833333
Confusion matrix:
[[19  0  0  1  0  0]
 [ 3 15  0  0  0  2]
 [ 7  0  5  5  3  0]
 [ 1  0  0 15  3  1]
 [ 0  0  1  1 18  0]
 [ 5  2  0  0  0 13]]
Epoch: [10]
       [Avg Loss]          0.777627
       [Training]   Prec@1 71.969697 Max 71.969697
       [Avg Loss]          0.911716
       [Validation] Prec@1 66.666667 Max 70.833333
Confusion matrix:
[[14  1  0  5  0  0]
 [ 2 18  0  0  0  0]
 [ 3  0  6 10  1  0]
 [ 2  0  0 16  1  1]
 [ 0  3  0  2 15  0]
 [ 4  5  0  0  0 11]]
Epoch: [11]
       [Avg Loss]          0.768499
       [Training]   Prec@1 73.030303 Max 73.030303
       [Avg Loss]          1.071659
       [Validation] Prec@1 62.500000 Max 70.833333
Confusion matrix:
[[ 6  2  0  6  6  0]
 [ 0 19  0  1  0  0]
 [ 0  1  9  7  3  0]
 [ 0  0  0 16  3  1]
 [ 0  1  0  2 17  0]
 [ 5  7  0  0  0  8]]
Epoch: [12]
       [Avg Loss]          0.750936
       [Training]   Prec@1 72.424242 Max 73.030303
       [Avg Loss]          1.000927
       [Validation] Prec@1 63.333333 Max 70.833333
Confusion matrix:
[[ 6  2  0  4  8  0]
 [ 0 16  0  1  3  0]
 [ 1  0 10  4  5  0]
 [ 0  0  0 15  5  0]
 [ 0  1  0  0 19  0]
 [ 2  3  0  4  1 10]]
Epoch: [13]
       [Avg Loss]          0.702208
       [Training]   Prec@1 75.757576 Max 75.757576
       [Avg Loss]          0.800380
       [Validation] Prec@1 72.500000 Max 72.500000
Confusion matrix:
[[13  1  0  2  4  0]
 [ 1 19  0  0  0  0]
 [ 4  0 11  3  2  0]
 [ 2  0  0 13  4  1]
 [ 0  0  0  1 19  0]
 [ 5  3  0  0  0 12]]
Epoch: [14]
       [Avg Loss]          0.677880
       [Training]   Prec@1 74.848485 Max 75.757576
       [Avg Loss]          0.826895
       [Validation] Prec@1 68.333333 Max 72.500000
Confusion matrix:
[[14  0  0  5  1  0]
 [ 1 18  0  0  1  0]
 [ 4  0 14  2  0  0]
 [ 1  0  0 16  2  1]
 [ 1  0  0  5 14  0]
 [ 9  5  0  0  0  6]]
Fold "3" complete, final accuracy: 72.5
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.627945
       [Training]   Prec@1 34.179104 Max 34.179104
       [Avg Loss]          1.751075
       [Validation] Prec@1 27.272727 Max 27.272727
Confusion matrix:
[[ 0  0 15  0  5  0]
 [ 0  0 10  0 10  0]
 [ 0  0 20  0  0  0]
 [ 0  0 17  0  3  0]
 [ 0  0  0  0 10  0]
 [ 0  0 19  0  1  0]]
Epoch: [1]
       [Avg Loss]          1.355606
       [Training]   Prec@1 45.373134 Max 45.373134
       [Avg Loss]          1.527168
       [Validation] Prec@1 48.181818 Max 48.181818
Confusion matrix:
[[19  0  1  0  0  0]
 [11  0  8  0  1  0]
 [ 5  0 15  0  0  0]
 [16  0  2  0  0  2]
 [ 5  0  0  0  5  0]
 [ 6  0  0  0  0 14]]
Epoch: [2]
       [Avg Loss]          1.253328
       [Training]   Prec@1 50.447761 Max 50.447761
       [Avg Loss]          1.441000
       [Validation] Prec@1 39.090909 Max 48.181818
Confusion matrix:
[[ 6  8  6  0  0  0]
 [ 0  7 13  0  0  0]
 [ 0  5 15  0  0  0]
 [ 7  4  8  0  0  1]
 [ 0  0  8  0  2  0]
 [ 5  2  0  0  0 13]]
Epoch: [3]
       [Avg Loss]          1.190918
       [Training]   Prec@1 51.791045 Max 51.791045
       [Avg Loss]          2.004746
       [Validation] Prec@1 31.818182 Max 48.181818
Confusion matrix:
[[ 0  3 10  0  7  0]
 [ 0  5  5  0 10  0]
 [ 0  1 19  0  0  0]
 [ 0  4  6  0 10  0]
 [ 0  0  0  0 10  0]
 [ 0 18  1  0  0  1]]
Epoch: [4]
       [Avg Loss]          1.101569
       [Training]   Prec@1 57.014925 Max 57.014925
       [Avg Loss]          1.528122
       [Validation] Prec@1 52.727273 Max 52.727273
Confusion matrix:
[[ 9  2  8  0  1  0]
 [ 0  0  9  0 11  0]
 [ 0  3 17  0  0  0]
 [ 0  3  7  3  7  0]
 [ 0  0  0  0 10  0]
 [ 0  0  1  0  0 19]]
Epoch: [5]
       [Avg Loss]          1.087684
       [Training]   Prec@1 57.164179 Max 57.164179
       [Avg Loss]          1.546357
       [Validation] Prec@1 36.363636 Max 52.727273
Confusion matrix:
[[12  4  1  0  3  0]
 [ 1  5  2  0 12  0]
 [ 1  4  6  0  9  0]
 [ 1  5  2  5  7  0]
 [ 0  0  0  0 10  0]
 [ 9  9  0  0  0  2]]
Epoch: [6]
       [Avg Loss]          1.033975
       [Training]   Prec@1 57.462687 Max 57.462687
       [Avg Loss]          1.398340
       [Validation] Prec@1 48.181818 Max 52.727273
Confusion matrix:
[[ 8  3  7  0  2  0]
 [ 0  2 11  0  7  0]
 [ 0  4 16  0  0  0]
 [ 4  2  7  2  4  1]
 [ 0  0  0  0 10  0]
 [ 4  0  1  0  0 15]]
Epoch: [7]
       [Avg Loss]          1.030430
       [Training]   Prec@1 61.194030 Max 61.194030
       [Avg Loss]          1.125589
       [Validation] Prec@1 60.909091 Max 60.909091
Confusion matrix:
[[12  5  2  1  0  0]
 [ 2 10  7  0  1  0]
 [ 0  5 15  0  0  0]
 [ 7  1  4  5  0  3]
 [ 0  0  3  0  7  0]
 [ 2  0  0  0  0 18]]
Epoch: [8]
       [Avg Loss]          0.965311
       [Training]   Prec@1 63.880597 Max 63.880597
       [Avg Loss]          1.205617
       [Validation] Prec@1 56.363636 Max 60.909091
Confusion matrix:
[[16  0  2  1  1  0]
 [ 2  5  4  1  8  0]
 [ 3  2 12  0  3  0]
 [ 1  5  2  5  7  0]
 [ 0  0  0  0 10  0]
 [ 5  1  0  0  0 14]]
Epoch: [9]
       [Avg Loss]          0.916753
       [Training]   Prec@1 64.776119 Max 64.776119
       [Avg Loss]          1.434651
       [Validation] Prec@1 50.000000 Max 60.909091
Confusion matrix:
[[14  0  6  0  0  0]
 [ 9  4  2  0  5  0]
 [ 6  1 13  0  0  0]
 [ 7  3  8  2  0  0]
 [ 0  0  0  0 10  0]
 [ 8  0  0  0  0 12]]
Epoch: [10]
       [Avg Loss]          0.868590
       [Training]   Prec@1 67.313433 Max 67.313433
       [Avg Loss]          1.163345
       [Validation] Prec@1 63.636364 Max 63.636364
Confusion matrix:
[[12  0  2  6  0  0]
 [ 7  9  4  0  0  0]
 [ 3  2 15  0  0  0]
 [ 1  0  0 15  0  4]
 [ 0  0  8  2  0  0]
 [ 0  0  0  1  0 19]]
Epoch: [11]
       [Avg Loss]          0.828594
       [Training]   Prec@1 69.402985 Max 69.402985
       [Avg Loss]          1.152935
       [Validation] Prec@1 60.909091 Max 63.636364
Confusion matrix:
[[18  0  1  1  0  0]
 [ 3 13  3  0  1  0]
 [ 4  2 14  0  0  0]
 [ 8  2  1  8  0  1]
 [ 1  0  7  0  2  0]
 [ 8  0  0  0  0 12]]
Epoch: [12]
       [Avg Loss]          0.775955
       [Training]   Prec@1 70.149254 Max 70.149254
       [Avg Loss]          1.597253
       [Validation] Prec@1 58.181818 Max 63.636364
Confusion matrix:
[[14  0  1  2  3  0]
 [ 0  1  0  0 19  0]
 [ 4  1  9  1  5  0]
 [ 0  2  0 11  6  1]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [13]
       [Avg Loss]          0.689755
       [Training]   Prec@1 75.223881 Max 75.223881
       [Avg Loss]          1.048207
       [Validation] Prec@1 58.181818 Max 63.636364
Confusion matrix:
[[16  0  1  3  0  0]
 [ 4 12  1  0  3  0]
 [ 5  1 14  0  0  0]
 [ 4  1  1  9  3  2]
 [ 0  0  7  0  3  0]
 [ 0  0  0 10  0 10]]
Epoch: [14]
       [Avg Loss]          0.668868
       [Training]   Prec@1 76.417910 Max 76.417910
       [Avg Loss]          1.115679
       [Validation] Prec@1 65.454545 Max 65.454545
Confusion matrix:
[[11  4  2  2  0  1]
 [ 4 14  1  0  1  0]
 [ 2  3 15  0  0  0]
 [ 4  0  2  8  3  3]
 [ 0  0  6  0  4  0]
 [ 0  0  0  0  0 20]]
Fold "4" complete, final accuracy: 65.45454545454545

-----------------------------------------------------------------------
Training for stage 7 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=5)")
Average accuracy is: 63.50682500682501


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 8-----
Evaluated preprocessing: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=5)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.548415
       [Training]   Prec@1 36.666667 Max 36.666667
       [Avg Loss]          1.767906
       [Validation] Prec@1 16.666667 Max 16.666667
Confusion matrix:
[[ 0  0  0 40  0  0]
 [ 0  0  0 30  0  0]
 [ 0  0  0 30  0  0]
 [ 0  0  0 30  0  0]
 [ 0  0  0 30  0  0]
 [ 0  0  0 20  0  0]]
Epoch: [1]
       [Avg Loss]          1.169987
       [Training]   Prec@1 57.333333 Max 57.333333
       [Avg Loss]          1.637455
       [Validation] Prec@1 27.222222 Max 27.222222
Confusion matrix:
[[ 0  1  9 27  2  1]
 [ 0 13 15  1  0  1]
 [ 0  0 30  0  0  0]
 [ 0  0 29  0  1  0]
 [ 0  0 23  3  4  0]
 [ 0  9  1  8  0  2]]
Epoch: [2]
       [Avg Loss]          1.144525
       [Training]   Prec@1 60.000000 Max 60.000000
       [Avg Loss]          1.632480
       [Validation] Prec@1 41.111111 Max 41.111111
Confusion matrix:
[[27  2  1  0  0 10]
 [ 0 28  0  0  0  2]
 [ 0 22  8  0  0  0]
 [ 5 18  5  0  2  0]
 [ 5 13 10  0  2  0]
 [ 0 11  0  0  0  9]]
Epoch: [3]
       [Avg Loss]          1.100482
       [Training]   Prec@1 58.666667 Max 60.000000
       [Avg Loss]          1.656917
       [Validation] Prec@1 41.111111 Max 41.111111
Confusion matrix:
[[ 1  0  3  9 18  9]
 [ 0 22  1  2  1  4]
 [ 0  1 29  0  0  0]
 [ 0  1 19  0 10  0]
 [ 0  0 15  2 13  0]
 [ 0 10  0  1  0  9]]
Epoch: [4]
       [Avg Loss]          1.017527
       [Training]   Prec@1 62.166667 Max 62.166667
       [Avg Loss]          2.323560
       [Validation] Prec@1 19.444444 Max 41.111111
Confusion matrix:
[[ 7  4  0  0  0 29]
 [ 0  9  0  0  0 21]
 [ 0 30  0  0  0  0]
 [ 1 26  0  0  0  3]
 [ 3 19  0  3  0  5]
 [ 0  1  0  0  0 19]]
Epoch: [5]
       [Avg Loss]          1.007379
       [Training]   Prec@1 66.666667 Max 66.666667
       [Avg Loss]          1.656547
       [Validation] Prec@1 36.666667 Max 41.111111
Confusion matrix:
[[ 9  0  6 15  1  9]
 [ 0 19  0  4  3  4]
 [ 0  4 26  0  0  0]
 [ 0  3 22  0  5  0]
 [ 1  1 21  3  4  0]
 [ 0 10  0  2  0  8]]
Epoch: [6]
       [Avg Loss]          0.951412
       [Training]   Prec@1 66.333333 Max 66.666667
       [Avg Loss]          1.579610
       [Validation] Prec@1 50.000000 Max 50.000000
Confusion matrix:
[[15  0  0  8  6 11]
 [ 2 16  0  5  3  4]
 [ 0  0 30  0  0  0]
 [ 2  1 15  2 10  0]
 [ 1  0  8  3 18  0]
 [ 0 10  0  1  0  9]]
Epoch: [7]
       [Avg Loss]          0.944147
       [Training]   Prec@1 67.500000 Max 67.500000
       [Avg Loss]          2.098793
       [Validation] Prec@1 24.444444 Max 50.000000
Confusion matrix:
[[ 5  4  0 22  0  9]
 [ 0 26  0  2  0  2]
 [ 0 30  0  0  0  0]
 [ 1 26  0  3  0  0]
 [ 0 17  1 11  1  0]
 [ 0 11  0  0  0  9]]
Epoch: [8]
       [Avg Loss]          0.937090
       [Training]   Prec@1 66.333333 Max 67.500000
       [Avg Loss]          2.020782
       [Validation] Prec@1 40.000000 Max 50.000000
Confusion matrix:
[[ 6  0  2  3 19 10]
 [ 2  9  0 11  3  5]
 [ 0  0 30  0  0  0]
 [ 0  1 18  0 11  0]
 [ 0  0 11  1 18  0]
 [ 0  9  0  2  0  9]]
Epoch: [9]
       [Avg Loss]          0.861225
       [Training]   Prec@1 70.500000 Max 70.500000
       [Avg Loss]          1.993721
       [Validation] Prec@1 32.222222 Max 50.000000
Confusion matrix:
[[30  0  0  0  0 10]
 [ 5  9  0  4  0 12]
 [30  0  0  0  0  0]
 [29  0  0  1  0  0]
 [24  0  0  1  5  0]
 [ 1  5  0  1  0 13]]
Epoch: [10]
       [Avg Loss]          0.836903
       [Training]   Prec@1 71.666667 Max 71.666667
       [Avg Loss]          1.626177
       [Validation] Prec@1 48.888889 Max 50.000000
Confusion matrix:
[[26  0  1  0  3 10]
 [ 4  6  0  9  1 10]
 [ 0  0 30  0  0  0]
 [ 2  1 14  3 10  0]
 [ 2  0 14  3 11  0]
 [ 0  6  0  2  0 12]]
Epoch: [11]
       [Avg Loss]          0.833551
       [Training]   Prec@1 69.833333 Max 71.666667
       [Avg Loss]          1.486729
       [Validation] Prec@1 55.000000 Max 55.000000
Confusion matrix:
[[30  1  0  0  0  9]
 [ 5 24  0  1  0  0]
 [ 8  2 20  0  0  0]
 [12  1  7  1  9  0]
 [11  0  2  1 16  0]
 [ 0 12  0  0  0  8]]
Epoch: [12]
       [Avg Loss]          0.780690
       [Training]   Prec@1 72.166667 Max 72.166667
       [Avg Loss]          1.847722
       [Validation] Prec@1 41.666667 Max 55.000000
Confusion matrix:
[[19  3  0  8  0 10]
 [ 5 21  0  1  0  3]
 [ 0  5 22  3  0  0]
 [ 3 10 14  3  0  0]
 [ 1  9  6 14  0  0]
 [ 0 10  0  0  0 10]]
Epoch: [13]
       [Avg Loss]          0.964542
       [Training]   Prec@1 65.500000 Max 72.166667
       [Avg Loss]          2.410502
       [Validation] Prec@1 36.111111 Max 55.000000
Confusion matrix:
[[ 2 10 24  2  1  1]
 [ 0 23  1  1  5  0]
 [ 0  0 30  0  0  0]
 [ 0  0 26  0  4  0]
 [ 0  0 25  0  5  0]
 [ 0 11  1  3  0  5]]
Epoch: [14]
       [Avg Loss]          0.849976
       [Training]   Prec@1 69.166667 Max 72.166667
       [Avg Loss]          1.688801
       [Validation] Prec@1 53.333333 Max 55.000000
Confusion matrix:
[[18  2  1  2  9  8]
 [ 2 23  0  1  3  1]
 [ 1  0 29  0  0  0]
 [ 0  1 19  0 10  0]
 [ 3  0  9  1 17  0]
 [ 0 11  0  0  0  9]]
Fold "0" complete, final accuracy: 55.0
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.562994
       [Training]   Prec@1 38.655462 Max 38.655462
       [Avg Loss]          1.719272
       [Validation] Prec@1 23.783784 Max 23.783784
Confusion matrix:
[[ 0  7 18  0  5  0]
 [ 0  8 27  0  0  0]
 [ 0  0 22  0  8  0]
 [ 0  0 20  0 10  0]
 [ 0  0 16  0 14  0]
 [ 0 13 17  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.342631
       [Training]   Prec@1 48.907563 Max 48.907563
       [Avg Loss]          1.495657
       [Validation] Prec@1 38.918919 Max 38.918919
Confusion matrix:
[[20  7  1  0  0  2]
 [ 1 16 18  0  0  0]
 [15  2 13  0  0  0]
 [20  0  2  8  0  0]
 [22  0  5  3  0  0]
 [ 1  1  1 12  0 15]]
Epoch: [2]
       [Avg Loss]          1.231394
       [Training]   Prec@1 54.621849 Max 54.621849
       [Avg Loss]          1.442059
       [Validation] Prec@1 45.945946 Max 45.945946
Confusion matrix:
[[ 0  9 15  0  5  1]
 [ 0 27  8  0  0  0]
 [ 0  2 28  0  0  0]
 [ 0  0 14  8  8  0]
 [ 0  0 19  3  8  0]
 [ 1  2  2 11  0 14]]
Epoch: [3]
       [Avg Loss]          1.175824
       [Training]   Prec@1 54.117647 Max 54.621849
       [Avg Loss]          1.139675
       [Validation] Prec@1 62.162162 Max 62.162162
Confusion matrix:
[[ 9  7  0  1 10  3]
 [ 1 31  3  0  0  0]
 [ 0  2 23  1  4  0]
 [ 0  0  4 12 13  1]
 [ 0  0  2  7 21  0]
 [ 0  1  1  9  0 19]]
Epoch: [4]
       [Avg Loss]          1.093981
       [Training]   Prec@1 62.352941 Max 62.352941
       [Avg Loss]          1.650454
       [Validation] Prec@1 38.378378 Max 62.162162
Confusion matrix:
[[ 4 10 10  0  1  5]
 [ 0 16  1  0  0 18]
 [ 0 12 18  0  0  0]
 [ 2  3  6 11  8  0]
 [ 0  7  7  6  8  2]
 [ 8  3  0  5  0 14]]
Epoch: [5]
       [Avg Loss]          1.219190
       [Training]   Prec@1 53.445378 Max 62.352941
       [Avg Loss]          1.409905
       [Validation] Prec@1 54.054054 Max 62.162162
Confusion matrix:
[[ 2  7 14  0  4  3]
 [ 0 31  4  0  0  0]
 [ 0  2 28  0  0  0]
 [ 0  1 11  4 10  4]
 [ 0  2 15  3 10  0]
 [ 0  2  2  1  0 25]]
Epoch: [6]
       [Avg Loss]          1.153123
       [Training]   Prec@1 57.983193 Max 62.352941
       [Avg Loss]          1.448578
       [Validation] Prec@1 50.810811 Max 62.162162
Confusion matrix:
[[17  9  4  0  0  0]
 [ 0 15 20  0  0  0]
 [ 0  1 28  0  1  0]
 [ 8  0 12  6  2  2]
 [ 8  0 10  0 12  0]
 [ 1  7  2  4  0 16]]
Epoch: [7]
       [Avg Loss]          1.103417
       [Training]   Prec@1 59.327731 Max 62.352941
       [Avg Loss]          1.451730
       [Validation] Prec@1 50.810811 Max 62.162162
Confusion matrix:
[[18  3  0  1  1  7]
 [ 1 10  2 16  0  6]
 [ 0  1 25  0  4  0]
 [ 6  0  3 13  8  0]
 [ 1  0  1  9 19  0]
 [ 0  0  1 20  0  9]]
Epoch: [8]
       [Avg Loss]          1.036972
       [Training]   Prec@1 63.193277 Max 63.193277
       [Avg Loss]          1.390558
       [Validation] Prec@1 55.135135 Max 62.162162
Confusion matrix:
[[11  9  0  8  0  2]
 [ 0 34  0  0  0  1]
 [ 0 11 17  2  0  0]
 [ 0  4  2 20  0  4]
 [ 1  7  3 17  2  0]
 [ 0  3  0  9  0 18]]
Epoch: [9]
       [Avg Loss]          1.048867
       [Training]   Prec@1 62.857143 Max 63.193277
       [Avg Loss]          1.199428
       [Validation] Prec@1 60.540541 Max 62.162162
Confusion matrix:
[[17  4  0  2  1  6]
 [ 1 18  1  0  0 15]
 [ 0  4 25  0  1  0]
 [ 4  0  5 14  7  0]
 [ 0  1  2  8 19  0]
 [ 1  0  1  9  0 19]]
Epoch: [10]
       [Avg Loss]          1.006093
       [Training]   Prec@1 64.873950 Max 64.873950
       [Avg Loss]          1.254375
       [Validation] Prec@1 63.243243 Max 63.243243
Confusion matrix:
[[15 10  5  0  0  0]
 [ 0 33  2  0  0  0]
 [ 0  3 27  0  0  0]
 [ 4  3  8  6  7  2]
 [ 1  3  6  3 17  0]
 [ 1  4  1  5  0 19]]
Epoch: [11]
       [Avg Loss]          0.985599
       [Training]   Prec@1 65.546218 Max 65.546218
       [Avg Loss]          1.244949
       [Validation] Prec@1 55.675676 Max 63.243243
Confusion matrix:
[[16 10  3  0  1  0]
 [ 0 32  3  0  0  0]
 [ 0  2 27  0  1  0]
 [ 5  2  7  7  7  2]
 [ 5  0  7  6 12  0]
 [12  1  2  6  0  9]]
Epoch: [12]
       [Avg Loss]          0.978822
       [Training]   Prec@1 64.369748 Max 65.546218
       [Avg Loss]          1.233876
       [Validation] Prec@1 65.945946 Max 65.945946
Confusion matrix:
[[16 10  1  2  1  0]
 [ 1 34  0  0  0  0]
 [ 0  8 22  0  0  0]
 [ 3  2  7  8  7  3]
 [ 2  5  2  4 17  0]
 [ 0  2  1  2  0 25]]
Epoch: [13]
       [Avg Loss]          0.903250
       [Training]   Prec@1 67.563025 Max 67.563025
       [Avg Loss]          1.150083
       [Validation] Prec@1 59.459459 Max 65.945946
Confusion matrix:
[[12 14  4  0  0  0]
 [ 0 35  0  0  0  0]
 [ 0  6 24  0  0  0]
 [ 2  3  9  6  6  4]
 [ 3  5  7  5 10  0]
 [ 0  3  0  4  0 23]]
Epoch: [14]
       [Avg Loss]          0.867281
       [Training]   Prec@1 69.579832 Max 69.579832
       [Avg Loss]          1.151430
       [Validation] Prec@1 56.756757 Max 65.945946
Confusion matrix:
[[19  7  0  3  0  1]
 [ 7 26  0  0  0  2]
 [ 2  4 22  2  0  0]
 [ 7  0  1 18  4  0]
 [ 9  0  2 12  7  0]
 [ 2  2  0 13  0 13]]
Fold "1" complete, final accuracy: 65.94594594594595
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.595414
       [Training]   Prec@1 36.302521 Max 36.302521
       [Avg Loss]          1.685272
       [Validation] Prec@1 47.027027 Max 47.027027
Confusion matrix:
[[ 3 15  6  6  0  0]
 [ 0 30  2  2  0  1]
 [ 0  0 18 12  0  0]
 [ 0 10  0 16  0  4]
 [ 0  2  0 28  0  0]
 [ 0 10  0  0  0 20]]
Epoch: [1]
       [Avg Loss]          1.291225
       [Training]   Prec@1 50.252101 Max 50.252101
       [Avg Loss]          1.496270
       [Validation] Prec@1 34.054054 Max 47.027027
Confusion matrix:
[[17  1  0  8  0  4]
 [ 3  5  0 13  0 14]
 [ 3  0  0 25  2  0]
 [14  0  0 11  0  5]
 [30  0  0  0  0  0]
 [ 0  0  0  0  0 30]]
Epoch: [2]
       [Avg Loss]          1.254766
       [Training]   Prec@1 57.983193 Max 57.983193
       [Avg Loss]          1.416987
       [Validation] Prec@1 44.324324 Max 47.027027
Confusion matrix:
[[ 4 17  7  2  0  0]
 [ 0 32  1  1  0  1]
 [ 0 26  4  0  0  0]
 [ 0 14  4 11  0  1]
 [ 5  6  5  4 10  0]
 [ 1  5  0  3  0 21]]
Epoch: [3]
       [Avg Loss]          1.330859
       [Training]   Prec@1 49.243697 Max 57.983193
       [Avg Loss]          2.319386
       [Validation] Prec@1 16.216216 Max 47.027027
Confusion matrix:
[[ 0  0  0  0  0 30]
 [ 0  0  0  0  0 35]
 [ 0  0  0  0  0 30]
 [ 0  0  0  0  0 30]
 [ 0  0  0  0  0 30]
 [ 0  0  0  0  0 30]]
Epoch: [4]
       [Avg Loss]          1.332247
       [Training]   Prec@1 51.092437 Max 57.983193
       [Avg Loss]          1.326822
       [Validation] Prec@1 48.108108 Max 48.108108
Confusion matrix:
[[10  7  0  5  8  0]
 [ 2 30  0  2  0  1]
 [ 0  2  2 21  5  0]
 [ 3  9  0 16  0  2]
 [17  0  0  0 13  0]
 [ 0 12  0  0  0 18]]
Epoch: [5]
       [Avg Loss]          1.211103
       [Training]   Prec@1 58.151261 Max 58.151261
       [Avg Loss]          1.364522
       [Validation] Prec@1 45.945946 Max 48.108108
Confusion matrix:
[[20  5  2  0  3  0]
 [ 4 26  2  0  1  2]
 [ 3  0 13  0 14  0]
 [18  6  3  1  0  2]
 [28  0  0  0  2  0]
 [ 3  4  0  0  0 23]]
Epoch: [6]
       [Avg Loss]          1.146300
       [Training]   Prec@1 61.176471 Max 61.176471
       [Avg Loss]          2.615172
       [Validation] Prec@1 32.432432 Max 48.108108
Confusion matrix:
[[ 3  3 22  0  2  0]
 [ 0 12 23  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  1 18  2  8  0]
 [ 1  0 18  0 11  0]
 [ 9 18  1  0  0  2]]
Epoch: [7]
       [Avg Loss]          1.077571
       [Training]   Prec@1 59.663866 Max 61.176471
       [Avg Loss]          1.403832
       [Validation] Prec@1 47.027027 Max 48.108108
Confusion matrix:
[[11  5  0 11  3  0]
 [ 4 18  0  5  2  6]
 [ 0  0  1  0 29  0]
 [11  0  0 14  5  0]
 [15  0  0  0 15  0]
 [ 0  1  0  1  0 28]]
Epoch: [8]
       [Avg Loss]          1.053147
       [Training]   Prec@1 61.848739 Max 61.848739
       [Avg Loss]          1.033381
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[12  5  3  5  5  0]
 [ 4 20  5  2  0  4]
 [ 0  0 18  0 12  0]
 [ 3  1  5 13  5  3]
 [11  0  0  0 19  0]
 [ 0  1  0  0  0 29]]
Epoch: [9]
       [Avg Loss]          0.992103
       [Training]   Prec@1 61.344538 Max 61.848739
       [Avg Loss]          1.110955
       [Validation] Prec@1 58.918919 Max 60.000000
Confusion matrix:
[[17  4  4  3  2  0]
 [ 7 11 10  3  0  4]
 [ 0  0 23  0  7  0]
 [ 4  0  5 17  2  2]
 [15  0  0  2 13  0]
 [ 1  1  0  0  0 28]]
Epoch: [10]
       [Avg Loss]          0.971849
       [Training]   Prec@1 64.033613 Max 64.033613
       [Avg Loss]          1.268442
       [Validation] Prec@1 56.216216 Max 60.000000
Confusion matrix:
[[12  4  2 10  2  0]
 [ 5 12  5  8  2  3]
 [ 0  0 12  0 18  0]
 [ 3  0  1 21  4  1]
 [ 9  0  0  1 20  0]
 [ 0  2  0  1  0 27]]
Epoch: [11]
       [Avg Loss]          0.910905
       [Training]   Prec@1 67.563025 Max 67.563025
       [Avg Loss]          1.183413
       [Validation] Prec@1 58.378378 Max 60.000000
Confusion matrix:
[[12  7  2  8  1  0]
 [ 2 27  3  2  0  1]
 [ 0  0 24  4  2  0]
 [ 1  8  1 12  2  6]
 [ 9  0  0  3 18  0]
 [ 4 11  0  0  0 15]]
Epoch: [12]
       [Avg Loss]          0.932958
       [Training]   Prec@1 64.873950 Max 67.563025
       [Avg Loss]          1.070261
       [Validation] Prec@1 63.243243 Max 63.243243
Confusion matrix:
[[16  8  2  3  1  0]
 [ 6 25  2  1  0  1]
 [ 0  0 28  0  2  0]
 [ 0  8  1 15  1  5]
 [11  0  0  7 12  0]
 [ 2  7  0  0  0 21]]
Epoch: [13]
       [Avg Loss]          0.899407
       [Training]   Prec@1 67.058824 Max 67.563025
       [Avg Loss]          1.185276
       [Validation] Prec@1 61.081081 Max 63.243243
Confusion matrix:
[[21  6  3  0  0  0]
 [ 4 21  2  1  0  7]
 [ 2  0 26  2  0  0]
 [ 6  4  1 12  0  7]
 [21  0  0  6  3  0]
 [ 0  0  0  0  0 30]]
Epoch: [14]
       [Avg Loss]          0.909350
       [Training]   Prec@1 67.226891 Max 67.563025
       [Avg Loss]          1.055081
       [Validation] Prec@1 62.702703 Max 63.243243
Confusion matrix:
[[17  6  2  2  3  0]
 [ 4 26  2  1  0  2]
 [ 0  0 25  0  5  0]
 [ 5  2  6 11  5  1]
 [14  0  0  0 16  0]
 [ 5  4  0  0  0 21]]
Fold "2" complete, final accuracy: 63.24324324324324
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.620685
       [Training]   Prec@1 35.757576 Max 35.757576
       [Avg Loss]          1.699548
       [Validation] Prec@1 42.500000 Max 42.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 15  5  0  0  0]
 [ 4  0 16  0  0  0]
 [ 7  2 11  0  0  0]
 [10  0 10  0  0  0]
 [ 1 19  0  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.341184
       [Training]   Prec@1 50.757576 Max 50.757576
       [Avg Loss]          1.374609
       [Validation] Prec@1 47.500000 Max 47.500000
Confusion matrix:
[[ 4  0  0 12  4  0]
 [ 0 13  0  0  0  7]
 [ 0  7 11  2  0  0]
 [ 3  3  1 11  0  2]
 [ 0  0  5 15  0  0]
 [ 0  2  0  0  0 18]]
Epoch: [2]
       [Avg Loss]          1.310025
       [Training]   Prec@1 53.636364 Max 53.636364
       [Avg Loss]          1.228965
       [Validation] Prec@1 50.833333 Max 50.833333
Confusion matrix:
[[15  0  0  0  5  0]
 [ 8  4  7  0  0  1]
 [ 0  0 20  0  0  0]
 [11  0  4  1  4  0]
 [ 0  0  9  0 11  0]
 [ 5  0  1  4  0 10]]
Epoch: [3]
       [Avg Loss]          1.206563
       [Training]   Prec@1 56.515152 Max 56.515152
       [Avg Loss]          1.145394
       [Validation] Prec@1 55.833333 Max 55.833333
Confusion matrix:
[[ 4  0  0  6 10  0]
 [ 0 16  0  0  0  4]
 [ 0  6 14  0  0  0]
 [ 0  2  5 12  0  1]
 [ 0  5  8  3  4  0]
 [ 0  3  0  0  0 17]]
Epoch: [4]
       [Avg Loss]          1.134770
       [Training]   Prec@1 60.151515 Max 60.151515
       [Avg Loss]          1.097279
       [Validation] Prec@1 57.500000 Max 57.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 11  0  1  0  8]
 [ 2  6  1  6  5  0]
 [ 4  0  0 14  0  2]
 [ 5  1  0 10  4  0]
 [ 1  0  0  0  0 19]]
Epoch: [5]
       [Avg Loss]          1.086493
       [Training]   Prec@1 58.787879 Max 60.151515
       [Avg Loss]          1.424156
       [Validation] Prec@1 50.833333 Max 57.500000
Confusion matrix:
[[ 3  0  0  0 17  0]
 [ 0  9  0  3  0  8]
 [ 0  2 15  3  0  0]
 [ 4  0  5  8  3  0]
 [ 0  0 10  1  9  0]
 [ 2  0  0  1  0 17]]
Epoch: [6]
       [Avg Loss]          1.052573
       [Training]   Prec@1 63.181818 Max 63.181818
       [Avg Loss]          1.172209
       [Validation] Prec@1 61.666667 Max 61.666667
Confusion matrix:
[[18  0  0  2  0  0]
 [ 0  7  0  1  0 12]
 [ 0  5 13  2  0  0]
 [ 5  0  1 13  0  1]
 [ 3  2  9  2  4  0]
 [ 1  0  0  0  0 19]]
Epoch: [7]
       [Avg Loss]          1.043379
       [Training]   Prec@1 62.575758 Max 63.181818
       [Avg Loss]          1.199202
       [Validation] Prec@1 53.333333 Max 61.666667
Confusion matrix:
[[ 4  0  0  6 10  0]
 [ 2 17  0  1  0  0]
 [ 0  1 15  4  0  0]
 [ 1  2  0 15  0  2]
 [ 0  0  9  3  8  0]
 [ 9  6  0  0  0  5]]
Epoch: [8]
       [Avg Loss]          0.975937
       [Training]   Prec@1 63.787879 Max 63.787879
       [Avg Loss]          1.804141
       [Validation] Prec@1 45.833333 Max 61.666667
Confusion matrix:
[[ 1  0  0  0 19  0]
 [ 2 14  3  1  0  0]
 [ 0  0 19  1  0  0]
 [ 3  1  1  5 10  0]
 [ 0  0  5  0 15  0]
 [10  9  0  0  0  1]]
Epoch: [9]
       [Avg Loss]          0.979809
       [Training]   Prec@1 64.696970 Max 64.696970
       [Avg Loss]          1.270286
       [Validation] Prec@1 55.833333 Max 61.666667
Confusion matrix:
[[ 8  0  0  2 10  0]
 [ 0 16  0  0  0  4]
 [ 0  6 14  0  0  0]
 [ 2  3  6  6  1  2]
 [ 0  0 10  1  9  0]
 [ 5  1  0  0  0 14]]
Epoch: [10]
       [Avg Loss]          0.905619
       [Training]   Prec@1 68.333333 Max 68.333333
       [Avg Loss]          1.117642
       [Validation] Prec@1 55.833333 Max 61.666667
Confusion matrix:
[[11  0  0  9  0  0]
 [ 1 13  0  1  0  5]
 [ 0  1  9 10  0  0]
 [ 3  1  0 15  0  1]
 [ 4  0  6  6  4  0]
 [ 4  1  0  0  0 15]]
Epoch: [11]
       [Avg Loss]          0.887810
       [Training]   Prec@1 67.121212 Max 68.333333
       [Avg Loss]          1.778291
       [Validation] Prec@1 45.833333 Max 61.666667
Confusion matrix:
[[ 4  0  0  0 16  0]
 [ 6 13  0  1  0  0]
 [ 0  2 17  1  0  0]
 [ 2  2  2  7  6  1]
 [ 0  0  8  0 12  0]
 [15  3  0  0  0  2]]
Epoch: [12]
       [Avg Loss]          0.878729
       [Training]   Prec@1 67.727273 Max 68.333333
       [Avg Loss]          1.449464
       [Validation] Prec@1 42.500000 Max 61.666667
Confusion matrix:
[[ 9  0  0 11  0  0]
 [ 2 14  0  0  0  4]
 [ 1  8  0 11  0  0]
 [ 2  0  0 14  0  4]
 [ 4  5  2  9  0  0]
 [ 5  1  0  0  0 14]]
Epoch: [13]
       [Avg Loss]          0.852619
       [Training]   Prec@1 67.121212 Max 68.333333
       [Avg Loss]          0.938603
       [Validation] Prec@1 63.333333 Max 63.333333
Confusion matrix:
[[15  0  0  4  1  0]
 [ 0 15  0  1  0  4]
 [ 1  4  9  6  0  0]
 [ 3  1  0 16  0  0]
 [ 6  0  0  6  8  0]
 [ 6  1  0  0  0 13]]
Epoch: [14]
       [Avg Loss]          0.865049
       [Training]   Prec@1 69.848485 Max 69.848485
       [Avg Loss]          0.842884
       [Validation] Prec@1 65.833333 Max 65.833333
Confusion matrix:
[[ 9  0  0  5  6  0]
 [ 0 14  0  1  0  5]
 [ 0  1 15  4  0  0]
 [ 3  0  0 14  1  2]
 [ 0  0  3  6 11  0]
 [ 3  1  0  0  0 16]]
Fold "3" complete, final accuracy: 65.83333333333333
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.531412
       [Training]   Prec@1 39.701493 Max 39.701493
       [Avg Loss]          1.689813
       [Validation] Prec@1 51.818182 Max 51.818182
Confusion matrix:
[[ 9  6  2  0  3  0]
 [ 0  7  3  0 10  0]
 [ 1  1 16  0  2  0]
 [ 2  9  2  0  7  0]
 [ 0  0  0  0 10  0]
 [ 0  5  0  0  0 15]]
Epoch: [1]
       [Avg Loss]          1.235013
       [Training]   Prec@1 55.223881 Max 55.223881
       [Avg Loss]          1.688298
       [Validation] Prec@1 40.000000 Max 51.818182
Confusion matrix:
[[14  2  0  0  0  4]
 [14  3  0  2  1  0]
 [10  0  0  5  4  1]
 [12  0  0  3  0  5]
 [ 5  0  0  0  5  0]
 [ 1  0  0  0  0 19]]
Epoch: [2]
       [Avg Loss]          1.155863
       [Training]   Prec@1 55.820896 Max 55.820896
       [Avg Loss]          1.477875
       [Validation] Prec@1 52.727273 Max 52.727273
Confusion matrix:
[[11  6  1  2  0  0]
 [ 9  9  1  1  0  0]
 [ 6  0  9  3  0  2]
 [ 0  6  2 10  0  2]
 [ 0  0  0  5  5  0]
 [ 0  6  0  0  0 14]]
Epoch: [3]
       [Avg Loss]          1.074869
       [Training]   Prec@1 58.507463 Max 58.507463
       [Avg Loss]          2.254432
       [Validation] Prec@1 40.909091 Max 52.727273
Confusion matrix:
[[14  1  1  0  3  1]
 [ 7  5  1  0  7  0]
 [ 8  0  0  0 12  0]
 [ 8  1  1  2  4  4]
 [ 0  0  0  0 10  0]
 [ 4  1  0  1  0 14]]
Epoch: [4]
       [Avg Loss]          1.094147
       [Training]   Prec@1 60.149254 Max 60.149254
       [Avg Loss]          1.887493
       [Validation] Prec@1 56.363636 Max 56.363636
Confusion matrix:
[[11  6  2  0  1  0]
 [ 1  7  2  1  9  0]
 [ 7  0 10  0  3  0]
 [ 2  3  1 11  0  3]
 [ 0  0  0  0 10  0]
 [ 3  4  0  0  0 13]]
Epoch: [5]
       [Avg Loss]          1.022416
       [Training]   Prec@1 61.791045 Max 61.791045
       [Avg Loss]          2.052593
       [Validation] Prec@1 48.181818 Max 56.363636
Confusion matrix:
[[13  4  0  0  0  3]
 [11  5  0  0  1  3]
 [11  0  0  0  8  1]
 [ 2  1  0  7  0 10]
 [ 2  0  0  0  8  0]
 [ 0  0  0  0  0 20]]
Epoch: [6]
       [Avg Loss]          1.020659
       [Training]   Prec@1 61.044776 Max 61.791045
       [Avg Loss]          1.686872
       [Validation] Prec@1 42.727273 Max 56.363636
Confusion matrix:
[[11  4  0  3  0  2]
 [10  6  1  1  0  2]
 [ 9  0  1  9  0  1]
 [ 0  0  0 17  0  3]
 [10  0  0  0  0  0]
 [ 0  0  0  8  0 12]]
Epoch: [7]
       [Avg Loss]          0.928282
       [Training]   Prec@1 66.268657 Max 66.268657
       [Avg Loss]          1.964507
       [Validation] Prec@1 50.000000 Max 56.363636
Confusion matrix:
[[11  3  0  3  3  0]
 [ 4  5  1  0  9  1]
 [ 8  0  0  0 12  0]
 [ 0  2  0 14  1  3]
 [ 0  0  0  0 10  0]
 [ 0  2  0  3  0 15]]
Epoch: [8]
       [Avg Loss]          0.903511
       [Training]   Prec@1 67.164179 Max 67.164179
       [Avg Loss]          1.780055
       [Validation] Prec@1 47.272727 Max 56.363636
Confusion matrix:
[[13  6  0  1  0  0]
 [11  7  1  1  0  0]
 [ 9  0  8  2  0  1]
 [ 2  3  0  7  0  8]
 [ 9  0  0  0  1  0]
 [ 0  4  0  0  0 16]]
Epoch: [9]
       [Avg Loss]          0.867812
       [Training]   Prec@1 67.014925 Max 67.164179
       [Avg Loss]          2.237693
       [Validation] Prec@1 42.727273 Max 56.363636
Confusion matrix:
[[17  3  0  0  0  0]
 [13  5  0  0  1  1]
 [17  0  0  0  2  1]
 [ 4  0  0  6  0 10]
 [10  0  0  0  0  0]
 [ 0  1  0  0  0 19]]
Epoch: [10]
       [Avg Loss]          0.900074
       [Training]   Prec@1 64.925373 Max 67.164179
       [Avg Loss]          2.117664
       [Validation] Prec@1 43.636364 Max 56.363636
Confusion matrix:
[[ 6  7  1  2  0  4]
 [ 3 15  2  0  0  0]
 [ 5  3 11  1  0  0]
 [ 0 15  1  3  0  1]
 [ 0  0  4  4  2  0]
 [ 0  9  0  0  0 11]]
Epoch: [11]
       [Avg Loss]          0.889408
       [Training]   Prec@1 65.223881 Max 67.164179
       [Avg Loss]          1.865561
       [Validation] Prec@1 51.818182 Max 56.363636
Confusion matrix:
[[11  3  0  3  3  0]
 [ 7  4  1  1  6  1]
 [ 9  0  3  0  8  0]
 [ 1  0  0 16  0  3]
 [ 0  0  0  0 10  0]
 [ 0  0  0  7  0 13]]
Epoch: [12]
       [Avg Loss]          0.833855
       [Training]   Prec@1 70.000000 Max 70.000000
       [Avg Loss]          1.802254
       [Validation] Prec@1 55.454545 Max 56.363636
Confusion matrix:
[[14  5  0  1  0  0]
 [11  6  1  0  1  1]
 [10  0  1  0  9  0]
 [ 3  2  0 12  0  3]
 [ 0  0  0  0 10  0]
 [ 0  2  0  0  0 18]]
Epoch: [13]
       [Avg Loss]          0.795292
       [Training]   Prec@1 70.895522 Max 70.895522
       [Avg Loss]          1.636668
       [Validation] Prec@1 56.363636 Max 56.363636
Confusion matrix:
[[12  6  0  2  0  0]
 [11  6  1  1  0  1]
 [ 9  0  7  3  1  0]
 [ 0  2  0 15  0  3]
 [ 4  0  0  0  6  0]
 [ 0  1  0  3  0 16]]
Epoch: [14]
       [Avg Loss]          0.753226
       [Training]   Prec@1 74.925373 Max 74.925373
       [Avg Loss]          1.622268
       [Validation] Prec@1 57.272727 Max 57.272727
Confusion matrix:
[[12  7  1  0  0  0]
 [ 8 10  2  0  0  0]
 [ 9  0 10  1  0  0]
 [ 1  9  0  8  0  2]
 [ 0  0  2  0  8  0]
 [ 0  5  0  0  0 15]]
Fold "4" complete, final accuracy: 57.27272727272727

-----------------------------------------------------------------------
Training for stage 8 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=5)")
Average accuracy is: 61.459049959049956


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 9-----
Evaluated preprocessing: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=4)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.704771
       [Training]   Prec@1 29.166667 Max 29.166667
       [Avg Loss]          1.734952
       [Validation] Prec@1 27.777778 Max 27.777778
Confusion matrix:
[[ 0 14  9  6  6  5]
 [ 0 27  0  2  0  1]
 [ 0 16 12  0  1  1]
 [ 0 16  8  0  6  0]
 [ 0  7 11  4  3  5]
 [ 0 10  0  2  0  8]]
Epoch: [1]
       [Avg Loss]          1.458694
       [Training]   Prec@1 42.666667 Max 42.666667
       [Avg Loss]          1.800747
       [Validation] Prec@1 31.666667 Max 31.666667
Confusion matrix:
[[12  2  5  2 11  8]
 [ 4 19  0  0  2  5]
 [ 0 14 13  0  0  3]
 [ 5  9  4  0  6  6]
 [ 4  6  3  6  5  6]
 [ 1  9  0  2  0  8]]
Epoch: [2]
       [Avg Loss]          1.290942
       [Training]   Prec@1 49.666667 Max 49.666667
       [Avg Loss]          1.797100
       [Validation] Prec@1 39.444444 Max 39.444444
Confusion matrix:
[[14 10  1  1 12  2]
 [ 0 23  1  0  3  3]
 [ 1 14 14  0  1  0]
 [ 2 12  5  0 10  1]
 [ 0 10  3  0 16  1]
 [ 0  8  2  0  6  4]]
Epoch: [3]
       [Avg Loss]          1.168874
       [Training]   Prec@1 56.833333 Max 56.833333
       [Avg Loss]          2.129990
       [Validation] Prec@1 23.888889 Max 39.444444
Confusion matrix:
[[ 9  0  3  4 10 14]
 [ 9  0  0  0 10 11]
 [ 5  0 21  0  1  3]
 [12  2  1  1  8  6]
 [11  1  1  1  3 13]
 [ 5  1  0  1  4  9]]
Epoch: [4]
       [Avg Loss]          1.064742
       [Training]   Prec@1 56.666667 Max 56.833333
       [Avg Loss]          1.802938
       [Validation] Prec@1 35.000000 Max 39.444444
Confusion matrix:
[[14  1  7 11  3  4]
 [18  7  0  0  2  3]
 [ 0  0 25  5  0  0]
 [ 6  2  9  8  2  3]
 [ 5  1  8  9  7  0]
 [ 7  0  1  9  1  2]]
Epoch: [5]
       [Avg Loss]          1.048522
       [Training]   Prec@1 57.500000 Max 57.500000
       [Avg Loss]          2.101530
       [Validation] Prec@1 33.333333 Max 39.444444
Confusion matrix:
[[13  1  5  3  8 10]
 [ 4 19  0  0  0  7]
 [ 9  3 16  0  0  2]
 [ 9  3  5  1  6  6]
 [ 3  8  0  4  2 13]
 [ 4  4  0  2  1  9]]
Epoch: [6]
       [Avg Loss]          0.996259
       [Training]   Prec@1 62.166667 Max 62.166667
       [Avg Loss]          2.080625
       [Validation] Prec@1 35.555556 Max 39.444444
Confusion matrix:
[[ 9  1 10  1 11  8]
 [ 9 12  0  1  4  4]
 [ 3  2 22  2  0  1]
 [ 5  3 11  0 11  0]
 [ 7  5  3  1 13  1]
 [ 4  2  3  0  3  8]]
Epoch: [7]
       [Avg Loss]          0.901507
       [Training]   Prec@1 65.833333 Max 65.833333
       [Avg Loss]          1.975829
       [Validation] Prec@1 32.222222 Max 39.444444
Confusion matrix:
[[12  0  6  5  3 14]
 [ 4  7  0  0  6 13]
 [ 2  1 22  2  1  2]
 [ 7  3  6  2  6  6]
 [ 9  1  1  1  5 13]
 [ 5  0  0  3  2 10]]
Epoch: [8]
       [Avg Loss]          0.817173
       [Training]   Prec@1 67.500000 Max 67.500000
       [Avg Loss]          1.729559
       [Validation] Prec@1 45.555556 Max 45.555556
Confusion matrix:
[[18  1  8  4  2  7]
 [ 8 20  0  1  1  0]
 [ 2  0 24  4  0  0]
 [ 8  2  8 12  0  0]
 [ 5  4  4 10  6  1]
 [ 5  0  1 12  0  2]]
Epoch: [9]
       [Avg Loss]          0.778469
       [Training]   Prec@1 69.833333 Max 69.833333
       [Avg Loss]          2.112589
       [Validation] Prec@1 41.666667 Max 45.555556
Confusion matrix:
[[12  0  8  5  4 11]
 [ 3 18  0  0  4  5]
 [ 3  1 22  2  0  2]
 [ 3  2  9  8  5  3]
 [ 9  2  2  3  9  5]
 [ 3  2  2  6  1  6]]
Epoch: [10]
       [Avg Loss]          0.678358
       [Training]   Prec@1 74.166667 Max 74.166667
       [Avg Loss]          1.789719
       [Validation] Prec@1 35.000000 Max 45.555556
Confusion matrix:
[[ 7  0  7  2 13 11]
 [ 1 16  0  0  5  8]
 [ 3  2 21  3  0  1]
 [ 7  3  3  3  8  6]
 [ 5  6  0  4  9  6]
 [ 3  1  0  6  3  7]]
Epoch: [11]
       [Avg Loss]          0.662429
       [Training]   Prec@1 76.500000 Max 76.500000
       [Avg Loss]          1.721477
       [Validation] Prec@1 38.888889 Max 45.555556
Confusion matrix:
[[10  0  8  4  6 12]
 [ 4  9  0  1  7  9]
 [ 0  0 25  4  0  1]
 [ 5  1  7 10  5  2]
 [ 7  2  1  6  7  7]
 [ 3  0  1  4  3  9]]
Epoch: [12]
       [Avg Loss]          0.579303
       [Training]   Prec@1 79.666667 Max 79.666667
       [Avg Loss]          1.726353
       [Validation] Prec@1 43.888889 Max 45.555556
Confusion matrix:
[[14  0  8  2  5 11]
 [ 2 19  0  3  2  4]
 [ 4  1 21  3  0  1]
 [ 5  2  6 16  1  0]
 [ 5  6  0  9  4  6]
 [ 3  2  0  9  1  5]]
Epoch: [13]
       [Avg Loss]          0.569122
       [Training]   Prec@1 79.000000 Max 79.666667
       [Avg Loss]          2.025807
       [Validation] Prec@1 41.666667 Max 45.555556
Confusion matrix:
[[14  2 11  3  2  8]
 [ 3 13  0  0  7  7]
 [ 1  1 23  4  0  1]
 [ 5  0  8  9  5  3]
 [ 9  0  4  6  7  4]
 [ 3  0  2  3  3  9]]
Epoch: [14]
       [Avg Loss]          0.501298
       [Training]   Prec@1 82.000000 Max 82.000000
       [Avg Loss]          2.198081
       [Validation] Prec@1 34.444444 Max 45.555556
Confusion matrix:
[[11  0  9  2 10  8]
 [ 0  9  0  0  7 14]
 [ 7  2 19  1  0  1]
 [ 5  2  4  8  6  5]
 [ 4  8  0  3  6  9]
 [ 4  1  0  1  5  9]]
Fold "0" complete, final accuracy: 45.55555555555556
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.752078
       [Training]   Prec@1 30.084034 Max 30.084034
       [Avg Loss]          1.609253
       [Validation] Prec@1 33.513514 Max 33.513514
Confusion matrix:
[[ 5 15  8  0  2  0]
 [ 0 29  5  0  0  1]
 [10 16  3  0  1  0]
 [ 4  3  6  4  5  8]
 [ 4  8  5  0  5  8]
 [ 1  8  3  0  2 16]]
Epoch: [1]
       [Avg Loss]          1.593432
       [Training]   Prec@1 35.798319 Max 35.798319
       [Avg Loss]          1.494860
       [Validation] Prec@1 40.540541 Max 40.540541
Confusion matrix:
[[19  5  5  0  0  1]
 [14 12  3  0  1  5]
 [13  6  9  0  2  0]
 [18  1  1  8  1  1]
 [16  4  0  2  4  4]
 [ 0  3  0  2  2 23]]
Epoch: [2]
       [Avg Loss]          1.394493
       [Training]   Prec@1 46.218487 Max 46.218487
       [Avg Loss]          1.580538
       [Validation] Prec@1 47.567568 Max 47.567568
Confusion matrix:
[[10 17  1  1  1  0]
 [ 0 31  4  0  0  0]
 [ 3 11 15  1  0  0]
 [ 6  4  2 10  8  0]
 [ 4 14  0  0 11  1]
 [ 0 16  0  0  3 11]]
Epoch: [3]
       [Avg Loss]          1.331031
       [Training]   Prec@1 50.252101 Max 50.252101
       [Avg Loss]          1.408689
       [Validation] Prec@1 51.351351 Max 51.351351
Confusion matrix:
[[17 11  1  0  1  0]
 [ 1 28  6  0  0  0]
 [ 2  4 24  0  0  0]
 [ 8  3  5 13  1  0]
 [ 8  9  3  2  7  1]
 [ 4  8  0  4  8  6]]
Epoch: [4]
       [Avg Loss]          1.231418
       [Training]   Prec@1 54.285714 Max 54.285714
       [Avg Loss]          1.292045
       [Validation] Prec@1 52.432432 Max 52.432432
Confusion matrix:
[[18 10  0  0  2  0]
 [ 0 35  0  0  0  0]
 [ 2 10 17  1  0  0]
 [ 6  1  2  7 13  1]
 [ 8 10  0  0  9  3]
 [ 2 10  0  1  6 11]]
Epoch: [5]
       [Avg Loss]          1.118949
       [Training]   Prec@1 60.000000 Max 60.000000
       [Avg Loss]          1.347225
       [Validation] Prec@1 53.513514 Max 53.513514
Confusion matrix:
[[14  6  5  0  5  0]
 [ 1 29  1  0  2  2]
 [ 0  6 24  0  0  0]
 [ 5  2  2 15  5  1]
 [ 9 10  0  4  6  1]
 [ 2  5  1  6  5 11]]
Epoch: [6]
       [Avg Loss]          1.147927
       [Training]   Prec@1 59.663866 Max 60.000000
       [Avg Loss]          1.487603
       [Validation] Prec@1 47.027027 Max 53.513514
Confusion matrix:
[[15  3  8  1  2  1]
 [ 4 21  5  1  2  2]
 [ 0  7 22  1  0  0]
 [ 8  0  7 14  0  1]
 [14  8  1  2  3  2]
 [ 8  4  1  4  1 12]]
Epoch: [7]
       [Avg Loss]          1.039883
       [Training]   Prec@1 62.521008 Max 62.521008
       [Avg Loss]          1.167650
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[17  7  1  1  3  1]
 [ 2 29  2  0  1  1]
 [ 1  7 19  3  0  0]
 [ 3  0  2 15  9  1]
 [ 4  8  0  2 16  0]
 [ 0  3  0  5  7 15]]
Epoch: [8]
       [Avg Loss]          0.928931
       [Training]   Prec@1 66.554622 Max 66.554622
       [Avg Loss]          1.195985
       [Validation] Prec@1 63.783784 Max 63.783784
Confusion matrix:
[[24  1  4  0  1  0]
 [ 2 32  0  0  0  1]
 [ 1  6 22  1  0  0]
 [ 7  1  3 15  3  1]
 [12  8  0  2  7  1]
 [ 6  2  1  3  0 18]]
Epoch: [9]
       [Avg Loss]          0.834922
       [Training]   Prec@1 70.084034 Max 70.084034
       [Avg Loss]          1.297190
       [Validation] Prec@1 60.000000 Max 63.783784
Confusion matrix:
[[17  9  0  0  3  1]
 [ 0 34  0  0  0  1]
 [ 1  8 20  1  0  0]
 [ 3  1  2  8 15  1]
 [ 5  9  0  1 14  1]
 [ 3  2  0  4  3 18]]
Epoch: [10]
       [Avg Loss]          0.779046
       [Training]   Prec@1 73.277311 Max 73.277311
       [Avg Loss]          1.380923
       [Validation] Prec@1 53.513514 Max 63.783784
Confusion matrix:
[[23  3  3  0  0  1]
 [ 4 27  1  0  1  2]
 [ 3  5 21  1  0  0]
 [ 5  1  2  9 12  1]
 [12  7  1  1  8  1]
 [10  2  0  5  2 11]]
Epoch: [11]
       [Avg Loss]          0.706944
       [Training]   Prec@1 75.630252 Max 75.630252
       [Avg Loss]          1.326886
       [Validation] Prec@1 60.000000 Max 63.783784
Confusion matrix:
[[18  9  1  1  0  1]
 [ 0 34  0  0  0  1]
 [ 0  6 21  3  0  0]
 [ 7  1  2 15  4  1]
 [10  9  1  3  4  3]
 [ 4  3  0  4  0 19]]
Epoch: [12]
       [Avg Loss]          0.680062
       [Training]   Prec@1 76.134454 Max 76.134454
       [Avg Loss]          1.235167
       [Validation] Prec@1 59.459459 Max 63.783784
Confusion matrix:
[[17  2  4  0  4  3]
 [ 6 20  1  0  3  5]
 [ 1  1 27  1  0  0]
 [ 2  0  1 13 12  2]
 [ 4  7  1  3 14  1]
 [ 1  1  1  5  3 19]]
Epoch: [13]
       [Avg Loss]          0.649603
       [Training]   Prec@1 75.630252 Max 76.134454
       [Avg Loss]          1.329562
       [Validation] Prec@1 62.702703 Max 63.783784
Confusion matrix:
[[20  4  5  0  0  1]
 [ 0 33  0  0  0  2]
 [ 0  4 26  0  0  0]
 [ 6  1  2 15  4  2]
 [11  9  1  2  3  4]
 [ 6  3  0  2  0 19]]
Epoch: [14]
       [Avg Loss]          0.554315
       [Training]   Prec@1 80.504202 Max 80.504202
       [Avg Loss]          1.382176
       [Validation] Prec@1 60.540541 Max 63.783784
Confusion matrix:
[[20  2  4  1  3  0]
 [ 2 28  2  0  2  1]
 [ 0  2 27  1  0  0]
 [ 2  0  2  7 18  1]
 [ 2  8  0  3 15  2]
 [ 1  3  0  4  7 15]]
Fold "1" complete, final accuracy: 63.78378378378378
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.820528
       [Training]   Prec@1 27.058824 Max 27.058824
       [Avg Loss]          1.638213
       [Validation] Prec@1 30.270270 Max 30.270270
Confusion matrix:
[[ 6 15  3  0  0  6]
 [ 0 24  2  0  0  9]
 [21  4  3  1  0  1]
 [10  2  0  1  0 17]
 [ 8  5  0  1  0 16]
 [ 0  8  0  0  0 22]]
Epoch: [1]
       [Avg Loss]          1.705243
       [Training]   Prec@1 33.109244 Max 33.109244
       [Avg Loss]          1.545271
       [Validation] Prec@1 38.918919 Max 38.918919
Confusion matrix:
[[ 6 12  6  0  3  3]
 [ 0 27  5  0  1  2]
 [10  1 12  3  3  1]
 [ 1  5  0 10  1 13]
 [ 3  6  0  9  1 11]
 [ 0 14  0  0  0 16]]
Epoch: [2]
       [Avg Loss]          1.627470
       [Training]   Prec@1 36.134454 Max 36.134454
       [Avg Loss]          1.421100
       [Validation] Prec@1 45.945946 Max 45.945946
Confusion matrix:
[[ 8 19  1  2  0  0]
 [ 0 34  0  0  0  1]
 [ 3 10 17  0  0  0]
 [ 3  7  0 17  0  3]
 [ 4 11  0  9  4  2]
 [ 0 25  0  0  0  5]]
Epoch: [3]
       [Avg Loss]          1.483239
       [Training]   Prec@1 43.361345 Max 43.361345
       [Avg Loss]          1.373699
       [Validation] Prec@1 43.783784 Max 45.945946
Confusion matrix:
[[10 12  1  1  0  6]
 [ 2 15  4  2  1 11]
 [ 3  1 26  0  0  0]
 [ 3  0  1  6  7 13]
 [ 1  2  0  1  2 24]
 [ 3  3  2  0  0 22]]
Epoch: [4]
       [Avg Loss]          1.364082
       [Training]   Prec@1 49.243697 Max 49.243697
       [Avg Loss]          1.284854
       [Validation] Prec@1 49.189189 Max 49.189189
Confusion matrix:
[[ 6 12  0  1  0 11]
 [ 0 26  4  1  0  4]
 [ 1  0 24  5  0  0]
 [ 2  1  1  9  4 13]
 [ 1  2  0  4  9 14]
 [ 1  6  6  0  0 17]]
Epoch: [5]
       [Avg Loss]          1.142630
       [Training]   Prec@1 56.134454 Max 56.134454
       [Avg Loss]          1.389810
       [Validation] Prec@1 52.432432 Max 52.432432
Confusion matrix:
[[15  7  0  0  1  7]
 [ 4 15  5  0  2  9]
 [ 0  0 30  0  0  0]
 [ 0  1  6 11  4  8]
 [ 9  3  0  2 10  6]
 [ 6  2  6  0  0 16]]
Epoch: [6]
       [Avg Loss]          1.059555
       [Training]   Prec@1 60.336134 Max 60.336134
       [Avg Loss]          1.321554
       [Validation] Prec@1 51.891892 Max 52.432432
Confusion matrix:
[[17  8  0  0  3  2]
 [ 3 20  8  1  2  1]
 [ 1  0 26  3  0  0]
 [ 0  0  1 19  5  5]
 [ 8  4  0  8  7  3]
 [ 1 15  7  0  0  7]]
Epoch: [7]
       [Avg Loss]          0.937907
       [Training]   Prec@1 66.554622 Max 66.554622
       [Avg Loss]          1.076710
       [Validation] Prec@1 61.621622 Max 61.621622
Confusion matrix:
[[18  1  0  1  1  9]
 [ 4 12  0 11  1  7]
 [ 0  0 29  1  0  0]
 [ 0  0  5 23  0  2]
 [ 3  0  0 13  9  5]
 [ 1  2  2  2  0 23]]
Epoch: [8]
       [Avg Loss]          0.847175
       [Training]   Prec@1 69.411765 Max 69.411765
       [Avg Loss]          1.146624
       [Validation] Prec@1 60.000000 Max 61.621622
Confusion matrix:
[[19  3  1  3  1  3]
 [10 19  2  1  1  2]
 [ 0  0 27  2  1  0]
 [ 0  0  1 18  2  9]
 [ 1  5  0  4 15  5]
 [ 8  8  1  0  0 13]]
Epoch: [9]
       [Avg Loss]          0.766415
       [Training]   Prec@1 70.756303 Max 70.756303
       [Avg Loss]          1.284266
       [Validation] Prec@1 57.297297 Max 61.621622
Confusion matrix:
[[17  6  0  0  0  7]
 [ 4 15  5  0  3  8]
 [ 0  0 29  1  0  0]
 [ 0  0  1 20  3  6]
 [ 5  4  0  4 10  7]
 [ 1  7  7  0  0 15]]
Epoch: [10]
       [Avg Loss]          0.787361
       [Training]   Prec@1 69.075630 Max 70.756303
       [Avg Loss]          1.487824
       [Validation] Prec@1 49.189189 Max 61.621622
Confusion matrix:
[[16  1  0  5  0  8]
 [ 7 11  1  7  1  8]
 [ 0  0 23  7  0  0]
 [ 0  0  0 22  0  8]
 [ 1  0  0 11  3 15]
 [ 1  5  7  1  0 16]]
Epoch: [11]
       [Avg Loss]          0.678081
       [Training]   Prec@1 75.630252 Max 75.630252
       [Avg Loss]          1.364096
       [Validation] Prec@1 57.837838 Max 61.621622
Confusion matrix:
[[16  4  0  1  0  9]
 [ 4 11  2  4  2 12]
 [ 0  0 30  0  0  0]
 [ 0  0  1 18  0 11]
 [ 1  1  1  3 11 13]
 [ 5  2  1  1  0 21]]
Epoch: [12]
       [Avg Loss]          0.654170
       [Training]   Prec@1 77.142857 Max 77.142857
       [Avg Loss]          1.259502
       [Validation] Prec@1 56.756757 Max 61.621622
Confusion matrix:
[[13  7  0  2  0  8]
 [ 7 19  3  1  2  3]
 [ 0  0 25  5  0  0]
 [ 0  1  0 22  2  5]
 [ 2  6  0  6 15  1]
 [ 4  9  5  1  0 11]]
Epoch: [13]
       [Avg Loss]          0.548349
       [Training]   Prec@1 80.672269 Max 80.672269
       [Avg Loss]          1.311531
       [Validation] Prec@1 63.783784 Max 63.783784
Confusion matrix:
[[16  3  0  1  1  9]
 [ 3 15  4  5  4  4]
 [ 0  0 28  2  0  0]
 [ 0  0  1 25  0  4]
 [ 1  5  0  6 16  2]
 [ 3  3  4  2  0 18]]
Epoch: [14]
       [Avg Loss]          0.450384
       [Training]   Prec@1 84.537815 Max 84.537815
       [Avg Loss]          1.617720
       [Validation] Prec@1 49.729730 Max 63.783784
Confusion matrix:
[[11  2  0  3  0 14]
 [ 3 14  4  4  3  7]
 [ 0  0 27  3  0  0]
 [ 0  0  0 23  0  7]
 [ 1  5  0  7  2 15]
 [ 2  6  6  1  0 15]]
Fold "2" complete, final accuracy: 63.78378378378378
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.778306
       [Training]   Prec@1 29.696970 Max 29.696970
       [Avg Loss]          1.679084
       [Validation] Prec@1 39.166667 Max 39.166667
Confusion matrix:
[[10  0  5  3  2  0]
 [ 8  5  3  0  1  3]
 [ 5  0  6  2  0  7]
 [ 1  0  1 14  1  3]
 [ 6  0  4  9  0  1]
 [ 0  3  2  3  0 12]]
Epoch: [1]
       [Avg Loss]          1.525967
       [Training]   Prec@1 39.393939 Max 39.393939
       [Avg Loss]          1.537408
       [Validation] Prec@1 44.166667 Max 44.166667
Confusion matrix:
[[15  1  0  4  0  0]
 [ 6 12  1  1  0  0]
 [ 7  1  4  4  1  3]
 [ 1  0  1 18  0  0]
 [ 9  3  0  8  0  0]
 [ 1  5  0 10  0  4]]
Epoch: [2]
       [Avg Loss]          1.474756
       [Training]   Prec@1 41.969697 Max 41.969697
       [Avg Loss]          1.308685
       [Validation] Prec@1 54.166667 Max 54.166667
Confusion matrix:
[[18  0  0  2  0  0]
 [ 2 11  3  0  0  4]
 [ 4  0 11  1  0  4]
 [ 2  0  1 11  1  5]
 [ 6  6  0  5  3  0]
 [ 4  4  0  1  0 11]]
Epoch: [3]
       [Avg Loss]          1.305355
       [Training]   Prec@1 48.333333 Max 48.333333
       [Avg Loss]          1.655362
       [Validation] Prec@1 43.333333 Max 54.166667
Confusion matrix:
[[ 5  0  2 13  0  0]
 [ 4 13  0  2  0  1]
 [ 3  0 10  4  0  3]
 [ 1  0  0 18  0  1]
 [ 4  2  1 10  3  0]
 [ 5  4  0  8  0  3]]
Epoch: [4]
       [Avg Loss]          1.223282
       [Training]   Prec@1 55.454545 Max 55.454545
       [Avg Loss]          1.339606
       [Validation] Prec@1 54.166667 Max 54.166667
Confusion matrix:
[[12  3  0  1  4  0]
 [ 1 14  2  0  1  2]
 [ 3  1 13  0  2  1]
 [ 1  3  0 14  0  2]
 [ 5  7  1  4  2  1]
 [ 2  7  0  0  1 10]]
Epoch: [5]
       [Avg Loss]          1.106688
       [Training]   Prec@1 59.545455 Max 59.545455
       [Avg Loss]          1.735786
       [Validation] Prec@1 40.833333 Max 54.166667
Confusion matrix:
[[ 4  1  0  6  9  0]
 [ 0 18  0  1  1  0]
 [ 3  2  8  5  2  0]
 [ 1  2  0 15  2  0]
 [ 6  5  0  5  4  0]
 [ 4  7  0  2  7  0]]
Epoch: [6]
       [Avg Loss]          1.026350
       [Training]   Prec@1 60.757576 Max 60.757576
       [Avg Loss]          1.332795
       [Validation] Prec@1 59.166667 Max 59.166667
Confusion matrix:
[[12  0  0  5  3  0]
 [ 1 18  0  1  0  0]
 [ 1  1 12  5  1  0]
 [ 1  0  0 16  1  2]
 [ 5  5  0  6  4  0]
 [ 2  7  0  2  0  9]]
Epoch: [7]
       [Avg Loss]          0.911118
       [Training]   Prec@1 68.787879 Max 68.787879
       [Avg Loss]          1.441779
       [Validation] Prec@1 52.500000 Max 59.166667
Confusion matrix:
[[ 7  1  0  1 11  0]
 [ 0 18  0  1  1  0]
 [ 0  0 14  2  2  2]
 [ 1  2  0 15  1  1]
 [ 2  8  0  8  2  0]
 [ 3  6  0  2  2  7]]
Epoch: [8]
       [Avg Loss]          0.782417
       [Training]   Prec@1 69.696970 Max 69.696970
       [Avg Loss]          1.840053
       [Validation] Prec@1 47.500000 Max 59.166667
Confusion matrix:
[[ 8  2  0  1  9  0]
 [ 0 18  0  0  2  0]
 [ 3  0  9  5  1  2]
 [ 1  1  0 16  0  2]
 [ 2  7  0 10  1  0]
 [ 2  8  0  2  3  5]]
Epoch: [9]
       [Avg Loss]          0.755834
       [Training]   Prec@1 75.000000 Max 75.000000
       [Avg Loss]          1.609173
       [Validation] Prec@1 55.000000 Max 59.166667
Confusion matrix:
[[ 5  0  2  7  6  0]
 [ 0 18  0  2  0  0]
 [ 1  0 13  3  1  2]
 [ 0  1  0 16  1  2]
 [ 1  5  0 10  4  0]
 [ 2  5  0  2  1 10]]
Epoch: [10]
       [Avg Loss]          0.652745
       [Training]   Prec@1 77.121212 Max 77.121212
       [Avg Loss]          1.583009
       [Validation] Prec@1 57.500000 Max 59.166667
Confusion matrix:
[[ 4  1  1  2 12  0]
 [ 0 18  0  0  2  0]
 [ 2  0 14  2  0  2]
 [ 0  1  0 16  1  2]
 [ 0  8  0  3  9  0]
 [ 1  8  0  1  2  8]]
Epoch: [11]
       [Avg Loss]          0.662434
       [Training]   Prec@1 77.272727 Max 77.272727
       [Avg Loss]          1.791000
       [Validation] Prec@1 49.166667 Max 59.166667
Confusion matrix:
[[ 4  3  0  2 10  1]
 [ 0 18  0  0  2  0]
 [ 4  0  9  4  0  3]
 [ 0  1  0 15  3  1]
 [ 0  7  0  7  6  0]
 [ 0  5  0  1  7  7]]
Epoch: [12]
       [Avg Loss]          0.663397
       [Training]   Prec@1 76.060606 Max 77.272727
       [Avg Loss]          1.839603
       [Validation] Prec@1 50.000000 Max 59.166667
Confusion matrix:
[[ 3  6  2  1  8  0]
 [ 1 19  0  0  0  0]
 [ 0  0 15  2  3  0]
 [ 0  2  6 10  1  1]
 [ 0 10  0  6  4  0]
 [ 0  8  0  1  2  9]]
Epoch: [13]
       [Avg Loss]          0.532781
       [Training]   Prec@1 81.515152 Max 81.515152
       [Avg Loss]          1.680449
       [Validation] Prec@1 54.166667 Max 59.166667
Confusion matrix:
[[ 6  0  0  7  6  1]
 [ 1 15  1  2  1  0]
 [ 3  0 12  3  0  2]
 [ 0  2  0 15  1  2]
 [ 2  3  0  6  9  0]
 [ 1  8  0  2  1  8]]
Epoch: [14]
       [Avg Loss]          0.495774
       [Training]   Prec@1 83.181818 Max 83.181818
       [Avg Loss]          1.739382
       [Validation] Prec@1 50.833333 Max 59.166667
Confusion matrix:
[[ 1  4  0  2 13  0]
 [ 0 18  0  0  2  0]
 [ 0  0 14  4  1  1]
 [ 0  1  0 16  1  2]
 [ 0  6  0  8  6  0]
 [ 2  7  0  2  3  6]]
Fold "3" complete, final accuracy: 59.166666666666664
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.743475
       [Training]   Prec@1 30.149254 Max 30.149254
       [Avg Loss]          1.658278
       [Validation] Prec@1 25.454545 Max 25.454545
Confusion matrix:
[[ 0  4  9  0  7  0]
 [ 0  6 10  0  0  4]
 [ 0  4 16  0  0  0]
 [ 0  0 10  0 10  0]
 [ 1  0  4  0  5  0]
 [ 0  1 10  0  8  1]]
Epoch: [1]
       [Avg Loss]          1.601337
       [Training]   Prec@1 36.567164 Max 36.567164
       [Avg Loss]          1.720711
       [Validation] Prec@1 26.363636 Max 26.363636
Confusion matrix:
[[ 3  0 14  0  3  0]
 [ 6  4  8  0  0  2]
 [ 0  0 20  0  0  0]
 [ 0  0 15  0  5  0]
 [ 3  0  5  0  2  0]
 [ 0  0 15  0  5  0]]
Epoch: [2]
       [Avg Loss]          1.378289
       [Training]   Prec@1 45.671642 Max 45.671642
       [Avg Loss]          1.632806
       [Validation] Prec@1 38.181818 Max 38.181818
Confusion matrix:
[[13  0  5  0  2  0]
 [ 6 10  1  0  1  2]
 [ 1  2 17  0  0  0]
 [ 5  2  6  0  7  0]
 [10  0  0  0  0  0]
 [ 4  1  4  0  9  2]]
Epoch: [3]
       [Avg Loss]          1.364924
       [Training]   Prec@1 47.313433 Max 47.313433
       [Avg Loss]          1.682678
       [Validation] Prec@1 30.909091 Max 38.181818
Confusion matrix:
[[ 9  0  7  0  4  0]
 [ 3 10  6  1  0  0]
 [ 9  1 10  0  0  0]
 [ 4  2  7  4  3  0]
 [ 4  0  5  0  1  0]
 [ 1  3  5  5  6  0]]
Epoch: [4]
       [Avg Loss]          1.209434
       [Training]   Prec@1 52.686567 Max 52.686567
       [Avg Loss]          1.557163
       [Validation] Prec@1 40.909091 Max 40.909091
Confusion matrix:
[[12  0  0  2  6  0]
 [ 8  6  0  1  1  4]
 [ 9  1 10  0  0  0]
 [ 2  1  2  6  6  3]
 [ 3  0  0  2  5  0]
 [ 5  0  0  2  7  6]]
Epoch: [5]
       [Avg Loss]          1.144217
       [Training]   Prec@1 56.268657 Max 56.268657
       [Avg Loss]          1.484069
       [Validation] Prec@1 50.000000 Max 50.000000
Confusion matrix:
[[15  0  0  1  4  0]
 [10  3  0  0  1  6]
 [ 1  0 19  0  0  0]
 [ 0  0  5 10  2  3]
 [ 4  0  0  1  5  0]
 [ 9  4  0  1  3  3]]
Epoch: [6]
       [Avg Loss]          1.038293
       [Training]   Prec@1 61.791045 Max 61.791045
       [Avg Loss]          1.436702
       [Validation] Prec@1 45.454545 Max 50.000000
Confusion matrix:
[[14  0  3  1  2  0]
 [ 4  9  1  1  3  2]
 [ 0  1 19  0  0  0]
 [ 4  0  8  6  1  1]
 [ 5  0  5  0  0  0]
 [ 6  1  1  8  2  2]]
Epoch: [7]
       [Avg Loss]          0.914958
       [Training]   Prec@1 66.119403 Max 66.119403
       [Avg Loss]          1.433692
       [Validation] Prec@1 49.090909 Max 50.000000
Confusion matrix:
[[13  2  0  2  3  0]
 [ 1  9  0  2  5  3]
 [ 4  1 14  0  1  0]
 [ 3  0  3  6  4  4]
 [ 0  0  0  0 10  0]
 [ 2  1  0  9  6  2]]
Epoch: [8]
       [Avg Loss]          0.796534
       [Training]   Prec@1 71.641791 Max 71.641791
       [Avg Loss]          1.939875
       [Validation] Prec@1 46.363636 Max 50.000000
Confusion matrix:
[[16  0  3  1  0  0]
 [ 9  4  1  2  0  4]
 [ 0  0 20  0  0  0]
 [ 5  0  3  8  0  4]
 [ 0  0  0 10  0  0]
 [ 5  0  0 12  0  3]]
Epoch: [9]
       [Avg Loss]          0.747814
       [Training]   Prec@1 71.791045 Max 71.791045
       [Avg Loss]          1.624827
       [Validation] Prec@1 50.909091 Max 50.909091
Confusion matrix:
[[14  0  3  0  3  0]
 [ 3 10  0  1  6  0]
 [ 6  1 12  1  0  0]
 [ 3  0  4  6  7  0]
 [ 0  0  0  0 10  0]
 [ 2  0  0 10  4  4]]
Epoch: [10]
       [Avg Loss]          0.673515
       [Training]   Prec@1 73.432836 Max 73.432836
       [Avg Loss]          1.876027
       [Validation] Prec@1 42.727273 Max 50.909091
Confusion matrix:
[[13  0  3  1  3  0]
 [ 8  6  0  3  0  3]
 [ 2  0 16  2  0  0]
 [ 1  0  3  8  4  4]
 [ 0  0  0 10  0  0]
 [ 6  0  0 10  0  4]]
Epoch: [11]
       [Avg Loss]          0.608152
       [Training]   Prec@1 77.313433 Max 77.313433
       [Avg Loss]          1.651322
       [Validation] Prec@1 47.272727 Max 50.909091
Confusion matrix:
[[14  1  1  3  1  0]
 [ 3 10  0  2  4  1]
 [ 5  1 13  1  0  0]
 [ 2  0  4 12  2  0]
 [ 0  0  0 10  0  0]
 [ 3  1  0 10  3  3]]
Epoch: [12]
       [Avg Loss]          0.614765
       [Training]   Prec@1 76.268657 Max 77.313433
       [Avg Loss]          2.206306
       [Validation] Prec@1 37.272727 Max 50.909091
Confusion matrix:
[[14  0  5  0  1  0]
 [10  1  0  2  1  6]
 [ 0  0 19  1  0  0]
 [ 5  0  5  3  3  4]
 [ 0  0  0 10  0  0]
 [ 5  0  0 11  0  4]]
Epoch: [13]
       [Avg Loss]          0.548541
       [Training]   Prec@1 80.000000 Max 80.000000
       [Avg Loss]          1.982578
       [Validation] Prec@1 50.000000 Max 50.909091
Confusion matrix:
[[14  0  3  3  0  0]
 [ 9  9  0  1  0  1]
 [ 1  0 18  1  0  0]
 [ 0  0  4 12  0  4]
 [ 0  0  0 10  0  0]
 [ 4  0  0 14  0  2]]
Epoch: [14]
       [Avg Loss]          0.509343
       [Training]   Prec@1 82.388060 Max 82.388060
       [Avg Loss]          2.156207
       [Validation] Prec@1 41.818182 Max 50.909091
Confusion matrix:
[[11  0  4  0  5  0]
 [ 7  1  0  5  2  5]
 [ 2  0 17  1  0  0]
 [ 0  0  3 14  2  1]
 [ 0  0  0 10  0  0]
 [ 1  0  0 11  5  3]]
Fold "4" complete, final accuracy: 50.90909090909091

-----------------------------------------------------------------------
Training for stage 9 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=4)")
Average accuracy is: 56.63977613977613


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 10-----
Evaluated preprocessing: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=4)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.410402
       [Training]   Prec@1 44.833333 Max 44.833333
       [Avg Loss]          1.400881
       [Validation] Prec@1 67.222222 Max 67.222222
Confusion matrix:
[[26  0  0  3  0 11]
 [ 0 29  0  0  0  1]
 [ 0  0 30  0  0  0]
 [ 1  1 10  1 17  0]
 [ 0  0  8  6 16  0]
 [ 0  1  0  0  0 19]]
Epoch: [1]
       [Avg Loss]          1.156649
       [Training]   Prec@1 57.333333 Max 57.333333
       [Avg Loss]          1.225733
       [Validation] Prec@1 57.222222 Max 67.222222
Confusion matrix:
[[15  4  1 10  5  5]
 [ 0 27  0  0  0  3]
 [ 0  0 30  0  0  0]
 [ 1  1 17  1 10  0]
 [ 0  0 11  3 16  0]
 [ 1  5  0  0  0 14]]
Epoch: [2]
       [Avg Loss]          1.089964
       [Training]   Prec@1 58.000000 Max 58.000000
       [Avg Loss]          1.167477
       [Validation] Prec@1 56.666667 Max 67.222222
Confusion matrix:
[[26  0  1  5  0  8]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  1 27  1  0  0]
 [ 0  0 26  4  0  0]
 [ 0  5  0  0  0 15]]
Epoch: [3]
       [Avg Loss]          1.013657
       [Training]   Prec@1 63.166667 Max 63.166667
       [Avg Loss]          1.293175
       [Validation] Prec@1 62.222222 Max 67.222222
Confusion matrix:
[[18  0  1  2  9 10]
 [ 0 24  0  1  0  5]
 [ 0  1 29  0  0  0]
 [ 1  1 19  0  9  0]
 [ 0  1  5  2 22  0]
 [ 1  0  0  0  0 19]]
Epoch: [4]
       [Avg Loss]          0.987964
       [Training]   Prec@1 65.833333 Max 65.833333
       [Avg Loss]          1.577815
       [Validation] Prec@1 60.555556 Max 67.222222
Confusion matrix:
[[19  0  1  4  6 10]
 [ 0 30  0  0  0  0]
 [ 0  1 23  0  6  0]
 [ 1  2 10  0 17  0]
 [ 0  1  8  2 19  0]
 [ 0  1  0  1  0 18]]
Epoch: [5]
       [Avg Loss]          0.973818
       [Training]   Prec@1 67.666667 Max 67.666667
       [Avg Loss]          1.037433
       [Validation] Prec@1 63.333333 Max 67.222222
Confusion matrix:
[[27  0  0  3  0 10]
 [ 0 29  0  1  0  0]
 [ 0  0 30  0  0  0]
 [ 1  2 21  5  1  0]
 [ 0  0 10  8 12  0]
 [ 0  1  0  8  0 11]]
Epoch: [6]
       [Avg Loss]          0.898213
       [Training]   Prec@1 68.166667 Max 68.166667
       [Avg Loss]          1.064279
       [Validation] Prec@1 62.222222 Max 67.222222
Confusion matrix:
[[20  0  0 10  0 10]
 [ 0 28  0  1  0  1]
 [ 0  0 30  0  0  0]
 [ 1  1 21  2  5  0]
 [ 0  0  8  5 17  0]
 [ 4  1  0  0  0 15]]
Epoch: [7]
       [Avg Loss]          0.853731
       [Training]   Prec@1 69.000000 Max 69.000000
       [Avg Loss]          1.266265
       [Validation] Prec@1 57.777778 Max 67.222222
Confusion matrix:
[[18  0  1 18  1  2]
 [ 0 28  0  2  0  0]
 [ 0  0 30  0  0  0]
 [ 1  1 19  3  6  0]
 [ 0  0  7  5 18  0]
 [ 0  0  0 13  0  7]]
Epoch: [8]
       [Avg Loss]          0.892121
       [Training]   Prec@1 67.500000 Max 69.000000
       [Avg Loss]          1.283988
       [Validation] Prec@1 56.111111 Max 67.222222
Confusion matrix:
[[11  1  0 16  3  9]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 16  3 10  0]
 [ 0  0  4  7 19  0]
 [ 0  1  0 11  0  8]]
Epoch: [9]
       [Avg Loss]          0.830133
       [Training]   Prec@1 72.166667 Max 72.166667
       [Avg Loss]          1.424036
       [Validation] Prec@1 61.111111 Max 67.222222
Confusion matrix:
[[24  0  0  6  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 15  0 15  0]
 [ 2  1  8  2 17  0]
 [ 1  0  0  5 24  0]
 [ 4  1  0  0  0 15]]
Epoch: [10]
       [Avg Loss]          0.791353
       [Training]   Prec@1 71.833333 Max 72.166667
       [Avg Loss]          1.235339
       [Validation] Prec@1 63.333333 Max 67.222222
Confusion matrix:
[[20  0  0 11  0  9]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  5  7  3 14  0]
 [ 0  0  2  8 20  0]
 [ 3  1  0  5  0 11]]
Epoch: [11]
       [Avg Loss]          0.712495
       [Training]   Prec@1 76.833333 Max 76.833333
       [Avg Loss]          1.483617
       [Validation] Prec@1 63.888889 Max 67.222222
Confusion matrix:
[[16  1  7  3  3 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 17  1 11  0]
 [ 0  0  7  3 20  0]
 [ 0  1  0  1  0 18]]
Epoch: [12]
       [Avg Loss]          0.714840
       [Training]   Prec@1 75.333333 Max 76.833333
       [Avg Loss]          1.511001
       [Validation] Prec@1 63.888889 Max 67.222222
Confusion matrix:
[[15  0  4  5  6 10]
 [ 0 30  0  0  0  0]
 [ 0  0 28  0  2  0]
 [ 1  5 13  1 10  0]
 [ 0  2  2  5 21  0]
 [ 0  0  0  0  0 20]]
Epoch: [13]
       [Avg Loss]          0.749799
       [Training]   Prec@1 74.333333 Max 76.833333
       [Avg Loss]          1.270723
       [Validation] Prec@1 56.111111 Max 67.222222
Confusion matrix:
[[21  0  0 10  0  9]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  4 14  7  4  0]
 [ 0  1 12 13  4  0]
 [ 5  5  0  1  0  9]]
Epoch: [14]
       [Avg Loss]          0.716306
       [Training]   Prec@1 75.166667 Max 76.833333
       [Avg Loss]          2.070032
       [Validation] Prec@1 53.888889 Max 67.222222
Confusion matrix:
[[17  0  0  6  7 10]
 [ 0 29  0  1  0  0]
 [ 0  0  5  0 25  0]
 [ 1  1  3  1 24  0]
 [ 0  1  2  0 27  0]
 [ 0  0  0  2  0 18]]
Fold "0" complete, final accuracy: 67.22222222222223
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.473304
       [Training]   Prec@1 44.873950 Max 44.873950
       [Avg Loss]          1.367183
       [Validation] Prec@1 62.162162 Max 62.162162
Confusion matrix:
[[14  1  0  6  0  9]
 [ 0 29  4  0  0  2]
 [ 0  2 20  0  8  0]
 [ 6  1  9  2  4  8]
 [ 0  1  6  1 21  1]
 [ 0  0  1  0  0 29]]
Epoch: [1]
       [Avg Loss]          1.153375
       [Training]   Prec@1 58.655462 Max 58.655462
       [Avg Loss]          1.197387
       [Validation] Prec@1 60.540541 Max 62.162162
Confusion matrix:
[[20  3  0  0  0  7]
 [ 1 32  0  2  0  0]
 [ 0  4 14  7  5  0]
 [ 6  2  2  5 11  4]
 [ 0  4  2  4 20  0]
 [ 7  1  1  0  0 21]]
Epoch: [2]
       [Avg Loss]          1.150132
       [Training]   Prec@1 58.655462 Max 58.655462
       [Avg Loss]          1.354352
       [Validation] Prec@1 60.000000 Max 62.162162
Confusion matrix:
[[20  4  0  0  0  6]
 [ 1 32  0  2  0  0]
 [ 0  3 21  6  0  0]
 [16  2  3  3  1  5]
 [ 8  2  3  6 11  0]
 [ 2  2  1  1  0 24]]
Epoch: [3]
       [Avg Loss]          1.028793
       [Training]   Prec@1 63.529412 Max 63.529412
       [Avg Loss]          1.110388
       [Validation] Prec@1 63.783784 Max 63.783784
Confusion matrix:
[[16  2  0  4  0  8]
 [ 0 31  0  2  0  2]
 [ 0  3 21  6  0  0]
 [ 9  1  6  7  0  7]
 [ 0  0 12  3 14  1]
 [ 0  0  1  0  0 29]]
Epoch: [4]
       [Avg Loss]          0.980391
       [Training]   Prec@1 66.386555 Max 66.386555
       [Avg Loss]          1.149619
       [Validation] Prec@1 55.675676 Max 63.783784
Confusion matrix:
[[20  4  0  0  0  6]
 [ 0 27  0  8  0  0]
 [ 0  2 17 10  1  0]
 [14  2  3  6  2  3]
 [ 5  0  3  7 15  0]
 [ 8  1  1  2  0 18]]
Epoch: [5]
       [Avg Loss]          0.889444
       [Training]   Prec@1 70.252101 Max 70.252101
       [Avg Loss]          1.202509
       [Validation] Prec@1 60.540541 Max 63.783784
Confusion matrix:
[[19  2  0  1  0  8]
 [ 1 29  0  3  0  2]
 [ 0  3 21  6  0  0]
 [15  0  3  4  2  6]
 [ 1  0  3 11 15  0]
 [ 4  0  1  1  0 24]]
Epoch: [6]
       [Avg Loss]          0.886469
       [Training]   Prec@1 70.084034 Max 70.252101
       [Avg Loss]          1.675051
       [Validation] Prec@1 52.972973 Max 63.783784
Confusion matrix:
[[20  1  0  0  0  9]
 [ 1 25  1  1  0  7]
 [ 0  2  2  5 21  0]
 [13  0  1  4  6  6]
 [ 0  0  2  7 21  0]
 [ 2  0  1  1  0 26]]
Epoch: [7]
       [Avg Loss]          1.033393
       [Training]   Prec@1 60.168067 Max 70.252101
       [Avg Loss]          1.280771
       [Validation] Prec@1 57.837838 Max 63.783784
Confusion matrix:
[[20  6  0  0  0  4]
 [ 0 32  2  1  0  0]
 [ 0  3 20  7  0  0]
 [17  3  2  6  2  0]
 [ 7  1  5  5 12  0]
 [ 9  1  1  2  0 17]]
Epoch: [8]
       [Avg Loss]          0.966931
       [Training]   Prec@1 64.033613 Max 70.252101
       [Avg Loss]          1.197401
       [Validation] Prec@1 60.000000 Max 63.783784
Confusion matrix:
[[19  2  0  1  0  8]
 [ 0 30  0  2  0  3]
 [ 0  3 13 13  1  0]
 [12  1  2  9  1  5]
 [ 3  1  3  8 15  0]
 [ 2  0  0  3  0 25]]
Epoch: [9]
       [Avg Loss]          0.869101
       [Training]   Prec@1 69.579832 Max 70.252101
       [Avg Loss]          1.394682
       [Validation] Prec@1 51.891892 Max 63.783784
Confusion matrix:
[[20  2  0  0  0  8]
 [ 1 27  0  5  0  2]
 [ 0  3  6 10 11  0]
 [14  1  3  5  2  5]
 [ 6  0  2  7 15  0]
 [ 1  0  3  3  0 23]]
Epoch: [10]
       [Avg Loss]          0.826018
       [Training]   Prec@1 71.932773 Max 71.932773
       [Avg Loss]          1.265283
       [Validation] Prec@1 57.837838 Max 63.783784
Confusion matrix:
[[19  3  0  1  0  7]
 [ 1 32  1  1  0  0]
 [ 0  4  8 10  8  0]
 [10  2  2 10  2  4]
 [ 1  0  2 12 15  0]
 [ 4  0  0  3  0 23]]
Epoch: [11]
       [Avg Loss]          0.773367
       [Training]   Prec@1 72.100840 Max 72.100840
       [Avg Loss]          1.484358
       [Validation] Prec@1 60.000000 Max 63.783784
Confusion matrix:
[[20  4  0  0  0  6]
 [ 1 33  0  1  0  0]
 [ 0  8 11  9  2  0]
 [13  2  2  7  2  4]
 [ 6  3  0  6 15  0]
 [ 2  0  0  3  0 25]]
Epoch: [12]
       [Avg Loss]          0.766759
       [Training]   Prec@1 74.789916 Max 74.789916
       [Avg Loss]          1.431291
       [Validation] Prec@1 54.594595 Max 63.783784
Confusion matrix:
[[20  2  0  0  0  8]
 [ 1 28  0  6  0  0]
 [ 0  2  4 18  6  0]
 [14  1  1  9  1  4]
 [ 5  0  1  9 15  0]
 [ 1  1  0  3  0 25]]
Epoch: [13]
       [Avg Loss]          0.828392
       [Training]   Prec@1 70.588235 Max 74.789916
       [Avg Loss]          1.269417
       [Validation] Prec@1 64.324324 Max 64.324324
Confusion matrix:
[[20  2  0  0  0  8]
 [ 1 31  0  1  0  2]
 [ 0  7 21  2  0  0]
 [15  3  1  5  2  4]
 [ 1  1  2  8 18  0]
 [ 3  0  0  3  0 24]]
Epoch: [14]
       [Avg Loss]          0.700740
       [Training]   Prec@1 76.302521 Max 76.302521
       [Avg Loss]          1.226712
       [Validation] Prec@1 57.297297 Max 64.324324
Confusion matrix:
[[19  2  0  1  0  8]
 [ 1 27  1  3  0  3]
 [ 0  3 19  7  1  0]
 [16  0  1  7  3  3]
 [ 0  1  3 11 15  0]
 [ 7  0  2  2  0 19]]
Fold "1" complete, final accuracy: 64.32432432432432
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.496130
       [Training]   Prec@1 44.369748 Max 44.369748
       [Avg Loss]          1.452268
       [Validation] Prec@1 60.540541 Max 60.540541
Confusion matrix:
[[22  6  1  1  0  0]
 [ 2 30  2  0  0  1]
 [ 4  0 23  3  0  0]
 [14 11  1  0  0  4]
 [10  0  7  4  9  0]
 [ 0  2  0  0  0 28]]
Epoch: [1]
       [Avg Loss]          1.180361
       [Training]   Prec@1 56.302521 Max 56.302521
       [Avg Loss]          1.094173
       [Validation] Prec@1 62.702703 Max 62.702703
Confusion matrix:
[[14  6  1  4  3  2]
 [ 1 24  0  1  1  8]
 [ 3  0 18  0  9  0]
 [ 9  4  4  1  3  9]
 [ 1  0  0  0 29  0]
 [ 0  0  0  0  0 30]]
Epoch: [2]
       [Avg Loss]          1.175281
       [Training]   Prec@1 60.168067 Max 60.168067
       [Avg Loss]          1.330000
       [Validation] Prec@1 52.972973 Max 62.702703
Confusion matrix:
[[12  6  1  8  0  3]
 [ 1 23  1  1  0  9]
 [ 5  0 13 12  0  0]
 [ 3  6  2 11  0  8]
 [ 1  1 13  6  9  0]
 [ 0  0  0  0  0 30]]
Epoch: [3]
       [Avg Loss]          1.072816
       [Training]   Prec@1 57.310924 Max 60.168067
       [Avg Loss]          1.102137
       [Validation] Prec@1 68.648649 Max 68.648649
Confusion matrix:
[[19  5  2  2  2  0]
 [ 2 31  0  0  1  1]
 [ 6  0 18  0  6  0]
 [10  6  4  3  3  4]
 [ 1  0  0  0 29  0]
 [ 0  3  0  0  0 27]]
Epoch: [4]
       [Avg Loss]          1.072764
       [Training]   Prec@1 64.537815 Max 64.537815
       [Avg Loss]          1.282959
       [Validation] Prec@1 55.675676 Max 68.648649
Confusion matrix:
[[14  5  1  8  1  1]
 [ 1 22  1  2  0  9]
 [ 2  0  5 14  9  0]
 [ 9  3  3  4  1 10]
 [ 2  0  0  0 28  0]
 [ 0  0  0  0  0 30]]
Epoch: [5]
       [Avg Loss]          1.003255
       [Training]   Prec@1 66.554622 Max 66.554622
       [Avg Loss]          1.170116
       [Validation] Prec@1 57.297297 Max 68.648649
Confusion matrix:
[[18  6  1  4  1  0]
 [ 4 27  1  1  0  2]
 [ 9  0 12  9  0  0]
 [13  5  1  7  1  3]
 [ 1  0 10  6 13  0]
 [ 1  0  0  0  0 29]]
Epoch: [6]
       [Avg Loss]          0.996562
       [Training]   Prec@1 66.722689 Max 66.722689
       [Avg Loss]          1.063178
       [Validation] Prec@1 62.702703 Max 68.648649
Confusion matrix:
[[11  3  3 11  1  1]
 [ 0 28  2  2  0  3]
 [ 2  0 14 12  2  0]
 [ 7  3  4  9  1  6]
 [ 3  0  1  0 26  0]
 [ 0  2  0  0  0 28]]
Epoch: [7]
       [Avg Loss]          0.918064
       [Training]   Prec@1 68.067227 Max 68.067227
       [Avg Loss]          1.310081
       [Validation] Prec@1 54.594595 Max 68.648649
Confusion matrix:
[[12  7  0 10  1  0]
 [ 0 29  0  4  0  2]
 [ 5  0  3 19  3  0]
 [10  8  0 10  1  1]
 [11  0  0  0 19  0]
 [ 0  2  0  0  0 28]]
Epoch: [8]
       [Avg Loss]          0.944942
       [Training]   Prec@1 68.403361 Max 68.403361
       [Avg Loss]          1.108645
       [Validation] Prec@1 68.108108 Max 68.648649
Confusion matrix:
[[20  5  1  2  2  0]
 [ 2 20  1  6  0  6]
 [ 5  0 17  4  4  0]
 [10  0  2  9  6  3]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0  0 30]]
Epoch: [9]
       [Avg Loss]          0.859590
       [Training]   Prec@1 71.260504 Max 71.260504
       [Avg Loss]          1.100975
       [Validation] Prec@1 61.621622 Max 68.648649
Confusion matrix:
[[ 4  7  1 12  2  4]
 [ 2 27  1  2  0  3]
 [ 4  0 10 13  3  0]
 [ 2  2  3 16  5  2]
 [ 0  0  0  0 30  0]
 [ 1  2  0  0  0 27]]
Epoch: [10]
       [Avg Loss]          0.813459
       [Training]   Prec@1 71.764706 Max 71.764706
       [Avg Loss]          1.070611
       [Validation] Prec@1 65.405405 Max 68.648649
Confusion matrix:
[[12  5  0 12  1  0]
 [ 3 25  0  5  0  2]
 [ 5  1 19  5  0  0]
 [ 7  3  1 15  2  2]
 [ 5  0  0  1 24  0]
 [ 4  0  0  0  0 26]]
Epoch: [11]
       [Avg Loss]          0.749765
       [Training]   Prec@1 74.621849 Max 74.621849
       [Avg Loss]          1.450940
       [Validation] Prec@1 49.729730 Max 68.648649
Confusion matrix:
[[ 0  5  4 13  0  8]
 [ 7 15  3  3  0  7]
 [ 2  0 16 12  0  0]
 [ 0  0  7 16  1  6]
 [ 0  0 12  3 15  0]
 [ 0  0  0  0  0 30]]
Epoch: [12]
       [Avg Loss]          0.817606
       [Training]   Prec@1 72.100840 Max 74.621849
       [Avg Loss]          1.080917
       [Validation] Prec@1 69.729730 Max 69.729730
Confusion matrix:
[[ 8  5  3 14  0  0]
 [ 1 31  1  0  0  2]
 [ 0  1 26  3  0  0]
 [ 0  6  4 15  2  3]
 [ 0  0  5  1 24  0]
 [ 2  3  0  0  0 25]]
Epoch: [13]
       [Avg Loss]          0.814033
       [Training]   Prec@1 71.932773 Max 74.621849
       [Avg Loss]          1.251177
       [Validation] Prec@1 58.378378 Max 69.729730
Confusion matrix:
[[15  5  2  6  1  1]
 [ 1 13  0  8  0 13]
 [ 5  0 13 12  0  0]
 [10  1  1 13  2  3]
 [ 1  0  2  3 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [14]
       [Avg Loss]          0.688851
       [Training]   Prec@1 75.294118 Max 75.294118
       [Avg Loss]          1.207567
       [Validation] Prec@1 58.918919 Max 69.729730
Confusion matrix:
[[10  6  2 11  0  1]
 [ 0 32  1  0  0  2]
 [ 2  0 13 15  0  0]
 [ 7  3  2 14  2  2]
 [ 1  0  4  9 16  0]
 [ 3  3  0  0  0 24]]
Fold "2" complete, final accuracy: 69.72972972972973
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.524461
       [Training]   Prec@1 40.151515 Max 40.151515
       [Avg Loss]          1.315430
       [Validation] Prec@1 67.500000 Max 67.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 20  0  0  0  0]
 [ 0  2 15  3  0  0]
 [ 9  1  5  0  0  5]
 [ 0  0  7  6  7  0]
 [ 0  1  0  0  0 19]]
Epoch: [1]
       [Avg Loss]          1.232853
       [Training]   Prec@1 60.000000 Max 60.000000
       [Avg Loss]          1.108472
       [Validation] Prec@1 63.333333 Max 67.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 20  0  0  0  0]
 [ 0  2 18  0  0  0]
 [15  2  0  0  0  3]
 [ 2  0 18  0  0  0]
 [ 0  2  0  0  0 18]]
Epoch: [2]
       [Avg Loss]          1.220326
       [Training]   Prec@1 57.272727 Max 60.000000
       [Avg Loss]          0.912896
       [Validation] Prec@1 70.000000 Max 70.000000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 14  0  0  0  6]
 [ 0  1 12  0  7  0]
 [ 7  1  3  4  1  4]
 [ 0  0  5  0 15  0]
 [ 0  1  0  0  0 19]]
Epoch: [3]
       [Avg Loss]          1.182735
       [Training]   Prec@1 56.212121 Max 60.000000
       [Avg Loss]          0.966269
       [Validation] Prec@1 67.500000 Max 70.000000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 20  0  0  0  0]
 [ 0  5 13  0  2  0]
 [15  2  0  2  0  1]
 [ 2  0  9  0  9  0]
 [ 0  3  0  0  0 17]]
Epoch: [4]
       [Avg Loss]          1.159842
       [Training]   Prec@1 60.909091 Max 60.909091
       [Avg Loss]          0.808689
       [Validation] Prec@1 73.333333 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 18  0  0  0  2]
 [ 0  1 18  0  1  0]
 [12  1  0  6  0  1]
 [ 0  0 10  2  8  0]
 [ 0  2  0  0  0 18]]
Epoch: [5]
       [Avg Loss]          1.017003
       [Training]   Prec@1 63.636364 Max 63.636364
       [Avg Loss]          1.017581
       [Validation] Prec@1 68.333333 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 18  0  1  0  1]
 [ 0  1 19  0  0  0]
 [ 8  1  3  7  0  1]
 [ 0  0 20  0  0  0]
 [ 0  1  0  1  0 18]]
Epoch: [6]
       [Avg Loss]          1.035276
       [Training]   Prec@1 63.484848 Max 63.636364
       [Avg Loss]          1.306895
       [Validation] Prec@1 52.500000 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 16  0  1  0  3]
 [ 0  9  7  4  0  0]
 [13  2  0  4  0  1]
 [ 0  4 15  1  0  0]
 [ 3  0  0  1  0 16]]
Epoch: [7]
       [Avg Loss]          1.001227
       [Training]   Prec@1 63.484848 Max 63.636364
       [Avg Loss]          0.862325
       [Validation] Prec@1 65.833333 Max 73.333333
Confusion matrix:
[[13  0  0  7  0  0]
 [ 0 11  1  1  0  7]
 [ 0  0 16  2  2  0]
 [ 1  0  1 15  3  0]
 [ 0  0  9  0 11  0]
 [ 1  0  0  6  0 13]]
Epoch: [8]
       [Avg Loss]          1.007578
       [Training]   Prec@1 64.696970 Max 64.696970
       [Avg Loss]          0.940252
       [Validation] Prec@1 58.333333 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 19  0  1  0  0]
 [ 0  1 19  0  0  0]
 [16  1  1  1  0  1]
 [ 0  0 14  2  4  0]
 [ 2  2  0  9  0  7]]
Epoch: [9]
       [Avg Loss]          0.901845
       [Training]   Prec@1 68.939394 Max 68.939394
       [Avg Loss]          0.611950
       [Validation] Prec@1 80.833333 Max 80.833333
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 20  0  0  0]
 [ 7  2  0 10  0  1]
 [ 0  0  7  1 12  0]
 [ 0  3  0  0  0 17]]
Epoch: [10]
       [Avg Loss]          0.814316
       [Training]   Prec@1 71.060606 Max 71.060606
       [Avg Loss]          0.754177
       [Validation] Prec@1 71.666667 Max 80.833333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 18  0  1  0  1]
 [ 0  1 15  4  0  0]
 [13  1  0  4  1  1]
 [ 0  0  8  2 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [11]
       [Avg Loss]          0.755366
       [Training]   Prec@1 74.545455 Max 74.545455
       [Avg Loss]          0.741760
       [Validation] Prec@1 74.166667 Max 80.833333
Confusion matrix:
[[18  0  0  1  1  0]
 [ 1 15  0  1  0  3]
 [ 0  1 13  0  6  0]
 [ 7  4  1  6  1  1]
 [ 0  0  0  1 19  0]
 [ 0  0  0  2  0 18]]
Epoch: [12]
       [Avg Loss]          0.867774
       [Training]   Prec@1 71.515152 Max 74.545455
       [Avg Loss]          0.901025
       [Validation] Prec@1 65.833333 Max 80.833333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 1 15  0  1  0  3]
 [ 0  0 16  1  3  0]
 [16  0  0  3  0  1]
 [ 0  0  9  0 11  0]
 [ 4  0  0  2  0 14]]
Epoch: [13]
       [Avg Loss]          0.816598
       [Training]   Prec@1 71.818182 Max 74.545455
       [Avg Loss]          0.660654
       [Validation] Prec@1 78.333333 Max 80.833333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 18  0  0  0  2]
 [ 0  1 19  0  0  0]
 [ 6  1  0 11  0  2]
 [ 0  0 12  0  8  0]
 [ 0  2  0  0  0 18]]
Epoch: [14]
       [Avg Loss]          0.749384
       [Training]   Prec@1 75.454545 Max 75.454545
       [Avg Loss]          0.768782
       [Validation] Prec@1 73.333333 Max 80.833333
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0 18  0  1  0  1]
 [ 0  0 20  0  0  0]
 [10  1  1  7  0  1]
 [ 0  0  9  2  9  0]
 [ 2  1  0  2  0 15]]
Fold "3" complete, final accuracy: 80.83333333333333
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.391555
       [Training]   Prec@1 48.358209 Max 48.358209
       [Avg Loss]          1.606653
       [Validation] Prec@1 46.363636 Max 46.363636
Confusion matrix:
[[12  4  3  0  1  0]
 [ 0  6  4  0 10  0]
 [ 7  0 10  0  3  0]
 [ 0  6 14  0  0  0]
 [ 0  0  0  0 10  0]
 [ 4  2  1  0  0 13]]
Epoch: [1]
       [Avg Loss]          1.105183
       [Training]   Prec@1 61.791045 Max 61.791045
       [Avg Loss]          1.630937
       [Validation] Prec@1 47.272727 Max 47.272727
Confusion matrix:
[[10  4  3  0  2  1]
 [ 0  5 12  0  3  0]
 [ 4  0 12  1  1  2]
 [ 0  6 13  0  0  1]
 [ 0  0  4  0  6  0]
 [ 0  1  0  0  0 19]]
Epoch: [2]
       [Avg Loss]          1.026094
       [Training]   Prec@1 62.686567 Max 62.686567
       [Avg Loss]          1.673461
       [Validation] Prec@1 47.272727 Max 47.272727
Confusion matrix:
[[11  3  2  2  0  2]
 [ 0  4 13  2  1  0]
 [ 6  0 11  2  1  0]
 [ 0  5 10  2  0  3]
 [ 0  0  5  0  5  0]
 [ 0  1  0  0  0 19]]
Epoch: [3]
       [Avg Loss]          1.024521
       [Training]   Prec@1 61.791045 Max 62.686567
       [Avg Loss]          1.722736
       [Validation] Prec@1 50.909091 Max 50.909091
Confusion matrix:
[[12  5  1  2  0  0]
 [ 0  8  3  3  5  1]
 [ 6  0  5  2  6  1]
 [ 0 13  3  3  0  1]
 [ 0  0  0  0 10  0]
 [ 1  1  0  0  0 18]]
Epoch: [4]
       [Avg Loss]          0.953229
       [Training]   Prec@1 64.477612 Max 64.477612
       [Avg Loss]          2.199867
       [Validation] Prec@1 46.363636 Max 50.909091
Confusion matrix:
[[10  3  1  2  3  1]
 [ 0  7  4  0  9  0]
 [ 4  0  0  2 13  1]
 [ 0  5  7  5  3  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [5]
       [Avg Loss]          0.976045
       [Training]   Prec@1 64.477612 Max 64.477612
       [Avg Loss]          1.929463
       [Validation] Prec@1 48.181818 Max 50.909091
Confusion matrix:
[[12  5  1  2  0  0]
 [ 0 10  6  1  3  0]
 [ 6  0  7  2  5  0]
 [ 0 12  4  3  1  0]
 [ 0  0  0  0 10  0]
 [ 5  2  0  2  0 11]]
Epoch: [6]
       [Avg Loss]          0.890359
       [Training]   Prec@1 67.910448 Max 67.910448
       [Avg Loss]          1.666704
       [Validation] Prec@1 58.181818 Max 58.181818
Confusion matrix:
[[12  3  1  4  0  0]
 [ 0  7  4  1  8  0]
 [ 8  0 10  1  1  0]
 [ 0  5  5  8  2  0]
 [ 0  0  0  0 10  0]
 [ 1  0  0  2  0 17]]
Epoch: [7]
       [Avg Loss]          0.817415
       [Training]   Prec@1 70.746269 Max 70.746269
       [Avg Loss]          1.881499
       [Validation] Prec@1 47.272727 Max 58.181818
Confusion matrix:
[[11  4  2  3  0  0]
 [ 0  7  5  3  5  0]
 [ 6  0  8  2  4  0]
 [ 0  6  5  4  5  0]
 [ 0  0  0  0 10  0]
 [ 4  1  0  3  0 12]]
Epoch: [8]
       [Avg Loss]          0.830632
       [Training]   Prec@1 70.298507 Max 70.746269
       [Avg Loss]          1.782908
       [Validation] Prec@1 59.090909 Max 59.090909
Confusion matrix:
[[11  4  1  4  0  0]
 [ 0  7  5  7  1  0]
 [ 6  0  7  4  2  1]
 [ 0  6  3 11  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [9]
       [Avg Loss]          0.841426
       [Training]   Prec@1 68.656716 Max 70.746269
       [Avg Loss]          1.706203
       [Validation] Prec@1 49.090909 Max 59.090909
Confusion matrix:
[[11  4  1  4  0  0]
 [ 0  7  3  6  4  0]
 [ 4  0 11  4  1  0]
 [ 0  6  6  7  1  0]
 [ 0  0  3  0  7  0]
 [ 3  5  0  1  0 11]]
Epoch: [10]
       [Avg Loss]          0.753295
       [Training]   Prec@1 70.895522 Max 70.895522
       [Avg Loss]          1.848913
       [Validation] Prec@1 57.272727 Max 59.090909
Confusion matrix:
[[ 8  4  3  2  3  0]
 [ 0  8  7  0  5  0]
 [ 6  0 12  1  0  1]
 [ 0  7  2 10  0  1]
 [ 0  0  4  0  6  0]
 [ 0  1  0  0  0 19]]
Epoch: [11]
       [Avg Loss]          0.755263
       [Training]   Prec@1 73.880597 Max 73.880597
       [Avg Loss]          1.722669
       [Validation] Prec@1 49.090909 Max 59.090909
Confusion matrix:
[[10  3  1  6  0  0]
 [ 0  7  2  6  5  0]
 [ 6  0  6  2  5  1]
 [ 0  6  1  8  5  0]
 [ 0  0  0  0 10  0]
 [ 4  0  0  3  0 13]]
Epoch: [12]
       [Avg Loss]          0.716515
       [Training]   Prec@1 74.179104 Max 74.179104
       [Avg Loss]          1.883329
       [Validation] Prec@1 51.818182 Max 59.090909
Confusion matrix:
[[ 7  4  1  5  3  0]
 [ 0  7  3  3  7  0]
 [ 5  0 10  3  1  1]
 [ 0  6  3 11  0  0]
 [ 0  0  0  0 10  0]
 [ 2  2  0  4  0 12]]
Epoch: [13]
       [Avg Loss]          0.741514
       [Training]   Prec@1 73.283582 Max 74.179104
       [Avg Loss]          1.843988
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[13  5  0  2  0  0]
 [ 1  8  2  5  3  1]
 [ 8  0  5  2  4  1]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 3  1  0  0  0 16]]
Epoch: [14]
       [Avg Loss]          0.773982
       [Training]   Prec@1 71.044776 Max 74.179104
       [Avg Loss]          1.736049
       [Validation] Prec@1 52.727273 Max 60.000000
Confusion matrix:
[[10  4  0  6  0  0]
 [ 0  8  2  6  4  0]
 [ 6  0 11  2  0  1]
 [ 0  6  0 14  0  0]
 [ 0  0  5  3  2  0]
 [ 3  1  0  3  0 13]]
Fold "4" complete, final accuracy: 60.0

-----------------------------------------------------------------------
Training for stage 10 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=4)")
Average accuracy is: 68.42192192192192


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 11-----
Evaluated preprocessing: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=4)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.734927
       [Training]   Prec@1 29.833333 Max 29.833333
       [Avg Loss]          1.770312
       [Validation] Prec@1 17.777778 Max 17.777778
Confusion matrix:
[[ 0  3 37  0  0  0]
 [ 0  2 28  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  4 26  0  0  0]
 [ 0  1 29  0  0  0]
 [ 0  1 16  3  0  0]]
Epoch: [1]
       [Avg Loss]          1.491286
       [Training]   Prec@1 38.833333 Max 38.833333
       [Avg Loss]          1.873682
       [Validation] Prec@1 19.444444 Max 19.444444
Confusion matrix:
[[ 0  0  8 32  0  0]
 [ 0  0  7 22  1  0]
 [ 0  0 16 14  0  0]
 [ 0  0 11 19  0  0]
 [ 0  0  9 21  0  0]
 [ 0  0  4 16  0  0]]
Epoch: [2]
       [Avg Loss]          1.475272
       [Training]   Prec@1 41.833333 Max 41.833333
       [Avg Loss]          1.858797
       [Validation] Prec@1 20.555556 Max 20.555556
Confusion matrix:
[[ 0  0 25  0 15  0]
 [ 0  0 19  2  9  0]
 [ 0  0 28  0  2  0]
 [ 0  0 25  0  4  1]
 [ 0  0 21  0  9  0]
 [ 0  0 10  1  9  0]]
Epoch: [3]
       [Avg Loss]          1.397700
       [Training]   Prec@1 39.500000 Max 41.833333
       [Avg Loss]          1.948247
       [Validation] Prec@1 27.222222 Max 27.222222
Confusion matrix:
[[10  3  0  2 16  9]
 [11 11  0  2  2  4]
 [ 6 14  0  0  8  2]
 [14  7  0  0  5  4]
 [ 4  1  0  0 19  6]
 [ 3  5  0  1  2  9]]
Epoch: [4]
       [Avg Loss]          1.404030
       [Training]   Prec@1 43.833333 Max 43.833333
       [Avg Loss]          1.966966
       [Validation] Prec@1 30.555556 Max 30.555556
Confusion matrix:
[[13  3 15  0  3  6]
 [ 7 10  8  1  1  3]
 [ 2  7 19  0  0  2]
 [ 7  6 15  0  2  0]
 [ 9  1 13  0  6  1]
 [ 0  4  7  0  2  7]]
Epoch: [5]
       [Avg Loss]          1.311121
       [Training]   Prec@1 47.333333 Max 47.333333
       [Avg Loss]          2.074418
       [Validation] Prec@1 20.555556 Max 30.555556
Confusion matrix:
[[ 1  0  4 24  2  9]
 [ 3  0 11  6  4  6]
 [ 1  0 17  2  4  6]
 [ 0  1 14  6  4  5]
 [ 0  1  9 13  6  1]
 [ 0  0  6  7  0  7]]
Epoch: [6]
       [Avg Loss]          1.239874
       [Training]   Prec@1 50.166667 Max 50.166667
       [Avg Loss]          1.898889
       [Validation] Prec@1 26.666667 Max 30.555556
Confusion matrix:
[[13  0  9 12  0  6]
 [11  0  8  6  3  2]
 [ 6  0 22  0  0  2]
 [ 3  1 16  2  6  2]
 [ 4  0  9 11  5  1]
 [ 2  0  5  7  0  6]]
Epoch: [7]
       [Avg Loss]          1.208265
       [Training]   Prec@1 52.833333 Max 52.833333
       [Avg Loss]          2.260113
       [Validation] Prec@1 16.111111 Max 30.555556
Confusion matrix:
[[ 4  0  4 17  6  9]
 [ 5  1  1  3 12  8]
 [ 8  1 12  3  4  2]
 [ 3  2  5  3 10  7]
 [ 3  1  6 14  4  2]
 [ 3  0  1  7  4  5]]
Epoch: [8]
       [Avg Loss]          1.158800
       [Training]   Prec@1 54.833333 Max 54.833333
       [Avg Loss]          2.695099
       [Validation] Prec@1 25.000000 Max 30.555556
Confusion matrix:
[[ 6 28  3  0  0  3]
 [ 4 25  0  0  0  1]
 [ 0 21  7  0  0  2]
 [ 8 14  6  0  1  1]
 [ 6 22  1  0  1  0]
 [ 0  8  3  0  3  6]]
Epoch: [9]
       [Avg Loss]          1.158950
       [Training]   Prec@1 56.166667 Max 56.166667
       [Avg Loss]          1.823981
       [Validation] Prec@1 32.222222 Max 32.222222
Confusion matrix:
[[12  0  0  2 18  8]
 [12  4  4  0  8  2]
 [ 4  0 20  0  6  0]
 [ 6  3  8  1 11  1]
 [ 4  0  7  1 17  1]
 [ 2  0  4  6  4  4]]
Epoch: [10]
       [Avg Loss]          1.059010
       [Training]   Prec@1 58.833333 Max 58.833333
       [Avg Loss]          2.546628
       [Validation] Prec@1 25.555556 Max 32.222222
Confusion matrix:
[[ 9  0  0  0  3 28]
 [ 2 13  0  0  0 15]
 [15  5  5  0  0  5]
 [10  4  0  0  0 16]
 [ 7  2  1  0  2 18]
 [ 3  0  0  0  0 17]]
Epoch: [11]
       [Avg Loss]          1.004179
       [Training]   Prec@1 60.500000 Max 60.500000
       [Avg Loss]          1.929011
       [Validation] Prec@1 38.333333 Max 38.333333
Confusion matrix:
[[19  1  2  1  7 10]
 [ 7 14  1  0  2  6]
 [ 7  3 17  1  0  2]
 [10  5  6  0  3  6]
 [ 3  3  6  2 14  2]
 [ 3  2  1  5  4  5]]
Epoch: [12]
       [Avg Loss]          0.944766
       [Training]   Prec@1 62.500000 Max 62.500000
       [Avg Loss]          1.695486
       [Validation] Prec@1 32.777778 Max 38.333333
Confusion matrix:
[[20  0  5  4  4  7]
 [ 8  6  0  0  7  9]
 [ 7  3 15  3  2  0]
 [ 8  2  6  1  8  5]
 [ 6  3  1  4 15  1]
 [ 5  0  0 10  3  2]]
Epoch: [13]
       [Avg Loss]          0.898181
       [Training]   Prec@1 65.333333 Max 65.333333
       [Avg Loss]          2.221812
       [Validation] Prec@1 30.555556 Max 38.333333
Confusion matrix:
[[ 6  0 10  3  8 13]
 [ 4  6  2  3  6  9]
 [ 2  0 25  1  0  2]
 [ 1  0 11  4  7  7]
 [ 1  1  9 10  8  1]
 [ 0  0  4  9  1  6]]
Epoch: [14]
       [Avg Loss]          0.950252
       [Training]   Prec@1 63.166667 Max 65.333333
       [Avg Loss]          1.819343
       [Validation] Prec@1 31.666667 Max 38.333333
Confusion matrix:
[[14  0  3  5  7 11]
 [ 8  1  1  4  6 10]
 [ 5  0 21  3  0  1]
 [ 5  0  8  5  8  4]
 [10  0  2  5 10  3]
 [ 3  0  1  9  1  6]]
Fold "0" complete, final accuracy: 38.333333333333336
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.751122
       [Training]   Prec@1 27.058824 Max 27.058824
       [Avg Loss]          1.739862
       [Validation] Prec@1 35.675676 Max 35.675676
Confusion matrix:
[[ 0  0 20  0 10  0]
 [ 0  0 25  0  9  1]
 [ 1  0 27  0  2  0]
 [ 0  0 15  5 10  0]
 [ 0  0 10  0 12  8]
 [ 0  0  6  0  2 22]]
Epoch: [1]
       [Avg Loss]          1.632165
       [Training]   Prec@1 33.949580 Max 33.949580
       [Avg Loss]          1.691685
       [Validation] Prec@1 26.486486 Max 35.675676
Confusion matrix:
[[ 0 16 14  0  0  0]
 [ 0 26  9  0  0  0]
 [ 0 12 17  0  1  0]
 [14  2 13  0  1  0]
 [ 2  9 17  0  2  0]
 [ 3 15  8  0  0  4]]
Epoch: [2]
       [Avg Loss]          1.598302
       [Training]   Prec@1 35.966387 Max 35.966387
       [Avg Loss]          1.497152
       [Validation] Prec@1 42.702703 Max 42.702703
Confusion matrix:
[[10  0 18  2  0  0]
 [ 5  0 24  0  0  6]
 [ 0  0 30  0  0  0]
 [ 2  0 11 15  1  1]
 [10  0  7  9  1  3]
 [ 0  0  3  1  3 23]]
Epoch: [3]
       [Avg Loss]          1.622561
       [Training]   Prec@1 36.302521 Max 36.302521
       [Avg Loss]          1.490195
       [Validation] Prec@1 36.756757 Max 42.702703
Confusion matrix:
[[ 9  0 21  0  0  0]
 [ 5  7 22  0  0  1]
 [ 1  1 28  0  0  0]
 [ 6  0 14 10  0  0]
 [12  0 11  7  0  0]
 [ 4  4  5  1  2 14]]
Epoch: [4]
       [Avg Loss]          1.470628
       [Training]   Prec@1 43.193277 Max 43.193277
       [Avg Loss]          2.187885
       [Validation] Prec@1 25.945946 Max 42.702703
Confusion matrix:
[[ 0 30  0  0  0  0]
 [ 0 35  0  0  0  0]
 [ 1 27  2  0  0  0]
 [ 3 19  1  0  1  6]
 [ 0 23  0  0  0  7]
 [ 0 19  0  0  0 11]]
Epoch: [5]
       [Avg Loss]          1.517960
       [Training]   Prec@1 41.344538 Max 43.193277
       [Avg Loss]          1.866444
       [Validation] Prec@1 34.594595 Max 42.702703
Confusion matrix:
[[ 0 26  3  0  0  1]
 [ 0 34  0  0  0  1]
 [ 1 23  6  0  0  0]
 [ 6 14  2  1  1  6]
 [ 4 18  0  0  0  8]
 [ 0  7  0  0  0 23]]
Epoch: [6]
       [Avg Loss]          1.421165
       [Training]   Prec@1 45.546218 Max 45.546218
       [Avg Loss]          1.676912
       [Validation] Prec@1 31.891892 Max 42.702703
Confusion matrix:
[[ 0 12 15  0  3  0]
 [ 0 30  5  0  0  0]
 [ 1 12 17  0  0  0]
 [ 8  2 13  7  0  0]
 [ 4 10 13  0  3  0]
 [ 2 18  2  6  0  2]]
Epoch: [7]
       [Avg Loss]          1.466841
       [Training]   Prec@1 41.344538 Max 45.546218
       [Avg Loss]          1.360765
       [Validation] Prec@1 43.243243 Max 43.243243
Confusion matrix:
[[23  0  6  0  1  0]
 [ 9  7 14  0  4  1]
 [ 8  1 17  2  2  0]
 [12  0  0 14  4  0]
 [14  0  5  4  7  0]
 [11  1  2  2  2 12]]
Epoch: [8]
       [Avg Loss]          1.402922
       [Training]   Prec@1 45.210084 Max 45.546218
       [Avg Loss]          1.801817
       [Validation] Prec@1 37.297297 Max 43.243243
Confusion matrix:
[[ 0 12 16  0  2  0]
 [ 0 33  2  0  0  0]
 [ 1 11 18  0  0  0]
 [ 5  2 12 10  1  0]
 [ 0  6 14  5  5  0]
 [ 3 15  4  5  0  3]]
Epoch: [9]
       [Avg Loss]          1.345993
       [Training]   Prec@1 46.554622 Max 46.554622
       [Avg Loss]          1.669955
       [Validation] Prec@1 38.918919 Max 43.243243
Confusion matrix:
[[ 6 11 10  0  3  0]
 [ 0 31  3  0  0  1]
 [ 1 12 16  0  1  0]
 [ 9  3 10  7  1  0]
 [ 6  8  6  4  6  0]
 [ 1 17  1  3  2  6]]
Epoch: [10]
       [Avg Loss]          1.341509
       [Training]   Prec@1 45.714286 Max 46.554622
       [Avg Loss]          1.239149
       [Validation] Prec@1 50.810811 Max 50.810811
Confusion matrix:
[[10  0  9  6  3  2]
 [ 2 10 13  0  4  6]
 [ 0  1 20  9  0  0]
 [ 1  0  4 24  0  1]
 [ 3  0  4 14  6  3]
 [ 0  2  0  3  1 24]]
Epoch: [11]
       [Avg Loss]          1.274464
       [Training]   Prec@1 50.084034 Max 50.084034
       [Avg Loss]          1.184197
       [Validation] Prec@1 55.675676 Max 55.675676
Confusion matrix:
[[11  3 15  0  1  0]
 [ 2 19 12  0  0  2]
 [ 0  2 28  0  0  0]
 [ 2  0 10 18  0  0]
 [ 6  3  9  7  4  1]
 [ 1  2  0  3  1 23]]
Epoch: [12]
       [Avg Loss]          1.263375
       [Training]   Prec@1 51.764706 Max 51.764706
       [Avg Loss]          1.799143
       [Validation] Prec@1 40.540541 Max 55.675676
Confusion matrix:
[[ 6 20  4  0  0  0]
 [ 0 32  2  0  0  1]
 [ 1 16 13  0  0  0]
 [ 5  2  9 12  2  0]
 [ 3 17  1  4  5  0]
 [ 2 14  0  5  2  7]]
Epoch: [13]
       [Avg Loss]          1.247687
       [Training]   Prec@1 52.100840 Max 52.100840
       [Avg Loss]          2.060003
       [Validation] Prec@1 38.378378 Max 55.675676
Confusion matrix:
[[11 15  0  0  4  0]
 [ 3 28  0  0  1  3]
 [15 15  0  0  0  0]
 [ 7  5  0 11  7  0]
 [ 3 16  0  3  6  2]
 [ 0  8  0  4  3 15]]
Epoch: [14]
       [Avg Loss]          1.177448
       [Training]   Prec@1 55.294118 Max 55.294118
       [Avg Loss]          1.486055
       [Validation] Prec@1 50.810811 Max 55.675676
Confusion matrix:
[[ 7  6 10  4  0  3]
 [ 0 13 16  0  0  6]
 [ 1  0 26  2  0  1]
 [ 1  0  4 22  0  3]
 [ 4  2  5  9  4  6]
 [ 3  0  4  1  0 22]]
Fold "1" complete, final accuracy: 55.67567567567568
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.797489
       [Training]   Prec@1 27.058824 Max 27.058824
       [Avg Loss]          1.785804
       [Validation] Prec@1 16.216216 Max 16.216216
Confusion matrix:
[[ 0  0  0 29  1  0]
 [ 5  0  0 30  0  0]
 [ 3  0  0 27  0  0]
 [ 0  0  0 30  0  0]
 [ 0  0  0 30  0  0]
 [ 0  0  0 30  0  0]]
Epoch: [1]
       [Avg Loss]          1.695057
       [Training]   Prec@1 33.949580 Max 33.949580
       [Avg Loss]          1.787371
       [Validation] Prec@1 18.378378 Max 18.378378
Confusion matrix:
[[30  0  0  0  0  0]
 [35  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [26  0  0  0  0  4]]
Epoch: [2]
       [Avg Loss]          1.698663
       [Training]   Prec@1 33.781513 Max 33.949580
       [Avg Loss]          1.595528
       [Validation] Prec@1 31.351351 Max 31.351351
Confusion matrix:
[[26  0  0  0  0  4]
 [19  6  0  0  0 10]
 [27  3  0  0  0  0]
 [28  0  0  0  0  2]
 [30  0  0  0  0  0]
 [ 4  0  0  0  0 26]]
Epoch: [3]
       [Avg Loss]          1.543081
       [Training]   Prec@1 38.151261 Max 38.151261
       [Avg Loss]          1.712650
       [Validation] Prec@1 29.189189 Max 31.351351
Confusion matrix:
[[ 2 25  3  0  0  0]
 [ 0 33  2  0  0  0]
 [ 5  6 19  0  0  0]
 [19 11  0  0  0  0]
 [11 16  3  0  0  0]
 [ 1 29  0  0  0  0]]
Epoch: [4]
       [Avg Loss]          1.502241
       [Training]   Prec@1 38.487395 Max 38.487395
       [Avg Loss]          1.648665
       [Validation] Prec@1 24.864865 Max 31.351351
Confusion matrix:
[[30  0  0  0  0  0]
 [34  0  0  0  0  1]
 [30  0  0  0  0  0]
 [21  0  0  2  2  5]
 [28  0  0  0  0  2]
 [16  0  0  0  0 14]]
Epoch: [5]
       [Avg Loss]          1.451465
       [Training]   Prec@1 41.008403 Max 41.008403
       [Avg Loss]          1.499845
       [Validation] Prec@1 32.972973 Max 32.972973
Confusion matrix:
[[26  0  0  0  4  0]
 [26  2  6  0  0  1]
 [19  0  4  7  0  0]
 [10  0  0 19  0  1]
 [18  0  0 10  2  0]
 [13  2  0  0  7  8]]
Epoch: [6]
       [Avg Loss]          1.408666
       [Training]   Prec@1 45.042017 Max 45.042017
       [Avg Loss]          1.502974
       [Validation] Prec@1 40.540541 Max 40.540541
Confusion matrix:
[[21  0  2  2  2  3]
 [21  0  8  0  1  5]
 [ 4  0  6 20  0  0]
 [ 2  0  0 20  0  8]
 [20  0  0  9  0  1]
 [ 1  1  0  0  0 28]]
Epoch: [7]
       [Avg Loss]          1.348220
       [Training]   Prec@1 46.386555 Max 46.386555
       [Avg Loss]          2.143341
       [Validation] Prec@1 22.162162 Max 40.540541
Confusion matrix:
[[ 0  0  0  0  3 27]
 [ 0  2  0  0  0 33]
 [ 0  2  2  5  0 21]
 [ 0  0  0  7  0 23]
 [ 0  0  0  0  0 30]
 [ 0  0  0  0  0 30]]
Epoch: [8]
       [Avg Loss]          1.291159
       [Training]   Prec@1 50.924370 Max 50.924370
       [Avg Loss]          1.562870
       [Validation] Prec@1 31.891892 Max 40.540541
Confusion matrix:
[[ 7  0  0  3  5 15]
 [ 0  1  2  5  0 27]
 [ 0  0  3 25  0  2]
 [ 0  0  0 16  0 14]
 [ 5  0  0  6  2 17]
 [ 0  0  0  0  0 30]]
Epoch: [9]
       [Avg Loss]          1.249927
       [Training]   Prec@1 50.756303 Max 50.924370
       [Avg Loss]          1.367440
       [Validation] Prec@1 43.243243 Max 43.243243
Confusion matrix:
[[25  0  2  1  0  2]
 [22  1  9  0  0  3]
 [ 1  0 14 15  0  0]
 [ 6  0  0 19  2  3]
 [19  0  0 11  0  0]
 [ 9  0  0  0  0 21]]
Epoch: [10]
       [Avg Loss]          1.221363
       [Training]   Prec@1 54.117647 Max 54.117647
       [Avg Loss]          1.504550
       [Validation] Prec@1 40.000000 Max 43.243243
Confusion matrix:
[[20  0  5  4  0  1]
 [21  0 11  0  0  3]
 [ 1  0 20  9  0  0]
 [ 6  0  0 17  0  7]
 [22  0  0  8  0  0]
 [ 7  1  1  4  0 17]]
Epoch: [11]
       [Avg Loss]          1.207593
       [Training]   Prec@1 54.621849 Max 54.621849
       [Avg Loss]          1.609692
       [Validation] Prec@1 30.270270 Max 43.243243
Confusion matrix:
[[13 16  0  0  0  1]
 [ 4 30  1  0  0  0]
 [13  9  8  0  0  0]
 [11  0  0  0  7 12]
 [18  6  2  0  0  4]
 [ 2 23  0  0  0  5]]
Epoch: [12]
       [Avg Loss]          1.174858
       [Training]   Prec@1 55.630252 Max 55.630252
       [Avg Loss]          1.657951
       [Validation] Prec@1 31.891892 Max 43.243243
Confusion matrix:
[[19  0  2  2  4  3]
 [25  1  4  0  0  5]
 [11  0  7  1  2  9]
 [ 0  0  0  6  4 20]
 [13  0  0  0  5 12]
 [ 1  4  0  4  0 21]]
Epoch: [13]
       [Avg Loss]          1.166109
       [Training]   Prec@1 56.470588 Max 56.470588
       [Avg Loss]          1.704539
       [Validation] Prec@1 37.297297 Max 43.243243
Confusion matrix:
[[12  0  0  2  4 12]
 [ 7  2  1  0  0 25]
 [ 5  0  6  8  0 11]
 [ 0  0  0 16  0 14]
 [ 8  0  0  2  5 15]
 [ 0  2  0  0  0 28]]
Epoch: [14]
       [Avg Loss]          1.136697
       [Training]   Prec@1 58.655462 Max 58.655462
       [Avg Loss]          1.418383
       [Validation] Prec@1 42.702703 Max 43.243243
Confusion matrix:
[[20  1  6  1  1  1]
 [10 12 11  0  2  0]
 [ 5  0 25  0  0  0]
 [ 3  0  7 17  0  3]
 [25  0  4  1  0  0]
 [ 8 14  1  2  0  5]]
Fold "2" complete, final accuracy: 43.24324324324324
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.740148
       [Training]   Prec@1 30.454545 Max 30.454545
       [Avg Loss]          1.734674
       [Validation] Prec@1 25.833333 Max 25.833333
Confusion matrix:
[[ 0  0 17  0  0  3]
 [ 0  0 11  0  0  9]
 [ 0  0 18  0  0  2]
 [ 0  0 18  1  0  1]
 [ 0  0 17  0  0  3]
 [ 0  0  8  0  0 12]]
Epoch: [1]
       [Avg Loss]          1.557101
       [Training]   Prec@1 39.090909 Max 39.090909
       [Avg Loss]          1.778856
       [Validation] Prec@1 17.500000 Max 25.833333
Confusion matrix:
[[ 0  0 20  0  0  0]
 [ 0  0 19  0  0  1]
 [ 0  0 20  0  0  0]
 [ 0  0 19  0  0  1]
 [ 0  0 20  0  0  0]
 [ 0  0 19  0  0  1]]
Epoch: [2]
       [Avg Loss]          1.633287
       [Training]   Prec@1 38.030303 Max 39.090909
       [Avg Loss]          1.912997
       [Validation] Prec@1 20.833333 Max 25.833333
Confusion matrix:
[[ 0  0  0 15  5  0]
 [ 0  0  1 10  9  0]
 [ 0  0  0 14  6  0]
 [ 0  0  0 20  0  0]
 [ 0  0  0 15  5  0]
 [ 0  0  0 12  8  0]]
Epoch: [3]
       [Avg Loss]          1.499939
       [Training]   Prec@1 39.393939 Max 39.393939
       [Avg Loss]          1.622355
       [Validation] Prec@1 23.333333 Max 25.833333
Confusion matrix:
[[ 8  0  0  0 12  0]
 [10  2  1  0  6  1]
 [ 8  0  0  0 11  1]
 [ 0  0  0  4 15  1]
 [ 8  0  0  0 12  0]
 [ 5  0  0  0 13  2]]
Epoch: [4]
       [Avg Loss]          1.431240
       [Training]   Prec@1 44.545455 Max 44.545455
       [Avg Loss]          1.646755
       [Validation] Prec@1 27.500000 Max 27.500000
Confusion matrix:
[[10  6  2  0  2  0]
 [ 3 16  1  0  0  0]
 [10  4  6  0  0  0]
 [ 6  4  0  1  9  0]
 [ 8 11  1  0  0  0]
 [ 8 12  0  0  0  0]]
Epoch: [5]
       [Avg Loss]          1.346084
       [Training]   Prec@1 49.242424 Max 49.242424
       [Avg Loss]          1.420064
       [Validation] Prec@1 41.666667 Max 41.666667
Confusion matrix:
[[ 6  0  0  4 10  0]
 [ 2 14  0  2  1  1]
 [ 5  0  2  6  4  3]
 [ 1  0  0 12  1  6]
 [ 5  5  0  4  6  0]
 [ 3  3  0  1  3 10]]
Epoch: [6]
       [Avg Loss]          1.309165
       [Training]   Prec@1 51.515152 Max 51.515152
       [Avg Loss]          1.985849
       [Validation] Prec@1 47.500000 Max 47.500000
Confusion matrix:
[[ 7  4  8  1  0  0]
 [ 1 18  0  1  0  0]
 [ 2  1 14  2  0  1]
 [ 1  2  1 14  0  2]
 [ 5 10  3  2  0  0]
 [ 4 10  2  0  0  4]]
Epoch: [7]
       [Avg Loss]          1.284598
       [Training]   Prec@1 51.969697 Max 51.969697
       [Avg Loss]          1.518467
       [Validation] Prec@1 43.333333 Max 47.500000
Confusion matrix:
[[ 7  1  0 11  1  0]
 [ 5 12  2  1  0  0]
 [ 3  0  9  6  0  2]
 [ 2  0  2 14  0  2]
 [ 1  4  1  9  5  0]
 [ 4  6  0  5  0  5]]
Epoch: [8]
       [Avg Loss]          1.247243
       [Training]   Prec@1 51.363636 Max 51.969697
       [Avg Loss]          1.863175
       [Validation] Prec@1 45.833333 Max 47.500000
Confusion matrix:
[[11  4  1  0  4  0]
 [ 1 18  0  1  0  0]
 [ 7  2  4  5  1  1]
 [ 2  0  1 11  0  6]
 [ 6 10  0  2  2  0]
 [ 1  8  0  0  2  9]]
Epoch: [9]
       [Avg Loss]          1.252714
       [Training]   Prec@1 52.727273 Max 52.727273
       [Avg Loss]          1.745262
       [Validation] Prec@1 38.333333 Max 47.500000
Confusion matrix:
[[ 6  4  0  5  5  0]
 [ 1 18  0  1  0  0]
 [ 0  1  3 11  5  0]
 [ 3  0  0 16  0  1]
 [ 5  9  0  5  1  0]
 [ 9  8  0  1  0  2]]
Epoch: [10]
       [Avg Loss]          1.108439
       [Training]   Prec@1 56.666667 Max 56.666667
       [Avg Loss]          1.595381
       [Validation] Prec@1 47.500000 Max 47.500000
Confusion matrix:
[[17  3  0  0  0  0]
 [ 2 18  0  0  0  0]
 [11  0  6  1  1  1]
 [ 4  0  2 11  1  2]
 [11  8  0  1  0  0]
 [ 7  8  0  0  0  5]]
Epoch: [11]
       [Avg Loss]          1.094835
       [Training]   Prec@1 56.212121 Max 56.666667
       [Avg Loss]          1.699320
       [Validation] Prec@1 43.333333 Max 47.500000
Confusion matrix:
[[ 4  1  0  3  0 12]
 [ 0 16  0  1  0  3]
 [ 2  1  3  7  2  5]
 [ 0  0  0 12  0  8]
 [ 2  7  0  5  1  5]
 [ 2  1  0  1  0 16]]
Epoch: [12]
       [Avg Loss]          1.058670
       [Training]   Prec@1 61.060606 Max 61.060606
       [Avg Loss]          1.282075
       [Validation] Prec@1 46.666667 Max 47.500000
Confusion matrix:
[[ 8  0  1  7  4  0]
 [ 6 11  0  1  1  1]
 [ 0  1 14  2  2  1]
 [ 1  0  2 13  0  4]
 [10  0  0  9  0  1]
 [ 3  5  0  2  0 10]]
Epoch: [13]
       [Avg Loss]          1.006376
       [Training]   Prec@1 62.424242 Max 62.424242
       [Avg Loss]          1.989857
       [Validation] Prec@1 48.333333 Max 48.333333
Confusion matrix:
[[10  1  0  1  7  1]
 [ 1 18  0  0  1  0]
 [ 2  1  7  7  2  1]
 [ 1  0  0 11  0  8]
 [ 5  7  0  3  2  3]
 [ 3  6  0  0  1 10]]
Epoch: [14]
       [Avg Loss]          1.004520
       [Training]   Prec@1 60.909091 Max 62.424242
       [Avg Loss]          1.687322
       [Validation] Prec@1 44.166667 Max 48.333333
Confusion matrix:
[[ 6  0  0  9  5  0]
 [ 0 18  0  2  0  0]
 [ 1  1  6 10  2  0]
 [ 0  0  0 17  2  1]
 [ 1  5  0 10  4  0]
 [ 4  6  0  4  4  2]]
Fold "3" complete, final accuracy: 48.333333333333336
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.717050
       [Training]   Prec@1 32.238806 Max 32.238806
       [Avg Loss]          1.776544
       [Validation] Prec@1 27.272727 Max 27.272727
Confusion matrix:
[[ 0  0 14  0  6  0]
 [ 0  0 14  0  6  0]
 [ 0  0 20  0  0  0]
 [ 0  0 20  0  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0 19  0  1  0]]
Epoch: [1]
       [Avg Loss]          1.617495
       [Training]   Prec@1 35.522388 Max 35.522388
       [Avg Loss]          1.832160
       [Validation] Prec@1 22.727273 Max 27.272727
Confusion matrix:
[[ 0  0  3  0 17  0]
 [ 0  0  0  0 16  4]
 [ 0  0 15  0  5  0]
 [ 0  0  2  0 18  0]
 [ 0  0  0  0 10  0]
 [ 0  0  2  0 18  0]]
Epoch: [2]
       [Avg Loss]          1.521193
       [Training]   Prec@1 39.850746 Max 39.850746
       [Avg Loss]          1.674873
       [Validation] Prec@1 34.545455 Max 34.545455
Confusion matrix:
[[10  0 10  0  0  0]
 [ 9  8  3  0  0  0]
 [ 2  0 18  0  0  0]
 [ 5  0 14  1  0  0]
 [ 9  0  0  0  1  0]
 [ 3  0 10  0  7  0]]
Epoch: [3]
       [Avg Loss]          1.476707
       [Training]   Prec@1 40.746269 Max 40.746269
       [Avg Loss]          1.943839
       [Validation] Prec@1 26.363636 Max 34.545455
Confusion matrix:
[[ 0 16  0  0  0  4]
 [ 0 14  0  0  0  6]
 [ 0 19  0  0  0  1]
 [ 0  0  0  0  0 20]
 [ 0 10  0  0  0  0]
 [ 0  5  0  0  0 15]]
Epoch: [4]
       [Avg Loss]          1.408434
       [Training]   Prec@1 43.283582 Max 43.283582
       [Avg Loss]          2.342973
       [Validation] Prec@1 20.000000 Max 34.545455
Confusion matrix:
[[ 0  0  1 19  0  0]
 [ 0  0  1  9  1  9]
 [ 0  0  5 15  0  0]
 [ 0  0  0 14  0  6]
 [ 0  0  0 10  0  0]
 [ 0  0  0 17  0  3]]
Epoch: [5]
       [Avg Loss]          1.375576
       [Training]   Prec@1 43.880597 Max 43.880597
       [Avg Loss]          1.584740
       [Validation] Prec@1 48.181818 Max 48.181818
Confusion matrix:
[[ 6  0  6  7  1  0]
 [ 9  7  0  1  1  2]
 [ 0  1 19  0  0  0]
 [ 0  0  3 10  0  7]
 [ 4  0  0  6  0  0]
 [ 0  0  0  8  1 11]]
Epoch: [6]
       [Avg Loss]          1.301740
       [Training]   Prec@1 49.850746 Max 49.850746
       [Avg Loss]          1.496139
       [Validation] Prec@1 40.909091 Max 48.181818
Confusion matrix:
[[ 5  0  4  0  8  3]
 [ 4  1  1  0  5  9]
 [ 1  1 17  0  0  1]
 [ 4  0  0  0  3 13]
 [ 3  0  0  0  7  0]
 [ 1  0  0  0  4 15]]
Epoch: [7]
       [Avg Loss]          1.234440
       [Training]   Prec@1 52.238806 Max 52.238806
       [Avg Loss]          1.577765
       [Validation] Prec@1 40.909091 Max 48.181818
Confusion matrix:
[[ 8  0  3  2  7  0]
 [ 7  7  0  1  1  4]
 [ 1  2 15  2  0  0]
 [ 2  0  0  3  8  7]
 [ 7  0  0  0  3  0]
 [ 1  0  0  2  8  9]]
Epoch: [8]
       [Avg Loss]          1.187505
       [Training]   Prec@1 53.432836 Max 53.432836
       [Avg Loss]          1.710593
       [Validation] Prec@1 40.909091 Max 48.181818
Confusion matrix:
[[10  0  5  3  2  0]
 [ 8  1  1  0  2  8]
 [ 0  0 20  0  0  0]
 [ 2  0  3  6  3  6]
 [ 4  0  4  2  0  0]
 [ 2  0  1  8  1  8]]
Epoch: [9]
       [Avg Loss]          1.153843
       [Training]   Prec@1 52.985075 Max 53.432836
       [Avg Loss]          1.899376
       [Validation] Prec@1 38.181818 Max 48.181818
Confusion matrix:
[[12  0  5  2  1  0]
 [ 7  1  1  0  2  9]
 [ 0  1 16  0  3  0]
 [ 4  0  2 11  0  3]
 [ 9  0  0  1  0  0]
 [ 2  0  1 12  3  2]]
Epoch: [10]
       [Avg Loss]          1.109333
       [Training]   Prec@1 57.761194 Max 57.761194
       [Avg Loss]          1.451404
       [Validation] Prec@1 53.636364 Max 53.636364
Confusion matrix:
[[13  0  5  1  1  0]
 [ 5 12  1  0  1  1]
 [ 0  1 19  0  0  0]
 [ 4  0  2  2  6  6]
 [ 5  0  4  1  0  0]
 [ 5  0  1  1  0 13]]
Epoch: [11]
       [Avg Loss]          1.067591
       [Training]   Prec@1 58.059701 Max 58.059701
       [Avg Loss]          1.876820
       [Validation] Prec@1 37.272727 Max 53.636364
Confusion matrix:
[[14  0  6  0  0  0]
 [ 9  2  3  0  1  5]
 [ 2  0 18  0  0  0]
 [ 5  0  7  6  2  0]
 [ 5  0  2  3  0  0]
 [ 3  0 11  2  3  1]]
Epoch: [12]
       [Avg Loss]          1.017654
       [Training]   Prec@1 61.343284 Max 61.343284
       [Avg Loss]          1.708311
       [Validation] Prec@1 45.454545 Max 53.636364
Confusion matrix:
[[13  0  6  1  0  0]
 [ 7  7  1  0  2  3]
 [ 0  1 18  0  1  0]
 [ 1  0  5 11  2  1]
 [ 2  0  0  7  1  0]
 [ 3  0  8  5  4  0]]
Epoch: [13]
       [Avg Loss]          1.005941
       [Training]   Prec@1 59.850746 Max 61.343284
       [Avg Loss]          1.800341
       [Validation] Prec@1 46.363636 Max 53.636364
Confusion matrix:
[[12  0  7  1  0  0]
 [ 7  3  2  2  0  6]
 [ 0  0 20  0  0  0]
 [ 0  0  6 11  2  1]
 [ 0  0  9  1  0  0]
 [ 1  0  5  9  0  5]]
Epoch: [14]
       [Avg Loss]          0.983134
       [Training]   Prec@1 59.402985 Max 61.343284
       [Avg Loss]          1.648845
       [Validation] Prec@1 48.181818 Max 53.636364
Confusion matrix:
[[11  0  8  1  0  0]
 [ 3  4  5  1  1  6]
 [ 0  0 20  0  0  0]
 [ 0  0  1 13  3  3]
 [ 0  0  5  5  0  0]
 [ 2  0  1 12  0  5]]
Fold "4" complete, final accuracy: 53.63636363636363

-----------------------------------------------------------------------
Training for stage 11 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=4)")
Average accuracy is: 47.84438984438985


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 12-----
Evaluated preprocessing: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=4)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.588922
       [Training]   Prec@1 35.333333 Max 35.333333
       [Avg Loss]          1.714190
       [Validation] Prec@1 38.888889 Max 38.888889
Confusion matrix:
[[ 0 10  0 30  0  0]
 [ 0 30  0  0  0  0]
 [ 0  0 15 15  0  0]
 [ 0  0  4 20  6  0]
 [ 0  0  0 25  5  0]
 [ 0 20  0  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.344486
       [Training]   Prec@1 51.333333 Max 51.333333
       [Avg Loss]          1.658123
       [Validation] Prec@1 27.777778 Max 38.888889
Confusion matrix:
[[ 7  7 21  2  0  3]
 [ 0  9 19  0  0  2]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0 12  4  0  0  4]]
Epoch: [2]
       [Avg Loss]          1.295311
       [Training]   Prec@1 53.000000 Max 53.000000
       [Avg Loss]          1.355914
       [Validation] Prec@1 50.000000 Max 50.000000
Confusion matrix:
[[ 5  7  0  2 24  2]
 [ 0 29  0  1  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 17  0 13  0]
 [ 0  0  4  1 25  0]
 [ 0 18  1  0  0  1]]
Epoch: [3]
       [Avg Loss]          1.188711
       [Training]   Prec@1 56.166667 Max 56.166667
       [Avg Loss]          1.573291
       [Validation] Prec@1 39.444444 Max 50.000000
Confusion matrix:
[[ 4  4 19  6  1  6]
 [ 0 28  0  0  0  2]
 [ 0  0 30  0  0  0]
 [ 0  1 29  0  0  0]
 [ 0  0 29  0  1  0]
 [ 0 12  0  0  0  8]]
Epoch: [4]
       [Avg Loss]          1.193459
       [Training]   Prec@1 58.000000 Max 58.000000
       [Avg Loss]          2.225651
       [Validation] Prec@1 35.000000 Max 50.000000
Confusion matrix:
[[ 2  2  9  1 19  7]
 [ 0 21  7  0  0  2]
 [ 0  0 30  0  0  0]
 [ 0  0 29  0  1  0]
 [ 0  0 28  0  2  0]
 [ 0 11  1  0  0  8]]
Epoch: [5]
       [Avg Loss]          1.166609
       [Training]   Prec@1 60.833333 Max 60.833333
       [Avg Loss]          1.903469
       [Validation] Prec@1 26.666667 Max 50.000000
Confusion matrix:
[[ 0  2  1 27  0 10]
 [ 3 27  0  0  0  0]
 [ 0 22  8  0  0  0]
 [ 0 19  6  5  0  0]
 [ 0 13 12  5  0  0]
 [ 0 12  0  0  0  8]]
Epoch: [6]
       [Avg Loss]          1.075338
       [Training]   Prec@1 61.000000 Max 61.000000
       [Avg Loss]          1.421475
       [Validation] Prec@1 49.444444 Max 50.000000
Confusion matrix:
[[19  0  0  3 11  7]
 [ 0 10  1 10  7  2]
 [ 0  0 30  0  0  0]
 [ 0  0 19  0 11  0]
 [ 1  0  7  0 22  0]
 [ 0  0  1 11  0  8]]
Epoch: [7]
       [Avg Loss]          1.032222
       [Training]   Prec@1 62.333333 Max 62.333333
       [Avg Loss]          1.816766
       [Validation] Prec@1 32.777778 Max 50.000000
Confusion matrix:
[[ 0  0  4 27  0  9]
 [ 0  8  0  4  0 18]
 [ 0  1 21  8  0  0]
 [ 0  1 18 11  0  0]
 [ 0  1 21  8  0  0]
 [ 0  0  0  1  0 19]]
Epoch: [8]
       [Avg Loss]          1.122509
       [Training]   Prec@1 59.333333 Max 62.333333
       [Avg Loss]          1.606656
       [Validation] Prec@1 33.888889 Max 50.000000
Confusion matrix:
[[ 2  1  1 27  0  9]
 [ 0 22  0  1  0  7]
 [ 0  8 22  0  0  0]
 [ 0 20  8  2  0  0]
 [ 0 10 13  7  0  0]
 [ 0  7  0  0  0 13]]
Epoch: [9]
       [Avg Loss]          1.027316
       [Training]   Prec@1 63.000000 Max 63.000000
       [Avg Loss]          1.426560
       [Validation] Prec@1 43.888889 Max 50.000000
Confusion matrix:
[[17  0  0  9  4 10]
 [ 4 12  0  6  1  7]
 [ 0  0 24  6  0  0]
 [ 0  1 11  7 11  0]
 [ 0  0 10 12  8  0]
 [ 0  5  0  4  0 11]]
Epoch: [10]
       [Avg Loss]          0.979296
       [Training]   Prec@1 64.833333 Max 64.833333
       [Avg Loss]          2.727165
       [Validation] Prec@1 36.666667 Max 50.000000
Confusion matrix:
[[ 1  4  3  6 24  2]
 [ 0 20  3  1  6  0]
 [ 0  0 30  0  0  0]
 [ 0  0 20  0 10  0]
 [ 0  0 19  0 11  0]
 [ 0 14  1  1  0  4]]
Epoch: [11]
       [Avg Loss]          1.013499
       [Training]   Prec@1 63.666667 Max 64.833333
       [Avg Loss]          1.660201
       [Validation] Prec@1 37.222222 Max 50.000000
Confusion matrix:
[[30  0  0  0  0 10]
 [ 5 10  0  2  0 13]
 [ 0  0  0 30  0  0]
 [17  1  0 12  0  0]
 [24  0  0  6  0  0]
 [ 0  5  0  0  0 15]]
Epoch: [12]
       [Avg Loss]          0.986628
       [Training]   Prec@1 66.000000 Max 66.000000
       [Avg Loss]          1.551978
       [Validation] Prec@1 51.666667 Max 51.666667
Confusion matrix:
[[18  0  0  8  4 10]
 [ 6 21  0  0  0  3]
 [ 0  0 26  4  0  0]
 [ 0  2 14  4 10  0]
 [ 0  3  6  6 15  0]
 [ 0 11  0  0  0  9]]
Epoch: [13]
       [Avg Loss]          0.905781
       [Training]   Prec@1 70.166667 Max 70.166667
       [Avg Loss]          1.590814
       [Validation] Prec@1 54.444444 Max 54.444444
Confusion matrix:
[[15  0  0  9  6 10]
 [ 0 29  0  0  0  1]
 [ 0  0 30  0  0  0]
 [ 0  1 17  2 10  0]
 [ 0  0 12  4 14  0]
 [ 0 12  0  0  0  8]]
Epoch: [14]
       [Avg Loss]          0.880233
       [Training]   Prec@1 65.500000 Max 70.166667
       [Avg Loss]          1.271849
       [Validation] Prec@1 49.444444 Max 54.444444
Confusion matrix:
[[ 6  0  0 13 11 10]
 [ 2 24  0  1  0  3]
 [ 0  0 25  5  0  0]
 [ 0  1 10  7 12  0]
 [ 0  0  3 10 17  0]
 [ 0 10  0  0  0 10]]
Fold "0" complete, final accuracy: 54.44444444444444
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.620446
       [Training]   Prec@1 36.806723 Max 36.806723
       [Avg Loss]          1.692931
       [Validation] Prec@1 37.837838 Max 37.837838
Confusion matrix:
[[ 1  9 15  0  4  1]
 [ 0 13 22  0  0  0]
 [ 0  2 28  0  0  0]
 [ 0  0 29  0  0  1]
 [ 0  0 20  0 10  0]
 [ 0  6  6  0  0 18]]
Epoch: [1]
       [Avg Loss]          1.292289
       [Training]   Prec@1 51.260504 Max 51.260504
       [Avg Loss]          1.422883
       [Validation] Prec@1 50.270270 Max 50.270270
Confusion matrix:
[[18  0  0  3  0  9]
 [ 5  2  1 16  0 11]
 [ 0  2 25  0  3  0]
 [ 9  0  2 12  3  4]
 [10  0  2  8 10  0]
 [ 1  0  0  3  0 26]]
Epoch: [2]
       [Avg Loss]          1.318138
       [Training]   Prec@1 52.941176 Max 52.941176
       [Avg Loss]          1.440102
       [Validation] Prec@1 50.810811 Max 50.810811
Confusion matrix:
[[ 2 10  6  9  3  0]
 [ 0 33  1  1  0  0]
 [ 0  2 28  0  0  0]
 [ 2  7 14  4  1  2]
 [ 0  5 14  5  6  0]
 [ 0  7  1  1  0 21]]
Epoch: [3]
       [Avg Loss]          1.374946
       [Training]   Prec@1 49.579832 Max 52.941176
       [Avg Loss]          1.529715
       [Validation] Prec@1 38.378378 Max 50.810811
Confusion matrix:
[[20  2  0  0  0  8]
 [ 0  7  0 20  0  8]
 [ 5  2 15  6  2  0]
 [15  0  1 13  0  1]
 [20  0  0  9  1  0]
 [ 0  0  0 15  0 15]]
Epoch: [4]
       [Avg Loss]          1.231097
       [Training]   Prec@1 54.453782 Max 54.453782
       [Avg Loss]          1.355034
       [Validation] Prec@1 43.783784 Max 50.810811
Confusion matrix:
[[ 6  7  0 15  0  2]
 [ 0 13  7 15  0  0]
 [ 0  1 29  0  0  0]
 [ 8  0  5 14  2  1]
 [14  0  3 10  3  0]
 [ 0  1  0 13  0 16]]
Epoch: [5]
       [Avg Loss]          1.167476
       [Training]   Prec@1 57.310924 Max 57.310924
       [Avg Loss]          1.689945
       [Validation] Prec@1 40.540541 Max 50.810811
Confusion matrix:
[[ 4  9  0 16  0  1]
 [ 0 34  0  1  0  0]
 [ 0 25  5  0  0  0]
 [ 0 12  0 12  0  6]
 [ 0 14  2 14  0  0]
 [ 0  9  0  1  0 20]]
Epoch: [6]
       [Avg Loss]          1.178193
       [Training]   Prec@1 57.310924 Max 57.310924
       [Avg Loss]          1.308918
       [Validation] Prec@1 51.351351 Max 51.351351
Confusion matrix:
[[16  3  6  4  0  1]
 [ 0  9 13 13  0  0]
 [ 0  1 28  0  1  0]
 [ 4  0  7 12  7  0]
 [ 1  0  8  5 16  0]
 [ 0  0  2 14  0 14]]
Epoch: [7]
       [Avg Loss]          1.134690
       [Training]   Prec@1 57.478992 Max 57.478992
       [Avg Loss]          1.513733
       [Validation] Prec@1 53.513514 Max 53.513514
Confusion matrix:
[[16  8  2  0  3  1]
 [ 1 14 17  3  0  0]
 [ 0  1 24  0  5  0]
 [ 9  1  6  3  8  3]
 [ 3  0  3  6 18  0]
 [ 3  1  2  0  0 24]]
Epoch: [8]
       [Avg Loss]          1.175884
       [Training]   Prec@1 57.478992 Max 57.478992
       [Avg Loss]          2.394751
       [Validation] Prec@1 22.702703 Max 53.513514
Confusion matrix:
[[20  0  0  1  0  9]
 [ 1  0  0 28  0  6]
 [ 4  0  0  9 17  0]
 [22  0  0  8  0  0]
 [20  0  0  5  5  0]
 [ 5  0  0 16  0  9]]
Epoch: [9]
       [Avg Loss]          1.155952
       [Training]   Prec@1 57.647059 Max 57.647059
       [Avg Loss]          1.555232
       [Validation] Prec@1 52.432432 Max 53.513514
Confusion matrix:
[[ 1  9  7  9  3  1]
 [ 0 32  2  1  0  0]
 [ 0  1 29  0  0  0]
 [ 0  6 10  5  4  5]
 [ 0  7 14  0  9  0]
 [ 0  8  1  0  0 21]]
Epoch: [10]
       [Avg Loss]          1.108664
       [Training]   Prec@1 60.672269 Max 60.672269
       [Avg Loss]          1.240026
       [Validation] Prec@1 59.459459 Max 59.459459
Confusion matrix:
[[11  6  4  4  1  4]
 [ 0 30  0  3  0  2]
 [ 0  5 23  2  0  0]
 [ 2  1  4 15  8  0]
 [ 1  1  4  7 17  0]
 [ 0  0  0 16  0 14]]
Epoch: [11]
       [Avg Loss]          1.109435
       [Training]   Prec@1 59.663866 Max 60.672269
       [Avg Loss]          1.223316
       [Validation] Prec@1 55.135135 Max 59.459459
Confusion matrix:
[[11  9  3  6  0  1]
 [ 0 33  1  1  0  0]
 [ 0  3 27  0  0  0]
 [ 6  3  9  8  2  2]
 [ 2  2  9  8  9  0]
 [ 0  2  1 13  0 14]]
Epoch: [12]
       [Avg Loss]          1.026025
       [Training]   Prec@1 64.201681 Max 64.201681
       [Avg Loss]          1.545685
       [Validation] Prec@1 49.729730 Max 59.459459
Confusion matrix:
[[20  7  0  0  0  3]
 [ 2 13  1 18  0  1]
 [ 1  2 20  2  5  0]
 [10  0  1 12  7  0]
 [ 8  0  1  5 16  0]
 [ 1  0  0 18  0 11]]
Epoch: [13]
       [Avg Loss]          1.014889
       [Training]   Prec@1 63.697479 Max 64.201681
       [Avg Loss]          1.391519
       [Validation] Prec@1 47.567568 Max 59.459459
Confusion matrix:
[[15  2  0  5  0  8]
 [ 0 15  0  3  0 17]
 [ 0  4 18  7  0  1]
 [ 8  0  1 17  2  2]
 [14  0  1 11  4  0]
 [ 0  0  0 11  0 19]]
Epoch: [14]
       [Avg Loss]          1.027936
       [Training]   Prec@1 62.352941 Max 64.201681
       [Avg Loss]          1.344683
       [Validation] Prec@1 64.324324 Max 64.324324
Confusion matrix:
[[14  8  0  0  6  2]
 [ 1 28  6  0  0  0]
 [ 0  1 27  0  2  0]
 [ 6  0  4  8 10  2]
 [ 0  0  3  6 21  0]
 [ 0  1  1  7  0 21]]
Fold "1" complete, final accuracy: 64.32432432432432
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.664147
       [Training]   Prec@1 35.798319 Max 35.798319
       [Avg Loss]          1.695812
       [Validation] Prec@1 38.918919 Max 38.918919
Confusion matrix:
[[ 3  4 20  0  3  0]
 [ 0  5 24  0  0  6]
 [ 0  0 30  0  0  0]
 [ 5  0 18  0  0  7]
 [ 3  0 22  0  5  0]
 [ 0  1  0  0  0 29]]
Epoch: [1]
       [Avg Loss]          1.354005
       [Training]   Prec@1 52.605042 Max 52.605042
       [Avg Loss]          1.438937
       [Validation] Prec@1 47.567568 Max 47.567568
Confusion matrix:
[[15  4  4  0  0  7]
 [ 0 17  6  1  0 11]
 [ 4  0 24  2  0  0]
 [ 7  1  6  1  0 15]
 [28  0  0  1  1  0]
 [ 0  0  0  0  0 30]]
Epoch: [2]
       [Avg Loss]          1.276907
       [Training]   Prec@1 56.470588 Max 56.470588
       [Avg Loss]          1.212210
       [Validation] Prec@1 59.459459 Max 59.459459
Confusion matrix:
[[ 3  6 11  2  8  0]
 [ 0 25  6  0  0  4]
 [ 0  0 28  0  2  0]
 [ 5  1 11  4  8  1]
 [ 1  0  6  0 23  0]
 [ 0  3  0  0  0 27]]
Epoch: [3]
       [Avg Loss]          1.409397
       [Training]   Prec@1 45.210084 Max 56.470588
       [Avg Loss]          2.051978
       [Validation] Prec@1 21.081081 Max 59.459459
Confusion matrix:
[[ 0  0  0 10  0 20]
 [ 0  0  0  3  0 32]
 [ 0  0  0 30  0  0]
 [ 0  0  0  9  0 21]
 [ 1  0  0 29  0  0]
 [ 0  0  0  0  0 30]]
Epoch: [4]
       [Avg Loss]          1.348116
       [Training]   Prec@1 49.915966 Max 56.470588
       [Avg Loss]          2.562890
       [Validation] Prec@1 16.216216 Max 59.459459
Confusion matrix:
[[30  0  0  0  0  0]
 [29  0  0  6  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [14  0  0 16  0  0]]
Epoch: [5]
       [Avg Loss]          1.234448
       [Training]   Prec@1 56.134454 Max 56.470588
       [Avg Loss]          1.323808
       [Validation] Prec@1 41.621622 Max 59.459459
Confusion matrix:
[[ 5 22  1  0  2  0]
 [ 0 34  0  0  0  1]
 [ 0 25  5  0  0  0]
 [10 13  0  0  3  4]
 [ 5  7  0  0 18  0]
 [ 0 15  0  0  0 15]]
Epoch: [6]
       [Avg Loss]          1.163673
       [Training]   Prec@1 58.319328 Max 58.319328
       [Avg Loss]          1.346372
       [Validation] Prec@1 52.972973 Max 59.459459
Confusion matrix:
[[ 9  4  6  0 11  0]
 [ 0 28  5  0  1  1]
 [ 0  0 24  0  6  0]
 [13  4  6  0  6  1]
 [10  0  0  0 20  0]
 [ 0 13  0  0  0 17]]
Epoch: [7]
       [Avg Loss]          1.154216
       [Training]   Prec@1 58.319328 Max 58.319328
       [Avg Loss]          1.232527
       [Validation] Prec@1 55.135135 Max 59.459459
Confusion matrix:
[[ 8  5  3  1 13  0]
 [ 0 22  6  0  2  5]
 [ 0  0 26  0  4  0]
 [13  0  6  1  8  2]
 [ 8  0  0  0 22  0]
 [ 6  1  0  0  0 23]]
Epoch: [8]
       [Avg Loss]          1.025288
       [Training]   Prec@1 64.369748 Max 64.369748
       [Avg Loss]          1.538965
       [Validation] Prec@1 38.918919 Max 59.459459
Confusion matrix:
[[16  7  0  7  0  0]
 [ 0 24  0  3  0  8]
 [ 6  1  3 20  0  0]
 [11  7  0  3  0  9]
 [30  0  0  0  0  0]
 [ 3  1  0  0  0 26]]
Epoch: [9]
       [Avg Loss]          1.091812
       [Training]   Prec@1 60.672269 Max 64.369748
       [Avg Loss]          1.706052
       [Validation] Prec@1 40.000000 Max 59.459459
Confusion matrix:
[[ 3  4  3 12  8  0]
 [ 0 17  9  4  2  3]
 [ 0  0 12  0 18  0]
 [13  0  6  5  6  0]
 [13  0  0  3 14  0]
 [ 6  1  0  0  0 23]]
Epoch: [10]
       [Avg Loss]          1.050007
       [Training]   Prec@1 63.361345 Max 64.369748
       [Avg Loss]          1.520982
       [Validation] Prec@1 40.000000 Max 59.459459
Confusion matrix:
[[ 4  6  0 19  0  1]
 [ 1 20  1  4  0  9]
 [ 0  1  4 25  0  0]
 [ 2  3  0 16  0  9]
 [19  0  0 10  1  0]
 [ 1  0  0  0  0 29]]
Epoch: [11]
       [Avg Loss]          1.037076
       [Training]   Prec@1 62.857143 Max 64.369748
       [Avg Loss]          1.421545
       [Validation] Prec@1 49.189189 Max 59.459459
Confusion matrix:
[[ 3  7  2 17  1  0]
 [ 0 31  2  1  0  1]
 [ 0  0 25  1  4  0]
 [13  9  1  4  3  0]
 [13  0  0  2 15  0]
 [ 7 10  0  0  0 13]]
Epoch: [12]
       [Avg Loss]          1.009862
       [Training]   Prec@1 63.865546 Max 64.369748
       [Avg Loss]          1.103395
       [Validation] Prec@1 61.621622 Max 61.621622
Confusion matrix:
[[ 4  4  4 16  2  0]
 [ 0 17  8  3  0  7]
 [ 0  0 26  0  4  0]
 [ 6  0  8 11  3  2]
 [ 2  0  1  0 27  0]
 [ 0  1  0  0  0 29]]
Epoch: [13]
       [Avg Loss]          0.997182
       [Training]   Prec@1 65.042017 Max 65.042017
       [Avg Loss]          1.264828
       [Validation] Prec@1 57.297297 Max 61.621622
Confusion matrix:
[[ 3  5  2 18  2  0]
 [ 0 23  5  2  1  4]
 [ 0  0 26  0  4  0]
 [ 9  3  6  8  3  1]
 [11  0  0  0 19  0]
 [ 0  3  0  0  0 27]]
Epoch: [14]
       [Avg Loss]          0.982711
       [Training]   Prec@1 64.033613 Max 65.042017
       [Avg Loss]          1.641701
       [Validation] Prec@1 36.756757 Max 61.621622
Confusion matrix:
[[ 3  7  0  7  0 13]
 [ 0 19  1  2  0 13]
 [ 0  2  8 20  0  0]
 [ 0  7  0  7  0 16]
 [ 2  1  0 25  1  1]
 [ 0  0  0  0  0 30]]
Fold "2" complete, final accuracy: 61.62162162162162
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.647204
       [Training]   Prec@1 35.000000 Max 35.000000
       [Avg Loss]          1.676805
       [Validation] Prec@1 34.166667 Max 34.166667
Confusion matrix:
[[ 0  0  0 15  5  0]
 [ 0  4  0  2  0 14]
 [ 0  3  0 17  0  0]
 [ 0  0  1 15  0  4]
 [ 0  0  0 17  3  0]
 [ 0  1  0  0  0 19]]
Epoch: [1]
       [Avg Loss]          1.462572
       [Training]   Prec@1 46.212121 Max 46.212121
       [Avg Loss]          1.633038
       [Validation] Prec@1 20.833333 Max 34.166667
Confusion matrix:
[[ 3  0  0  3  0 14]
 [ 0  1  0  0  0 19]
 [ 0 15  0  0  0  5]
 [ 0  2  0  1  0 17]
 [ 0  6  1  3  0 10]
 [ 0  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          1.402873
       [Training]   Prec@1 49.848485 Max 49.848485
       [Avg Loss]          1.244793
       [Validation] Prec@1 55.000000 Max 55.000000
Confusion matrix:
[[ 5  0  5  2  8  0]
 [ 0 15  0  0  0  5]
 [ 0  6 14  0  0  0]
 [ 0  3  8  7  1  1]
 [ 0  0  8  3  9  0]
 [ 0  4  0  0  0 16]]
Epoch: [3]
       [Avg Loss]          1.250894
       [Training]   Prec@1 53.939394 Max 53.939394
       [Avg Loss]          1.796377
       [Validation] Prec@1 29.166667 Max 55.000000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 7  0  0  1  0 12]
 [ 9  1  0 10  0  0]
 [19  0  0  1  0  0]
 [19  0  0  1  0  0]
 [ 5  0  0  1  0 14]]
Epoch: [4]
       [Avg Loss]          1.251239
       [Training]   Prec@1 53.484848 Max 53.939394
       [Avg Loss]          1.478039
       [Validation] Prec@1 42.500000 Max 55.000000
Confusion matrix:
[[ 4  0  2 13  1  0]
 [ 0  6  0  0  0 14]
 [ 0 10  8  2  0  0]
 [ 0  2  1 14  0  3]
 [ 0  5  6  9  0  0]
 [ 0  1  0  0  0 19]]
Epoch: [5]
       [Avg Loss]          1.200128
       [Training]   Prec@1 53.636364 Max 53.939394
       [Avg Loss]          1.623052
       [Validation] Prec@1 38.333333 Max 55.000000
Confusion matrix:
[[ 5  0  7  4  4  0]
 [ 0 19  0  0  0  1]
 [ 0  6 14  0  0  0]
 [ 1  5 12  2  0  0]
 [ 0  5 15  0  0  0]
 [ 0 14  0  0  0  6]]
Epoch: [6]
       [Avg Loss]          1.183561
       [Training]   Prec@1 58.939394 Max 58.939394
       [Avg Loss]          1.274052
       [Validation] Prec@1 49.166667 Max 55.000000
Confusion matrix:
[[ 4  1  0 15  0  0]
 [ 0 12  0  0  0  8]
 [ 0 10 10  0  0  0]
 [ 0  4  2 12  0  2]
 [ 0  7  4  6  3  0]
 [ 0  2  0  0  0 18]]
Epoch: [7]
       [Avg Loss]          1.112714
       [Training]   Prec@1 60.757576 Max 60.757576
       [Avg Loss]          1.193674
       [Validation] Prec@1 53.333333 Max 55.000000
Confusion matrix:
[[ 6  0  0  4 10  0]
 [ 0  8  0  4  0  8]
 [ 0  0 15  5  0  0]
 [ 2  0  4 10  3  1]
 [ 0  0  5  7  8  0]
 [ 0  0  0  3  0 17]]
Epoch: [8]
       [Avg Loss]          1.123472
       [Training]   Prec@1 60.303030 Max 60.757576
       [Avg Loss]          1.111343
       [Validation] Prec@1 59.166667 Max 59.166667
Confusion matrix:
[[12  0  0  0  8  0]
 [ 0  7  0  2  0 11]
 [ 0  1 13  6  0  0]
 [ 8  0  0  5  6  1]
 [ 1  0  3  0 16  0]
 [ 1  0  0  1  0 18]]
Epoch: [9]
       [Avg Loss]          1.075852
       [Training]   Prec@1 63.030303 Max 63.030303
       [Avg Loss]          0.989981
       [Validation] Prec@1 57.500000 Max 59.166667
Confusion matrix:
[[11  0  0  4  5  0]
 [ 0 19  0  1  0  0]
 [ 0  3 14  3  0  0]
 [ 1  2  6 10  0  1]
 [ 0  0 10  5  5  0]
 [ 0 10  0  0  0 10]]
Epoch: [10]
       [Avg Loss]          1.022208
       [Training]   Prec@1 65.606061 Max 65.606061
       [Avg Loss]          1.137599
       [Validation] Prec@1 54.166667 Max 59.166667
Confusion matrix:
[[ 9  0  0  5  6  0]
 [ 0 18  2  0  0  0]
 [ 0  1 19  0  0  0]
 [ 3  3 10  3  1  0]
 [ 0  4 11  0  5  0]
 [ 0  9  0  0  0 11]]
Epoch: [11]
       [Avg Loss]          1.015424
       [Training]   Prec@1 62.121212 Max 65.606061
       [Avg Loss]          1.119653
       [Validation] Prec@1 58.333333 Max 59.166667
Confusion matrix:
[[12  0  0  0  8  0]
 [ 0 13  1  1  0  5]
 [ 0  1 15  4  0  0]
 [ 8  1  3  4  4  0]
 [ 4  0  4  2 10  0]
 [ 3  1  0  0  0 16]]
Epoch: [12]
       [Avg Loss]          1.030139
       [Training]   Prec@1 63.181818 Max 65.606061
       [Avg Loss]          1.317763
       [Validation] Prec@1 50.833333 Max 59.166667
Confusion matrix:
[[18  0  0  2  0  0]
 [ 0 11  0  2  0  7]
 [ 1  3  6 10  0  0]
 [ 7  3  0  9  0  1]
 [ 5  4  0 11  0  0]
 [ 2  1  0  0  0 17]]
Epoch: [13]
       [Avg Loss]          0.957580
       [Training]   Prec@1 67.424242 Max 67.424242
       [Avg Loss]          0.943285
       [Validation] Prec@1 64.166667 Max 64.166667
Confusion matrix:
[[15  0  0  5  0  0]
 [ 0 11  1  1  0  7]
 [ 0  0 14  6  0  0]
 [ 3  3  2 11  0  1]
 [ 5  0  3  4  8  0]
 [ 1  1  0  0  0 18]]
Epoch: [14]
       [Avg Loss]          0.911103
       [Training]   Prec@1 68.484848 Max 68.484848
       [Avg Loss]          0.967296
       [Validation] Prec@1 58.333333 Max 64.166667
Confusion matrix:
[[ 6  0  0  5  9  0]
 [ 0 11  0  2  0  7]
 [ 0  1 15  4  0  0]
 [ 1  2  1 12  3  1]
 [ 0  2  3  7  8  0]
 [ 1  1  0  0  0 18]]
Fold "3" complete, final accuracy: 64.16666666666667
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.575160
       [Training]   Prec@1 36.417910 Max 36.417910
       [Avg Loss]          1.717230
       [Validation] Prec@1 31.818182 Max 31.818182
Confusion matrix:
[[ 0  3  5  0 12  0]
 [ 0  0 10  0 10  0]
 [ 0  0 19  0  1  0]
 [ 0  0 20  0  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1 13  0  0  6]]
Epoch: [1]
       [Avg Loss]          1.336559
       [Training]   Prec@1 49.850746 Max 49.850746
       [Avg Loss]          1.638357
       [Validation] Prec@1 29.090909 Max 31.818182
Confusion matrix:
[[ 3  3  6  4  4  0]
 [ 0  0 17  0  3  0]
 [ 0  0 15  1  4  0]
 [ 0  3 17  0  0  0]
 [ 0  0  9  0  1  0]
 [ 0  4  3  0  0 13]]
Epoch: [2]
       [Avg Loss]          1.218340
       [Training]   Prec@1 54.776119 Max 54.776119
       [Avg Loss]          1.564525
       [Validation] Prec@1 62.727273 Max 62.727273
Confusion matrix:
[[10  5  2  1  1  1]
 [ 0  7  3  2  7  1]
 [ 1  0 12  6  0  1]
 [ 0  3  0 11  0  6]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [3]
       [Avg Loss]          1.199867
       [Training]   Prec@1 54.029851 Max 54.776119
       [Avg Loss]          1.647319
       [Validation] Prec@1 52.727273 Max 62.727273
Confusion matrix:
[[10  1  0  4  0  5]
 [ 2  7  1  4  2  4]
 [ 2  0  8  8  0  2]
 [ 0  2  0  3  0 15]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          1.194281
       [Training]   Prec@1 54.925373 Max 54.925373
       [Avg Loss]          1.880638
       [Validation] Prec@1 39.090909 Max 62.727273
Confusion matrix:
[[ 7  2  0  8  2  1]
 [ 2  0  5  5  8  0]
 [ 6  0  1  2 11  0]
 [ 6  0  0 10  1  3]
 [ 0  0  0  0 10  0]
 [ 0  0  0  5  0 15]]
Epoch: [5]
       [Avg Loss]          1.188668
       [Training]   Prec@1 55.970149 Max 55.970149
       [Avg Loss]          1.503552
       [Validation] Prec@1 58.181818 Max 62.727273
Confusion matrix:
[[10  6  2  1  1  0]
 [ 1  9  2  1  7  0]
 [ 4  0 12  3  0  1]
 [ 0  9  1 10  0  0]
 [ 0  0  0  0 10  0]
 [ 0  6  0  1  0 13]]
Epoch: [6]
       [Avg Loss]          1.039621
       [Training]   Prec@1 60.895522 Max 60.895522
       [Avg Loss]          1.733657
       [Validation] Prec@1 54.545455 Max 62.727273
Confusion matrix:
[[10  4  2  1  3  0]
 [ 0  3  6  0 10  1]
 [ 2  0 11  0  6  1]
 [ 1  2  2  8  4  3]
 [ 0  0  0  0 10  0]
 [ 0  0  0  2  0 18]]
Epoch: [7]
       [Avg Loss]          1.055417
       [Training]   Prec@1 61.492537 Max 61.492537
       [Avg Loss]          1.636425
       [Validation] Prec@1 48.181818 Max 62.727273
Confusion matrix:
[[ 4  5  0 10  0  1]
 [ 7  7  1  1  1  3]
 [ 1  0  7 11  0  1]
 [ 2  3  0 10  0  5]
 [ 0  0  0  5  5  0]
 [ 0  0  0  0  0 20]]
Epoch: [8]
       [Avg Loss]          1.039884
       [Training]   Prec@1 60.746269 Max 61.492537
       [Avg Loss]          1.567633
       [Validation] Prec@1 56.363636 Max 62.727273
Confusion matrix:
[[11  3  0  5  1  0]
 [ 4  5  2  2  6  1]
 [ 4  0  5  9  1  1]
 [ 1  0  0 15  0  4]
 [ 1  0  0  0  9  0]
 [ 0  0  0  3  0 17]]
Epoch: [9]
       [Avg Loss]          0.950202
       [Training]   Prec@1 66.119403 Max 66.119403
       [Avg Loss]          1.664280
       [Validation] Prec@1 57.272727 Max 62.727273
Confusion matrix:
[[ 8  4  1  4  3  0]
 [ 0  7  3  1  8  1]
 [ 1  0  5  2 11  1]
 [ 0  2  0 15  0  3]
 [ 0  0  0  0 10  0]
 [ 0  1  0  1  0 18]]
Epoch: [10]
       [Avg Loss]          0.977638
       [Training]   Prec@1 62.985075 Max 66.119403
       [Avg Loss]          2.025307
       [Validation] Prec@1 47.272727 Max 62.727273
Confusion matrix:
[[11  3  0  4  2  0]
 [ 3  5  1  1  8  2]
 [ 6  0  0  1 12  1]
 [ 7  0  0  8  0  5]
 [ 0  0  0  0 10  0]
 [ 0  1  0  1  0 18]]
Epoch: [11]
       [Avg Loss]          0.949619
       [Training]   Prec@1 65.373134 Max 66.119403
       [Avg Loss]          1.891738
       [Validation] Prec@1 56.363636 Max 62.727273
Confusion matrix:
[[11  5  0  2  1  1]
 [ 9  7  1  2  0  1]
 [ 6  0  3  7  3  1]
 [ 0  2  0 15  0  3]
 [ 0  0  0  0 10  0]
 [ 0  3  0  1  0 16]]
Epoch: [12]
       [Avg Loss]          0.917805
       [Training]   Prec@1 67.611940 Max 67.611940
       [Avg Loss]          1.508084
       [Validation] Prec@1 56.363636 Max 62.727273
Confusion matrix:
[[10  0  0  5  2  3]
 [ 1  5  1  4  7  2]
 [ 1  0  5  7  6  1]
 [ 0  0  0 15  0  5]
 [ 0  0  0  0 10  0]
 [ 0  0  0  3  0 17]]
Epoch: [13]
       [Avg Loss]          0.948470
       [Training]   Prec@1 65.074627 Max 67.611940
       [Avg Loss]          2.252588
       [Validation] Prec@1 40.909091 Max 62.727273
Confusion matrix:
[[ 7  4  1  2  6  0]
 [ 1  7  2  1  9  0]
 [ 1  0  2  1 16  0]
 [ 8  2  0  5  2  3]
 [ 0  0  0  0 10  0]
 [ 2  2  0  2  0 14]]
Epoch: [14]
       [Avg Loss]          0.913499
       [Training]   Prec@1 66.567164 Max 67.611940
       [Avg Loss]          1.467678
       [Validation] Prec@1 57.272727 Max 62.727273
Confusion matrix:
[[11  4  0  4  1  0]
 [ 4  6  3  1  5  1]
 [ 3  0 10  5  1  1]
 [ 2  2  0 13  0  3]
 [ 0  0  2  1  7  0]
 [ 0  1  0  3  0 16]]
Fold "4" complete, final accuracy: 62.72727272727273

-----------------------------------------------------------------------
Training for stage 12 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=4)")
Average accuracy is: 61.45686595686597


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 13-----
Evaluated preprocessing: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=2)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.672196
       [Training]   Prec@1 30.333333 Max 30.333333
       [Avg Loss]          1.774936
       [Validation] Prec@1 30.000000 Max 30.000000
Confusion matrix:
[[ 0  1  9  0 25  5]
 [ 0  8  7  0 12  3]
 [ 0  4 24  0  1  1]
 [ 0  6 14  0  5  5]
 [ 0  1 10  0 17  2]
 [ 0  5  5  0  5  5]]
Epoch: [1]
       [Avg Loss]          1.525367
       [Training]   Prec@1 37.500000 Max 37.500000
       [Avg Loss]          1.797943
       [Validation] Prec@1 23.333333 Max 30.000000
Confusion matrix:
[[ 5  1  8  0 21  5]
 [ 5  6  7  0 10  2]
 [12  0 15  0  3  0]
 [ 5  2 11  0 11  1]
 [ 7  1  5  0 16  1]
 [ 1  0  6  7  6  0]]
Epoch: [2]
       [Avg Loss]          1.361149
       [Training]   Prec@1 44.500000 Max 44.500000
       [Avg Loss]          1.764606
       [Validation] Prec@1 26.111111 Max 30.000000
Confusion matrix:
[[ 2  6 16  3  7  6]
 [ 3  4 11  1  5  6]
 [ 4  0 23  1  0  2]
 [ 0  3 17  1  4  5]
 [ 1  2 11  2 10  4]
 [ 0  0 10  2  1  7]]
Epoch: [3]
       [Avg Loss]          1.306662
       [Training]   Prec@1 49.500000 Max 49.500000
       [Avg Loss]          1.818346
       [Validation] Prec@1 32.222222 Max 32.222222
Confusion matrix:
[[ 8  2 12  0 12  6]
 [ 1  8 11  0  5  5]
 [ 4  3 21  0  2  0]
 [ 2  0 17  0  8  3]
 [ 2  1 10  1 15  1]
 [ 0  0 10  3  1  6]]
Epoch: [4]
       [Avg Loss]          1.243591
       [Training]   Prec@1 52.333333 Max 52.333333
       [Avg Loss]          1.840620
       [Validation] Prec@1 26.111111 Max 32.222222
Confusion matrix:
[[ 9  2  0  2 10 17]
 [ 1  7  0  7  5 10]
 [ 7  0  7 11  1  4]
 [ 4  0  4 12  2  8]
 [ 8  3  1  5  5  8]
 [ 0  0  2 10  1  7]]
Epoch: [5]
       [Avg Loss]          1.265952
       [Training]   Prec@1 52.666667 Max 52.666667
       [Avg Loss]          1.862270
       [Validation] Prec@1 33.888889 Max 33.888889
Confusion matrix:
[[13  1  6  1  9 10]
 [ 3  8 10  0  7  2]
 [ 5  0 23  0  2  0]
 [ 1  1 18  1  7  2]
 [ 3  2  9  3 10  3]
 [ 0  0 10  4  0  6]]
Epoch: [6]
       [Avg Loss]          1.164507
       [Training]   Prec@1 54.666667 Max 54.666667
       [Avg Loss]          1.825653
       [Validation] Prec@1 33.888889 Max 33.888889
Confusion matrix:
[[27  0  1  0  1 11]
 [ 6  9  6  0  4  5]
 [15  0 13  0  0  2]
 [ 7  3 10  0  4  6]
 [14  1  3  0  6  6]
 [ 1  0 10  1  2  6]]
Epoch: [7]
       [Avg Loss]          1.120536
       [Training]   Prec@1 55.500000 Max 55.500000
       [Avg Loss]          1.921436
       [Validation] Prec@1 35.555556 Max 35.555556
Confusion matrix:
[[17  0  1  0  1 21]
 [ 0 18  5  0  4  3]
 [11  0 15  0  0  4]
 [ 2  3 13  0  6  6]
 [ 3  8  2  0  4 13]
 [ 2  0  7  1  0 10]]
Epoch: [8]
       [Avg Loss]          1.061731
       [Training]   Prec@1 59.833333 Max 59.833333
       [Avg Loss]          1.783196
       [Validation] Prec@1 36.111111 Max 36.111111
Confusion matrix:
[[23  0  1  0  7  9]
 [ 4  5  6  0  8  7]
 [ 9  0 19  0  2  0]
 [ 1  1 16  0  6  6]
 [ 5  3  8  0 13  1]
 [ 2  0  7  0  6  5]]
Epoch: [9]
       [Avg Loss]          1.080680
       [Training]   Prec@1 58.666667 Max 59.833333
       [Avg Loss]          2.108165
       [Validation] Prec@1 25.000000 Max 36.111111
Confusion matrix:
[[21  0  0  0  7 12]
 [ 6  0  6  0  8 10]
 [10  3 14  2  1  0]
 [ 4  1 12  2  5  6]
 [ 5  8  0  6  7  4]
 [ 4  0  5  7  3  1]]
Epoch: [10]
       [Avg Loss]          1.148802
       [Training]   Prec@1 59.666667 Max 59.833333
       [Avg Loss]          1.865557
       [Validation] Prec@1 39.444444 Max 39.444444
Confusion matrix:
[[25  0  3  0  1 11]
 [ 4 11  5  2  6  2]
 [ 6  0 19  2  3  0]
 [ 1  2 10  4 10  3]
 [ 8  1  7  1 10  3]
 [ 2  0  8  4  4  2]]
Epoch: [11]
       [Avg Loss]          0.946695
       [Training]   Prec@1 63.666667 Max 63.666667
       [Avg Loss]          1.818163
       [Validation] Prec@1 45.555556 Max 45.555556
Confusion matrix:
[[16  1  2  0  0 21]
 [ 3 22  4  0  1  0]
 [ 3  0 24  3  0  0]
 [ 0  4 14  7  1  4]
 [ 3  9  3  3  6  6]
 [ 5  1  3  4  0  7]]
Epoch: [12]
       [Avg Loss]          0.896605
       [Training]   Prec@1 67.833333 Max 67.833333
       [Avg Loss]          1.920379
       [Validation] Prec@1 30.000000 Max 45.555556
Confusion matrix:
[[20  0  0  0  0 20]
 [ 6  3  4  0  7 10]
 [12  0 14  2  2  0]
 [ 2  0 14  1  7  6]
 [10  3  0  2  6  9]
 [ 9  0  0  0  1 10]]
Epoch: [13]
       [Avg Loss]          0.892142
       [Training]   Prec@1 65.333333 Max 67.833333
       [Avg Loss]          1.985031
       [Validation] Prec@1 45.000000 Max 45.555556
Confusion matrix:
[[24  0  1  0  0 15]
 [ 1 23  1  0  3  2]
 [13  0 13  3  1  0]
 [ 1  5 11  2  6  5]
 [ 6  8  0  0  9  7]
 [ 7  0  0  2  1 10]]
Epoch: [14]
       [Avg Loss]          0.880655
       [Training]   Prec@1 65.666667 Max 67.833333
       [Avg Loss]          1.883284
       [Validation] Prec@1 35.555556 Max 45.555556
Confusion matrix:
[[16  0  8  0  3 13]
 [ 3  0  8  1  8 10]
 [ 1  0 27  1  1  0]
 [ 0  0 18  2  6  4]
 [ 3  0  9  1 12  5]
 [ 1  0 10  1  1  7]]
Fold "0" complete, final accuracy: 45.55555555555556
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.852214
       [Training]   Prec@1 25.378151 Max 25.378151
       [Avg Loss]          1.687825
       [Validation] Prec@1 36.756757 Max 36.756757
Confusion matrix:
[[ 5 10 14  0  0  1]
 [ 1 23  8  0  0  3]
 [ 2 12 16  0  0  0]
 [19  1  7  0  0  3]
 [15  5  4  0  0  6]
 [ 3  3  0  0  0 24]]
Epoch: [1]
       [Avg Loss]          1.698748
       [Training]   Prec@1 33.277311 Max 33.277311
       [Avg Loss]          1.527493
       [Validation] Prec@1 44.324324 Max 44.324324
Confusion matrix:
[[ 8 10 11  0  0  1]
 [ 0 33  1  0  0  1]
 [ 7 11 11  0  1  0]
 [ 4  1  6  4 13  2]
 [ 7  3  3  0 11  6]
 [ 1  8  3  0  3 15]]
Epoch: [2]
       [Avg Loss]          1.519955
       [Training]   Prec@1 38.991597 Max 38.991597
       [Avg Loss]          1.328947
       [Validation] Prec@1 48.108108 Max 48.108108
Confusion matrix:
[[ 8 10 12  0  0  0]
 [ 2 31  1  0  0  1]
 [ 0  9 21  0  0  0]
 [ 1  2  9 15  0  3]
 [ 9  6  6  6  0  3]
 [ 0 11  0  3  2 14]]
Epoch: [3]
       [Avg Loss]          1.426189
       [Training]   Prec@1 46.554622 Max 46.554622
       [Avg Loss]          1.912108
       [Validation] Prec@1 46.486486 Max 48.108108
Confusion matrix:
[[12 16  2  0  0  0]
 [ 0 34  0  0  1  0]
 [ 1 17 12  0  0  0]
 [ 5  3  8 13  0  1]
 [ 6 13  1  5  5  0]
 [ 3  6  0  8  3 10]]
Epoch: [4]
       [Avg Loss]          1.479689
       [Training]   Prec@1 43.865546 Max 46.554622
       [Avg Loss]          1.235189
       [Validation] Prec@1 56.216216 Max 56.216216
Confusion matrix:
[[20  2  8  0  0  0]
 [ 0 30  3  0  2  0]
 [ 1  6 23  0  0  0]
 [ 4  0 11 12  3  0]
 [12  6  3  4  4  1]
 [ 3  5  1  3  3 15]]
Epoch: [5]
       [Avg Loss]          1.282538
       [Training]   Prec@1 51.260504 Max 51.260504
       [Avg Loss]          1.222790
       [Validation] Prec@1 56.756757 Max 56.756757
Confusion matrix:
[[18  3  8  0  0  1]
 [ 2 29  0  0  1  3]
 [ 0  6 22  0  0  2]
 [ 1  0  7 16  2  4]
 [11  6  2  5  5  1]
 [ 2  4  0  7  2 15]]
Epoch: [6]
       [Avg Loss]          1.199501
       [Training]   Prec@1 55.126050 Max 55.126050
       [Avg Loss]          1.341131
       [Validation] Prec@1 50.270270 Max 56.756757
Confusion matrix:
[[12 15  3  0  0  0]
 [ 0 34  0  0  0  1]
 [ 3 12 15  0  0  0]
 [ 7  2  7 12  1  1]
 [10 13  0  3  2  2]
 [ 5  4  0  3  0 18]]
Epoch: [7]
       [Avg Loss]          1.122672
       [Training]   Prec@1 59.327731 Max 59.327731
       [Avg Loss]          1.129357
       [Validation] Prec@1 57.297297 Max 57.297297
Confusion matrix:
[[24  0  1  0  5  0]
 [ 2 23  2  0  7  1]
 [ 2  7 19  2  0  0]
 [ 3  0  2 18  6  1]
 [11  5  1  4  9  0]
 [11  2  0  3  1 13]]
Epoch: [8]
       [Avg Loss]          1.078973
       [Training]   Prec@1 61.008403 Max 61.008403
       [Avg Loss]          1.510362
       [Validation] Prec@1 50.810811 Max 57.297297
Confusion matrix:
[[11 11  6  0  2  0]
 [ 0 35  0  0  0  0]
 [ 0 11 18  1  0  0]
 [ 0  3  6 17  4  0]
 [ 8 11  1  4  6  0]
 [ 5 11  0  4  3  7]]
Epoch: [9]
       [Avg Loss]          1.142202
       [Training]   Prec@1 56.806723 Max 61.008403
       [Avg Loss]          1.124398
       [Validation] Prec@1 58.918919 Max 58.918919
Confusion matrix:
[[17  4  7  0  0  2]
 [ 1 31  0  0  1  2]
 [ 0  6 23  0  0  1]
 [ 2  1 11 11  3  2]
 [ 8  7  1  5  4  5]
 [ 2  2  0  3  0 23]]
Epoch: [10]
       [Avg Loss]          1.019998
       [Training]   Prec@1 62.184874 Max 62.184874
       [Avg Loss]          1.215036
       [Validation] Prec@1 56.216216 Max 58.918919
Confusion matrix:
[[11  6  5  0  8  0]
 [ 0 34  1  0  0  0]
 [ 0  9 21  0  0  0]
 [ 1  1  6 13  9  0]
 [ 4  7  1  7 11  0]
 [ 5  3  0  3  5 14]]
Epoch: [11]
       [Avg Loss]          0.926953
       [Training]   Prec@1 64.705882 Max 64.705882
       [Avg Loss]          1.358831
       [Validation] Prec@1 52.432432 Max 58.918919
Confusion matrix:
[[13  3 14  0  0  0]
 [ 2 22  9  0  0  2]
 [ 0  3 24  3  0  0]
 [ 0  1  9 17  1  2]
 [ 9  6  7  4  2  2]
 [ 5  2  0  3  1 19]]
Epoch: [12]
       [Avg Loss]          0.911729
       [Training]   Prec@1 67.058824 Max 67.058824
       [Avg Loss]          1.185050
       [Validation] Prec@1 55.675676 Max 58.918919
Confusion matrix:
[[23  2  5  0  0  0]
 [ 0 28  4  0  3  0]
 [ 1  6 19  1  3  0]
 [ 4  1  3 12  9  1]
 [14  3  2  7  3  1]
 [ 4  2  0  5  1 18]]
Epoch: [13]
       [Avg Loss]          0.943822
       [Training]   Prec@1 65.210084 Max 67.058824
       [Avg Loss]          1.357666
       [Validation] Prec@1 54.594595 Max 58.918919
Confusion matrix:
[[19  6  5  0  0  0]
 [ 0 30  5  0  0  0]
 [ 1  7 22  0  0  0]
 [ 4  2  7  9  7  1]
 [11  8  5  3  3  0]
 [ 6  3  0  3  0 18]]
Epoch: [14]
       [Avg Loss]          0.797844
       [Training]   Prec@1 72.773109 Max 72.773109
       [Avg Loss]          1.206116
       [Validation] Prec@1 57.837838 Max 58.918919
Confusion matrix:
[[19  4  5  0  2  0]
 [ 1 31  3  0  0  0]
 [ 1  8 20  1  0  0]
 [ 1  0  7 13  7  2]
 [ 9  5  3  8  5  0]
 [ 3  4  0  3  1 19]]
Fold "1" complete, final accuracy: 58.91891891891892
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.827834
       [Training]   Prec@1 27.563025 Max 27.563025
       [Avg Loss]          1.649849
       [Validation] Prec@1 36.756757 Max 36.756757
Confusion matrix:
[[13 12  0  0  4  1]
 [ 0 34  0  0  0  1]
 [10 11  0  0  9  0]
 [ 3  5  0  0 17  5]
 [11  3  0  0 10  6]
 [ 0 19  0  0  0 11]]
Epoch: [1]
       [Avg Loss]          1.635738
       [Training]   Prec@1 34.789916 Max 34.789916
       [Avg Loss]          1.535177
       [Validation] Prec@1 38.918919 Max 38.918919
Confusion matrix:
[[ 5 18  1  0  4  2]
 [ 0 33  0  0  0  2]
 [ 4 11  3  2 10  0]
 [ 0  4  0  6 14  6]
 [ 8  6  0  0 10  6]
 [ 0 15  0  0  0 15]]
Epoch: [2]
       [Avg Loss]          1.568902
       [Training]   Prec@1 35.630252 Max 35.630252
       [Avg Loss]          2.365473
       [Validation] Prec@1 22.162162 Max 38.918919
Confusion matrix:
[[ 1 29  0  0  0  0]
 [ 0 35  0  0  0  0]
 [ 2 26  0  0  2  0]
 [ 0 13  0  1 14  2]
 [ 2 21  0  0  4  3]
 [ 0 30  0  0  0  0]]
Epoch: [3]
       [Avg Loss]          1.520754
       [Training]   Prec@1 40.000000 Max 40.000000
       [Avg Loss]          1.745277
       [Validation] Prec@1 29.729730 Max 38.918919
Confusion matrix:
[[10  3  1  0  0 16]
 [ 1 17  4  0  0 13]
 [ 5  1  7  0  1 16]
 [ 0  0  0  0  3 27]
 [ 2  0  0  0  0 28]
 [ 0  9  0  0  0 21]]
Epoch: [4]
       [Avg Loss]          1.407777
       [Training]   Prec@1 45.378151 Max 45.378151
       [Avg Loss]          1.556439
       [Validation] Prec@1 32.432432 Max 38.918919
Confusion matrix:
[[18  7  0  0  2  3]
 [ 6 26  1  0  1  1]
 [15  5  5  1  4  0]
 [ 4  0  0  5  8 13]
 [23  1  0  0  1  5]
 [ 6 19  0  0  0  5]]
Epoch: [5]
       [Avg Loss]          1.279149
       [Training]   Prec@1 50.756303 Max 50.756303
       [Avg Loss]          1.478681
       [Validation] Prec@1 43.243243 Max 43.243243
Confusion matrix:
[[ 7  5  1  0  8  9]
 [ 1 16  3  0  0 15]
 [ 0  2  6  4 10  8]
 [ 0  0  0  8  5 17]
 [ 0  2  0  1 15 12]
 [ 0  2  0  0  0 28]]
Epoch: [6]
       [Avg Loss]          1.209119
       [Training]   Prec@1 51.932773 Max 51.932773
       [Avg Loss]          1.665832
       [Validation] Prec@1 33.513514 Max 43.243243
Confusion matrix:
[[ 8  0  6  0  2 14]
 [ 1  2  6  0  0 26]
 [ 0  1  7  9  4  9]
 [ 0  0  0 15  0 15]
 [ 0  0  0  4  3 23]
 [ 0  3  0  0  0 27]]
Epoch: [7]
       [Avg Loss]          1.075004
       [Training]   Prec@1 59.663866 Max 59.663866
       [Avg Loss]          1.308334
       [Validation] Prec@1 50.810811 Max 50.810811
Confusion matrix:
[[21  1  2  0  1  5]
 [ 7 13  3  1  4  7]
 [ 0  3  8 18  1  0]
 [ 0  0  0 27  0  3]
 [13  0  0  8  3  6]
 [ 1  5  0  1  1 22]]
Epoch: [8]
       [Avg Loss]          1.058702
       [Training]   Prec@1 60.840336 Max 60.840336
       [Avg Loss]          1.866701
       [Validation] Prec@1 34.054054 Max 50.810811
Confusion matrix:
[[19  0  2  3  0  6]
 [ 8  0  0 23  2  2]
 [ 0  0  3 24  3  0]
 [ 0  0  0 26  0  4]
 [12  0  0  4  2 12]
 [ 0  0  0 16  1 13]]
Epoch: [9]
       [Avg Loss]          1.041858
       [Training]   Prec@1 61.008403 Max 61.008403
       [Avg Loss]          1.720400
       [Validation] Prec@1 36.216216 Max 50.810811
Confusion matrix:
[[ 7  3  1  0  0 19]
 [ 0  6  5  5  0 19]
 [ 0  0  8 10  0 12]
 [ 0  0  0 19  0 11]
 [ 1  2  0  3  1 23]
 [ 0  3  0  1  0 26]]
Epoch: [10]
       [Avg Loss]          0.970062
       [Training]   Prec@1 63.025210 Max 63.025210
       [Avg Loss]          1.530092
       [Validation] Prec@1 45.405405 Max 50.810811
Confusion matrix:
[[ 7  7  0  4 12  0]
 [ 0 15  5 13  2  0]
 [ 0  2  7 15  6  0]
 [ 0  0  0 20 10  0]
 [ 1  0  0  2 27  0]
 [ 0  8  0 13  1  8]]
Epoch: [11]
       [Avg Loss]          0.920090
       [Training]   Prec@1 66.050420 Max 66.050420
       [Avg Loss]          1.514932
       [Validation] Prec@1 42.702703 Max 50.810811
Confusion matrix:
[[18  0  0  0  4  8]
 [10  7  2  1  1 14]
 [ 5  0  0 12  8  5]
 [ 0  0  0 18  0 12]
 [10  3  0  1  7  9]
 [ 0  1  0  0  0 29]]
Epoch: [12]
       [Avg Loss]          0.936313
       [Training]   Prec@1 66.050420 Max 66.050420
       [Avg Loss]          1.576776
       [Validation] Prec@1 44.324324 Max 50.810811
Confusion matrix:
[[ 6 16  0  0  1  7]
 [ 2 27  2  0  0  4]
 [ 0  4 12 13  1  0]
 [ 0  1  1 19  7  2]
 [ 3 10  0  2  6  9]
 [ 0 13  0  5  0 12]]
Epoch: [13]
       [Avg Loss]          0.881460
       [Training]   Prec@1 67.226891 Max 67.226891
       [Avg Loss]          1.742952
       [Validation] Prec@1 42.162162 Max 50.810811
Confusion matrix:
[[12  0  0  1  6 11]
 [ 2  0  2 20  6  5]
 [ 0  0  4 26  0  0]
 [ 0  0  0 29  0  1]
 [ 7  0  0 10 13  0]
 [ 0  1  0  8  1 20]]
Epoch: [14]
       [Avg Loss]          0.791780
       [Training]   Prec@1 69.915966 Max 69.915966
       [Avg Loss]          1.487893
       [Validation] Prec@1 51.891892 Max 51.891892
Confusion matrix:
[[21  0  1  0  0  8]
 [ 7  3  5  6  0 14]
 [ 0  0 13 14  3  0]
 [ 0  0  0 27  1  2]
 [14  1  0  3 10  2]
 [ 0  2  0  6  0 22]]
Fold "2" complete, final accuracy: 51.891891891891895
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.756322
       [Training]   Prec@1 30.757576 Max 30.757576
       [Avg Loss]          1.655749
       [Validation] Prec@1 32.500000 Max 32.500000
Confusion matrix:
[[10  0  0 10  0  0]
 [ 5  9  1  4  0  1]
 [11  0  0  6  0  3]
 [ 0  0  0 14  3  3]
 [ 8  0  0 12  0  0]
 [ 0  5  0  4  5  6]]
Epoch: [1]
       [Avg Loss]          1.609094
       [Training]   Prec@1 36.212121 Max 36.212121
       [Avg Loss]          1.565481
       [Validation] Prec@1 39.166667 Max 39.166667
Confusion matrix:
[[ 0  4  4 10  2  0]
 [ 0 12  2  2  4  0]
 [ 1  0  9  9  1  0]
 [ 0  0  0 20  0  0]
 [ 0  3  1 10  6  0]
 [ 0  5  0 15  0  0]]
Epoch: [2]
       [Avg Loss]          1.522048
       [Training]   Prec@1 41.212121 Max 41.212121
       [Avg Loss]          1.677074
       [Validation] Prec@1 35.000000 Max 39.166667
Confusion matrix:
[[10  5  0  0  5  0]
 [ 3 16  0  0  1  0]
 [10  2  0  1  4  3]
 [ 0  3  0  7  6  4]
 [10  6  0  3  1  0]
 [ 2  8  0  1  1  8]]
Epoch: [3]
       [Avg Loss]          1.432823
       [Training]   Prec@1 43.484848 Max 43.484848
       [Avg Loss]          1.937744
       [Validation] Prec@1 30.833333 Max 39.166667
Confusion matrix:
[[ 4  1  0 15  0  0]
 [ 1 14  2  2  1  0]
 [ 6  0  3 10  0  1]
 [ 3  0  0 14  3  0]
 [ 1  3  4 10  2  0]
 [ 5  6  0  3  6  0]]
Epoch: [4]
       [Avg Loss]          1.346136
       [Training]   Prec@1 51.212121 Max 51.212121
       [Avg Loss]          1.724109
       [Validation] Prec@1 39.166667 Max 39.166667
Confusion matrix:
[[ 3  2  0  3 12  0]
 [ 0 18  0  1  1  0]
 [ 6  1  0 10  2  1]
 [ 1  1  0 15  1  2]
 [ 2  8  0  6  4  0]
 [ 3  6  0  2  2  7]]
Epoch: [5]
       [Avg Loss]          1.299314
       [Training]   Prec@1 51.515152 Max 51.515152
       [Avg Loss]          1.993902
       [Validation] Prec@1 31.666667 Max 39.166667
Confusion matrix:
[[ 5  0  0  8  7  0]
 [ 0  9  0  1 10  0]
 [ 6  0  1 11  1  1]
 [ 1  0  0 12  7  0]
 [ 0  0  0  9 11  0]
 [ 4  2  0  2 12  0]]
Epoch: [6]
       [Avg Loss]          1.264622
       [Training]   Prec@1 51.212121 Max 51.515152
       [Avg Loss]          2.177633
       [Validation] Prec@1 36.666667 Max 39.166667
Confusion matrix:
[[ 0  5  0 10  5  0]
 [ 0 17  1  2  0  0]
 [ 2  0  5  9  3  1]
 [ 0  1  0 19  0  0]
 [ 0  8  0 10  2  0]
 [ 0  9  0  9  1  1]]
Epoch: [7]
       [Avg Loss]          1.174266
       [Training]   Prec@1 55.606061 Max 55.606061
       [Avg Loss]          1.708682
       [Validation] Prec@1 38.333333 Max 39.166667
Confusion matrix:
[[ 5  0  0  8  7  0]
 [ 0  7  1  0 12  0]
 [ 0  0 11  9  0  0]
 [ 1  0  1 12  5  1]
 [ 0  0  0  9 11  0]
 [ 5  5  0  2  8  0]]
Epoch: [8]
       [Avg Loss]          1.107293
       [Training]   Prec@1 57.878788 Max 57.878788
       [Avg Loss]          1.862271
       [Validation] Prec@1 40.000000 Max 40.000000
Confusion matrix:
[[ 0  5  0  9  6  0]
 [ 0 14  1  1  4  0]
 [ 0  1 10  8  1  0]
 [ 0  4  0 12  2  2]
 [ 0  6  0  8  6  0]
 [ 0  9  0  2  3  6]]
Epoch: [9]
       [Avg Loss]          0.996949
       [Training]   Prec@1 60.757576 Max 60.757576
       [Avg Loss]          1.656085
       [Validation] Prec@1 40.833333 Max 40.833333
Confusion matrix:
[[ 1  5  4  4  6  0]
 [ 0 13  2  0  5  0]
 [ 2  0 15  2  1  0]
 [ 0  4  5  8  2  1]
 [ 0  3  0 10  7  0]
 [ 1  9  0  2  3  5]]
Epoch: [10]
       [Avg Loss]          0.910183
       [Training]   Prec@1 64.848485 Max 64.848485
       [Avg Loss]          1.695657
       [Validation] Prec@1 45.000000 Max 45.000000
Confusion matrix:
[[ 5  0  0  6  9  0]
 [ 0 16  0  1  3  0]
 [ 2  0  7  9  2  0]
 [ 1  0  0 12  4  3]
 [ 0  1  0  8 11  0]
 [ 5  4  0  2  6  3]]
Epoch: [11]
       [Avg Loss]          0.976072
       [Training]   Prec@1 63.030303 Max 64.848485
       [Avg Loss]          2.110097
       [Validation] Prec@1 45.000000 Max 45.000000
Confusion matrix:
[[ 5  0  0 11  4  0]
 [ 2 13  0  2  3  0]
 [ 1  0  8 11  0  0]
 [ 1  0  0 16  2  1]
 [ 0  1  0 10  9  0]
 [ 5  6  0  5  1  3]]
Epoch: [12]
       [Avg Loss]          0.890128
       [Training]   Prec@1 67.878788 Max 67.878788
       [Avg Loss]          1.940421
       [Validation] Prec@1 40.833333 Max 45.000000
Confusion matrix:
[[ 0  5  1  4 10  0]
 [ 0 18  0  0  2  0]
 [ 4  0  7  8  1  0]
 [ 0  3  0 13  1  3]
 [ 0  8  2  7  3  0]
 [ 1  9  0  2  0  8]]
Epoch: [13]
       [Avg Loss]          0.826935
       [Training]   Prec@1 71.363636 Max 71.363636
       [Avg Loss]          2.245903
       [Validation] Prec@1 47.500000 Max 47.500000
Confusion matrix:
[[ 6  0  0 13  1  0]
 [ 0 17  0  2  1  0]
 [ 3  0  5 11  1  0]
 [ 1  1  0 17  0  1]
 [ 0  5  0 10  5  0]
 [ 5  3  0  4  1  7]]
Epoch: [14]
       [Avg Loss]          0.768039
       [Training]   Prec@1 70.606061 Max 71.363636
       [Avg Loss]          1.795981
       [Validation] Prec@1 45.000000 Max 47.500000
Confusion matrix:
[[ 0  5  1  2 12  0]
 [ 0 13  0  0  7  0]
 [ 1  0 13  4  2  0]
 [ 1  0  1 14  4  0]
 [ 0  1  0  9 10  0]
 [ 3  6  0  2  5  4]]
Fold "3" complete, final accuracy: 47.5
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.719251
       [Training]   Prec@1 29.850746 Max 29.850746
       [Avg Loss]          1.680048
       [Validation] Prec@1 30.000000 Max 30.000000
Confusion matrix:
[[ 5  0 11  0  4  0]
 [ 1  8 10  0  0  1]
 [ 0  1 19  0  0  0]
 [ 3  8  2  0  7  0]
 [ 5  0  5  0  0  0]
 [ 1  7  4  0  7  1]]
Epoch: [1]
       [Avg Loss]          1.571941
       [Training]   Prec@1 37.761194 Max 37.761194
       [Avg Loss]          1.623956
       [Validation] Prec@1 33.636364 Max 33.636364
Confusion matrix:
[[ 1  4 12  0  3  0]
 [ 0 15  1  0  0  4]
 [ 0 12  8  0  0  0]
 [ 0  4  5 10  1  0]
 [ 0  1  4  2  3  0]
 [ 5  3  8  0  4  0]]
Epoch: [2]
       [Avg Loss]          1.566705
       [Training]   Prec@1 38.805970 Max 38.805970
       [Avg Loss]          1.756928
       [Validation] Prec@1 34.545455 Max 34.545455
Confusion matrix:
[[10  0  9  0  1  0]
 [ 4  1  6  0  1  8]
 [ 1  0 19  0  0  0]
 [ 2  0  8  0  4  6]
 [ 4  0  6  0  0  0]
 [ 4  0  3  0  5  8]]
Epoch: [3]
       [Avg Loss]          1.439997
       [Training]   Prec@1 44.477612 Max 44.477612
       [Avg Loss]          1.563014
       [Validation] Prec@1 36.363636 Max 36.363636
Confusion matrix:
[[ 7  2  5  1  5  0]
 [ 1  6  4  0  1  8]
 [ 2  2 16  0  0  0]
 [ 2  0  5  4  6  3]
 [ 0  0  5  0  5  0]
 [ 4  0  5  1  8  2]]
Epoch: [4]
       [Avg Loss]          1.339487
       [Training]   Prec@1 48.955224 Max 48.955224
       [Avg Loss]          1.494468
       [Validation] Prec@1 44.545455 Max 44.545455
Confusion matrix:
[[11  1  7  1  0  0]
 [ 3  3  6  0  0  8]
 [ 0  1 19  0  0  0]
 [ 0  0  1 14  2  3]
 [ 3  0  5  2  0  0]
 [ 5  0  0  6  7  2]]
Epoch: [5]
       [Avg Loss]          1.259683
       [Training]   Prec@1 51.641791 Max 51.641791
       [Avg Loss]          1.727294
       [Validation] Prec@1 40.909091 Max 44.545455
Confusion matrix:
[[ 8  0 10  2  0  0]
 [ 9  0  0  1  1  9]
 [ 0  0 16  4  0  0]
 [ 0  0  1  8  5  6]
 [ 5  0  0  0  5  0]
 [ 4  0  0  6  2  8]]
Epoch: [6]
       [Avg Loss]          1.257434
       [Training]   Prec@1 52.537313 Max 52.537313
       [Avg Loss]          1.951828
       [Validation] Prec@1 40.000000 Max 44.545455
Confusion matrix:
[[ 4  0 15  1  0  0]
 [ 5 10  5  0  0  0]
 [ 0  1 19  0  0  0]
 [ 0  2  7 11  0  0]
 [ 0  0  5  5  0  0]
 [ 1  1 10  4  4  0]]
Epoch: [7]
       [Avg Loss]          1.178882
       [Training]   Prec@1 55.373134 Max 55.373134
       [Avg Loss]          1.828639
       [Validation] Prec@1 32.727273 Max 44.545455
Confusion matrix:
[[17  0  2  1  0  0]
 [ 8  0  0  3  2  7]
 [ 7  1 10  0  2  0]
 [ 1  0  4  5  6  4]
 [ 1  0  1  8  0  0]
 [ 7  0  0  9  0  4]]
Epoch: [8]
       [Avg Loss]          1.071624
       [Training]   Prec@1 61.492537 Max 61.492537
       [Avg Loss]          1.807917
       [Validation] Prec@1 42.727273 Max 44.545455
Confusion matrix:
[[12  0  7  1  0  0]
 [ 8  4  2  0  0  6]
 [ 0  1 19  0  0  0]
 [ 0  0  1  7  7  5]
 [ 0  0  5  5  0  0]
 [ 2  0  1  9  3  5]]
Epoch: [9]
       [Avg Loss]          0.985806
       [Training]   Prec@1 63.880597 Max 63.880597
       [Avg Loss]          1.846829
       [Validation] Prec@1 47.272727 Max 47.272727
Confusion matrix:
[[16  0  3  1  0  0]
 [10  3  0  1  0  6]
 [ 0  1 19  0  0  0]
 [ 0  0  3  9  4  4]
 [ 0  0  1  9  0  0]
 [ 2  0  0  9  4  5]]
Epoch: [10]
       [Avg Loss]          0.947040
       [Training]   Prec@1 63.582090 Max 63.880597
       [Avg Loss]          2.001047
       [Validation] Prec@1 47.272727 Max 47.272727
Confusion matrix:
[[11  0  8  1  0  0]
 [ 8  5  1  1  1  4]
 [ 0  0 20  0  0  0]
 [ 0  0  3 13  1  3]
 [ 0  0  1  9  0  0]
 [ 0  0  4  9  4  3]]
Epoch: [11]
       [Avg Loss]          0.897904
       [Training]   Prec@1 64.626866 Max 64.626866
       [Avg Loss]          2.156053
       [Validation] Prec@1 40.909091 Max 47.272727
Confusion matrix:
[[14  0  4  1  1  0]
 [10  2  0  2  1  5]
 [ 2  0 18  0  0  0]
 [ 0  0  4  5  7  4]
 [ 0  0  1  8  1  0]
 [ 5  0  2  7  1  5]]
Epoch: [12]
       [Avg Loss]          0.829911
       [Training]   Prec@1 69.104478 Max 69.104478
       [Avg Loss]          1.947844
       [Validation] Prec@1 46.363636 Max 47.272727
Confusion matrix:
[[13  0  5  1  1  0]
 [ 8  5  1  1  0  5]
 [ 0  0 18  2  0  0]
 [ 0  0  3  8  6  3]
 [ 0  0  0 10  0  0]
 [ 3  0  3  5  2  7]]
Epoch: [13]
       [Avg Loss]          0.753995
       [Training]   Prec@1 73.283582 Max 73.283582
       [Avg Loss]          2.156677
       [Validation] Prec@1 41.818182 Max 47.272727
Confusion matrix:
[[ 7  0  8  1  4  0]
 [ 0  2  3  3  8  4]
 [ 0  0 19  1  0  0]
 [ 0  0  1 14  4  1]
 [ 0  0  2  8  0  0]
 [ 0  0  1 11  4  4]]
Epoch: [14]
       [Avg Loss]          0.714598
       [Training]   Prec@1 73.283582 Max 73.283582
       [Avg Loss]          2.406392
       [Validation] Prec@1 41.818182 Max 47.272727
Confusion matrix:
[[14  0  6  0  0  0]
 [10  1  1  1  2  5]
 [ 1  0 18  1  0  0]
 [ 0  0  7  8  2  3]
 [ 0  0  5  5  0  0]
 [ 6  0  5  4  0  5]]
Fold "4" complete, final accuracy: 47.27272727272727

-----------------------------------------------------------------------
Training for stage 13 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=2)")
Average accuracy is: 50.22781872781873


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 14-----
Evaluated preprocessing: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=2)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.662302
       [Training]   Prec@1 28.833333 Max 28.833333
       [Avg Loss]          1.516883
       [Validation] Prec@1 43.888889 Max 43.888889
Confusion matrix:
[[ 0  1  4  0 26  9]
 [ 0  7  0  0  1 22]
 [ 0  0 30  0  0  0]
 [ 0  0 20  0 10  0]
 [ 0  0  7  0 23  0]
 [ 0  1  0  0  0 19]]
Epoch: [1]
       [Avg Loss]          1.531832
       [Training]   Prec@1 39.000000 Max 39.000000
       [Avg Loss]          1.464200
       [Validation] Prec@1 41.111111 Max 43.888889
Confusion matrix:
[[ 0  9 23  0  7  1]
 [ 0 29  1  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 25  0  4  0]
 [ 0  0 20  0 10  0]
 [ 0 15  0  0  0  5]]
Epoch: [2]
       [Avg Loss]          1.408995
       [Training]   Prec@1 46.333333 Max 46.333333
       [Avg Loss]          1.695699
       [Validation] Prec@1 33.888889 Max 43.888889
Confusion matrix:
[[ 0  4  0  1 30  5]
 [ 0 23  1  0  0  6]
 [ 0  0  0  0 30  0]
 [ 0  1  0  0 29  0]
 [ 0  0  0  0 30  0]
 [ 0 12  0  0  0  8]]
Epoch: [3]
       [Avg Loss]          1.502453
       [Training]   Prec@1 38.333333 Max 46.333333
       [Avg Loss]          1.514603
       [Validation] Prec@1 38.333333 Max 43.888889
Confusion matrix:
[[ 0  7  1  0 29  3]
 [ 0 24  1  5  0  0]
 [ 0  0 15  0 15  0]
 [ 0  0  7  0 23  0]
 [ 0  0  1  0 29  0]
 [ 0 18  0  1  0  1]]
Epoch: [4]
       [Avg Loss]          1.469935
       [Training]   Prec@1 40.166667 Max 46.333333
       [Avg Loss]          1.477631
       [Validation] Prec@1 31.666667 Max 43.888889
Confusion matrix:
[[ 0  4 28  1  2  5]
 [ 0 23  2  2  0  3]
 [ 0  0 30  0  0  0]
 [ 0  1 29  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0 16  0  0  0  4]]
Epoch: [5]
       [Avg Loss]          1.389018
       [Training]   Prec@1 47.666667 Max 47.666667
       [Avg Loss]          1.611332
       [Validation] Prec@1 33.888889 Max 43.888889
Confusion matrix:
[[ 0  3 30  1  0  6]
 [ 0 27  0  0  0  3]
 [ 0  0 30  0  0  0]
 [ 0  1 29  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0 16  0  0  0  4]]
Epoch: [6]
       [Avg Loss]          1.308321
       [Training]   Prec@1 47.666667 Max 47.666667
       [Avg Loss]          1.428674
       [Validation] Prec@1 47.777778 Max 47.777778
Confusion matrix:
[[ 0  1  3  6 22  8]
 [ 0 26  0  0  0  4]
 [ 0  0 30  0  0  0]
 [ 0  1 16  4  9  0]
 [ 0  0  8  2 20  0]
 [ 0 14  0  0  0  6]]
Epoch: [7]
       [Avg Loss]          1.264368
       [Training]   Prec@1 51.000000 Max 51.000000
       [Avg Loss]          1.597417
       [Validation] Prec@1 36.111111 Max 47.777778
Confusion matrix:
[[ 1  0 28  2  0  9]
 [ 0 18  0  0  0 12]
 [ 0  0 30  0  0  0]
 [ 0  2 28  0  0  0]
 [ 0  2 26  2  0  0]
 [ 0  4  0  0  0 16]]
Epoch: [8]
       [Avg Loss]          1.254370
       [Training]   Prec@1 51.000000 Max 51.000000
       [Avg Loss]          1.401952
       [Validation] Prec@1 48.888889 Max 48.888889
Confusion matrix:
[[ 0  0  0  1 30  9]
 [ 0 17  0  1  0 12]
 [ 0  0 29  0  1  0]
 [ 0  1  7  6 16  0]
 [ 0  0  2  3 25  0]
 [ 0  9  0  0  0 11]]
Epoch: [9]
       [Avg Loss]          1.161284
       [Training]   Prec@1 54.833333 Max 54.833333
       [Avg Loss]          1.383348
       [Validation] Prec@1 52.222222 Max 52.222222
Confusion matrix:
[[10  2  2  1 17  8]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 16  3 10  0]
 [ 1  0 11  1 17  0]
 [ 0 16  0  0  0  4]]
Epoch: [10]
       [Avg Loss]          1.151976
       [Training]   Prec@1 56.333333 Max 56.333333
       [Avg Loss]          1.424538
       [Validation] Prec@1 50.000000 Max 52.222222
Confusion matrix:
[[12  6  1  4 12  5]
 [ 0 29  0  1  0  0]
 [ 0  0 29  1  0  0]
 [ 0  1 16  4  9  0]
 [ 1  0 12  3 14  0]
 [ 0 18  0  0  0  2]]
Epoch: [11]
       [Avg Loss]          1.101976
       [Training]   Prec@1 58.666667 Max 58.666667
       [Avg Loss]          1.442186
       [Validation] Prec@1 50.000000 Max 52.222222
Confusion matrix:
[[ 0  5  0  1 30  4]
 [ 0 30  0  0  0  0]
 [ 0  0 27  0  3  0]
 [ 1  0  7  0 22  0]
 [ 2  0  3  0 25  0]
 [ 0 11  1  0  0  8]]
Epoch: [12]
       [Avg Loss]          1.103301
       [Training]   Prec@1 57.500000 Max 58.666667
       [Avg Loss]          1.625898
       [Validation] Prec@1 47.222222 Max 52.222222
Confusion matrix:
[[11  1  8  1 11  8]
 [ 0 29  0  0  0  1]
 [ 0  0 30  0  0  0]
 [ 0  1 28  1  0  0]
 [ 2  0 12  2 14  0]
 [ 0 20  0  0  0  0]]
Epoch: [13]
       [Avg Loss]          1.017810
       [Training]   Prec@1 60.666667 Max 60.666667
       [Avg Loss]          1.542122
       [Validation] Prec@1 46.666667 Max 52.222222
Confusion matrix:
[[15  3  0  2 15  5]
 [ 0 24  0  4  0  2]
 [ 1  0 20  0  9  0]
 [ 4  2  2  2 20  0]
 [ 8  1  0  1 20  0]
 [ 0 17  0  0  0  3]]
Epoch: [14]
       [Avg Loss]          1.020910
       [Training]   Prec@1 64.166667 Max 64.166667
       [Avg Loss]          1.414439
       [Validation] Prec@1 49.444444 Max 52.222222
Confusion matrix:
[[20  7  0  2  5  6]
 [ 0 29  0  1  0  0]
 [ 0  0 22  8  0  0]
 [ 2  1  5  7 15  0]
 [15  2  0  4  9  0]
 [ 3 15  0  0  0  2]]
Fold "0" complete, final accuracy: 52.22222222222222
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.667494
       [Training]   Prec@1 30.084034 Max 30.084034
       [Avg Loss]          1.524194
       [Validation] Prec@1 30.810811 Max 30.810811
Confusion matrix:
[[ 0  0  0  0 20 10]
 [ 0  0  1  0  1 33]
 [ 3  1  8  1 15  2]
 [ 1  1  6  2 14  6]
 [ 0  1  4  1 21  3]
 [ 0  1  2  1  0 26]]
Epoch: [1]
       [Avg Loss]          1.530522
       [Training]   Prec@1 35.294118 Max 35.294118
       [Avg Loss]          1.583851
       [Validation] Prec@1 38.378378 Max 38.378378
Confusion matrix:
[[ 0  2 20  0  0  8]
 [ 0 28  4  0  0  3]
 [ 0  1 25  3  0  1]
 [ 0  6 21  3  0  0]
 [ 0  0 29  1  0  0]
 [ 0 12  2  1  0 15]]
Epoch: [2]
       [Avg Loss]          1.456317
       [Training]   Prec@1 41.848739 Max 41.848739
       [Avg Loss]          1.539881
       [Validation] Prec@1 35.675676 Max 38.378378
Confusion matrix:
[[ 0  0  0  0 20 10]
 [ 0 14  0  3  0 18]
 [ 0  2  4  5 18  1]
 [ 2  7  1  3 16  1]
 [ 1  2  0  6 21  0]
 [ 0  2  1  3  0 24]]
Epoch: [3]
       [Avg Loss]          1.423912
       [Training]   Prec@1 42.857143 Max 42.857143
       [Avg Loss]          1.494371
       [Validation] Prec@1 47.027027 Max 47.027027
Confusion matrix:
[[ 0  2 15  0  5  8]
 [ 0 27  1  2  0  5]
 [ 0  2 22  5  0  1]
 [ 0  6 11  3 10  0]
 [ 0  1  8  6 15  0]
 [ 0  7  2  1  0 20]]
Epoch: [4]
       [Avg Loss]          1.325390
       [Training]   Prec@1 48.907563 Max 48.907563
       [Avg Loss]          1.491704
       [Validation] Prec@1 50.810811 Max 50.810811
Confusion matrix:
[[ 8  2  7  0  5  8]
 [ 0 30  0  3  0  2]
 [ 0  3 21  6  0  0]
 [ 0  6  6  8 10  0]
 [ 9  1  1  8 11  0]
 [ 0 11  0  3  0 16]]
Epoch: [5]
       [Avg Loss]          1.326456
       [Training]   Prec@1 48.571429 Max 48.907563
       [Avg Loss]          1.457755
       [Validation] Prec@1 49.189189 Max 50.810811
Confusion matrix:
[[ 0  2  2  0 18  8]
 [ 0 23  0  2  0 10]
 [ 0  2 20  6  1  1]
 [ 0  5  5 10 10  0]
 [ 0  1  0  8 21  0]
 [ 0  9  0  4  0 17]]
Epoch: [6]
       [Avg Loss]          1.268115
       [Training]   Prec@1 54.117647 Max 54.117647
       [Avg Loss]          1.505708
       [Validation] Prec@1 42.702703 Max 50.810811
Confusion matrix:
[[ 0  2 14  0  6  8]
 [ 0 27  0  3  0  5]
 [ 0  3 21  6  0  0]
 [ 0  8  8  4 10  0]
 [ 3  1  5  8 13  0]
 [ 0 12  2  2  0 14]]
Epoch: [7]
       [Avg Loss]          1.199867
       [Training]   Prec@1 54.285714 Max 54.285714
       [Avg Loss]          1.464599
       [Validation] Prec@1 42.702703 Max 50.810811
Confusion matrix:
[[ 2  5 13  0  5  5]
 [ 0 32  0  3  0  0]
 [ 0  2 21  7  0  0]
 [ 6  6  5  7  6  0]
 [ 9  1  3  8  9  0]
 [ 0 19  0  3  0  8]]
Epoch: [8]
       [Avg Loss]          1.207422
       [Training]   Prec@1 53.613445 Max 54.285714
       [Avg Loss]          1.524246
       [Validation] Prec@1 43.243243 Max 50.810811
Confusion matrix:
[[ 2  2  8  7  3  8]
 [ 0 24  0  3  0  8]
 [ 0  2 21  6  0  1]
 [ 8  5  5  9  2  1]
 [11  2  1  9  7  0]
 [ 0 10  0  3  0 17]]
Epoch: [9]
       [Avg Loss]          1.233646
       [Training]   Prec@1 49.243697 Max 54.285714
       [Avg Loss]          1.587729
       [Validation] Prec@1 45.405405 Max 50.810811
Confusion matrix:
[[ 0  3 15  0  5  7]
 [ 0 26  0  9  0  0]
 [ 0  2 23  5  0  0]
 [ 0  4  8  8 10  0]
 [ 0  1  2  8 19  0]
 [ 0 18  1  3  0  8]]
Epoch: [10]
       [Avg Loss]          1.171526
       [Training]   Prec@1 55.126050 Max 55.126050
       [Avg Loss]          1.616705
       [Validation] Prec@1 40.000000 Max 50.810811
Confusion matrix:
[[ 0  0  1  0 19 10]
 [ 0 11  0  1  0 23]
 [ 0  3 17  4  4  2]
 [ 2  7  5  3 10  3]
 [ 1  1  1  7 20  0]
 [ 0  5  0  2  0 23]]
Epoch: [11]
       [Avg Loss]          1.204979
       [Training]   Prec@1 53.277311 Max 55.126050
       [Avg Loss]          1.665914
       [Validation] Prec@1 38.378378 Max 50.810811
Confusion matrix:
[[ 1 10 10  4  4  1]
 [ 0 34  0  1  0  0]
 [ 0  3 21  6  0  0]
 [ 0 10 10  5  5  0]
 [ 2  3  8  7 10  0]
 [ 0 28  0  2  0  0]]
Epoch: [12]
       [Avg Loss]          1.136272
       [Training]   Prec@1 55.630252 Max 55.630252
       [Avg Loss]          1.521514
       [Validation] Prec@1 43.243243 Max 50.810811
Confusion matrix:
[[ 6  0  1  4  9 10]
 [ 0 20  0  3  0 12]
 [ 0  3 16  8  3  0]
 [ 1  6  5  7 10  1]
 [11  3  0  7  9  0]
 [ 0  5  2  1  0 22]]
Epoch: [13]
       [Avg Loss]          1.122212
       [Training]   Prec@1 56.302521 Max 56.302521
       [Avg Loss]          1.531000
       [Validation] Prec@1 44.864865 Max 50.810811
Confusion matrix:
[[15  4  1  2  2  6]
 [ 0 30  0  4  0  1]
 [ 0  2 18  7  3  0]
 [ 9  8  4  8  1  0]
 [18  1  0  8  3  0]
 [ 0 17  0  4  0  9]]
Epoch: [14]
       [Avg Loss]          1.145084
       [Training]   Prec@1 56.806723 Max 56.806723
       [Avg Loss]          1.648425
       [Validation] Prec@1 37.837838 Max 50.810811
Confusion matrix:
[[ 0  8 15  0  5  2]
 [ 0 31  0  4  0  0]
 [ 0  2 21  7  0  0]
 [ 2  6  9  7  6  0]
 [ 2  1 10  7 10  0]
 [ 0 26  0  3  0  1]]
Fold "1" complete, final accuracy: 50.810810810810814
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.767959
       [Training]   Prec@1 27.731092 Max 27.731092
       [Avg Loss]          1.486570
       [Validation] Prec@1 44.324324 Max 44.324324
Confusion matrix:
[[ 0  5  2  0 23  0]
 [ 0 25  2  0  4  4]
 [ 0  0  2  0 28  0]
 [ 0  5  4  1 17  3]
 [ 0  0  0  0 30  0]
 [ 0  6  0  0  0 24]]
Epoch: [1]
       [Avg Loss]          1.558449
       [Training]   Prec@1 37.983193 Max 37.983193
       [Avg Loss]          1.384482
       [Validation] Prec@1 36.216216 Max 44.324324
Confusion matrix:
[[ 8  5  9  0  8  0]
 [ 1 26  4  4  0  0]
 [16  0 14  0  0  0]
 [ 8  5 13  1  2  1]
 [23  0  0  0  7  0]
 [ 0 19  0  0  0 11]]
Epoch: [2]
       [Avg Loss]          1.452244
       [Training]   Prec@1 41.344538 Max 41.344538
       [Avg Loss]          1.266630
       [Validation] Prec@1 53.513514 Max 53.513514
Confusion matrix:
[[ 0  7 18  1  3  1]
 [ 0 25  1  0  0  9]
 [ 0  1 29  0  0  0]
 [ 0 16 13  0  0  1]
 [ 1  0 10  1 18  0]
 [ 0  3  0  0  0 27]]
Epoch: [3]
       [Avg Loss]          1.433641
       [Training]   Prec@1 43.865546 Max 43.865546
       [Avg Loss]          1.455386
       [Validation] Prec@1 47.027027 Max 53.513514
Confusion matrix:
[[ 0  7 15  1  7  0]
 [ 0 25  2  0  0  8]
 [ 0  1 28  0  1  0]
 [ 0 10 11  1  5  3]
 [ 0  0 24  0  6  0]
 [ 0  3  0  0  0 27]]
Epoch: [4]
       [Avg Loss]          1.465562
       [Training]   Prec@1 41.848739 Max 43.865546
       [Avg Loss]          1.333610
       [Validation] Prec@1 50.810811 Max 53.513514
Confusion matrix:
[[ 3  6 15  4  2  0]
 [ 0 30  2  0  0  3]
 [ 0  0 28  0  2  0]
 [ 3 11  7  4  1  4]
 [10  0 13  0  7  0]
 [ 0  8  0  0  0 22]]
Epoch: [5]
       [Avg Loss]          1.374837
       [Training]   Prec@1 47.226891 Max 47.226891
       [Avg Loss]          1.556820
       [Validation] Prec@1 43.243243 Max 53.513514
Confusion matrix:
[[ 5  3  0  0 18  4]
 [ 2 25  1  0  0  7]
 [10  0  6  0 14  0]
 [ 6  8  6  0  6  4]
 [10  0  0  0 20  0]
 [ 0  6  0  0  0 24]]
Epoch: [6]
       [Avg Loss]          1.300058
       [Training]   Prec@1 47.226891 Max 47.226891
       [Avg Loss]          1.499542
       [Validation] Prec@1 40.000000 Max 53.513514
Confusion matrix:
[[ 3 13  7  0  7  0]
 [ 1 21  7  3  0  3]
 [ 3  0 22  0  5  0]
 [ 6 13  5  2  4  0]
 [11  0 14  0  5  0]
 [ 0  9  0  0  0 21]]
Epoch: [7]
       [Avg Loss]          1.371986
       [Training]   Prec@1 43.697479 Max 47.226891
       [Avg Loss]          1.530026
       [Validation] Prec@1 47.567568 Max 53.513514
Confusion matrix:
[[ 3  4  9  1 12  1]
 [ 0 20  2  0  0 13]
 [ 2  0 18  1  9  0]
 [ 5  9  2  3  9  2]
 [10  0  5  0 15  0]
 [ 0  1  0  0  0 29]]
Epoch: [8]
       [Avg Loss]          1.331899
       [Training]   Prec@1 46.890756 Max 47.226891
       [Avg Loss]          1.542949
       [Validation] Prec@1 45.405405 Max 53.513514
Confusion matrix:
[[ 2  5  4  1 18  0]
 [ 0 27  3  5  0  0]
 [ 1  0 20  0  9  0]
 [ 3  5  5  4 12  1]
 [ 8  0  0  0 22  0]
 [ 0 21  0  0  0  9]]
Epoch: [9]
       [Avg Loss]          1.251605
       [Training]   Prec@1 52.773109 Max 52.773109
       [Avg Loss]          1.444876
       [Validation] Prec@1 51.351351 Max 53.513514
Confusion matrix:
[[ 0  8 15  4  3  0]
 [ 0 25  2  0  0  8]
 [ 0  1 28  0  1  0]
 [ 0 13  9  1  6  1]
 [ 5  0  9  1 15  0]
 [ 0  4  0  0  0 26]]
Epoch: [10]
       [Avg Loss]          1.240367
       [Training]   Prec@1 51.764706 Max 52.773109
       [Avg Loss]          1.336843
       [Validation] Prec@1 44.864865 Max 53.513514
Confusion matrix:
[[ 2  5 13  3  7  0]
 [ 0 20  7  0  0  8]
 [ 1  0 23  2  4  0]
 [ 5  5 11  1  6  2]
 [19  0  1  0 10  0]
 [ 1  2  0  0  0 27]]
Epoch: [11]
       [Avg Loss]          1.205945
       [Training]   Prec@1 53.277311 Max 53.277311
       [Avg Loss]          1.495216
       [Validation] Prec@1 50.270270 Max 53.513514
Confusion matrix:
[[ 3  5  5  5 11  1]
 [ 2 24  1  0  0  8]
 [ 0  0 23  0  7  0]
 [ 5 12  1  2  6  4]
 [10  0  5  0 15  0]
 [ 2  2  0  0  0 26]]
Epoch: [12]
       [Avg Loss]          1.202810
       [Training]   Prec@1 53.949580 Max 53.949580
       [Avg Loss]          1.364708
       [Validation] Prec@1 50.270270 Max 53.513514
Confusion matrix:
[[ 5  5 10  9  1  0]
 [ 1 29  2  0  0  3]
 [ 1  0 28  1  0  0]
 [ 8 10  6  4  2  0]
 [23  0  1  0  6  0]
 [ 5  4  0  0  0 21]]
Epoch: [13]
       [Avg Loss]          1.144614
       [Training]   Prec@1 55.798319 Max 55.798319
       [Avg Loss]          1.833645
       [Validation] Prec@1 44.324324 Max 53.513514
Confusion matrix:
[[ 3  4  3  6 13  1]
 [ 1 29  1  3  0  1]
 [ 2  0 15  3 10  0]
 [ 5  5  3  6  9  2]
 [12  0  0  0 18  0]
 [ 0 19  0  0  0 11]]
Epoch: [14]
       [Avg Loss]          1.113417
       [Training]   Prec@1 57.815126 Max 57.815126
       [Avg Loss]          1.308350
       [Validation] Prec@1 45.945946 Max 53.513514
Confusion matrix:
[[ 5  8  3  7  6  1]
 [ 2 24  0  0  0  9]
 [ 1  0 20  5  4  0]
 [ 7  9  4  2  3  5]
 [17  0  5  0  8  0]
 [ 2  2  0  0  0 26]]
Fold "2" complete, final accuracy: 53.513513513513516
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.646069
       [Training]   Prec@1 33.181818 Max 33.181818
       [Avg Loss]          1.571751
       [Validation] Prec@1 32.500000 Max 32.500000
Confusion matrix:
[[ 0  0  5 15  0  0]
 [ 0 20  0  0  0  0]
 [ 0  1 14  5  0  0]
 [ 0  4 11  5  0  0]
 [ 0  0 12  8  0  0]
 [ 0 20  0  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.510978
       [Training]   Prec@1 39.848485 Max 39.848485
       [Avg Loss]          1.428132
       [Validation] Prec@1 35.833333 Max 35.833333
Confusion matrix:
[[ 0  0 15  2  3  0]
 [ 0 20  0  0  0  0]
 [ 0  0 16  4  0  0]
 [ 0  4 14  2  0  0]
 [ 0  0 10  5  5  0]
 [ 0 20  0  0  0  0]]
Epoch: [2]
       [Avg Loss]          1.420518
       [Training]   Prec@1 45.606061 Max 45.606061
       [Avg Loss]          1.611229
       [Validation] Prec@1 30.000000 Max 35.833333
Confusion matrix:
[[ 0  0 20  0  0  0]
 [ 0 15  3  2  0  0]
 [ 0  0 20  0  0  0]
 [ 0  1 18  1  0  0]
 [ 0  0 20  0  0  0]
 [ 0 19  0  1  0  0]]
Epoch: [3]
       [Avg Loss]          1.509387
       [Training]   Prec@1 41.515152 Max 45.606061
       [Avg Loss]          1.283706
       [Validation] Prec@1 46.666667 Max 46.666667
Confusion matrix:
[[16  0  0  0  4  0]
 [ 0  6  0  0  0 14]
 [ 7  1  6  3  3  0]
 [ 6  4  2  3  4  1]
 [11  0  0  0  9  0]
 [ 0  4  0  0  0 16]]
Epoch: [4]
       [Avg Loss]          1.411733
       [Training]   Prec@1 43.787879 Max 45.606061
       [Avg Loss]          1.200899
       [Validation] Prec@1 43.333333 Max 46.666667
Confusion matrix:
[[ 8  0  5  2  5  0]
 [ 0 18  0  2  0  0]
 [ 3  0 12  5  0  0]
 [ 2  3  8  5  2  0]
 [10  0  4  0  6  0]
 [ 0 17  0  0  0  3]]
Epoch: [5]
       [Avg Loss]          1.342026
       [Training]   Prec@1 48.484848 Max 48.484848
       [Avg Loss]          1.148946
       [Validation] Prec@1 50.000000 Max 50.000000
Confusion matrix:
[[ 0  0  4  2 14  0]
 [ 0 17  0  0  0  3]
 [ 0  1 17  1  1  0]
 [ 1  4  9  4  2  0]
 [ 0  0  4  0 16  0]
 [ 0 14  0  0  0  6]]
Epoch: [6]
       [Avg Loss]          1.267016
       [Training]   Prec@1 48.484848 Max 48.484848
       [Avg Loss]          1.188348
       [Validation] Prec@1 51.666667 Max 51.666667
Confusion matrix:
[[ 0  0  4  2 14  0]
 [ 0 14  0  0  0  6]
 [ 0  1 14  4  1  0]
 [ 1  2  8  7  2  0]
 [ 0  0  7  0 13  0]
 [ 0  6  0  0  0 14]]
Epoch: [7]
       [Avg Loss]          1.259517
       [Training]   Prec@1 50.757576 Max 50.757576
       [Avg Loss]          1.411469
       [Validation] Prec@1 45.000000 Max 51.666667
Confusion matrix:
[[ 4  7  9  0  0  0]
 [ 0 13  0  0  0  7]
 [ 0  3 16  1  0  0]
 [ 1  7  6  5  0  1]
 [ 2  0  9  4  5  0]
 [ 0  9  0  0  0 11]]
Epoch: [8]
       [Avg Loss]          1.222469
       [Training]   Prec@1 53.030303 Max 53.030303
       [Avg Loss]          1.067266
       [Validation] Prec@1 55.833333 Max 55.833333
Confusion matrix:
[[ 2  0  0  0 18  0]
 [ 0 10  2  1  0  7]
 [ 0  0 17  1  2  0]
 [ 1  2  9  4  4  0]
 [ 0  0  2  0 18  0]
 [ 0  4  0  0  0 16]]
Epoch: [9]
       [Avg Loss]          1.218554
       [Training]   Prec@1 54.242424 Max 54.242424
       [Avg Loss]          1.295304
       [Validation] Prec@1 48.333333 Max 55.833333
Confusion matrix:
[[ 3  6 10  1  0  0]
 [ 0 12  1  1  0  6]
 [ 0  0 18  2  0  0]
 [ 2  4  9  5  0  0]
 [ 3  0  9  3  5  0]
 [ 0  4  0  1  0 15]]
Epoch: [10]
       [Avg Loss]          1.172219
       [Training]   Prec@1 55.000000 Max 55.000000
       [Avg Loss]          1.238905
       [Validation] Prec@1 49.166667 Max 55.833333
Confusion matrix:
[[ 4  0  5  3  8  0]
 [ 1 13  0  0  0  6]
 [ 0  1 14  5  0  0]
 [ 1  5  5  7  2  0]
 [ 0  0  8  2 10  0]
 [ 4  5  0  0  0 11]]
Epoch: [11]
       [Avg Loss]          1.132073
       [Training]   Prec@1 57.424242 Max 57.424242
       [Avg Loss]          1.234968
       [Validation] Prec@1 51.666667 Max 55.833333
Confusion matrix:
[[ 7  2  6  3  2  0]
 [ 3 12  0  0  0  5]
 [ 0  0 17  3  0  0]
 [ 2  2  7  9  0  0]
 [ 6  0  7  0  7  0]
 [ 4  6  0  0  0 10]]
Epoch: [12]
       [Avg Loss]          1.104299
       [Training]   Prec@1 58.939394 Max 58.939394
       [Avg Loss]          1.070689
       [Validation] Prec@1 55.833333 Max 55.833333
Confusion matrix:
[[ 9  0  0  0 11  0]
 [ 0 13  1  0  0  6]
 [ 0  0 13  3  4  0]
 [ 2  2  4  5  7  0]
 [ 3  0  0  0 17  0]
 [ 4  6  0  0  0 10]]
Epoch: [13]
       [Avg Loss]          1.114937
       [Training]   Prec@1 58.333333 Max 58.939394
       [Avg Loss]          1.357502
       [Validation] Prec@1 50.833333 Max 55.833333
Confusion matrix:
[[ 8  1 10  1  0  0]
 [ 0 12  0  2  0  6]
 [ 0  0 14  6  0  0]
 [ 1  2  8  8  1  0]
 [ 1  0  7  5  7  0]
 [ 1  1  0  6  0 12]]
Epoch: [14]
       [Avg Loss]          1.045191
       [Training]   Prec@1 59.696970 Max 59.696970
       [Avg Loss]          1.261115
       [Validation] Prec@1 51.666667 Max 55.833333
Confusion matrix:
[[ 7  1  7  3  2  0]
 [ 0 16  0  0  0  4]
 [ 0  0 19  1  0  0]
 [ 2  2  7  7  2  0]
 [ 3  0  6  3  8  0]
 [ 8  7  0  0  0  5]]
Fold "3" complete, final accuracy: 55.833333333333336
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.560046
       [Training]   Prec@1 36.119403 Max 36.119403
       [Avg Loss]          1.646667
       [Validation] Prec@1 31.818182 Max 31.818182
Confusion matrix:
[[ 0  3 11  0  5  1]
 [ 0  5 10  0  5  0]
 [ 0  1 19  0  0  0]
 [ 0  5 15  0  0  0]
 [ 0  0  5  0  5  0]
 [ 0 12  2  0  0  6]]
Epoch: [1]
       [Avg Loss]          1.478772
       [Training]   Prec@1 38.955224 Max 38.955224
       [Avg Loss]          1.605157
       [Validation] Prec@1 26.363636 Max 31.818182
Confusion matrix:
[[ 0  4  8  0  8  0]
 [ 0  8  9  0  3  0]
 [ 0  1 19  0  0  0]
 [ 0  5 15  0  0  0]
 [ 0  0  8  0  2  0]
 [ 0 17  3  0  0  0]]
Epoch: [2]
       [Avg Loss]          1.442126
       [Training]   Prec@1 39.253731 Max 39.253731
       [Avg Loss]          1.756593
       [Validation] Prec@1 26.363636 Max 31.818182
Confusion matrix:
[[ 0  5  4  0 11  0]
 [ 0  6 11  0  3  0]
 [ 0  1 11  0  8  0]
 [ 0  7 13  0  0  0]
 [ 0  0  3  0  7  0]
 [ 0 15  0  0  0  5]]
Epoch: [3]
       [Avg Loss]          1.450179
       [Training]   Prec@1 41.194030 Max 41.194030
       [Avg Loss]          1.794090
       [Validation] Prec@1 25.454545 Max 31.818182
Confusion matrix:
[[ 0  6  3  0 11  0]
 [ 0 12  5  0  3  0]
 [ 0  2  9  0  9  0]
 [ 0 20  0  0  0  0]
 [ 0  0  3  0  7  0]
 [ 0 20  0  0  0  0]]
Epoch: [4]
       [Avg Loss]          1.377295
       [Training]   Prec@1 43.731343 Max 43.731343
       [Avg Loss]          1.663375
       [Validation] Prec@1 32.727273 Max 32.727273
Confusion matrix:
[[ 6  4  4  0  5  1]
 [ 3  6 11  0  0  0]
 [ 2  1 10  0  7  0]
 [ 0  6 10  3  1  0]
 [10  0  0  0  0  0]
 [ 1  8  0  0  0 11]]
Epoch: [5]
       [Avg Loss]          1.336811
       [Training]   Prec@1 44.029851 Max 44.029851
       [Avg Loss]          1.880655
       [Validation] Prec@1 28.181818 Max 32.727273
Confusion matrix:
[[ 0  3  4  0 12  1]
 [ 0  6  5  1  8  0]
 [ 0  1  2  0 17  0]
 [ 0  4 12  2  0  2]
 [ 0  0  0  0 10  0]
 [ 0  9  0  0  0 11]]
Epoch: [6]
       [Avg Loss]          1.314293
       [Training]   Prec@1 46.716418 Max 46.716418
       [Avg Loss]          2.002094
       [Validation] Prec@1 31.818182 Max 32.727273
Confusion matrix:
[[ 0  5  3  0 12  0]
 [ 1  6  2  1  9  1]
 [ 0  2  4  0 14  0]
 [ 0  7  8  3  1  1]
 [ 0  0  0  0 10  0]
 [ 0  8  0  0  0 12]]
Epoch: [7]
       [Avg Loss]          1.242418
       [Training]   Prec@1 50.149254 Max 50.149254
       [Avg Loss]          2.150321
       [Validation] Prec@1 28.181818 Max 32.727273
Confusion matrix:
[[ 0  4  3  1 12  0]
 [ 0  6  1  0 12  1]
 [ 0  1  3  0 16  0]
 [ 0  5  8  2  5  0]
 [ 0  0  0  0 10  0]
 [ 0  7  0  1  2 10]]
Epoch: [8]
       [Avg Loss]          1.177281
       [Training]   Prec@1 51.343284 Max 51.343284
       [Avg Loss]          1.835321
       [Validation] Prec@1 40.909091 Max 40.909091
Confusion matrix:
[[ 0  5  2  0 12  1]
 [ 3  7  0  2  7  1]
 [ 0  1  5  1 13  0]
 [ 0 11  0  8  1  0]
 [ 0  0  0  0 10  0]
 [ 0  3  0  2  0 15]]
Epoch: [9]
       [Avg Loss]          1.130076
       [Training]   Prec@1 52.835821 Max 52.835821
       [Avg Loss]          1.690651
       [Validation] Prec@1 39.090909 Max 40.909091
Confusion matrix:
[[ 0  4  4  1 11  0]
 [ 2  6  3  1  7  1]
 [ 0  2 14  0  4  0]
 [ 0  8  3  8  1  0]
 [ 0  0  5  0  5  0]
 [ 0  8  0  1  1 10]]
Epoch: [10]
       [Avg Loss]          1.142978
       [Training]   Prec@1 54.477612 Max 54.477612
       [Avg Loss]          1.710992
       [Validation] Prec@1 45.454545 Max 45.454545
Confusion matrix:
[[ 6  4  9  0  0  1]
 [ 6  6  4  4  0  0]
 [ 0  2 17  0  1  0]
 [ 0  7  5  8  0  0]
 [ 1  0  9  0  0  0]
 [ 1  6  0  0  0 13]]
Epoch: [11]
       [Avg Loss]          1.098352
       [Training]   Prec@1 53.731343 Max 54.477612
       [Avg Loss]          2.018452
       [Validation] Prec@1 35.454545 Max 45.454545
Confusion matrix:
[[ 0  4  4  1 11  0]
 [ 2  6  2  2  8  0]
 [ 0  1  2  7 10  0]
 [ 0  5  2 12  1  0]
 [ 0  0  0  0 10  0]
 [ 0  8  1  1  1  9]]
Epoch: [12]
       [Avg Loss]          1.049979
       [Training]   Prec@1 55.970149 Max 55.970149
       [Avg Loss]          2.069766
       [Validation] Prec@1 35.454545 Max 45.454545
Confusion matrix:
[[ 1  3  3  1 11  1]
 [ 4  4  1  4  5  2]
 [ 3  1  1  5 10  0]
 [ 3  4  1  9  2  1]
 [ 0  0  0  0 10  0]
 [ 2  0  0  4  0 14]]
Epoch: [13]
       [Avg Loss]          1.028891
       [Training]   Prec@1 60.000000 Max 60.000000
       [Avg Loss]          1.931914
       [Validation] Prec@1 41.818182 Max 45.454545
Confusion matrix:
[[ 0  5  3  0 12  0]
 [ 2  7  1  3  6  1]
 [ 0  2 10  0  8  0]
 [ 0  9  2  9  0  0]
 [ 0  0  0  0 10  0]
 [ 1  5  0  4  0 10]]
Epoch: [14]
       [Avg Loss]          1.024599
       [Training]   Prec@1 58.208955 Max 60.000000
       [Avg Loss]          1.720645
       [Validation] Prec@1 50.000000 Max 50.000000
Confusion matrix:
[[ 0  4  4  1 11  0]
 [ 4  6  1  3  6  0]
 [ 0  1 12  1  6  0]
 [ 1  5  1 13  0  0]
 [ 0  0  0  0 10  0]
 [ 1  0  0  5  0 14]]
Fold "4" complete, final accuracy: 50.0

-----------------------------------------------------------------------
Training for stage 14 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=2)")
Average accuracy is: 52.475975975975985


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 15-----
Evaluated preprocessing: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=2)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.678568
       [Training]   Prec@1 29.333333 Max 29.333333
       [Avg Loss]          1.778101
       [Validation] Prec@1 27.222222 Max 27.222222
Confusion matrix:
[[ 0  2 17  0 21  0]
 [ 0  5 10  0 15  0]
 [ 0  1 27  0  2  0]
 [ 0  3 17  0 10  0]
 [ 0  1 12  0 17  0]
 [ 0  0 10  0 10  0]]
Epoch: [1]
       [Avg Loss]          1.474653
       [Training]   Prec@1 40.666667 Max 40.666667
       [Avg Loss]          1.867214
       [Validation] Prec@1 20.555556 Max 27.222222
Confusion matrix:
[[ 0  2 38  0  0  0]
 [ 0  7 23  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  3 27  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 20  0  0  0]]
Epoch: [2]
       [Avg Loss]          1.415335
       [Training]   Prec@1 42.500000 Max 42.500000
       [Avg Loss]          1.802770
       [Validation] Prec@1 21.111111 Max 27.222222
Confusion matrix:
[[ 0  0  0  0 40  0]
 [ 0  0  7  0 23  0]
 [ 0  0  8  0 22  0]
 [ 0  0  4  0 26  0]
 [ 0  0  2  0 28  0]
 [ 0  0  1  0 17  2]]
Epoch: [3]
       [Avg Loss]          1.378760
       [Training]   Prec@1 47.666667 Max 47.666667
       [Avg Loss]          1.821812
       [Validation] Prec@1 21.111111 Max 27.222222
Confusion matrix:
[[ 1  0  1  0 32  6]
 [ 0  7  0  0 21  2]
 [ 5  4  5  0 16  0]
 [ 1  3  6  0 19  1]
 [ 1  2  7  0 19  1]
 [ 0  1  1  0 12  6]]
Epoch: [4]
       [Avg Loss]          1.300538
       [Training]   Prec@1 48.833333 Max 48.833333
       [Avg Loss]          2.216641
       [Validation] Prec@1 18.888889 Max 27.222222
Confusion matrix:
[[ 1 12  0  0 10 17]
 [ 0 18  0  1  5  6]
 [ 0 27  0  0  1  2]
 [ 0 24  0  0  1  5]
 [ 0 12  0  0  8 10]
 [ 0 10  0  0  3  7]]
Epoch: [5]
       [Avg Loss]          1.275057
       [Training]   Prec@1 50.000000 Max 50.000000
       [Avg Loss]          1.987189
       [Validation] Prec@1 29.444444 Max 29.444444
Confusion matrix:
[[13 12 10  0  2  3]
 [ 1 20  1  0  7  1]
 [ 2 19  9  0  0  0]
 [ 3 16  6  0  2  3]
 [ 3  8 13  1  5  0]
 [ 0  8  3  1  2  6]]
Epoch: [6]
       [Avg Loss]          1.187892
       [Training]   Prec@1 53.333333 Max 53.333333
       [Avg Loss]          2.217583
       [Validation] Prec@1 22.222222 Max 29.444444
Confusion matrix:
[[ 1  0 15 23  0  1]
 [ 2  0 14  9  5  0]
 [ 0  0 28  2  0  0]
 [ 2  0 19  6  3  0]
 [ 0  0 12 17  1  0]
 [ 0  0 10  6  0  4]]
Epoch: [7]
       [Avg Loss]          1.195198
       [Training]   Prec@1 52.333333 Max 53.333333
       [Avg Loss]          2.465417
       [Validation] Prec@1 21.666667 Max 29.444444
Confusion matrix:
[[ 0  0  1 29  4  6]
 [ 3  0  1 20  5  1]
 [ 0  0 11 17  2  0]
 [ 0  0  5 22  2  1]
 [ 0  0 10 18  1  1]
 [ 0  0  2 13  0  5]]
Epoch: [8]
       [Avg Loss]          1.163703
       [Training]   Prec@1 54.666667 Max 54.666667
       [Avg Loss]          2.176916
       [Validation] Prec@1 24.444444 Max 29.444444
Confusion matrix:
[[ 1  0  2 11 17  9]
 [ 1  3  5  2 10  9]
 [ 3  0 17  6  3  1]
 [ 0  1  9  5  8  7]
 [ 0  0  7 10 12  1]
 [ 0  0  5  8  1  6]]
Epoch: [9]
       [Avg Loss]          1.200612
       [Training]   Prec@1 54.333333 Max 54.666667
       [Avg Loss]          4.527789
       [Validation] Prec@1 20.000000 Max 29.444444
Confusion matrix:
[[ 0 38  0  0  0  2]
 [ 0 28  0  0  0  2]
 [ 0 30  0  0  0  0]
 [ 0 26  0  0  0  4]
 [ 0 26  0  0  0  4]
 [ 0 10  0  2  0  8]]
Epoch: [10]
       [Avg Loss]          1.226675
       [Training]   Prec@1 54.666667 Max 54.666667
       [Avg Loss]          2.090858
       [Validation] Prec@1 20.000000 Max 29.444444
Confusion matrix:
[[ 3  0 25  6  2  4]
 [ 2  0 16  4  6  2]
 [ 1  0 28  1  0  0]
 [ 0  1 19  0  8  2]
 [ 0  0 22  5  3  0]
 [ 0  0 10  6  2  2]]
Epoch: [11]
       [Avg Loss]          1.151798
       [Training]   Prec@1 53.666667 Max 54.666667
       [Avg Loss]          1.878457
       [Validation] Prec@1 30.000000 Max 30.000000
Confusion matrix:
[[12  1 18  6  2  1]
 [ 5  5 13  0  6  1]
 [ 0  0 29  1  0  0]
 [ 0  0 20  0 10  0]
 [ 4  2 17  2  5  0]
 [ 0  0 10  7  0  3]]
Epoch: [12]
       [Avg Loss]          1.116043
       [Training]   Prec@1 57.666667 Max 57.666667
       [Avg Loss]          2.108630
       [Validation] Prec@1 30.000000 Max 30.000000
Confusion matrix:
[[18  0  2  2  3 15]
 [ 7  1  5  1  4 12]
 [ 2  0 21  6  1  0]
 [ 1  0 13  1  6  9]
 [ 5  0  6  3  7  9]
 [ 2  0  4  7  1  6]]
Epoch: [13]
       [Avg Loss]          1.088092
       [Training]   Prec@1 57.666667 Max 57.666667
       [Avg Loss]          1.953983
       [Validation] Prec@1 35.555556 Max 35.555556
Confusion matrix:
[[15  1  1  2  4 17]
 [ 3 15  4  0  4  4]
 [ 5  2 21  2  0  0]
 [ 0  5 15  0  5  5]
 [ 3  3  6  2  7  9]
 [ 1  2  7  4  0  6]]
Epoch: [14]
       [Avg Loss]          1.066351
       [Training]   Prec@1 58.166667 Max 58.166667
       [Avg Loss]          1.909252
       [Validation] Prec@1 33.888889 Max 35.555556
Confusion matrix:
[[ 8  0  1  2 10 19]
 [ 4 13  5  0  3  5]
 [ 2  0 21  7  0  0]
 [ 0  2 11  5  5  7]
 [ 2  3  6  6  6  7]
 [ 0  0  4  8  0  8]]
Fold "0" complete, final accuracy: 35.55555555555556
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.786182
       [Training]   Prec@1 28.739496 Max 28.739496
       [Avg Loss]          1.754932
       [Validation] Prec@1 24.864865 Max 24.864865
Confusion matrix:
[[10  0 20  0  0  0]
 [ 7  0 28  0  0  0]
 [ 0  0 30  0  0  0]
 [15  0 15  0  0  0]
 [18  0 12  0  0  0]
 [17  0  7  0  0  6]]
Epoch: [1]
       [Avg Loss]          1.687287
       [Training]   Prec@1 32.773109 Max 32.773109
       [Avg Loss]          1.737442
       [Validation] Prec@1 21.081081 Max 24.864865
Confusion matrix:
[[30  0  0  0  0  0]
 [35  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [21  0  0  0  0  9]]
Epoch: [2]
       [Avg Loss]          1.623508
       [Training]   Prec@1 36.134454 Max 36.134454
       [Avg Loss]          1.622220
       [Validation] Prec@1 32.972973 Max 32.972973
Confusion matrix:
[[ 4 22  4  0  0  0]
 [ 0 35  0  0  0  0]
 [ 1 16 13  0  0  0]
 [18  8  4  0  0  0]
 [13 17  0  0  0  0]
 [ 6 15  0  0  0  9]]
Epoch: [3]
       [Avg Loss]          1.531182
       [Training]   Prec@1 40.336134 Max 40.336134
       [Avg Loss]          2.106710
       [Validation] Prec@1 36.756757 Max 36.756757
Confusion matrix:
[[ 0 29  1  0  0  0]
 [ 0 32  0  0  0  3]
 [ 0 26  4  0  0  0]
 [ 2 16  4  8  0  0]
 [ 0 18  2  5  0  5]
 [ 1  4  0  1  0 24]]
Epoch: [4]
       [Avg Loss]          1.603179
       [Training]   Prec@1 38.655462 Max 40.336134
       [Avg Loss]          2.555652
       [Validation] Prec@1 25.405405 Max 36.756757
Confusion matrix:
[[ 0 17 13  0  0  0]
 [ 0 29  6  0  0  0]
 [ 0 12 18  0  0  0]
 [ 0  5 25  0  0  0]
 [ 0 13 17  0  0  0]
 [ 0 23  7  0  0  0]]
Epoch: [5]
       [Avg Loss]          1.509233
       [Training]   Prec@1 39.327731 Max 40.336134
       [Avg Loss]          2.079978
       [Validation] Prec@1 27.027027 Max 36.756757
Confusion matrix:
[[ 0  1 20  0  9  0]
 [ 0  8 24  0  3  0]
 [ 0  0 29  0  1  0]
 [ 0  0 18  0 12  0]
 [ 0  1 16  0 13  0]
 [ 0  9 17  0  4  0]]
Epoch: [6]
       [Avg Loss]          1.425739
       [Training]   Prec@1 45.714286 Max 45.714286
       [Avg Loss]          1.673637
       [Validation] Prec@1 30.270270 Max 36.756757
Confusion matrix:
[[ 0  0 19  0 11  0]
 [ 0  0 25  0 10  0]
 [ 0  0 29  0  1  0]
 [ 0  0 13 13  4  0]
 [ 0  0  8  9 13  0]
 [ 1  0  7  7 14  1]]
Epoch: [7]
       [Avg Loss]          1.373233
       [Training]   Prec@1 44.201681 Max 45.714286
       [Avg Loss]          2.178593
       [Validation] Prec@1 38.378378 Max 38.378378
Confusion matrix:
[[ 0 25  0  0  0  5]
 [ 0 34  0  0  0  1]
 [ 0 21  7  0  0  2]
 [ 0  8  0  4  4 14]
 [ 0 11  0  0  0 19]
 [ 0  4  0  0  0 26]]
Epoch: [8]
       [Avg Loss]          1.382273
       [Training]   Prec@1 45.882353 Max 45.882353
       [Avg Loss]          1.289573
       [Validation] Prec@1 49.189189 Max 49.189189
Confusion matrix:
[[ 0  0 11  2 11  6]
 [ 0  9 15  0  3  8]
 [ 0  0 27  3  0  0]
 [ 0  0  8 19  1  2]
 [ 0  0  4 10 10  6]
 [ 0  1  1  2  0 26]]
Epoch: [9]
       [Avg Loss]          1.372678
       [Training]   Prec@1 45.546218 Max 45.882353
       [Avg Loss]          1.481335
       [Validation] Prec@1 40.540541 Max 49.189189
Confusion matrix:
[[ 0  0 19  1 10  0]
 [ 2  3 19  0  7  4]
 [ 1  0 28  1  0  0]
 [ 4  0 10 16  0  0]
 [ 2  0  8 11  8  1]
 [ 0  1  3  4  2 20]]
Epoch: [10]
       [Avg Loss]          1.340787
       [Training]   Prec@1 46.554622 Max 46.554622
       [Avg Loss]          1.655140
       [Validation] Prec@1 32.432432 Max 49.189189
Confusion matrix:
[[ 0  0  4 20  0  6]
 [ 1  1  7  2  0 24]
 [ 0  2 13 15  0  0]
 [ 0  0  3 27  0  0]
 [ 2  0  0 27  0  1]
 [ 0  0  0 11  0 19]]
Epoch: [11]
       [Avg Loss]          1.288014
       [Training]   Prec@1 47.058824 Max 47.058824
       [Avg Loss]          1.488592
       [Validation] Prec@1 37.297297 Max 49.189189
Confusion matrix:
[[16  0  8  4  2  0]
 [15  3 12  0  4  1]
 [ 6  0 23  1  0  0]
 [ 9  0  8 12  0  1]
 [10  0  9  9  2  0]
 [ 9  0  2  3  3 13]]
Epoch: [12]
       [Avg Loss]          1.279416
       [Training]   Prec@1 51.932773 Max 51.932773
       [Avg Loss]          1.442042
       [Validation] Prec@1 43.783784 Max 49.189189
Confusion matrix:
[[20  0  4  0  6  0]
 [12  4 11  0  5  3]
 [ 5  0 25  0  0  0]
 [14  0  5  6  5  0]
 [ 6  0  5  3 13  3]
 [ 8  0  2  3  4 13]]
Epoch: [13]
       [Avg Loss]          1.277476
       [Training]   Prec@1 50.924370 Max 51.932773
       [Avg Loss]          1.494492
       [Validation] Prec@1 47.567568 Max 49.189189
Confusion matrix:
[[ 2 11 17  0  0  0]
 [ 0 29  5  0  0  1]
 [ 0  8 22  0  0  0]
 [ 2  1 15 12  0  0]
 [ 2  8  7  9  2  2]
 [ 0  4  1  3  1 21]]
Epoch: [14]
       [Avg Loss]          1.303685
       [Training]   Prec@1 47.058824 Max 51.932773
       [Avg Loss]          1.255810
       [Validation] Prec@1 57.297297 Max 57.297297
Confusion matrix:
[[ 4 10  6  4  1  5]
 [ 1 31  1  0  0  2]
 [ 0  9 19  2  0  0]
 [ 0  1  5 21  1  2]
 [ 3  4  2 15  5  1]
 [ 0  2  0  2  0 26]]
Fold "1" complete, final accuracy: 57.2972972972973
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.777385
       [Training]   Prec@1 28.907563 Max 28.907563
       [Avg Loss]          1.754397
       [Validation] Prec@1 31.891892 Max 31.891892
Confusion matrix:
[[ 1 23  0  0  6  0]
 [ 0 35  0  0  0  0]
 [ 0 10  0  0 20  0]
 [ 1 10  0  0 17  2]
 [ 2 10  0  0 16  2]
 [ 0 23  0  0  0  7]]
Epoch: [1]
       [Avg Loss]          1.623538
       [Training]   Prec@1 38.655462 Max 38.655462
       [Avg Loss]          1.741060
       [Validation] Prec@1 27.567568 Max 31.891892
Confusion matrix:
[[ 2  0 18  0 10  0]
 [ 0  0 34  0  1  0]
 [ 0  0 29  0  1  0]
 [ 0  0 18  8  4  0]
 [ 0  0 18  0 12  0]
 [ 1  0 20  0  9  0]]
Epoch: [2]
       [Avg Loss]          1.618028
       [Training]   Prec@1 37.815126 Max 38.655462
       [Avg Loss]          1.627597
       [Validation] Prec@1 23.783784 Max 31.891892
Confusion matrix:
[[23  0  0  0  6  1]
 [34  0  0  0  0  1]
 [25  0  0  0  5  0]
 [10  0  0  0 15  5]
 [16  0  0  0 11  3]
 [14  6  0  0  0 10]]
Epoch: [3]
       [Avg Loss]          1.554761
       [Training]   Prec@1 39.831933 Max 39.831933
       [Avg Loss]          1.613669
       [Validation] Prec@1 29.729730 Max 31.891892
Confusion matrix:
[[17  8  0  0  0  5]
 [ 7 24  1  0  0  3]
 [18  4  1  0  2  5]
 [ 0  2  0  0  2 26]
 [12  0  0  0  0 18]
 [ 0 17  0  0  0 13]]
Epoch: [4]
       [Avg Loss]          1.521188
       [Training]   Prec@1 41.848739 Max 41.848739
       [Avg Loss]          1.673901
       [Validation] Prec@1 25.945946 Max 31.891892
Confusion matrix:
[[28  1  0  0  0  1]
 [24  9  0  0  0  2]
 [28  2  0  0  0  0]
 [18  0  0  2  0 10]
 [26  0  0  0  0  4]
 [15  6  0  0  0  9]]
Epoch: [5]
       [Avg Loss]          1.397519
       [Training]   Prec@1 46.386555 Max 46.386555
       [Avg Loss]          1.555900
       [Validation] Prec@1 28.648649 Max 31.891892
Confusion matrix:
[[16  3  0  0  6  5]
 [14 16  0  0  0  5]
 [25  4  1  0  0  0]
 [20  0  0  1  1  8]
 [26  1  0  0  0  3]
 [ 4  7  0  0  0 19]]
Epoch: [6]
       [Avg Loss]          1.332016
       [Training]   Prec@1 48.403361 Max 48.403361
       [Avg Loss]          1.840247
       [Validation] Prec@1 24.324324 Max 31.891892
Confusion matrix:
[[12  0  0  0  2 16]
 [ 2  0  5  0  0 28]
 [ 0  0  4  0  0 26]
 [ 0  0  0  0  0 30]
 [ 2  0  0  0  0 28]
 [ 0  1  0  0  0 29]]
Epoch: [7]
       [Avg Loss]          1.309398
       [Training]   Prec@1 49.915966 Max 49.915966
       [Avg Loss]          2.872140
       [Validation] Prec@1 25.945946 Max 31.891892
Confusion matrix:
[[ 0 30  0  0  0  0]
 [ 0 35  0  0  0  0]
 [ 4 15 10  0  1  0]
 [ 7 11  1  3  4  4]
 [ 9 16  4  0  0  1]
 [ 0 30  0  0  0  0]]
Epoch: [8]
       [Avg Loss]          1.269944
       [Training]   Prec@1 50.588235 Max 50.588235
       [Avg Loss]          1.597882
       [Validation] Prec@1 37.837838 Max 37.837838
Confusion matrix:
[[16  0  0  1  3 10]
 [16  0  5  0  0 14]
 [ 9  0  8  4  1  8]
 [ 0  0  0 16  0 14]
 [13  0  0  2  2 13]
 [ 0  0  0  2  0 28]]
Epoch: [9]
       [Avg Loss]          1.269929
       [Training]   Prec@1 53.109244 Max 53.109244
       [Avg Loss]          1.633796
       [Validation] Prec@1 37.837838 Max 37.837838
Confusion matrix:
[[15  9  0  0  0  6]
 [ 3 31  0  0  0  1]
 [ 6  9  7  0  0  8]
 [ 6  0  0  0  1 23]
 [12  4  0  0  0 14]
 [ 0 13  0  0  0 17]]
Epoch: [10]
       [Avg Loss]          1.255400
       [Training]   Prec@1 50.924370 Max 53.109244
       [Avg Loss]          1.715585
       [Validation] Prec@1 42.702703 Max 42.702703
Confusion matrix:
[[20  0  0  4  1  5]
 [11 14  1  0  0  9]
 [10  4  0 14  1  1]
 [ 0  0  0 19  0 11]
 [11  1  0 15  0  3]
 [ 0  4  0  0  0 26]]
Epoch: [11]
       [Avg Loss]          1.187726
       [Training]   Prec@1 51.764706 Max 53.109244
       [Avg Loss]          1.366781
       [Validation] Prec@1 41.081081 Max 42.702703
Confusion matrix:
[[18  0  8  1  2  1]
 [ 6 14 14  0  1  0]
 [ 4  3 22  1  0  0]
 [ 2  0 11 15  0  2]
 [26  0  4  0  0  0]
 [ 7  6  6  4  0  7]]
Epoch: [12]
       [Avg Loss]          1.178313
       [Training]   Prec@1 57.647059 Max 57.647059
       [Avg Loss]          1.402905
       [Validation] Prec@1 46.486486 Max 46.486486
Confusion matrix:
[[18  1  5  1  4  1]
 [ 6 23  3  0  3  0]
 [ 2  4 22  2  0  0]
 [ 5  0  7 11  1  6]
 [21  3  3  0  2  1]
 [11  8  1  0  0 10]]
Epoch: [13]
       [Avg Loss]          1.097449
       [Training]   Prec@1 58.151261 Max 58.151261
       [Avg Loss]          2.035205
       [Validation] Prec@1 30.270270 Max 46.486486
Confusion matrix:
[[ 9  0  0  8  5  8]
 [14  0  0  5  4 12]
 [ 3  0  1 14  2 10]
 [ 0  0  0 18  0 12]
 [ 2  0  0 17  6  5]
 [ 1  0  0  6  1 22]]
Epoch: [14]
       [Avg Loss]          1.099444
       [Training]   Prec@1 58.319328 Max 58.319328
       [Avg Loss]          1.516963
       [Validation] Prec@1 41.621622 Max 46.486486
Confusion matrix:
[[21  0  1  3  2  3]
 [17  3  3  0  3  9]
 [ 9  2  5  5  1  8]
 [ 0  0  0 16  0 14]
 [13  0  0  1  5 11]
 [ 0  0  0  3  0 27]]
Fold "2" complete, final accuracy: 46.486486486486484
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.715914
       [Training]   Prec@1 30.303030 Max 30.303030
       [Avg Loss]          1.743654
       [Validation] Prec@1 25.000000 Max 25.000000
Confusion matrix:
[[ 0  0 16  4  0  0]
 [ 4  1 14  1  0  0]
 [ 0  0 20  0  0  0]
 [ 0  0 11  9  0  0]
 [ 0  0 17  3  0  0]
 [ 0  0 11  9  0  0]]
Epoch: [1]
       [Avg Loss]          1.601449
       [Training]   Prec@1 37.272727 Max 37.272727
       [Avg Loss]          1.700520
       [Validation] Prec@1 23.333333 Max 25.000000
Confusion matrix:
[[ 0  0  0  0 20  0]
 [ 1  7  1  0 11  0]
 [ 0  1  0  0 19  0]
 [ 0  0  0  1 18  1]
 [ 0  0  0  0 20  0]
 [ 1  5  0  4 10  0]]
Epoch: [2]
       [Avg Loss]          1.667794
       [Training]   Prec@1 31.515152 Max 37.272727
       [Avg Loss]          1.768566
       [Validation] Prec@1 26.666667 Max 26.666667
Confusion matrix:
[[ 3  2  0  0 15  0]
 [ 4 10  0  0  6  0]
 [ 3  3  0  0 14  0]
 [ 2  0  0  1 16  1]
 [ 0  2  0  0 18  0]
 [ 9  6  0  0  5  0]]
Epoch: [3]
       [Avg Loss]          1.609747
       [Training]   Prec@1 31.060606 Max 37.272727
       [Avg Loss]          2.123397
       [Validation] Prec@1 25.833333 Max 26.666667
Confusion matrix:
[[20  0  0  0  0  0]
 [12  0  8  0  0  0]
 [ 9  0 11  0  0  0]
 [19  0  0  0  0  1]
 [20  0  0  0  0  0]
 [17  0  2  0  1  0]]
Epoch: [4]
       [Avg Loss]          1.484744
       [Training]   Prec@1 39.393939 Max 39.393939
       [Avg Loss]          1.753930
       [Validation] Prec@1 31.666667 Max 31.666667
Confusion matrix:
[[ 0 12  0  0  8  0]
 [ 0 18  0  0  2  0]
 [ 0 15  2  0  3  0]
 [ 0  4  0  4 10  2]
 [ 0 10  0  2  8  0]
 [ 0  9  0  3  2  6]]
Epoch: [5]
       [Avg Loss]          1.468949
       [Training]   Prec@1 39.848485 Max 39.848485
       [Avg Loss]          1.703328
       [Validation] Prec@1 31.666667 Max 31.666667
Confusion matrix:
[[ 0  8  0  0  8  4]
 [ 0 16  0  0  2  2]
 [ 0 12  0  0  4  4]
 [ 0  0  0  0 13  7]
 [ 0 10  0  0 10  0]
 [ 0  6  0  0  2 12]]
Epoch: [6]
       [Avg Loss]          1.348237
       [Training]   Prec@1 46.060606 Max 46.060606
       [Avg Loss]          1.446331
       [Validation] Prec@1 33.333333 Max 33.333333
Confusion matrix:
[[ 6  0  0  3 11  0]
 [ 5  6  4  0  3  2]
 [ 6  0  6  6  0  2]
 [ 0  0  0 12  5  3]
 [10  0  0  8  2  0]
 [ 1  5  0  4  2  8]]
Epoch: [7]
       [Avg Loss]          1.339276
       [Training]   Prec@1 47.272727 Max 47.272727
       [Avg Loss]          1.615299
       [Validation] Prec@1 41.666667 Max 41.666667
Confusion matrix:
[[ 8  1  0  2  8  1]
 [ 1 14  0  0  2  3]
 [ 4  3  1 10  0  2]
 [ 0  0  0 11  1  8]
 [ 2  9  0  6  2  1]
 [ 1  3  0  2  0 14]]
Epoch: [8]
       [Avg Loss]          1.224267
       [Training]   Prec@1 54.545455 Max 54.545455
       [Avg Loss]          1.985956
       [Validation] Prec@1 36.666667 Max 41.666667
Confusion matrix:
[[ 4  7  0  1  7  1]
 [ 0 19  0  0  1  0]
 [ 2  5  0  9  2  2]
 [ 0  1  0 11  1  7]
 [ 2 11  0  6  0  1]
 [ 0  8  0  1  1 10]]
Epoch: [9]
       [Avg Loss]          1.233225
       [Training]   Prec@1 50.000000 Max 54.545455
       [Avg Loss]          1.580524
       [Validation] Prec@1 50.000000 Max 50.000000
Confusion matrix:
[[10  4  4  2  0  0]
 [ 2 16  1  1  0  0]
 [ 5  0 11  4  0  0]
 [ 2  1  0 14  1  2]
 [ 7  7  4  2  0  0]
 [ 3  6  2  0  0  9]]
Epoch: [10]
       [Avg Loss]          1.211269
       [Training]   Prec@1 52.727273 Max 54.545455
       [Avg Loss]          2.111177
       [Validation] Prec@1 26.666667 Max 50.000000
Confusion matrix:
[[ 8  0  0 11  1  0]
 [12  1  1  1  5  0]
 [ 3  0  4 11  2  0]
 [ 2  0  1 14  1  2]
 [ 9  0  0  9  2  0]
 [10  0  0  2  5  3]]
Epoch: [11]
       [Avg Loss]          1.131302
       [Training]   Prec@1 57.424242 Max 57.424242
       [Avg Loss]          2.051901
       [Validation] Prec@1 30.000000 Max 50.000000
Confusion matrix:
[[ 0  0  0  5 15  0]
 [ 6  1  0  1 10  2]
 [ 0  0  0 14  6  0]
 [ 1  0  0 14  2  3]
 [ 0  0  0  8 12  0]
 [ 3  0  0  2  6  9]]
Epoch: [12]
       [Avg Loss]          1.119072
       [Training]   Prec@1 53.636364 Max 57.424242
       [Avg Loss]          1.676335
       [Validation] Prec@1 41.666667 Max 50.000000
Confusion matrix:
[[ 1  5  0  4 10  0]
 [ 0 19  0  0  1  0]
 [ 5  0  5  8  2  0]
 [ 1  1  0 14  1  3]
 [ 0  9  0  7  4  0]
 [ 2  8  1  1  1  7]]
Epoch: [13]
       [Avg Loss]          1.074153
       [Training]   Prec@1 57.878788 Max 57.878788
       [Avg Loss]          1.671858
       [Validation] Prec@1 40.000000 Max 50.000000
Confusion matrix:
[[ 1  0  0  7 12  0]
 [ 0 15  0  1  4  0]
 [ 3  0  8  7  2  0]
 [ 0  0  0 14  5  1]
 [ 0  1  0  9 10  0]
 [ 3  6  1  2  8  0]]
Epoch: [14]
       [Avg Loss]          1.052146
       [Training]   Prec@1 61.060606 Max 61.060606
       [Avg Loss]          1.594464
       [Validation] Prec@1 50.833333 Max 50.833333
Confusion matrix:
[[11  6  0  0  3  0]
 [ 0 19  0  0  1  0]
 [10  0 10  0  0  0]
 [ 2  0  0  8  5  5]
 [ 6  9  1  0  4  0]
 [ 2  8  0  0  1  9]]
Fold "3" complete, final accuracy: 50.833333333333336
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.716537
       [Training]   Prec@1 31.194030 Max 31.194030
       [Avg Loss]          1.774845
       [Validation] Prec@1 27.272727 Max 27.272727
Confusion matrix:
[[ 0  0 13  0  7  0]
 [ 0  0 14  0  6  0]
 [ 0  0 20  0  0  0]
 [ 0  0 10  0 10  0]
 [ 0  0  0  0 10  0]
 [ 0  0 10  0 10  0]]
Epoch: [1]
       [Avg Loss]          1.587525
       [Training]   Prec@1 36.417910 Max 36.417910
       [Avg Loss]          1.824319
       [Validation] Prec@1 22.727273 Max 27.272727
Confusion matrix:
[[ 5  0 15  0  0  0]
 [ 5  0 15  0  0  0]
 [ 0  0 20  0  0  0]
 [ 0  0 20  0  0  0]
 [ 9  0  1  0  0  0]
 [ 1  0 18  0  1  0]]
Epoch: [2]
       [Avg Loss]          1.566723
       [Training]   Prec@1 37.462687 Max 37.462687
       [Avg Loss]          1.559538
       [Validation] Prec@1 31.818182 Max 31.818182
Confusion matrix:
[[ 0  4 13  0  2  1]
 [ 0  8  3  0  0  9]
 [ 0  8 12  0  0  0]
 [ 0  0  7  2  4  7]
 [ 0  0  9  0  1  0]
 [ 0  0  5  0  3 12]]
Epoch: [3]
       [Avg Loss]          1.491786
       [Training]   Prec@1 40.447761 Max 40.447761
       [Avg Loss]          1.698413
       [Validation] Prec@1 27.272727 Max 31.818182
Confusion matrix:
[[ 0 14  6  0  0  0]
 [ 0 13  3  0  0  4]
 [ 0  9 11  0  0  0]
 [ 0  4 11  0  0  5]
 [ 0  9  1  0  0  0]
 [ 0 11  3  0  0  6]]
Epoch: [4]
       [Avg Loss]          1.384298
       [Training]   Prec@1 44.626866 Max 44.626866
       [Avg Loss]          1.843771
       [Validation] Prec@1 28.181818 Max 31.818182
Confusion matrix:
[[ 0  0 20  0  0  0]
 [ 2 11  7  0  0  0]
 [ 0  0 20  0  0  0]
 [ 0  1 19  0  0  0]
 [ 3  0  7  0  0  0]
 [ 0  0 19  1  0  0]]
Epoch: [5]
       [Avg Loss]          1.407233
       [Training]   Prec@1 45.970149 Max 45.970149
       [Avg Loss]          1.581730
       [Validation] Prec@1 52.727273 Max 52.727273
Confusion matrix:
[[ 6  2  3  5  4  0]
 [ 3  4  4  0  1  8]
 [ 0  2 18  0  0  0]
 [ 0  0  0 11  1  8]
 [ 0  0  0  4  6  0]
 [ 2  0  0  1  4 13]]
Epoch: [6]
       [Avg Loss]          1.274684
       [Training]   Prec@1 50.895522 Max 50.895522
       [Avg Loss]          1.681133
       [Validation] Prec@1 40.000000 Max 52.727273
Confusion matrix:
[[ 7  0 12  1  0  0]
 [ 6  7  6  0  0  1]
 [ 0  0 20  0  0  0]
 [ 2  1  7  9  1  0]
 [ 6  0  4  0  0  0]
 [ 5  0 11  1  2  1]]
Epoch: [7]
       [Avg Loss]          1.275938
       [Training]   Prec@1 52.388060 Max 52.388060
       [Avg Loss]          1.575926
       [Validation] Prec@1 43.636364 Max 52.727273
Confusion matrix:
[[ 5  6  5  0  4  0]
 [ 0 14  1  0  0  5]
 [ 0  4 15  0  1  0]
 [ 2  6  2  0  6  4]
 [ 0  2  0  0  8  0]
 [ 3  6  4  0  1  6]]
Epoch: [8]
       [Avg Loss]          1.240401
       [Training]   Prec@1 53.582090 Max 53.582090
       [Avg Loss]          1.577677
       [Validation] Prec@1 42.727273 Max 52.727273
Confusion matrix:
[[13  0  4  1  2  0]
 [ 7  1  2  1  2  7]
 [ 0  0 20  0  0  0]
 [ 4  0  1 12  1  2]
 [ 9  0  0  0  1  0]
 [ 5  0  0  8  7  0]]
Epoch: [9]
       [Avg Loss]          1.221954
       [Training]   Prec@1 52.985075 Max 53.582090
       [Avg Loss]          1.454115
       [Validation] Prec@1 50.909091 Max 52.727273
Confusion matrix:
[[11  1  4  0  4  0]
 [ 3 15  1  0  1  0]
 [ 0  2 18  0  0  0]
 [ 1  3  3  0 10  3]
 [ 0  0  0  0 10  0]
 [13  0  1  0  4  2]]
Epoch: [10]
       [Avg Loss]          1.194572
       [Training]   Prec@1 52.089552 Max 53.582090
       [Avg Loss]          1.512595
       [Validation] Prec@1 50.000000 Max 52.727273
Confusion matrix:
[[15  0  3  2  0  0]
 [ 8  1  1  0  1  9]
 [ 0  1 19  0  0  0]
 [ 1  0  3  6  3  7]
 [ 6  0  0  1  3  0]
 [ 6  0  0  3  0 11]]
Epoch: [11]
       [Avg Loss]          1.123485
       [Training]   Prec@1 59.104478 Max 59.104478
       [Avg Loss]          1.517937
       [Validation] Prec@1 45.454545 Max 52.727273
Confusion matrix:
[[14  0  4  2  0  0]
 [ 6  4  1  1  3  5]
 [ 0  0 20  0  0  0]
 [ 1  0  5 11  0  3]
 [ 2  0  0  8  0  0]
 [ 6  0  1  4  8  1]]
Epoch: [12]
       [Avg Loss]          1.024933
       [Training]   Prec@1 59.253731 Max 59.253731
       [Avg Loss]          1.494178
       [Validation] Prec@1 50.909091 Max 52.727273
Confusion matrix:
[[14  0  4  1  1  0]
 [ 9  1  1  1  1  7]
 [ 0  0 19  1  0  0]
 [ 0  0  2 11  0  7]
 [ 0  0  0 10  0  0]
 [ 6  0  0  3  0 11]]
Epoch: [13]
       [Avg Loss]          0.987440
       [Training]   Prec@1 63.134328 Max 63.134328
       [Avg Loss]          1.493424
       [Validation] Prec@1 52.727273 Max 52.727273
Confusion matrix:
[[14  0  4  0  2  0]
 [ 9  8  1  0  0  2]
 [ 0  0 20  0  0  0]
 [ 0  1  3  5  6  5]
 [ 0  0  0  8  2  0]
 [ 5  0  0  4  2  9]]
Epoch: [14]
       [Avg Loss]          1.012257
       [Training]   Prec@1 60.895522 Max 63.134328
       [Avg Loss]          2.303088
       [Validation] Prec@1 30.000000 Max 52.727273
Confusion matrix:
[[ 0  1 10  3  6  0]
 [ 2  7  2  2  6  1]
 [ 0  3 16  1  0  0]
 [ 0  0 10 10  0  0]
 [ 0  0  0 10  0  0]
 [ 0  0 12  8  0  0]]
Fold "4" complete, final accuracy: 52.72727272727273

-----------------------------------------------------------------------
Training for stage 15 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=2)")
Average accuracy is: 48.57998907998908


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 16-----
Evaluated preprocessing: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=2)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.679879
       [Training]   Prec@1 27.500000 Max 27.500000
       [Avg Loss]          1.744140
       [Validation] Prec@1 33.333333 Max 33.333333
Confusion matrix:
[[ 0  4 30  0  0  6]
 [ 0 19  0  0  3  8]
 [ 0  0 30  0  0  0]
 [ 0  0 25  0  5  0]
 [ 0  0 29  0  1  0]
 [ 0  9  0  0  1 10]]
Epoch: [1]
       [Avg Loss]          1.542404
       [Training]   Prec@1 37.833333 Max 37.833333
       [Avg Loss]          1.817445
       [Validation] Prec@1 16.666667 Max 33.333333
Confusion matrix:
[[ 0  0 10  0 30  0]
 [ 0  0 19  0 11  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 30  0]
 [ 0  0 19  0  1  0]]
Epoch: [2]
       [Avg Loss]          1.461570
       [Training]   Prec@1 42.666667 Max 42.666667
       [Avg Loss]          1.859308
       [Validation] Prec@1 25.555556 Max 33.333333
Confusion matrix:
[[ 0  3 14  1 22  0]
 [ 0  1 24  0  5  0]
 [ 0  0 29  0  1  0]
 [ 0  0 10  0 20  0]
 [ 0  0 14  0 16  0]
 [ 0  6 13  1  0  0]]
Epoch: [3]
       [Avg Loss]          1.366203
       [Training]   Prec@1 46.000000 Max 46.000000
       [Avg Loss]          1.542389
       [Validation] Prec@1 45.000000 Max 45.000000
Confusion matrix:
[[ 0 10  0  0 30  0]
 [ 0 28  0  0  2  0]
 [ 0  0 30  0  0  0]
 [ 0  1 15  0 14  0]
 [ 0  0  7  0 23  0]
 [ 0 20  0  0  0  0]]
Epoch: [4]
       [Avg Loss]          1.385433
       [Training]   Prec@1 45.166667 Max 46.000000
       [Avg Loss]          2.873023
       [Validation] Prec@1 16.666667 Max 45.000000
Confusion matrix:
[[ 0  0  0  0 40  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 20  0]]
Epoch: [5]
       [Avg Loss]          1.333796
       [Training]   Prec@1 44.833333 Max 46.000000
       [Avg Loss]          1.637776
       [Validation] Prec@1 30.000000 Max 45.000000
Confusion matrix:
[[ 0  9  0  3 28  0]
 [ 0 29  0  1  0  0]
 [ 0  2  0 13 15  0]
 [ 0  1  0  3 26  0]
 [ 0  1  0  7 22  0]
 [ 0 20  0  0  0  0]]
Epoch: [6]
       [Avg Loss]          1.306408
       [Training]   Prec@1 45.833333 Max 46.000000
       [Avg Loss]          2.211171
       [Validation] Prec@1 16.666667 Max 45.000000
Confusion matrix:
[[ 0 30  1  0  0  9]
 [ 0 16  0  0  0 14]
 [ 0 30  0  0  0  0]
 [ 0 30  0  0  0  0]
 [ 0 30  0  0  0  0]
 [ 0  6  0  0  0 14]]
Epoch: [7]
       [Avg Loss]          1.275932
       [Training]   Prec@1 49.000000 Max 49.000000
       [Avg Loss]          2.771384
       [Validation] Prec@1 17.222222 Max 45.000000
Confusion matrix:
[[ 0 31  0  0  0  9]
 [ 0 12  0  0  0 18]
 [ 0 30  0  0  0  0]
 [ 1 28  0  0  0  1]
 [ 0 30  0  0  0  0]
 [ 0  1  0  0  0 19]]
Epoch: [8]
       [Avg Loss]          1.265927
       [Training]   Prec@1 51.000000 Max 51.000000
       [Avg Loss]          1.924812
       [Validation] Prec@1 23.333333 Max 45.000000
Confusion matrix:
[[ 0  1 10 20  0  9]
 [ 3 20  0  0  0  7]
 [ 0 15  4 11  0  0]
 [ 0 16  6  7  1  0]
 [ 3  2  9 15  1  0]
 [ 0 10  0  0  0 10]]
Epoch: [9]
       [Avg Loss]          1.213361
       [Training]   Prec@1 53.000000 Max 53.000000
       [Avg Loss]          1.853587
       [Validation] Prec@1 20.000000 Max 45.000000
Confusion matrix:
[[ 4  7  1  5 13 10]
 [ 5 11  0  0  0 14]
 [ 0 21  0  9  0  0]
 [ 7 12  2  8  1  0]
 [ 4 15  1  9  1  0]
 [ 0  8  0  0  0 12]]
Epoch: [10]
       [Avg Loss]          1.268943
       [Training]   Prec@1 49.000000 Max 53.000000
       [Avg Loss]          1.963891
       [Validation] Prec@1 31.666667 Max 45.000000
Confusion matrix:
[[11  6  9  1 13  0]
 [ 5  8 17  0  0  0]
 [ 0  0 30  0  0  0]
 [ 4  0 16  0 10  0]
 [ 9  0 13  0  8  0]
 [ 0  8 12  0  0  0]]
Epoch: [11]
       [Avg Loss]          1.232734
       [Training]   Prec@1 49.666667 Max 53.000000
       [Avg Loss]          1.777270
       [Validation] Prec@1 35.000000 Max 45.000000
Confusion matrix:
[[ 0  2 22  7  0  9]
 [ 4 20  0  0  0  6]
 [ 0  3 26  1  0  0]
 [ 0 10 11  6  3  0]
 [ 0  9 13  6  2  0]
 [ 0 11  0  0  0  9]]
Epoch: [12]
       [Avg Loss]          1.197008
       [Training]   Prec@1 52.666667 Max 53.000000
       [Avg Loss]          1.756105
       [Validation] Prec@1 32.777778 Max 45.000000
Confusion matrix:
[[ 0  3 27  1  1  8]
 [ 5 21  0  0  0  4]
 [ 0  1 29  0  0  0]
 [ 2  6 18  0  4  0]
 [ 2  2 20  5  1  0]
 [ 0 12  0  0  0  8]]
Epoch: [13]
       [Avg Loss]          1.159537
       [Training]   Prec@1 52.000000 Max 53.000000
       [Avg Loss]          1.659322
       [Validation] Prec@1 40.555556 Max 45.000000
Confusion matrix:
[[ 0  0  0  1 30  9]
 [ 5 17  0  2  0  6]
 [ 0  0 16  0 14  0]
 [ 0  1  2  1 26  0]
 [ 0  0  0  0 30  0]
 [ 0 10  1  0  0  9]]
Epoch: [14]
       [Avg Loss]          1.165945
       [Training]   Prec@1 55.166667 Max 55.166667
       [Avg Loss]          2.076363
       [Validation] Prec@1 33.333333 Max 45.000000
Confusion matrix:
[[ 0  1  3  7 19 10]
 [ 5 18  0  1  0  6]
 [ 0  2 13 15  0  0]
 [ 0  5  9  9  7  0]
 [ 1  2  9  7 11  0]
 [ 0 11  0  0  0  9]]
Fold "0" complete, final accuracy: 45.0
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.707483
       [Training]   Prec@1 31.764706 Max 31.764706
       [Avg Loss]          1.697533
       [Validation] Prec@1 31.351351 Max 31.351351
Confusion matrix:
[[ 5  0 16  0  0  9]
 [ 0  0 20  0  0 15]
 [ 0  0 29  0  0  1]
 [ 4  0 23  0  0  3]
 [ 9  0 21  0  0  0]
 [ 0  0  6  0  0 24]]
Epoch: [1]
       [Avg Loss]          1.539059
       [Training]   Prec@1 40.000000 Max 40.000000
       [Avg Loss]          1.628467
       [Validation] Prec@1 24.324324 Max 31.351351
Confusion matrix:
[[ 6  9 10  0  5  0]
 [ 0  4 31  0  0  0]
 [ 5  0 25  0  0  0]
 [ 0  1 19  0 10  0]
 [ 9  0 11  0 10  0]
 [ 0 18 12  0  0  0]]
Epoch: [2]
       [Avg Loss]          1.486888
       [Training]   Prec@1 37.647059 Max 40.000000
       [Avg Loss]          1.572754
       [Validation] Prec@1 35.675676 Max 35.675676
Confusion matrix:
[[ 3  1  0  0 17  9]
 [ 0 20  0  0  0 15]
 [13  9  0  3  3  2]
 [ 6 11  1  0 10  2]
 [ 3  4  3  2 18  0]
 [ 0  3  0  2  0 25]]
Epoch: [3]
       [Avg Loss]          1.427266
       [Training]   Prec@1 43.193277 Max 43.193277
       [Avg Loss]          1.574618
       [Validation] Prec@1 36.216216 Max 36.216216
Confusion matrix:
[[ 0  9  4  1 16  0]
 [ 0 15  3 17  0  0]
 [ 0  1 25  2  2  0]
 [ 0  2 11  6 11  0]
 [ 0  0  7  2 21  0]
 [ 0 18  4  8  0  0]]
Epoch: [4]
       [Avg Loss]          1.387967
       [Training]   Prec@1 46.050420 Max 46.050420
       [Avg Loss]          1.646301
       [Validation] Prec@1 38.378378 Max 38.378378
Confusion matrix:
[[ 0  8  6  1 14  1]
 [ 0 14 12  9  0  0]
 [ 0  1 27  0  2  0]
 [ 0  1 16  3 10  0]
 [ 0  0  9  0 21  0]
 [ 0 15  4  5  0  6]]
Epoch: [5]
       [Avg Loss]          1.312418
       [Training]   Prec@1 46.050420 Max 46.050420
       [Avg Loss]          1.466789
       [Validation] Prec@1 42.702703 Max 42.702703
Confusion matrix:
[[ 0  1 12  0  8  9]
 [ 0 15  2  4  0 14]
 [ 0  1 21  7  0  1]
 [ 0  5  9  4 10  2]
 [ 0  0 12  3 15  0]
 [ 0  4  1  1  0 24]]
Epoch: [6]
       [Avg Loss]          1.312619
       [Training]   Prec@1 47.058824 Max 47.058824
       [Avg Loss]          1.464124
       [Validation] Prec@1 47.567568 Max 47.567568
Confusion matrix:
[[ 5  1  9  0  6  9]
 [ 0 27  1  2  0  5]
 [ 0  3 24  3  0  0]
 [ 7  6 10  3  3  1]
 [ 6  1  9  4 10  0]
 [ 0  7  1  3  0 19]]
Epoch: [7]
       [Avg Loss]          1.290597
       [Training]   Prec@1 50.756303 Max 50.756303
       [Avg Loss]          1.692625
       [Validation] Prec@1 36.756757 Max 47.567568
Confusion matrix:
[[ 0  6 15  0  5  4]
 [ 0 29  0  6  0  0]
 [ 0  3 12 15  0  0]
 [ 0  7 16  7  0  0]
 [ 0  0 14  8  8  0]
 [ 0 16  0  2  0 12]]
Epoch: [8]
       [Avg Loss]          1.317293
       [Training]   Prec@1 48.571429 Max 50.756303
       [Avg Loss]          1.533290
       [Validation] Prec@1 40.540541 Max 47.567568
Confusion matrix:
[[ 2  0  0  0 18 10]
 [ 0 14  0  2  0 19]
 [ 0  2 15  7  5  1]
 [ 0  8  5  3 12  2]
 [ 2  2  1  6 19  0]
 [ 0  6  1  1  0 22]]
Epoch: [9]
       [Avg Loss]          1.261375
       [Training]   Prec@1 50.924370 Max 50.924370
       [Avg Loss]          1.439286
       [Validation] Prec@1 44.324324 Max 47.567568
Confusion matrix:
[[12  5  8  0  0  5]
 [ 0 18  3 14  0  0]
 [ 0  2 26  2  0  0]
 [ 8  1 13  6  2  0]
 [13  0  8  3  6  0]
 [ 0 12  1  3  0 14]]
Epoch: [10]
       [Avg Loss]          1.268882
       [Training]   Prec@1 49.915966 Max 50.924370
       [Avg Loss]          1.566893
       [Validation] Prec@1 42.162162 Max 47.567568
Confusion matrix:
[[ 0  5 15  0  5  5]
 [ 0 32  0  3  0  0]
 [ 0  3 16 11  0  0]
 [ 0  9 10  6  5  0]
 [ 0  2 11  7 10  0]
 [ 0 14  0  2  0 14]]
Epoch: [11]
       [Avg Loss]          1.289283
       [Training]   Prec@1 49.075630 Max 50.924370
       [Avg Loss]          1.460092
       [Validation] Prec@1 41.081081 Max 47.567568
Confusion matrix:
[[ 0  5 15  0  5  5]
 [ 0 32  1  2  0  0]
 [ 0  3 21  6  0  0]
 [ 3  8 13  2  4  0]
 [ 4  1 11  7  7  0]
 [ 0 14  1  1  0 14]]
Epoch: [12]
       [Avg Loss]          1.229329
       [Training]   Prec@1 51.428571 Max 51.428571
       [Avg Loss]          1.392843
       [Validation] Prec@1 47.567568 Max 47.567568
Confusion matrix:
[[19  3  0  0  1  7]
 [ 0 22  2  3  0  8]
 [ 1  2 20  2  5  0]
 [10  6  8  3  2  1]
 [16  0  1  7  6  0]
 [ 0  9  2  1  0 18]]
Epoch: [13]
       [Avg Loss]          1.201365
       [Training]   Prec@1 54.789916 Max 54.789916
       [Avg Loss]          1.370410
       [Validation] Prec@1 48.108108 Max 48.108108
Confusion matrix:
[[ 4  0  0  0 16 10]
 [ 0 24  1  4  0  6]
 [ 0  1 21  2  5  1]
 [ 0  6  9  4 10  1]
 [ 4  0  3  6 17  0]
 [ 0  7  1  3  0 19]]
Epoch: [14]
       [Avg Loss]          1.169748
       [Training]   Prec@1 56.134454 Max 56.134454
       [Avg Loss]          1.377703
       [Validation] Prec@1 45.405405 Max 48.108108
Confusion matrix:
[[10  5  4  1  1  9]
 [ 0 25  0  4  0  6]
 [ 0  2 20  7  0  1]
 [ 5  8  6  4  5  2]
 [13  2  2  8  5  0]
 [ 0  8  0  2  0 20]]
Fold "1" complete, final accuracy: 48.108108108108105
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.735347
       [Training]   Prec@1 30.588235 Max 30.588235
       [Avg Loss]          1.707959
       [Validation] Prec@1 31.891892 Max 31.891892
Confusion matrix:
[[ 0  3 16  0 11  0]
 [ 0  9 26  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 10  0 20  0]
 [ 0 29  1  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.570696
       [Training]   Prec@1 35.798319 Max 35.798319
       [Avg Loss]          1.608325
       [Validation] Prec@1 23.783784 Max 31.891892
Confusion matrix:
[[ 0  2 11  0 17  0]
 [ 0 10 23  0  2  0]
 [ 0  0  4  0 26  0]
 [ 0  0 20  0 10  0]
 [ 0  0  0  0 30  0]
 [ 0 29  1  0  0  0]]
Epoch: [2]
       [Avg Loss]          1.469353
       [Training]   Prec@1 40.840336 Max 40.840336
       [Avg Loss]          1.386525
       [Validation] Prec@1 52.432432 Max 52.432432
Confusion matrix:
[[ 0  6 10  0 14  0]
 [ 0 26  5  0  0  4]
 [ 0  0 21  0  9  0]
 [ 0 10 11  0  9  0]
 [ 0  0  0  0 30  0]
 [ 0 10  0  0  0 20]]
Epoch: [3]
       [Avg Loss]          1.419132
       [Training]   Prec@1 44.873950 Max 44.873950
       [Avg Loss]          1.460980
       [Validation] Prec@1 43.243243 Max 52.432432
Confusion matrix:
[[ 0 23  2  0  3  2]
 [ 0 23  0  0  0 12]
 [ 0 26  4  0  0  0]
 [ 0 22  6  1  1  0]
 [ 0  7  0  0 23  0]
 [ 0  1  0  0  0 29]]
Epoch: [4]
       [Avg Loss]          1.499503
       [Training]   Prec@1 42.857143 Max 44.873950
       [Avg Loss]          1.429251
       [Validation] Prec@1 37.837838 Max 52.432432
Confusion matrix:
[[ 3  6  7  3 11  0]
 [ 0 31  4  0  0  0]
 [ 0  0 24  0  6  0]
 [ 4  7 14  0  5  0]
 [18  0  0  0 12  0]
 [ 0 30  0  0  0  0]]
Epoch: [5]
       [Avg Loss]          1.433265
       [Training]   Prec@1 44.705882 Max 44.873950
       [Avg Loss]          1.422463
       [Validation] Prec@1 34.594595 Max 52.432432
Confusion matrix:
[[ 4  5  8  0 13  0]
 [ 0 22  7  0  2  4]
 [ 2  0 10  0 18  0]
 [ 6  3 18  0  3  0]
 [25  0  0  0  5  0]
 [ 0  7  0  0  0 23]]
Epoch: [6]
       [Avg Loss]          1.363872
       [Training]   Prec@1 48.403361 Max 48.403361
       [Avg Loss]          1.527356
       [Validation] Prec@1 33.513514 Max 52.432432
Confusion matrix:
[[ 2  7 11  7  3  0]
 [ 0 25  6  4  0  0]
 [ 0  0 28  0  2  0]
 [ 4  5 19  0  2  0]
 [17  0  0  6  7  0]
 [ 0 30  0  0  0  0]]
Epoch: [7]
       [Avg Loss]          1.441091
       [Training]   Prec@1 43.697479 Max 48.403361
       [Avg Loss]          1.572512
       [Validation] Prec@1 41.081081 Max 52.432432
Confusion matrix:
[[ 0 16  9  2  2  1]
 [ 0 22  2  0  0 11]
 [ 0  5 25  0  0  0]
 [ 0 20 10  0  0  0]
 [ 0  1 22  2  5  0]
 [ 0  6  0  0  0 24]]
Epoch: [8]
       [Avg Loss]          1.364113
       [Training]   Prec@1 45.546218 Max 48.403361
       [Avg Loss]          1.493890
       [Validation] Prec@1 39.459459 Max 52.432432
Confusion matrix:
[[ 0  4  6  7 12  1]
 [ 0 13  6  2  3 11]
 [ 0  0  4  0 26  0]
 [ 0  4 12  0 14  0]
 [ 0  0  0  0 30  0]
 [ 0  4  0  0  0 26]]
Epoch: [9]
       [Avg Loss]          1.309650
       [Training]   Prec@1 48.403361 Max 48.403361
       [Avg Loss]          1.515202
       [Validation] Prec@1 47.027027 Max 52.432432
Confusion matrix:
[[ 0  9  8  6  7  0]
 [ 0 31  4  0  0  0]
 [ 0  0 29  0  1  0]
 [ 4 14  9  2  1  0]
 [16  0  0  0 14  0]
 [ 0 19  0  0  0 11]]
Epoch: [10]
       [Avg Loss]          1.353367
       [Training]   Prec@1 45.714286 Max 48.403361
       [Avg Loss]          1.639025
       [Validation] Prec@1 43.783784 Max 52.432432
Confusion matrix:
[[ 1  6  6 10  7  0]
 [ 0 28  4  1  0  2]
 [ 1  0 18  0 11  0]
 [ 6  8  6  5  5  0]
 [16  0  0  1 13  0]
 [ 0 14  0  0  0 16]]
Epoch: [11]
       [Avg Loss]          1.259371
       [Training]   Prec@1 52.100840 Max 52.100840
       [Avg Loss]          1.496884
       [Validation] Prec@1 46.486486 Max 52.432432
Confusion matrix:
[[ 0 16  2  6  5  1]
 [ 0 20  3  0  0 12]
 [ 0  1 26  2  1  0]
 [ 2 18  6  0  3  1]
 [14  0  0  0 16  0]
 [ 2  4  0  0  0 24]]
Epoch: [12]
       [Avg Loss]          1.324313
       [Training]   Prec@1 47.731092 Max 52.100840
       [Avg Loss]          1.401463
       [Validation] Prec@1 49.729730 Max 52.432432
Confusion matrix:
[[ 1  4  7 10  7  1]
 [ 1 18  4  1  0 11]
 [ 0  0 27  0  3  0]
 [ 2  8 12  5  2  1]
 [12  0  0  1 17  0]
 [ 4  2  0  0  0 24]]
Epoch: [13]
       [Avg Loss]          1.259412
       [Training]   Prec@1 48.403361 Max 52.100840
       [Avg Loss]          1.503592
       [Validation] Prec@1 42.162162 Max 52.432432
Confusion matrix:
[[ 2  5  7 10  6  0]
 [ 0 22  6  2  0  5]
 [ 2  0 24  0  4  0]
 [ 4  3 19  2  2  0]
 [18  0  0  2 10  0]
 [ 0 12  0  0  0 18]]
Epoch: [14]
       [Avg Loss]          1.199219
       [Training]   Prec@1 53.445378 Max 53.445378
       [Avg Loss]          1.483904
       [Validation] Prec@1 52.972973 Max 52.972973
Confusion matrix:
[[ 0 12  6  4  8  0]
 [ 0 29  3  0  0  3]
 [ 0  0 26  0  4  0]
 [ 2 16  6  2  4  0]
 [ 7  0  0  0 23  0]
 [ 0 12  0  0  0 18]]
Fold "2" complete, final accuracy: 52.972972972972975
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.670583
       [Training]   Prec@1 33.939394 Max 33.939394
       [Avg Loss]          1.635687
       [Validation] Prec@1 30.000000 Max 30.000000
Confusion matrix:
[[ 0  0  9 11  0  0]
 [ 0 15  0  3  0  2]
 [ 0  1 12  7  0  0]
 [ 0  2  9  9  0  0]
 [ 0  0  6 14  0  0]
 [ 0 19  0  1  0  0]]
Epoch: [1]
       [Avg Loss]          1.504393
       [Training]   Prec@1 41.666667 Max 41.666667
       [Avg Loss]          1.341749
       [Validation] Prec@1 40.833333 Max 40.833333
Confusion matrix:
[[ 0  0  0  0 20  0]
 [ 0  6  0  0  0 14]
 [ 0  2  0 15  3  0]
 [ 0  3  0  7  9  1]
 [ 0  0  0  1 19  0]
 [ 0  2  0  1  0 17]]
Epoch: [2]
       [Avg Loss]          1.481475
       [Training]   Prec@1 42.121212 Max 42.121212
       [Avg Loss]          1.585475
       [Validation] Prec@1 25.833333 Max 40.833333
Confusion matrix:
[[ 0  0 20  0  0  0]
 [ 0  8  4  8  0  0]
 [ 0  0 20  0  0  0]
 [ 0  0 19  1  0  0]
 [ 0  0 20  0  0  0]
 [ 0 13  3  2  0  2]]
Epoch: [3]
       [Avg Loss]          1.550811
       [Training]   Prec@1 42.727273 Max 42.727273
       [Avg Loss]          1.449128
       [Validation] Prec@1 30.833333 Max 40.833333
Confusion matrix:
[[ 0  0 20  0  0  0]
 [ 0 14  4  0  0  2]
 [ 0  0 20  0  0  0]
 [ 0  2 17  1  0  0]
 [ 0  0 20  0  0  0]
 [ 0 17  1  0  0  2]]
Epoch: [4]
       [Avg Loss]          1.439309
       [Training]   Prec@1 42.575758 Max 42.727273
       [Avg Loss]          1.896889
       [Validation] Prec@1 21.666667 Max 40.833333
Confusion matrix:
[[ 0 13  7  0  0  0]
 [ 0 14  0  0  0  6]
 [ 0 20  0  0  0  0]
 [ 0 17  3  0  0  0]
 [ 0 18  2  0  0  0]
 [ 0  8  0  0  0 12]]
Epoch: [5]
       [Avg Loss]          1.427488
       [Training]   Prec@1 42.424242 Max 42.727273
       [Avg Loss]          1.176305
       [Validation] Prec@1 46.666667 Max 46.666667
Confusion matrix:
[[ 0  0  0  0 20  0]
 [ 0 17  0  1  0  2]
 [ 1  1  7  9  2  0]
 [ 0  5  1  3 11  0]
 [ 1  0  1  1 17  0]
 [ 0  8  0  0  0 12]]
Epoch: [6]
       [Avg Loss]          1.369204
       [Training]   Prec@1 48.181818 Max 48.181818
       [Avg Loss]          1.491946
       [Validation] Prec@1 36.666667 Max 46.666667
Confusion matrix:
[[ 0  0  0  0 20  0]
 [ 0 13  4  0  0  3]
 [ 0  0  2  0 18  0]
 [ 0  1  4  1 14  0]
 [ 0  0  0  0 20  0]
 [ 0 11  1  0  0  8]]
Epoch: [7]
       [Avg Loss]          1.348059
       [Training]   Prec@1 47.121212 Max 48.181818
       [Avg Loss]          1.633794
       [Validation] Prec@1 25.000000 Max 46.666667
Confusion matrix:
[[ 0  1  5 13  1  0]
 [ 0 20  0  0  0  0]
 [ 0 10  1  9  0  0]
 [ 0  7  4  9  0  0]
 [ 0  6  7  7  0  0]
 [ 0 20  0  0  0  0]]
Epoch: [8]
       [Avg Loss]          1.321907
       [Training]   Prec@1 49.848485 Max 49.848485
       [Avg Loss]          1.513937
       [Validation] Prec@1 40.000000 Max 46.666667
Confusion matrix:
[[ 0  0  0  0 20  0]
 [ 0 17  0  3  0  0]
 [ 0  0  0  2 18  0]
 [ 0  2  1  2 15  0]
 [ 0  0  0  0 20  0]
 [ 0 11  0  0  0  9]]
Epoch: [9]
       [Avg Loss]          1.375259
       [Training]   Prec@1 46.818182 Max 49.848485
       [Avg Loss]          1.300816
       [Validation] Prec@1 40.000000 Max 46.666667
Confusion matrix:
[[ 0  0 10  2  8  0]
 [ 0 15  0  1  0  4]
 [ 0  1 15  4  0  0]
 [ 0  4 13  3  0  0]
 [ 0  0 10  6  4  0]
 [ 0  9  0  0  0 11]]
Epoch: [10]
       [Avg Loss]          1.333793
       [Training]   Prec@1 49.393939 Max 49.848485
       [Avg Loss]          1.837275
       [Validation] Prec@1 28.333333 Max 46.666667
Confusion matrix:
[[ 0  5  6  9  0  0]
 [ 0  6  0  0  0 14]
 [ 0 13  0  7  0  0]
 [ 0  6  3  9  0  2]
 [ 0  9  2  9  0  0]
 [ 0  1  0  0  0 19]]
Epoch: [11]
       [Avg Loss]          1.329985
       [Training]   Prec@1 48.939394 Max 49.848485
       [Avg Loss]          1.381553
       [Validation] Prec@1 35.000000 Max 46.666667
Confusion matrix:
[[ 0  0  7  7  6  0]
 [ 0 10  0  0  0 10]
 [ 0  3 10  7  0  0]
 [ 0  4 11  4  0  1]
 [ 0  1 10  6  3  0]
 [ 0  5  0  0  0 15]]
Epoch: [12]
       [Avg Loss]          1.328193
       [Training]   Prec@1 48.484848 Max 49.848485
       [Avg Loss]          1.170067
       [Validation] Prec@1 42.500000 Max 46.666667
Confusion matrix:
[[ 1  0  0  0 19  0]
 [ 0 10  0  3  0  7]
 [ 0  1  7  5  7  0]
 [ 0  2  5  2 11  0]
 [ 2  0  0  0 18  0]
 [ 0  7  0  0  0 13]]
Epoch: [13]
       [Avg Loss]          1.318362
       [Training]   Prec@1 49.242424 Max 49.848485
       [Avg Loss]          1.407110
       [Validation] Prec@1 35.000000 Max 46.666667
Confusion matrix:
[[ 0  0 14  6  0  0]
 [ 0 18  0  1  0  1]
 [ 0  1  7 12  0  0]
 [ 0  4 10  6  0  0]
 [ 0  0 10 10  0  0]
 [ 0  9  0  0  0 11]]
Epoch: [14]
       [Avg Loss]          1.250985
       [Training]   Prec@1 50.000000 Max 50.000000
       [Avg Loss]          1.154300
       [Validation] Prec@1 49.166667 Max 49.166667
Confusion matrix:
[[ 5  0  0  0 15  0]
 [ 0 15  0  1  0  4]
 [ 0  2 14  4  0  0]
 [ 4  4  7  4  1  0]
 [ 4  0  6  2  8  0]
 [ 0  7  0  0  0 13]]
Fold "3" complete, final accuracy: 49.166666666666664
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.641310
       [Training]   Prec@1 32.388060 Max 32.388060
       [Avg Loss]          1.689353
       [Validation] Prec@1 20.000000 Max 20.000000
Confusion matrix:
[[12  3  4  0  0  1]
 [ 5  2  7  0  6  0]
 [11  1  1  0  7  0]
 [ 0  5 15  0  0  0]
 [ 5  0  0  0  5  0]
 [ 0 17  1  0  0  2]]
Epoch: [1]
       [Avg Loss]          1.541000
       [Training]   Prec@1 37.313433 Max 37.313433
       [Avg Loss]          1.710046
       [Validation] Prec@1 22.727273 Max 22.727273
Confusion matrix:
[[ 0  3 12  0  5  0]
 [ 0  1 15  0  4  0]
 [ 0  1 19  0  0  0]
 [ 0  5 15  0  0  0]
 [ 0  0  5  0  5  0]
 [ 0 14  6  0  0  0]]
Epoch: [2]
       [Avg Loss]          1.485525
       [Training]   Prec@1 40.149254 Max 40.149254
       [Avg Loss]          1.850087
       [Validation] Prec@1 17.272727 Max 22.727273
Confusion matrix:
[[ 0  3  5  0 12  0]
 [ 0  1 10  0  9  0]
 [ 0  1  8  0 11  0]
 [ 0  5 15  0  0  0]
 [ 0  0  0  0 10  0]
 [ 0 16  4  0  0  0]]
Epoch: [3]
       [Avg Loss]          1.366211
       [Training]   Prec@1 44.328358 Max 44.328358
       [Avg Loss]          1.882347
       [Validation] Prec@1 17.272727 Max 22.727273
Confusion matrix:
[[ 0  3  5  0 12  0]
 [ 0  4  7  0  9  0]
 [ 0  1  5  1 13  0]
 [ 0  5 15  0  0  0]
 [ 0  0  0  0 10  0]
 [ 0 18  2  0  0  0]]
Epoch: [4]
       [Avg Loss]          1.354949
       [Training]   Prec@1 45.820896 Max 45.820896
       [Avg Loss]          1.747516
       [Validation] Prec@1 24.545455 Max 24.545455
Confusion matrix:
[[ 0  6  2  0 12  0]
 [ 0  9  3  0  8  0]
 [ 0  1  8  0 11  0]
 [ 0 13  7  0  0  0]
 [ 0  0  0  0 10  0]
 [ 0 20  0  0  0  0]]
Epoch: [5]
       [Avg Loss]          1.333849
       [Training]   Prec@1 46.268657 Max 46.268657
       [Avg Loss]          2.088855
       [Validation] Prec@1 19.090909 Max 24.545455
Confusion matrix:
[[ 0  4  4  0 12  0]
 [ 0  4  6  0 10  0]
 [ 0  1  3  0 16  0]
 [ 0  5 14  0  1  0]
 [ 0  0  0  0 10  0]
 [ 0 15  1  0  0  4]]
Epoch: [6]
       [Avg Loss]          1.339150
       [Training]   Prec@1 46.716418 Max 46.716418
       [Avg Loss]          2.142200
       [Validation] Prec@1 30.909091 Max 30.909091
Confusion matrix:
[[ 0 18  0  0  0  2]
 [ 0 20  0  0  0  0]
 [ 0 20  0  0  0  0]
 [ 0 17  0  0  0  3]
 [ 0 10  0  0  0  0]
 [ 0  6  0  0  0 14]]
Epoch: [7]
       [Avg Loss]          1.367898
       [Training]   Prec@1 43.134328 Max 46.716418
       [Avg Loss]          1.953856
       [Validation] Prec@1 25.454545 Max 30.909091
Confusion matrix:
[[ 0  5  3  0 12  0]
 [ 1  6  3  0 10  0]
 [ 0  1  0  1 18  0]
 [ 0  5 11  2  2  0]
 [ 0  0  0  0 10  0]
 [ 0 10  0  0  0 10]]
Epoch: [8]
       [Avg Loss]          1.237751
       [Training]   Prec@1 49.253731 Max 49.253731
       [Avg Loss]          1.933427
       [Validation] Prec@1 48.181818 Max 48.181818
Confusion matrix:
[[ 9  5  2  0  3  1]
 [ 4  7  3  0  6  0]
 [ 3  1 12  0  4  0]
 [ 0 13  3  2  0  2]
 [ 1  0  0  0  9  0]
 [ 0  6  0  0  0 14]]
Epoch: [9]
       [Avg Loss]          1.207171
       [Training]   Prec@1 50.000000 Max 50.000000
       [Avg Loss]          1.860736
       [Validation] Prec@1 41.818182 Max 48.181818
Confusion matrix:
[[11  3  3  0  1  2]
 [ 9  5  4  0  1  1]
 [ 7  1  9  0  3  0]
 [ 0  4 11  2  0  3]
 [ 5  0  0  0  5  0]
 [ 0  6  0  0  0 14]]
Epoch: [10]
       [Avg Loss]          1.229962
       [Training]   Prec@1 49.402985 Max 50.000000
       [Avg Loss]          1.679709
       [Validation] Prec@1 46.363636 Max 48.181818
Confusion matrix:
[[ 5  5  2  0  7  1]
 [ 6  7  3  1  3  0]
 [ 2  1 16  0  1  0]
 [ 0  7 10  1  0  2]
 [ 2  0  0  0  8  0]
 [ 0  6  0  0  0 14]]
Epoch: [11]
       [Avg Loss]          1.179957
       [Training]   Prec@1 50.597015 Max 50.597015
       [Avg Loss]          2.323334
       [Validation] Prec@1 33.636364 Max 48.181818
Confusion matrix:
[[10  4  3  0  3  0]
 [ 7  6  4  0  3  0]
 [ 3  1  5  0 11  0]
 [ 1  7 12  0  0  0]
 [ 2  0  0  0  8  0]
 [ 0 11  1  0  0  8]]
Epoch: [12]
       [Avg Loss]          1.214137
       [Training]   Prec@1 48.358209 Max 50.597015
       [Avg Loss]          1.523193
       [Validation] Prec@1 47.272727 Max 48.181818
Confusion matrix:
[[ 3  5  5  1  5  1]
 [ 1  8  2  3  6  0]
 [ 0  1 18  1  0  0]
 [ 0 12  5  1  0  2]
 [ 0  0  0  2  8  0]
 [ 0  6  0  0  0 14]]
Epoch: [13]
       [Avg Loss]          1.188950
       [Training]   Prec@1 52.388060 Max 52.388060
       [Avg Loss]          1.639596
       [Validation] Prec@1 47.272727 Max 48.181818
Confusion matrix:
[[ 3  6  1  0  8  2]
 [ 3  9  1  0  5  2]
 [ 0  1 12  1  5  1]
 [ 0 15  0  1  0  4]
 [ 0  0  0  0 10  0]
 [ 0  3  0  0  0 17]]
Epoch: [14]
       [Avg Loss]          1.171326
       [Training]   Prec@1 51.940299 Max 52.388060
       [Avg Loss]          1.808338
       [Validation] Prec@1 42.727273 Max 48.181818
Confusion matrix:
[[ 4  4  2  0  8  2]
 [ 8  6  1  0  4  1]
 [ 1  1 10  0  8  0]
 [ 4  6  4  3  0  3]
 [ 0  0  0  0 10  0]
 [ 0  6  0  0  0 14]]
Fold "4" complete, final accuracy: 48.18181818181818

-----------------------------------------------------------------------
Training for stage 16 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=2)")
Average accuracy is: 48.68591318591318


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 1-----
Evaluated preprocessing: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=18)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.346112
       [Training]   Prec@1 44.833333 Max 44.833333
       [Avg Loss]          1.537106
       [Validation] Prec@1 59.444444 Max 59.444444
Confusion matrix:
[[26  1  2  0  2  9]
 [ 0 27  0  1  1  1]
 [ 2  4 21  0  3  0]
 [ 1  4 15  0 10  0]
 [ 1  0  7  0 22  0]
 [ 9  0  0  0  0 11]]
Epoch: [1]
       [Avg Loss]          0.830555
       [Training]   Prec@1 71.500000 Max 71.500000
       [Avg Loss]          1.145406
       [Validation] Prec@1 63.333333 Max 63.333333
Confusion matrix:
[[29  0  0  0  1 10]
 [ 0 27  0  1  0  2]
 [ 9  8 12  0  1  0]
 [ 9 15  1  0  5  0]
 [ 4  0  0  0 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          0.700164
       [Training]   Prec@1 73.833333 Max 73.833333
       [Avg Loss]          1.589492
       [Validation] Prec@1 56.666667 Max 63.333333
Confusion matrix:
[[22  0  8  0  0 10]
 [ 0 18  0  0  0 12]
 [ 0  1 29  0  0  0]
 [ 1  5 19  4  1  0]
 [ 1  0 20  0  9  0]
 [ 0  0  0  0  0 20]]
Epoch: [3]
       [Avg Loss]          0.485645
       [Training]   Prec@1 83.500000 Max 83.500000
       [Avg Loss]          1.739747
       [Validation] Prec@1 62.777778 Max 63.333333
Confusion matrix:
[[11  0  7  6  6 10]
 [ 0 30  0  0  0  0]
 [ 0  1 25  0  4  0]
 [ 0  9  3  0 18  0]
 [ 0  0  3  0 27  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          0.422969
       [Training]   Prec@1 85.666667 Max 85.666667
       [Avg Loss]          1.547199
       [Validation] Prec@1 65.555556 Max 65.555556
Confusion matrix:
[[23  0  6  1  0 10]
 [ 0 22  2  6  0  0]
 [ 0  0 29  1  0  0]
 [ 0  0 24  0  6  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  1  0 19]]
Epoch: [5]
       [Avg Loss]          0.396798
       [Training]   Prec@1 87.833333 Max 87.833333
       [Avg Loss]          1.352121
       [Validation] Prec@1 66.666667 Max 66.666667
Confusion matrix:
[[18  0 12  0  0 10]
 [ 0 27  0  3  0  0]
 [ 0  0 28  2  0  0]
 [ 0  5 14  3  8  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  1  0 19]]
Epoch: [6]
       [Avg Loss]          0.313288
       [Training]   Prec@1 90.833333 Max 90.833333
       [Avg Loss]          1.492581
       [Validation] Prec@1 67.222222 Max 67.222222
Confusion matrix:
[[22  0  7  1  0 10]
 [ 0 26  0  4  0  0]
 [ 0  0 29  1  0  0]
 [ 0  4 20  1  5  0]
 [ 1  3  1  0 25  0]
 [ 0  0  1  1  0 18]]
Epoch: [7]
       [Avg Loss]          0.260503
       [Training]   Prec@1 92.166667 Max 92.166667
       [Avg Loss]          1.723657
       [Validation] Prec@1 69.444444 Max 69.444444
Confusion matrix:
[[22  0  7  1  0 10]
 [ 0 29  0  1  0  0]
 [ 0  0 29  1  0  0]
 [ 0  3 17  1  9  0]
 [ 0  0  5  0 25  0]
 [ 0  0  1  0  0 19]]
Epoch: [8]
       [Avg Loss]          0.246882
       [Training]   Prec@1 92.333333 Max 92.333333
       [Avg Loss]          1.179628
       [Validation] Prec@1 74.444444 Max 74.444444
Confusion matrix:
[[24  0  5  1  0 10]
 [ 0 27  0  0  0  3]
 [ 0  0 27  3  0  0]
 [ 1  2 11 12  1  3]
 [ 0  2  3  0 25  0]
 [ 0  0  1  0  0 19]]
Epoch: [9]
       [Avg Loss]          0.247849
       [Training]   Prec@1 92.000000 Max 92.333333
       [Avg Loss]          1.582959
       [Validation] Prec@1 67.777778 Max 74.444444
Confusion matrix:
[[18  0  9  3  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 29  1  0  0]
 [ 0  3 22  2  3  0]
 [ 1  3  3  0 23  0]
 [ 0  0  0  0  0 20]]
Epoch: [10]
       [Avg Loss]          0.322951
       [Training]   Prec@1 89.666667 Max 92.333333
       [Avg Loss]          1.844644
       [Validation] Prec@1 65.000000 Max 74.444444
Confusion matrix:
[[16  0 14  0  0 10]
 [ 0 27  0  0  0  3]
 [ 0  0 29  0  1  0]
 [ 0  3 14  0 13  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [11]
       [Avg Loss]          0.278811
       [Training]   Prec@1 91.333333 Max 92.333333
       [Avg Loss]          1.227134
       [Validation] Prec@1 68.888889 Max 74.444444
Confusion matrix:
[[20  0  9  1  0 10]
 [ 0 29  0  1  0  0]
 [ 0  2 27  1  0  0]
 [ 0  4 20  4  2  0]
 [ 0  3  2  0 25  0]
 [ 0  0  0  1  0 19]]
Epoch: [12]
       [Avg Loss]          0.248416
       [Training]   Prec@1 91.833333 Max 92.333333
       [Avg Loss]          1.459630
       [Validation] Prec@1 63.333333 Max 74.444444
Confusion matrix:
[[13  0 10  2  5 10]
 [ 0 27  0  3  0  0]
 [ 0  0 29  1  0  0]
 [ 0  0 21  0  9  0]
 [ 0  0  4  0 26  0]
 [ 0  0  0  1  0 19]]
Epoch: [13]
       [Avg Loss]          0.245679
       [Training]   Prec@1 91.333333 Max 92.333333
       [Avg Loss]          1.634305
       [Validation] Prec@1 66.111111 Max 74.444444
Confusion matrix:
[[20  2  7  1  0 10]
 [ 0 27  0  0  0  3]
 [ 0  2 26  2  0  0]
 [ 0 11  2  1 16  0]
 [ 1  4  0  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [14]
       [Avg Loss]          0.233908
       [Training]   Prec@1 92.833333 Max 92.833333
       [Avg Loss]          1.613611
       [Validation] Prec@1 71.111111 Max 74.444444
Confusion matrix:
[[18  1 10  1  0 10]
 [ 0 29  0  1  0  0]
 [ 0  0 29  1  0  0]
 [ 0  3 20  7  0  0]
 [ 0  1  4  0 25  0]
 [ 0  0  0  0  0 20]]
Fold "0" complete, final accuracy: 74.44444444444444
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.600911
       [Training]   Prec@1 35.126050 Max 35.126050
       [Avg Loss]          1.572760
       [Validation] Prec@1 47.027027 Max 47.027027
Confusion matrix:
[[13 13  0  2  1  1]
 [ 0 35  0  0  0  0]
 [ 0 20  0  0 10  0]
 [ 1 10  0 10  9  0]
 [ 0  5  0 11 14  0]
 [ 4  3  0  8  0 15]]
Epoch: [1]
       [Avg Loss]          0.939279
       [Training]   Prec@1 67.563025 Max 67.563025
       [Avg Loss]          1.032432
       [Validation] Prec@1 64.324324 Max 64.324324
Confusion matrix:
[[26  2  0  0  0  2]
 [ 4 29  2  0  0  0]
 [12  3 14  0  1  0]
 [16  2  1  9  1  1]
 [15  0  0  0 15  0]
 [ 3  1  0  0  0 26]]
Epoch: [2]
       [Avg Loss]          0.627168
       [Training]   Prec@1 79.495798 Max 79.495798
       [Avg Loss]          0.844325
       [Validation] Prec@1 76.756757 Max 76.756757
Confusion matrix:
[[23  5  0  0  0  2]
 [ 0 35  0  0  0  0]
 [ 0  8 22  0  0  0]
 [ 8  1  3 11  6  1]
 [ 2  3  0  0 25  0]
 [ 2  2  0  0  0 26]]
Epoch: [3]
       [Avg Loss]          0.549179
       [Training]   Prec@1 81.680672 Max 81.680672
       [Avg Loss]          0.964995
       [Validation] Prec@1 77.297297 Max 77.297297
Confusion matrix:
[[24  2  0  0  0  4]
 [ 1 32  1  0  0  1]
 [ 1  5 24  0  0  0]
 [ 6  0  2 13  8  1]
 [ 2  2  0  0 26  0]
 [ 2  1  0  3  0 24]]
Epoch: [4]
       [Avg Loss]          0.481065
       [Training]   Prec@1 86.386555 Max 86.386555
       [Avg Loss]          0.938369
       [Validation] Prec@1 72.972973 Max 77.297297
Confusion matrix:
[[23  3  1  2  0  1]
 [ 2 25  8  0  0  0]
 [ 1  2 26  1  0  0]
 [10  0  3 15  2  0]
 [ 4  0  0  4 22  0]
 [ 2  3  0  1  0 24]]
Epoch: [5]
       [Avg Loss]          0.463530
       [Training]   Prec@1 85.378151 Max 86.386555
       [Avg Loss]          0.864613
       [Validation] Prec@1 74.594595 Max 77.297297
Confusion matrix:
[[24  5  1  0  0  0]
 [ 0 33  1  1  0  0]
 [ 1  4 25  0  0  0]
 [ 6  1  3 12  8  0]
 [ 1  4  0  0 25  0]
 [ 3  2  0  4  2 19]]
Epoch: [6]
       [Avg Loss]          0.434076
       [Training]   Prec@1 85.714286 Max 86.386555
       [Avg Loss]          0.803766
       [Validation] Prec@1 77.297297 Max 77.297297
Confusion matrix:
[[28  0  0  1  1  0]
 [10 25  0  0  0  0]
 [ 3  2 25  0  0  0]
 [ 7  0  3 13  7  0]
 [ 2  0  0  1 27  0]
 [ 3  1  0  1  0 25]]
Epoch: [7]
       [Avg Loss]          0.403864
       [Training]   Prec@1 86.218487 Max 86.386555
       [Avg Loss]          1.077683
       [Validation] Prec@1 75.675676 Max 77.297297
Confusion matrix:
[[25  5  0  0  0  0]
 [ 0 34  0  1  0  0]
 [ 2  6 21  1  0  0]
 [14  1  1 13  1  0]
 [ 5  4  0  0 21  0]
 [ 2  2  0  0  0 26]]
Epoch: [8]
       [Avg Loss]          0.387392
       [Training]   Prec@1 87.394958 Max 87.394958
       [Avg Loss]          1.009798
       [Validation] Prec@1 72.972973 Max 77.297297
Confusion matrix:
[[26  3  0  1  0  0]
 [ 2 32  1  0  0  0]
 [ 1  8 21  0  0  0]
 [12  0  3 14  1  0]
 [10  0  0  2 18  0]
 [ 2  2  0  2  0 24]]
Epoch: [9]
       [Avg Loss]          0.429106
       [Training]   Prec@1 86.050420 Max 87.394958
       [Avg Loss]          0.994758
       [Validation] Prec@1 75.675676 Max 77.297297
Confusion matrix:
[[23  4  0  0  3  0]
 [ 0 32  2  0  1  0]
 [ 1  2 27  0  0  0]
 [12  0  5 12  1  0]
 [ 4  2  0  2 22  0]
 [ 0  2  0  2  2 24]]
Epoch: [10]
       [Avg Loss]          0.372005
       [Training]   Prec@1 88.739496 Max 88.739496
       [Avg Loss]          0.919296
       [Validation] Prec@1 75.135135 Max 77.297297
Confusion matrix:
[[25  3  0  1  0  1]
 [ 2 32  0  0  1  0]
 [ 0  5 25  0  0  0]
 [ 9  0  7 14  0  0]
 [ 4  1  0  1 24  0]
 [ 4  2  0  5  0 19]]
Epoch: [11]
       [Avg Loss]          0.223674
       [Training]   Prec@1 92.436975 Max 92.436975
       [Avg Loss]          1.021565
       [Validation] Prec@1 74.054054 Max 77.297297
Confusion matrix:
[[24  5  0  1  0  0]
 [ 1 33  1  0  0  0]
 [ 1  1 28  0  0  0]
 [10  0  5 14  1  0]
 [ 7  7  0  1 15  0]
 [ 2  3  1  1  0 23]]
Epoch: [12]
       [Avg Loss]          0.232788
       [Training]   Prec@1 93.277311 Max 93.277311
       [Avg Loss]          0.966741
       [Validation] Prec@1 76.216216 Max 77.297297
Confusion matrix:
[[26  1  1  0  0  2]
 [ 3 30  0  1  1  0]
 [ 0  0 28  2  0  0]
 [ 9  0  4 11  6  0]
 [ 6  2  0  0 22  0]
 [ 5  1  0  0  0 24]]
Epoch: [13]
       [Avg Loss]          0.197619
       [Training]   Prec@1 94.285714 Max 94.285714
       [Avg Loss]          0.974254
       [Validation] Prec@1 76.756757 Max 77.297297
Confusion matrix:
[[26  4  0  0  0  0]
 [ 7 27  0  0  1  0]
 [ 1  2 27  0  0  0]
 [ 9  0  3 18  0  0]
 [ 4  2  0  2 22  0]
 [ 2  2  0  3  1 22]]
Epoch: [14]
       [Avg Loss]          0.177220
       [Training]   Prec@1 94.285714 Max 94.285714
       [Avg Loss]          0.736188
       [Validation] Prec@1 80.000000 Max 80.000000
Confusion matrix:
[[24  3  1  1  0  1]
 [ 0 33  0  1  0  1]
 [ 0  3 27  0  0  0]
 [ 2  0  6 20  1  1]
 [ 2  6  0  2 20  0]
 [ 1  2  0  2  1 24]]
Fold "1" complete, final accuracy: 80.0
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.488198
       [Training]   Prec@1 43.193277 Max 43.193277
       [Avg Loss]          1.481983
       [Validation] Prec@1 53.513514 Max 53.513514
Confusion matrix:
[[10 10  0  0 10  0]
 [ 0 29  0  0  2  4]
 [ 0 11  0  0 19  0]
 [ 1  2  0  0 27  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0  0 30]]
Epoch: [1]
       [Avg Loss]          0.881671
       [Training]   Prec@1 68.067227 Max 68.067227
       [Avg Loss]          1.044831
       [Validation] Prec@1 64.864865 Max 64.864865
Confusion matrix:
[[25  1  0  0  3  1]
 [ 4 28  0  0  0  3]
 [16  3  8  0  3  0]
 [ 9  7  0  7  5  2]
 [ 5  0  0  0 25  0]
 [ 3  0  0  0  0 27]]
Epoch: [2]
       [Avg Loss]          0.784358
       [Training]   Prec@1 73.109244 Max 73.109244
       [Avg Loss]          0.815422
       [Validation] Prec@1 74.054054 Max 74.054054
Confusion matrix:
[[13  3  8  0  6  0]
 [ 1 33  1  0  0  0]
 [ 0  0 29  1  0  0]
 [ 1  9  1 10  1  8]
 [ 1  0  0  0 29  0]
 [ 4  3  0  0  0 23]]
Epoch: [3]
       [Avg Loss]          0.686429
       [Training]   Prec@1 77.478992 Max 77.478992
       [Avg Loss]          0.722963
       [Validation] Prec@1 74.594595 Max 74.594595
Confusion matrix:
[[19  3  0  0  4  4]
 [ 2 31  0  0  0  2]
 [ 0  1 16 13  0  0]
 [ 0  8  0 20  2  0]
 [ 0  3  0  1 26  0]
 [ 1  3  0  0  0 26]]
Epoch: [4]
       [Avg Loss]          0.616433
       [Training]   Prec@1 79.831933 Max 79.831933
       [Avg Loss]          0.728147
       [Validation] Prec@1 78.378378 Max 78.378378
Confusion matrix:
[[22  0  0  0  8  0]
 [ 7 20  1  2  4  1]
 [ 1  0 29  0  0  0]
 [ 0  0  3 23  4  0]
 [ 0  0  0  4 26  0]
 [ 5  0  0  0  0 25]]
Epoch: [5]
       [Avg Loss]          0.513278
       [Training]   Prec@1 82.184874 Max 82.184874
       [Avg Loss]          0.653508
       [Validation] Prec@1 83.243243 Max 83.243243
Confusion matrix:
[[19  0  0  2  9  0]
 [ 2 28  0  3  0  2]
 [ 0  0 27  3  0  0]
 [ 0  0  1 27  1  1]
 [ 0  0  0  4 26  0]
 [ 3  0  0  0  0 27]]
Epoch: [6]
       [Avg Loss]          0.560239
       [Training]   Prec@1 80.000000 Max 82.184874
       [Avg Loss]          0.717688
       [Validation] Prec@1 75.675676 Max 83.243243
Confusion matrix:
[[17  4  3  1  5  0]
 [ 2 23  3  6  0  1]
 [ 0  0 30  0  0  0]
 [ 1  1  2 25  0  1]
 [ 2  1  0  7 20  0]
 [ 5  0  0  0  0 25]]
Epoch: [7]
       [Avg Loss]          0.488971
       [Training]   Prec@1 83.529412 Max 83.529412
       [Avg Loss]          0.558536
       [Validation] Prec@1 81.621622 Max 83.243243
Confusion matrix:
[[16  3  2  1  6  2]
 [ 2 32  0  0  0  1]
 [ 0  1 27  2  0  0]
 [ 0  3  2 20  4  1]
 [ 0  1  0  2 27  0]
 [ 0  1  0  0  0 29]]
Epoch: [8]
       [Avg Loss]          0.439089
       [Training]   Prec@1 84.369748 Max 84.369748
       [Avg Loss]          0.873026
       [Validation] Prec@1 76.756757 Max 83.243243
Confusion matrix:
[[22  1  3  0  4  0]
 [ 4 17  2  7  0  5]
 [ 0  0 30  0  0  0]
 [ 0  0  3 23  4  0]
 [ 6  0  0  1 23  0]
 [ 2  1  0  0  0 27]]
Epoch: [9]
       [Avg Loss]          0.390683
       [Training]   Prec@1 87.394958 Max 87.394958
       [Avg Loss]          0.536736
       [Validation] Prec@1 87.027027 Max 87.027027
Confusion matrix:
[[19  4  2  0  4  1]
 [ 0 32  0  0  0  3]
 [ 0  0 30  0  0  0]
 [ 1  3  1 25  0  0]
 [ 0  1  0  2 27  0]
 [ 2  0  0  0  0 28]]
Epoch: [10]
       [Avg Loss]          0.299589
       [Training]   Prec@1 90.252101 Max 90.252101
       [Avg Loss]          0.768355
       [Validation] Prec@1 78.378378 Max 87.027027
Confusion matrix:
[[21  2  2  0  4  1]
 [ 4 19  0  3  0  9]
 [ 0  0 30  0  0  0]
 [ 0  0  3 24  3  0]
 [ 2  0  0  4 24  0]
 [ 3  0  0  0  0 27]]
Epoch: [11]
       [Avg Loss]          0.238142
       [Training]   Prec@1 91.932773 Max 91.932773
       [Avg Loss]          0.687590
       [Validation] Prec@1 78.378378 Max 87.027027
Confusion matrix:
[[20  3  2  0  4  1]
 [ 6 25  0  2  0  2]
 [ 0  0 29  1  0  0]
 [ 2  1  3 23  1  0]
 [ 0  2  0  4 24  0]
 [ 5  1  0  0  0 24]]
Epoch: [12]
       [Avg Loss]          0.340295
       [Training]   Prec@1 89.243697 Max 91.932773
       [Avg Loss]          0.773970
       [Validation] Prec@1 80.540541 Max 87.027027
Confusion matrix:
[[21  1  0  1  6  1]
 [ 8 23  0  1  0  3]
 [ 0  0 26  2  2  0]
 [ 0  0  2 28  0  0]
 [ 0  1  0  3 26  0]
 [ 5  0  0  0  0 25]]
Epoch: [13]
       [Avg Loss]          0.265757
       [Training]   Prec@1 91.764706 Max 91.932773
       [Avg Loss]          0.790971
       [Validation] Prec@1 76.756757 Max 87.027027
Confusion matrix:
[[16  1  3  3  7  0]
 [10 22  0  2  1  0]
 [ 0  0 30  0  0  0]
 [ 0  0  1 26  3  0]
 [ 0  0  0  3 27  0]
 [ 9  0  0  0  0 21]]
Epoch: [14]
       [Avg Loss]          0.234252
       [Training]   Prec@1 92.941176 Max 92.941176
       [Avg Loss]          0.876983
       [Validation] Prec@1 75.135135 Max 87.027027
Confusion matrix:
[[19  2  2  1  6  0]
 [ 8 21  0  1  2  3]
 [ 3  0 25  2  0  0]
 [ 1  2  0 21  6  0]
 [ 0  1  0  1 28  0]
 [ 5  0  0  0  0 25]]
Fold "2" complete, final accuracy: 87.02702702702703
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.496589
       [Training]   Prec@1 43.939394 Max 43.939394
       [Avg Loss]          1.498686
       [Validation] Prec@1 64.166667 Max 64.166667
Confusion matrix:
[[19  0  0  0  1  0]
 [ 2 15  0  1  0  2]
 [ 8  5  4  0  3  0]
 [ 9  0  1  5  5  0]
 [ 0  0  0  0 20  0]
 [ 4  0  0  2  0 14]]
Epoch: [1]
       [Avg Loss]          0.852120
       [Training]   Prec@1 72.121212 Max 72.121212
       [Avg Loss]          0.902531
       [Validation] Prec@1 60.833333 Max 64.166667
Confusion matrix:
[[18  0  0  0  2  0]
 [ 0 18  0  0  2  0]
 [ 1  2  6  9  2  0]
 [ 4  0  0  3 12  1]
 [ 0  0  0  0 20  0]
 [10  0  0  2  0  8]]
Epoch: [2]
       [Avg Loss]          0.626525
       [Training]   Prec@1 81.060606 Max 81.060606
       [Avg Loss]          0.728319
       [Validation] Prec@1 76.666667 Max 76.666667
Confusion matrix:
[[16  0  0  4  0  0]
 [ 0 15  0  3  0  2]
 [ 0  2 11  7  0  0]
 [ 0  1  0 18  0  1]
 [ 0  0  0  5 15  0]
 [ 2  0  0  1  0 17]]
Epoch: [3]
       [Avg Loss]          0.644656
       [Training]   Prec@1 80.151515 Max 81.060606
       [Avg Loss]          1.221336
       [Validation] Prec@1 62.500000 Max 76.666667
Confusion matrix:
[[ 5  0  0 12  0  3]
 [ 0 18  0  2  0  0]
 [ 0  1  5 14  0  0]
 [ 0  0  0 19  0  1]
 [ 0  0  0 10 10  0]
 [ 0  2  0  0  0 18]]
Epoch: [4]
       [Avg Loss]          0.530539
       [Training]   Prec@1 82.878788 Max 82.878788
       [Avg Loss]          0.556470
       [Validation] Prec@1 82.500000 Max 82.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 18  2  0  0]
 [ 2  0  3 15  0  0]
 [ 0  0  0  9 11  0]
 [ 1  1  0  2  0 16]]
Epoch: [5]
       [Avg Loss]          0.426476
       [Training]   Prec@1 86.515152 Max 86.515152
       [Avg Loss]          0.666524
       [Validation] Prec@1 76.666667 Max 82.500000
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0 18  0  1  0  1]
 [ 2  0 14  4  0  0]
 [ 7  0  0 11  2  0]
 [ 0  0  0  1 19  0]
 [ 5  2  0  2  0 11]]
Epoch: [6]
       [Avg Loss]          0.484592
       [Training]   Prec@1 85.303030 Max 86.515152
       [Avg Loss]          0.576980
       [Validation] Prec@1 80.833333 Max 82.500000
Confusion matrix:
[[14  0  0  6  0  0]
 [ 0 19  0  1  0  0]
 [ 0  2 12  5  1  0]
 [ 0  1  0 17  2  0]
 [ 0  0  0  0 20  0]
 [ 3  1  0  1  0 15]]
Epoch: [7]
       [Avg Loss]          0.405888
       [Training]   Prec@1 85.606061 Max 86.515152
       [Avg Loss]          0.545533
       [Validation] Prec@1 84.166667 Max 84.166667
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 17  3  0  0]
 [ 2  1  4 11  0  2]
 [ 0  0  0  2 18  0]
 [ 0  2  0  1  0 17]]
Epoch: [8]
       [Avg Loss]          0.345326
       [Training]   Prec@1 90.454545 Max 90.454545
       [Avg Loss]          0.837072
       [Validation] Prec@1 75.833333 Max 84.166667
Confusion matrix:
[[ 6  0  0 14  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 12  8  0  0]
 [ 0  1  0 19  0  0]
 [ 0  0  0  0 20  0]
 [ 0  4  0  1  0 15]]
Epoch: [9]
       [Avg Loss]          0.323849
       [Training]   Prec@1 89.848485 Max 90.454545
       [Avg Loss]          0.539591
       [Validation] Prec@1 85.833333 Max 85.833333
Confusion matrix:
[[16  0  0  4  0  0]
 [ 0 19  0  1  0  0]
 [ 1  1 15  3  0  0]
 [ 1  0  1 18  0  0]
 [ 0  0  0  0 20  0]
 [ 2  0  0  2  1 15]]
Epoch: [10]
       [Avg Loss]          0.237672
       [Training]   Prec@1 93.181818 Max 93.181818
       [Avg Loss]          0.772017
       [Validation] Prec@1 75.833333 Max 85.833333
Confusion matrix:
[[10  0  0 10  0  0]
 [ 0 18  0  1  0  1]
 [ 0  0 15  5  0  0]
 [ 0  0  1 18  0  1]
 [ 0  0  0  6 14  0]
 [ 0  3  0  1  0 16]]
Epoch: [11]
       [Avg Loss]          0.254318
       [Training]   Prec@1 93.030303 Max 93.181818
       [Avg Loss]          1.308742
       [Validation] Prec@1 68.333333 Max 85.833333
Confusion matrix:
[[ 6  0  1 13  0  0]
 [ 0 19  0  1  0  0]
 [ 4  0 14  2  0  0]
 [ 0  1  1 17  0  1]
 [ 0  0  0  8 12  0]
 [ 5  0  0  1  0 14]]
Epoch: [12]
       [Avg Loss]          0.333408
       [Training]   Prec@1 90.606061 Max 93.181818
       [Avg Loss]          0.768927
       [Validation] Prec@1 73.333333 Max 85.833333
Confusion matrix:
[[ 5  0  0 12  0  3]
 [ 0 18  0  1  0  1]
 [ 0  0 16  4  0  0]
 [ 0  2  0 17  0  1]
 [ 0  0  0  6 14  0]
 [ 0  2  0  0  0 18]]
Epoch: [13]
       [Avg Loss]          0.255229
       [Training]   Prec@1 91.212121 Max 93.181818
       [Avg Loss]          0.987121
       [Validation] Prec@1 72.500000 Max 85.833333
Confusion matrix:
[[ 6  0  0 14  0  0]
 [ 0 18  0  2  0  0]
 [ 0  0 13  7  0  0]
 [ 0  2  0 18  0  0]
 [ 0  0  0  0 20  0]
 [ 5  0  0  3  0 12]]
Epoch: [14]
       [Avg Loss]          0.182521
       [Training]   Prec@1 94.242424 Max 94.242424
       [Avg Loss]          0.518050
       [Validation] Prec@1 86.666667 Max 86.666667
Confusion matrix:
[[19  0  0  0  0  1]
 [ 0 18  0  1  0  1]
 [ 2  1 13  4  0  0]
 [ 1  0  1 17  0  1]
 [ 0  0  0  0 20  0]
 [ 2  1  0  0  0 17]]
Fold "3" complete, final accuracy: 86.66666666666667
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.429976
       [Training]   Prec@1 44.328358 Max 44.328358
       [Avg Loss]          1.488523
       [Validation] Prec@1 55.454545 Max 55.454545
Confusion matrix:
[[16  4  0  0  0  0]
 [10  7  1  1  1  0]
 [ 9  2  7  0  2  0]
 [ 7  7  0  6  0  0]
 [ 0  0  0  0 10  0]
 [ 5  0  0  0  0 15]]
Epoch: [1]
       [Avg Loss]          0.805475
       [Training]   Prec@1 73.283582 Max 73.283582
       [Avg Loss]          1.500359
       [Validation] Prec@1 50.909091 Max 55.454545
Confusion matrix:
[[19  0  1  0  0  0]
 [ 5  7  1  0  7  0]
 [ 8  0  7  0  5  0]
 [ 1  8  6  2  0  3]
 [ 0  0  0  0 10  0]
 [ 9  0  0  0  0 11]]
Epoch: [2]
       [Avg Loss]          0.618707
       [Training]   Prec@1 78.208955 Max 78.208955
       [Avg Loss]          1.530206
       [Validation] Prec@1 47.272727 Max 55.454545
Confusion matrix:
[[14  0  1  0  5  0]
 [ 4  2  8  1  5  0]
 [ 7  0 13  0  0  0]
 [ 0  5 12  3  0  0]
 [ 0  0  0  0 10  0]
 [ 9  0  0  1  0 10]]
Epoch: [3]
       [Avg Loss]          0.510374
       [Training]   Prec@1 81.791045 Max 81.791045
       [Avg Loss]          1.419133
       [Validation] Prec@1 66.363636 Max 66.363636
Confusion matrix:
[[17  1  1  0  1  0]
 [ 9  6  1  2  2  0]
 [ 6  0  8  3  2  1]
 [ 0  6  2 12  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          0.426128
       [Training]   Prec@1 85.970149 Max 85.970149
       [Avg Loss]          0.919920
       [Validation] Prec@1 72.727273 Max 72.727273
Confusion matrix:
[[12  6  0  1  0  1]
 [ 1 13  0  6  0  0]
 [ 4  1 14  0  0  1]
 [ 0  5  3 11  0  1]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.358755
       [Training]   Prec@1 86.119403 Max 86.119403
       [Avg Loss]          1.617809
       [Validation] Prec@1 50.909091 Max 72.727273
Confusion matrix:
[[15  1  0  1  3  0]
 [ 4 11  0  2  3  0]
 [ 7  1  2  9  1  0]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [14  0  0  2  0  4]]
Epoch: [6]
       [Avg Loss]          0.390565
       [Training]   Prec@1 87.611940 Max 87.611940
       [Avg Loss]          1.396967
       [Validation] Prec@1 64.545455 Max 72.727273
Confusion matrix:
[[15  1  0  1  2  1]
 [ 1  8  1  3  5  2]
 [ 5  0  5  7  2  1]
 [ 0  4  3 13  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [7]
       [Avg Loss]          0.277276
       [Training]   Prec@1 89.701493 Max 89.701493
       [Avg Loss]          1.146979
       [Validation] Prec@1 67.272727 Max 72.727273
Confusion matrix:
[[16  1  0  2  0  1]
 [ 2 12  0  5  1  0]
 [ 6  1  9  3  0  1]
 [ 0  3  3 14  0  0]
 [ 0  0  0  0 10  0]
 [ 6  0  0  1  0 13]]
Epoch: [8]
       [Avg Loss]          0.257696
       [Training]   Prec@1 91.492537 Max 91.492537
       [Avg Loss]          1.491611
       [Validation] Prec@1 60.000000 Max 72.727273
Confusion matrix:
[[14  0  0  4  0  2]
 [ 3  2  1  8  6  0]
 [ 7  0  8  3  2  0]
 [ 0  2  3 15  0  0]
 [ 0  0  0  0 10  0]
 [ 2  0  0  1  0 17]]
Epoch: [9]
       [Avg Loss]          0.214256
       [Training]   Prec@1 92.238806 Max 92.238806
       [Avg Loss]          0.963768
       [Validation] Prec@1 67.272727 Max 72.727273
Confusion matrix:
[[14  1  0  5  0  0]
 [ 0 12  1  4  3  0]
 [ 5  0 12  1  0  2]
 [ 0  3  2 15  0  0]
 [ 0  0  0  0 10  0]
 [ 3  0  0  6  0 11]]
Epoch: [10]
       [Avg Loss]          0.196734
       [Training]   Prec@1 92.537313 Max 92.537313
       [Avg Loss]          1.922516
       [Validation] Prec@1 46.363636 Max 72.727273
Confusion matrix:
[[14  0  0  2  3  1]
 [ 6  1  0  8  3  2]
 [ 8  0  0 12  0  0]
 [ 0  2  1 17  0  0]
 [ 0  0  0  1  9  0]
 [ 9  0  0  1  0 10]]
Epoch: [11]
       [Avg Loss]          0.179385
       [Training]   Prec@1 94.925373 Max 94.925373
       [Avg Loss]          1.895610
       [Validation] Prec@1 50.000000 Max 72.727273
Confusion matrix:
[[15  1  0  3  1  0]
 [ 5  3  0  8  4  0]
 [ 4  0  7  9  0  0]
 [ 0  0  5 15  0  0]
 [ 0  0  0  1  9  0]
 [ 6  0  0  8  0  6]]
Epoch: [12]
       [Avg Loss]          0.131787
       [Training]   Prec@1 95.970149 Max 95.970149
       [Avg Loss]          1.518892
       [Validation] Prec@1 62.727273 Max 72.727273
Confusion matrix:
[[13  4  0  3  0  0]
 [ 0  8  0  8  4  0]
 [ 6  0  5  9  0  0]
 [ 0  0  1 19  0  0]
 [ 0  0  0  0 10  0]
 [ 5  0  0  1  0 14]]
Epoch: [13]
       [Avg Loss]          0.114275
       [Training]   Prec@1 96.268657 Max 96.268657
       [Avg Loss]          2.047544
       [Validation] Prec@1 53.636364 Max 72.727273
Confusion matrix:
[[16  1  0  2  0  1]
 [ 0  0  0 10  8  2]
 [ 6  0  4 10  0  0]
 [ 0  0  0 20  0  0]
 [ 0  0  0  0 10  0]
 [ 5  0  0  6  0  9]]
Epoch: [14]
       [Avg Loss]          0.108068
       [Training]   Prec@1 96.268657 Max 96.268657
       [Avg Loss]          1.806197
       [Validation] Prec@1 54.545455 Max 72.727273
Confusion matrix:
[[16  3  0  1  0  0]
 [ 6 10  0  3  0  1]
 [ 6  1 12  1  0  0]
 [ 0  4  5 11  0  0]
 [ 0  0  0  2  8  0]
 [11  1  0  5  0  3]]
Fold "4" complete, final accuracy: 72.72727272727273

-----------------------------------------------------------------------
Training for stage 1 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=18)")
Average accuracy is: 80.17308217308218


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 2-----
Evaluated preprocessing: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=18)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.386246
       [Training]   Prec@1 49.000000 Max 49.000000
       [Avg Loss]          1.384256
       [Validation] Prec@1 72.222222 Max 72.222222
Confusion matrix:
[[29  0  0  0  1 10]
 [ 0 30  0  0  0  0]
 [ 0  4 20  3  3  0]
 [ 3  0  9  3 15  0]
 [ 2  0  0  0 28  0]
 [ 0  0  0  0  0 20]]
Epoch: [1]
       [Avg Loss]          0.853940
       [Training]   Prec@1 72.166667 Max 72.166667
       [Avg Loss]          1.233055
       [Validation] Prec@1 63.333333 Max 72.222222
Confusion matrix:
[[12  0  5  5  8 10]
 [ 0 25  0  1  0  4]
 [ 0  0 30  0  0  0]
 [ 0  3 25  1  1  0]
 [ 2  2  0  0 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          0.694467
       [Training]   Prec@1 77.666667 Max 77.666667
       [Avg Loss]          1.148169
       [Validation] Prec@1 72.777778 Max 72.777778
Confusion matrix:
[[29  0  1  0  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 27  0  3  0]
 [ 0  1 14  0 15  0]
 [ 4  0  1  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [3]
       [Avg Loss]          0.571469
       [Training]   Prec@1 83.000000 Max 83.000000
       [Avg Loss]          1.679803
       [Validation] Prec@1 62.222222 Max 72.777778
Confusion matrix:
[[14  1  8  7  0 10]
 [ 0 28  0  2  0  0]
 [ 0  1 29  0  0  0]
 [ 0  3 25  0  2  0]
 [ 0  0  5  0 25  0]
 [ 0  0  4  0  0 16]]
Epoch: [4]
       [Avg Loss]          0.470071
       [Training]   Prec@1 83.333333 Max 83.333333
       [Avg Loss]          1.475618
       [Validation] Prec@1 64.444444 Max 72.777778
Confusion matrix:
[[17  0  7  6  0 10]
 [ 0 25  1  4  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 29  0  0  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  1  0 19]]
Epoch: [5]
       [Avg Loss]          0.426067
       [Training]   Prec@1 85.500000 Max 85.500000
       [Avg Loss]          1.068627
       [Validation] Prec@1 71.666667 Max 72.777778
Confusion matrix:
[[25  0  3  2  0 10]
 [ 0 27  0  3  0  0]
 [ 0  3 27  0  0  0]
 [ 0  3 10  4 13  0]
 [ 2  0  1  0 27  0]
 [ 0  0  0  1  0 19]]
Epoch: [6]
       [Avg Loss]          0.425763
       [Training]   Prec@1 85.000000 Max 85.500000
       [Avg Loss]          1.502125
       [Validation] Prec@1 70.000000 Max 72.777778
Confusion matrix:
[[20  0  4  3  3 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 25  0  5  0]
 [ 0  0  3  0 27  0]
 [ 0  0  1  0  0 19]]
Epoch: [7]
       [Avg Loss]          0.358247
       [Training]   Prec@1 88.500000 Max 88.500000
       [Avg Loss]          1.099546
       [Validation] Prec@1 75.555556 Max 75.555556
Confusion matrix:
[[29  0  0  1  0 10]
 [ 0 29  0  1  0  0]
 [ 0  0 30  0  0  0]
 [ 1  3 21  5  0  0]
 [ 2  0  3  2 23  0]
 [ 0  0  0  0  0 20]]
Epoch: [8]
       [Avg Loss]          0.359463
       [Training]   Prec@1 89.500000 Max 89.500000
       [Avg Loss]          1.520391
       [Validation] Prec@1 70.555556 Max 75.555556
Confusion matrix:
[[21  0  6  1  2 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  3 24  1  2  0]
 [ 0  0  4  0 26  0]
 [ 0  0  0  1  0 19]]
Epoch: [9]
       [Avg Loss]          0.310692
       [Training]   Prec@1 91.166667 Max 91.166667
       [Avg Loss]          1.533403
       [Validation] Prec@1 63.333333 Max 75.555556
Confusion matrix:
[[15  0  5 10  0 10]
 [ 0 29  0  1  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 27  2  0  0]
 [ 0  0  4  0 26  0]
 [ 0  0  7  1  0 12]]
Epoch: [10]
       [Avg Loss]          0.297918
       [Training]   Prec@1 91.166667 Max 91.166667
       [Avg Loss]          1.180221
       [Validation] Prec@1 72.777778 Max 75.555556
Confusion matrix:
[[23  0  4  2  1 10]
 [ 0 29  0  1  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 25  4  1  0]
 [ 1  0  2  1 26  0]
 [ 0  0  0  1  0 19]]
Epoch: [11]
       [Avg Loss]          0.340177
       [Training]   Prec@1 90.166667 Max 91.166667
       [Avg Loss]          1.054817
       [Validation] Prec@1 75.000000 Max 75.555556
Confusion matrix:
[[15  0  4 10  1 10]
 [ 0 28  1  1  0  0]
 [ 0  0 29  0  1  0]
 [ 0  1  6 18  5  0]
 [ 0  0  3  0 27  0]
 [ 0  0  2  0  0 18]]
Epoch: [12]
       [Avg Loss]          0.296390
       [Training]   Prec@1 89.500000 Max 91.166667
       [Avg Loss]          1.534490
       [Validation] Prec@1 69.444444 Max 75.555556
Confusion matrix:
[[22  0  4  3  1 10]
 [ 0 29  0  1  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 28  1  0  0]
 [ 1  0  6  0 23  0]
 [ 0  0  0  0  0 20]]
Epoch: [13]
       [Avg Loss]          0.239142
       [Training]   Prec@1 93.000000 Max 93.000000
       [Avg Loss]          1.265475
       [Validation] Prec@1 70.555556 Max 75.555556
Confusion matrix:
[[20  0  5  4  1 10]
 [ 0 27  0  3  0  0]
 [ 0  0 30  0  0  0]
 [ 0  3 10  7 10  0]
 [ 0  1  2  0 27  0]
 [ 0  0  3  1  0 16]]
Epoch: [14]
       [Avg Loss]          0.202442
       [Training]   Prec@1 94.500000 Max 94.500000
       [Avg Loss]          1.307849
       [Validation] Prec@1 70.555556 Max 75.555556
Confusion matrix:
[[23  0  6  0  1 10]
 [ 0 29  1  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  2 20  4  4  0]
 [ 0  0  3  0 27  0]
 [ 0  0  6  0  0 14]]
Fold "0" complete, final accuracy: 75.55555555555556
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.455554
       [Training]   Prec@1 43.361345 Max 43.361345
       [Avg Loss]          1.401145
       [Validation] Prec@1 56.216216 Max 56.216216
Confusion matrix:
[[20  4  0  0  0  6]
 [ 1 34  0  0  0  0]
 [ 0  8  0 21  1  0]
 [13  4  0  8  3  2]
 [ 4  4  0  3 19  0]
 [ 2  3  0  2  0 23]]
Epoch: [1]
       [Avg Loss]          0.957655
       [Training]   Prec@1 67.899160 Max 67.899160
       [Avg Loss]          1.013999
       [Validation] Prec@1 61.081081 Max 61.081081
Confusion matrix:
[[10  5  0  0 10  5]
 [ 0 35  0  0  0  0]
 [ 0 10 12  8  0  0]
 [ 1  6  1  7 13  2]
 [ 0  4  0  0 26  0]
 [ 1  4  0  1  1 23]]
Epoch: [2]
       [Avg Loss]          0.716743
       [Training]   Prec@1 75.294118 Max 75.294118
       [Avg Loss]          0.908423
       [Validation] Prec@1 68.108108 Max 68.108108
Confusion matrix:
[[24  6  0  0  0  0]
 [ 1 29  1  4  0  0]
 [ 0  7 22  1  0  0]
 [14  1  3 11  1  0]
 [ 9  2  0  3 16  0]
 [ 1  2  1  2  0 24]]
Epoch: [3]
       [Avg Loss]          0.660392
       [Training]   Prec@1 77.647059 Max 77.647059
       [Avg Loss]          0.793852
       [Validation] Prec@1 71.351351 Max 71.351351
Confusion matrix:
[[24  5  0  0  0  1]
 [ 1 32  2  0  0  0]
 [ 1  6 22  1  0  0]
 [13  2  2 11  2  0]
 [ 8  2  0  0 20  0]
 [ 1  2  0  4  0 23]]
Epoch: [4]
       [Avg Loss]          0.506368
       [Training]   Prec@1 81.848739 Max 81.848739
       [Avg Loss]          0.979035
       [Validation] Prec@1 69.189189 Max 71.351351
Confusion matrix:
[[25  4  1  0  0  0]
 [ 2 31  2  0  0  0]
 [ 0  5 24  1  0  0]
 [15  0  2 12  1  0]
 [16  0  0  0 14  0]
 [ 3  1  0  4  0 22]]
Epoch: [5]
       [Avg Loss]          0.469969
       [Training]   Prec@1 84.201681 Max 84.201681
       [Avg Loss]          0.869965
       [Validation] Prec@1 72.432432 Max 72.432432
Confusion matrix:
[[24  4  2  0  0  0]
 [ 2 30  3  0  0  0]
 [ 0  2 27  1  0  0]
 [ 6  0  6 12  6  0]
 [ 8  3  0  0 19  0]
 [ 3  1  1  3  0 22]]
Epoch: [6]
       [Avg Loss]          0.404591
       [Training]   Prec@1 86.722689 Max 86.722689
       [Avg Loss]          0.879240
       [Validation] Prec@1 77.297297 Max 77.297297
Confusion matrix:
[[26  4  0  0  0  0]
 [ 1 32  1  0  0  1]
 [ 0  5 25  0  0  0]
 [ 7  2  0 21  0  0]
 [ 4  3  0  5 18  0]
 [ 2  1  0  6  0 21]]
Epoch: [7]
       [Avg Loss]          0.326902
       [Training]   Prec@1 88.907563 Max 88.907563
       [Avg Loss]          0.933065
       [Validation] Prec@1 69.189189 Max 77.297297
Confusion matrix:
[[25  3  2  0  0  0]
 [ 3 30  2  0  0  0]
 [ 0  6 24  0  0  0]
 [11  2  2 15  0  0]
 [13  0  0  2 15  0]
 [ 4  2  1  4  0 19]]
Epoch: [8]
       [Avg Loss]          0.359094
       [Training]   Prec@1 88.571429 Max 88.907563
       [Avg Loss]          1.004777
       [Validation] Prec@1 69.729730 Max 77.297297
Confusion matrix:
[[23  5  2  0  0  0]
 [ 1 30  4  0  0  0]
 [ 0  0 29  1  0  0]
 [10  1  8 10  1  0]
 [10  2  0  1 17  0]
 [ 2  2  1  5  0 20]]
Epoch: [9]
       [Avg Loss]          0.304175
       [Training]   Prec@1 90.588235 Max 90.588235
       [Avg Loss]          0.941833
       [Validation] Prec@1 76.216216 Max 77.297297
Confusion matrix:
[[27  3  0  0  0  0]
 [ 2 29  2  2  0  0]
 [ 1  0 29  0  0  0]
 [ 9  0  3 15  3  0]
 [ 8  0  0  2 20  0]
 [ 3  1  0  5  0 21]]
Epoch: [10]
       [Avg Loss]          0.257667
       [Training]   Prec@1 91.764706 Max 91.764706
       [Avg Loss]          1.185965
       [Validation] Prec@1 71.351351 Max 77.297297
Confusion matrix:
[[24  4  2  0  0  0]
 [ 4 29  1  0  1  0]
 [ 0  5 25  0  0  0]
 [10  1  2 12  5  0]
 [ 7  0  0  0 23  0]
 [ 3  2  0  6  0 19]]
Epoch: [11]
       [Avg Loss]          0.217435
       [Training]   Prec@1 93.277311 Max 93.277311
       [Avg Loss]          1.505222
       [Validation] Prec@1 67.567568 Max 77.297297
Confusion matrix:
[[25  4  1  0  0  0]
 [ 1 34  0  0  0  0]
 [ 1  4 23  2  0  0]
 [15  0  2 13  0  0]
 [16  3  0  0 11  0]
 [ 2  2  0  7  0 19]]
Epoch: [12]
       [Avg Loss]          0.254627
       [Training]   Prec@1 91.260504 Max 93.277311
       [Avg Loss]          1.110325
       [Validation] Prec@1 72.972973 Max 77.297297
Confusion matrix:
[[25  5  0  0  0  0]
 [ 1 31  0  1  0  2]
 [ 0  3 26  1  0  0]
 [14  0  3 12  1  0]
 [ 6  6  0  1 17  0]
 [ 2  2  0  1  1 24]]
Epoch: [13]
       [Avg Loss]          0.204894
       [Training]   Prec@1 92.605042 Max 93.277311
       [Avg Loss]          1.459265
       [Validation] Prec@1 69.729730 Max 77.297297
Confusion matrix:
[[23  4  3  0  0  0]
 [ 2 31  2  0  0  0]
 [ 0  6 23  1  0  0]
 [17  2  1 10  0  0]
 [ 7  2  0  0 21  0]
 [ 1  2  0  5  1 21]]
Epoch: [14]
       [Avg Loss]          0.360831
       [Training]   Prec@1 89.075630 Max 93.277311
       [Avg Loss]          0.678409
       [Validation] Prec@1 81.621622 Max 81.621622
Confusion matrix:
[[27  1  0  0  0  2]
 [ 2 27  0  0  2  4]
 [ 0  1 27  1  1  0]
 [ 8  0  1 18  2  1]
 [ 0  2  0  0 28  0]
 [ 1  1  0  3  1 24]]
Fold "1" complete, final accuracy: 81.62162162162163
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.392518
       [Training]   Prec@1 46.890756 Max 46.890756
       [Avg Loss]          1.475618
       [Validation] Prec@1 52.432432 Max 52.432432
Confusion matrix:
[[19  3  0  0  8  0]
 [ 1 32  0  0  1  1]
 [ 0  0  0  0 30  0]
 [ 0 10  0  0 17  3]
 [ 2  0  0  0 28  0]
 [ 0 12  0  0  0 18]]
Epoch: [1]
       [Avg Loss]          0.883409
       [Training]   Prec@1 70.252101 Max 70.252101
       [Avg Loss]          1.007771
       [Validation] Prec@1 75.675676 Max 75.675676
Confusion matrix:
[[23  0  0  0  7  0]
 [ 3 29  0  0  1  2]
 [ 5  0 14  2  9  0]
 [ 0  9  0 18  1  2]
 [ 4  0  0  0 26  0]
 [ 0  0  0  0  0 30]]
Epoch: [2]
       [Avg Loss]          0.733140
       [Training]   Prec@1 75.630252 Max 75.630252
       [Avg Loss]          0.799185
       [Validation] Prec@1 75.135135 Max 75.675676
Confusion matrix:
[[24  3  0  0  3  0]
 [ 5 30  0  0  0  0]
 [ 3  0 20  7  0  0]
 [ 0  7  1 20  0  2]
 [ 2  0  4  5 19  0]
 [ 3  1  0  0  0 26]]
Epoch: [3]
       [Avg Loss]          0.628126
       [Training]   Prec@1 80.168067 Max 80.168067
       [Avg Loss]          0.848442
       [Validation] Prec@1 77.837838 Max 77.837838
Confusion matrix:
[[21  1  0  0  8  0]
 [ 4 26  3  2  0  0]
 [ 2  0 15 13  0  0]
 [ 0  2  1 24  3  0]
 [ 0  0  0  2 28  0]
 [ 0  0  0  0  0 30]]
Epoch: [4]
       [Avg Loss]          0.584874
       [Training]   Prec@1 80.336134 Max 80.336134
       [Avg Loss]          0.822839
       [Validation] Prec@1 72.432432 Max 77.837838
Confusion matrix:
[[21  0  0  0  5  4]
 [ 4 24  5  0  0  2]
 [ 1  0 21  8  0  0]
 [ 0  2  3 21  3  1]
 [ 0  0  5  5 20  0]
 [ 1  2  0  0  0 27]]
Epoch: [5]
       [Avg Loss]          0.549299
       [Training]   Prec@1 81.512605 Max 81.512605
       [Avg Loss]          0.845191
       [Validation] Prec@1 75.135135 Max 77.837838
Confusion matrix:
[[21  4  0  0  5  0]
 [ 3 31  0  0  0  1]
 [ 2  1 13  4 10  0]
 [ 0  3  1 22  3  1]
 [ 1  0  0  0 29  0]
 [ 6  1  0  0  0 23]]
Epoch: [6]
       [Avg Loss]          0.465755
       [Training]   Prec@1 83.865546 Max 83.865546
       [Avg Loss]          0.687247
       [Validation] Prec@1 79.459459 Max 79.459459
Confusion matrix:
[[21  0  1  0  8  0]
 [ 2 24  4  1  0  4]
 [ 1  0 25  4  0  0]
 [ 1  2  3 22  0  2]
 [ 0  0  0  5 25  0]
 [ 0  0  0  0  0 30]]
Epoch: [7]
       [Avg Loss]          0.369492
       [Training]   Prec@1 88.739496 Max 88.739496
       [Avg Loss]          0.858097
       [Validation] Prec@1 72.432432 Max 79.459459
Confusion matrix:
[[24  1  1  1  2  1]
 [ 8 25  0  0  0  2]
 [ 2  0 14 10  4  0]
 [ 0  4  0 17  8  1]
 [ 3  0  0  2 25  0]
 [ 1  0  0  0  0 29]]
Epoch: [8]
       [Avg Loss]          0.386667
       [Training]   Prec@1 88.739496 Max 88.739496
       [Avg Loss]          1.002159
       [Validation] Prec@1 69.729730 Max 79.459459
Confusion matrix:
[[21  0  0  0  9  0]
 [ 7 18  0  0  3  7]
 [ 1  0 15 14  0  0]
 [ 0  3  0 18  3  6]
 [ 1  0  0  2 27  0]
 [ 0  0  0  0  0 30]]
Epoch: [9]
       [Avg Loss]          0.409888
       [Training]   Prec@1 87.226891 Max 88.739496
       [Avg Loss]          0.758160
       [Validation] Prec@1 80.540541 Max 80.540541
Confusion matrix:
[[23  3  1  0  3  0]
 [ 1 30  0  2  0  2]
 [ 1  0 24  5  0  0]
 [ 0  0  0 27  2  1]
 [ 2  0  0  8 20  0]
 [ 2  3  0  0  0 25]]
Epoch: [10]
       [Avg Loss]          0.377262
       [Training]   Prec@1 87.226891 Max 88.739496
       [Avg Loss]          0.839688
       [Validation] Prec@1 72.432432 Max 80.540541
Confusion matrix:
[[22  1  2  0  5  0]
 [13 21  0  0  0  1]
 [ 0  0 18  5  7  0]
 [ 1  4  5 20  0  0]
 [ 0  0  0  3 27  0]
 [ 4  0  0  0  0 26]]
Epoch: [11]
       [Avg Loss]          0.307037
       [Training]   Prec@1 91.260504 Max 91.260504
       [Avg Loss]          0.824754
       [Validation] Prec@1 76.216216 Max 80.540541
Confusion matrix:
[[20  3  0  0  6  1]
 [ 6 25  0  2  0  2]
 [ 2  0 24  4  0  0]
 [ 0  1  1 23  3  2]
 [ 5  0  0  2 23  0]
 [ 4  0  0  0  0 26]]
Epoch: [12]
       [Avg Loss]          0.257113
       [Training]   Prec@1 91.764706 Max 91.764706
       [Avg Loss]          0.796954
       [Validation] Prec@1 77.837838 Max 80.540541
Confusion matrix:
[[18  1  3  1  7  0]
 [ 5 28  0  1  0  1]
 [ 1  0 20  9  0  0]
 [ 0  0  1 27  1  1]
 [ 0  0  0  2 28  0]
 [ 7  0  0  0  0 23]]
Epoch: [13]
       [Avg Loss]          0.217419
       [Training]   Prec@1 93.613445 Max 93.613445
       [Avg Loss]          1.004084
       [Validation] Prec@1 75.135135 Max 80.540541
Confusion matrix:
[[24  1  0  1  4  0]
 [12 22  0  0  0  1]
 [ 1  0 19 10  0  0]
 [ 0  3  2 22  0  3]
 [ 0  0  0  3 27  0]
 [ 5  0  0  0  0 25]]
Epoch: [14]
       [Avg Loss]          0.259740
       [Training]   Prec@1 91.932773 Max 93.613445
       [Avg Loss]          1.321253
       [Validation] Prec@1 67.027027 Max 80.540541
Confusion matrix:
[[21  0  0  0  9  0]
 [ 5 28  0  0  0  2]
 [ 8  0  2 14  6  0]
 [ 1  7  0 13  5  4]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0  0 30]]
Fold "2" complete, final accuracy: 80.54054054054055
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.351936
       [Training]   Prec@1 50.606061 Max 50.606061
       [Avg Loss]          1.278656
       [Validation] Prec@1 64.166667 Max 64.166667
Confusion matrix:
[[16  0  0  0  4  0]
 [ 0 19  0  1  0  0]
 [ 0  8  4  1  7  0]
 [ 2  1  1  4 11  1]
 [ 0  0  0  0 20  0]
 [ 0  6  0  0  0 14]]
Epoch: [1]
       [Avg Loss]          0.854258
       [Training]   Prec@1 72.575758 Max 72.575758
       [Avg Loss]          0.873923
       [Validation] Prec@1 65.833333 Max 65.833333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 13  0  4  0  3]
 [ 0  1  7  9  3  0]
 [ 9  0  1  6  4  0]
 [ 0  0  0  2 18  0]
 [ 1  2  0  1  1 15]]
Epoch: [2]
       [Avg Loss]          0.748968
       [Training]   Prec@1 76.060606 Max 76.060606
       [Avg Loss]          0.669183
       [Validation] Prec@1 74.166667 Max 74.166667
Confusion matrix:
[[14  0  2  3  0  1]
 [ 0 19  0  0  1  0]
 [ 0  2  6 10  2  0]
 [ 1  0  1 16  2  0]
 [ 0  1  0  0 19  0]
 [ 0  2  0  3  0 15]]
Epoch: [3]
       [Avg Loss]          0.682778
       [Training]   Prec@1 80.454545 Max 80.454545
       [Avg Loss]          0.659946
       [Validation] Prec@1 79.166667 Max 79.166667
Confusion matrix:
[[18  0  2  0  0  0]
 [ 0 18  0  2  0  0]
 [ 0  1 10  8  1  0]
 [ 3  0  3 14  0  0]
 [ 0  0  0  0 20  0]
 [ 0  1  0  3  1 15]]
Epoch: [4]
       [Avg Loss]          0.586751
       [Training]   Prec@1 80.909091 Max 80.909091
       [Avg Loss]          0.588048
       [Validation] Prec@1 81.666667 Max 81.666667
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 15  0  5  0  0]
 [ 0  0 15  4  1  0]
 [ 4  0  1 14  1  0]
 [ 0  0  0  0 20  0]
 [ 1  0  0  4  1 14]]
Epoch: [5]
       [Avg Loss]          0.453227
       [Training]   Prec@1 84.393939 Max 84.393939
       [Avg Loss]          0.891408
       [Validation] Prec@1 75.000000 Max 81.666667
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 18  0  2  0  0]
 [ 0  1 16  3  0  0]
 [10  0  1  9  0  0]
 [ 0  0  0  6 14  0]
 [ 1  3  0  3  0 13]]
Epoch: [6]
       [Avg Loss]          0.408699
       [Training]   Prec@1 86.515152 Max 86.515152
       [Avg Loss]          0.890599
       [Validation] Prec@1 77.500000 Max 81.666667
Confusion matrix:
[[19  0  1  0  0  0]
 [ 0 17  0  2  0  1]
 [ 0  1 10  8  1  0]
 [ 7  0  1 11  0  1]
 [ 0  0  0  0 20  0]
 [ 3  0  0  1  0 16]]
Epoch: [7]
       [Avg Loss]          0.357342
       [Training]   Prec@1 88.787879 Max 88.787879
       [Avg Loss]          0.554275
       [Validation] Prec@1 85.000000 Max 85.000000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 19  0  1  0  0]
 [ 1  0 15  4  0  0]
 [ 3  0  3 13  1  0]
 [ 0  0  0  0 20  0]
 [ 0  2  0  3  0 15]]
Epoch: [8]
       [Avg Loss]          0.330783
       [Training]   Prec@1 89.545455 Max 89.545455
       [Avg Loss]          0.432400
       [Validation] Prec@1 87.500000 Max 87.500000
Confusion matrix:
[[18  0  1  1  0  0]
 [ 0 19  0  1  0  0]
 [ 0  1 14  5  0  0]
 [ 1  0  0 18  0  1]
 [ 0  0  0  2 18  0]
 [ 0  2  0  0  0 18]]
Epoch: [9]
       [Avg Loss]          0.330350
       [Training]   Prec@1 89.696970 Max 89.696970
       [Avg Loss]          0.634044
       [Validation] Prec@1 80.833333 Max 87.500000
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0 19  0  1  0  0]
 [ 0  1  9 10  0  0]
 [ 2  1  1 16  0  0]
 [ 0  0  0  0 20  0]
 [ 1  3  0  2  0 14]]
Epoch: [10]
       [Avg Loss]          0.224890
       [Training]   Prec@1 91.818182 Max 91.818182
       [Avg Loss]          0.755561
       [Validation] Prec@1 81.666667 Max 87.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 19  0  1  0  0]
 [ 0  1 14  5  0  0]
 [ 4  0  1 15  0  0]
 [ 0  0  0  3 17  0]
 [ 1  6  0  0  0 13]]
Epoch: [11]
       [Avg Loss]          0.209293
       [Training]   Prec@1 93.030303 Max 93.030303
       [Avg Loss]          1.285157
       [Validation] Prec@1 69.166667 Max 87.500000
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0 15  0  5  0  0]
 [ 1  0 13  6  0  0]
 [ 4  0  1 15  0  0]
 [ 0  0  0 10 10  0]
 [ 2  5  0  2  0 11]]
Epoch: [12]
       [Avg Loss]          0.278194
       [Training]   Prec@1 91.363636 Max 93.030303
       [Avg Loss]          0.660584
       [Validation] Prec@1 82.500000 Max 87.500000
Confusion matrix:
[[15  0  0  5  0  0]
 [ 0 19  0  1  0  0]
 [ 0  1 13  6  0  0]
 [ 0  2  0 18  0  0]
 [ 0  0  0  0 20  0]
 [ 1  3  0  1  1 14]]
Epoch: [13]
       [Avg Loss]          0.303843
       [Training]   Prec@1 90.454545 Max 93.030303
       [Avg Loss]          0.485106
       [Validation] Prec@1 87.500000 Max 87.500000
Confusion matrix:
[[18  0  0  2  0  0]
 [ 0 19  0  1  0  0]
 [ 0  1 17  2  0  0]
 [ 1  0  2 17  0  0]
 [ 0  0  0  1 19  0]
 [ 2  0  0  3  0 15]]
Epoch: [14]
       [Avg Loss]          0.244764
       [Training]   Prec@1 92.727273 Max 93.030303
       [Avg Loss]          0.526349
       [Validation] Prec@1 87.500000 Max 87.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 1 17  0  2  0  0]
 [ 0  0 18  2  0  0]
 [ 6  0  0 14  0  0]
 [ 0  0  0  0 20  0]
 [ 0  2  0  2  0 16]]
Fold "3" complete, final accuracy: 87.5
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.319233
       [Training]   Prec@1 48.507463 Max 48.507463
       [Avg Loss]          1.434120
       [Validation] Prec@1 58.181818 Max 58.181818
Confusion matrix:
[[16  3  1  0  0  0]
 [ 9  7  4  0  0  0]
 [ 9  0 10  0  0  1]
 [ 1 11  3  5  0  0]
 [ 0  0  4  0  6  0]
 [ 0  0  0  0  0 20]]
Epoch: [1]
       [Avg Loss]          0.744352
       [Training]   Prec@1 75.522388 Max 75.522388
       [Avg Loss]          1.409897
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[16  1  2  1  0  0]
 [10  6  2  2  0  0]
 [ 8  0  9  0  2  1]
 [ 0 11  2  7  0  0]
 [ 0  0  0  0 10  0]
 [ 0  2  0  0  0 18]]
Epoch: [2]
       [Avg Loss]          0.632907
       [Training]   Prec@1 76.567164 Max 76.567164
       [Avg Loss]          1.323886
       [Validation] Prec@1 70.000000 Max 70.000000
Confusion matrix:
[[15  2  1  2  0  0]
 [ 5  6  3  2  4  0]
 [ 6  0 11  2  0  1]
 [ 0  5  0 15  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [3]
       [Avg Loss]          0.558630
       [Training]   Prec@1 81.044776 Max 81.044776
       [Avg Loss]          1.572526
       [Validation] Prec@1 65.454545 Max 70.000000
Confusion matrix:
[[10  4  1  5  0  0]
 [ 0  8  1  3  8  0]
 [ 4  0 11  3  0  2]
 [ 0  5  2 13  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          0.510908
       [Training]   Prec@1 83.283582 Max 83.283582
       [Avg Loss]          1.540247
       [Validation] Prec@1 70.000000 Max 70.000000
Confusion matrix:
[[17  1  0  2  0  0]
 [ 3  7  1  1  8  0]
 [ 6  0  9  0  4  1]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.403380
       [Training]   Prec@1 85.671642 Max 85.671642
       [Avg Loss]          1.695296
       [Validation] Prec@1 59.090909 Max 70.000000
Confusion matrix:
[[16  2  1  1  0  0]
 [ 0  9  1  6  4  0]
 [ 6  0  3 10  0  1]
 [ 0  5  0 15  0  0]
 [ 0  0  0  0 10  0]
 [ 8  0  0  0  0 12]]
Epoch: [6]
       [Avg Loss]          0.344241
       [Training]   Prec@1 89.104478 Max 89.104478
       [Avg Loss]          1.540511
       [Validation] Prec@1 64.545455 Max 70.000000
Confusion matrix:
[[15  2  0  3  0  0]
 [ 1  8  1  3  6  1]
 [ 5  0  5  4  4  2]
 [ 0  6  0 13  0  1]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [7]
       [Avg Loss]          0.335673
       [Training]   Prec@1 87.462687 Max 89.104478
       [Avg Loss]          1.849183
       [Validation] Prec@1 61.818182 Max 70.000000
Confusion matrix:
[[15  2  0  3  0  0]
 [ 0 11  1  2  6  0]
 [ 6  0  7  7  0  0]
 [ 0  5  0 15  0  0]
 [ 0  0  0  0 10  0]
 [ 9  1  0  0  0 10]]
Epoch: [8]
       [Avg Loss]          0.319974
       [Training]   Prec@1 88.507463 Max 89.104478
       [Avg Loss]          1.767547
       [Validation] Prec@1 64.545455 Max 70.000000
Confusion matrix:
[[15  1  0  4  0  0]
 [ 0  9  1  7  3  0]
 [ 6  0  3 11  0  0]
 [ 0  2  0 18  0  0]
 [ 0  0  0  0 10  0]
 [ 4  0  0  0  0 16]]
Epoch: [9]
       [Avg Loss]          0.318302
       [Training]   Prec@1 89.850746 Max 89.850746
       [Avg Loss]          1.541024
       [Validation] Prec@1 70.000000 Max 70.000000
Confusion matrix:
[[13  3  2  2  0  0]
 [ 0 14  1  1  4  0]
 [ 6  0 12  2  0  0]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 5  0  0  1  0 14]]
Epoch: [10]
       [Avg Loss]          0.316957
       [Training]   Prec@1 89.850746 Max 89.850746
       [Avg Loss]          1.585528
       [Validation] Prec@1 58.181818 Max 70.000000
Confusion matrix:
[[14  0  0  5  1  0]
 [ 1  9  0  7  3  0]
 [ 6  0  0 14  0  0]
 [ 0  1  0 19  0  0]
 [ 0  0  0  2  8  0]
 [ 5  1  0  0  0 14]]
Epoch: [11]
       [Avg Loss]          0.203936
       [Training]   Prec@1 93.731343 Max 93.731343
       [Avg Loss]          1.716545
       [Validation] Prec@1 60.000000 Max 70.000000
Confusion matrix:
[[12  2  0  3  3  0]
 [ 0 11  1  4  4  0]
 [ 6  0 10  3  0  1]
 [ 0  4  0 15  0  1]
 [ 0  0  0  0 10  0]
 [11  0  0  1  0  8]]
Epoch: [12]
       [Avg Loss]          0.257295
       [Training]   Prec@1 92.238806 Max 93.731343
       [Avg Loss]          1.736610
       [Validation] Prec@1 62.727273 Max 70.000000
Confusion matrix:
[[16  1  0  3  0  0]
 [ 1  9  0  5  5  0]
 [ 8  0  0 11  0  1]
 [ 0  3  0 16  0  1]
 [ 0  0  0  0 10  0]
 [ 2  0  0  0  0 18]]
Epoch: [13]
       [Avg Loss]          0.226951
       [Training]   Prec@1 92.835821 Max 93.731343
       [Avg Loss]          1.674505
       [Validation] Prec@1 64.545455 Max 70.000000
Confusion matrix:
[[15  2  1  2  0  0]
 [ 2 11  2  3  2  0]
 [ 7  0 12  1  0  0]
 [ 0  4  0 16  0  0]
 [ 0  0  0  6  4  0]
 [ 5  1  0  1  0 13]]
Epoch: [14]
       [Avg Loss]          0.255200
       [Training]   Prec@1 92.835821 Max 93.731343
       [Avg Loss]          1.761907
       [Validation] Prec@1 64.545455 Max 70.000000
Confusion matrix:
[[15  2  1  2  0  0]
 [ 3 12  1  2  1  1]
 [ 8  0  6  3  2  1]
 [ 0  6  0 13  0  1]
 [ 0  0  0  0 10  0]
 [ 5  0  0  0  0 15]]
Fold "4" complete, final accuracy: 70.0

-----------------------------------------------------------------------
Training for stage 2 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=18)")
Average accuracy is: 79.04354354354355


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 3-----
Evaluated preprocessing: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=18)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.531456
       [Training]   Prec@1 37.166667 Max 37.166667
       [Avg Loss]          1.725611
       [Validation] Prec@1 42.222222 Max 42.222222
Confusion matrix:
[[39  0  1  0  0  0]
 [24  1  5  0  0  0]
 [ 0  0 30  0  0  0]
 [ 9  0 18  0  3  0]
 [ 7  0 17  0  6  0]
 [20  0  0  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.025315
       [Training]   Prec@1 62.333333 Max 62.333333
       [Avg Loss]          1.501898
       [Validation] Prec@1 35.000000 Max 42.222222
Confusion matrix:
[[30  0  0  0  0 10]
 [ 3  8  0  2  0 17]
 [18  5  4  3  0  0]
 [23  4  3  0  0  0]
 [27  0  0  2  1  0]
 [ 0  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          0.829360
       [Training]   Prec@1 71.333333 Max 71.333333
       [Avg Loss]          1.343904
       [Validation] Prec@1 61.666667 Max 61.666667
Confusion matrix:
[[19  0 10  0  1 10]
 [ 0 28  0  2  0  0]
 [ 0  0 30  0  0  0]
 [ 0  9 19  0  2  0]
 [ 0  0 14  0 16  0]
 [ 0  2  0  0  0 18]]
Epoch: [3]
       [Avg Loss]          0.655567
       [Training]   Prec@1 77.000000 Max 77.000000
       [Avg Loss]          1.398781
       [Validation] Prec@1 63.333333 Max 63.333333
Confusion matrix:
[[15  0 11  0  4 10]
 [ 0 29  0  0  0  1]
 [ 0  0 29  0  1  0]
 [ 0  4 16  0 10  0]
 [ 0  0  6  0 24  0]
 [ 0  3  0  0  0 17]]
Epoch: [4]
       [Avg Loss]          0.626731
       [Training]   Prec@1 79.166667 Max 79.166667
       [Avg Loss]          1.475128
       [Validation] Prec@1 51.666667 Max 63.333333
Confusion matrix:
[[ 7  0 12  9  2 10]
 [ 0 13  4 13  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 25  1  4  0]
 [ 0  0  5  0 25  0]
 [ 1  0  2  0  0 17]]
Epoch: [5]
       [Avg Loss]          0.581910
       [Training]   Prec@1 79.666667 Max 79.666667
       [Avg Loss]          1.589307
       [Validation] Prec@1 63.888889 Max 63.888889
Confusion matrix:
[[23  0  6  1  0 10]
 [ 0 28  0  2  0  0]
 [ 0 11 19  0  0  0]
 [ 0 28  2  0  0  0]
 [ 0  2  3  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [6]
       [Avg Loss]          0.556491
       [Training]   Prec@1 80.000000 Max 80.000000
       [Avg Loss]          1.938377
       [Validation] Prec@1 63.333333 Max 63.888889
Confusion matrix:
[[12  0 11  7  0 10]
 [ 0 27  0  3  0  0]
 [ 0  0 30  0  0  0]
 [ 0  9 19  2  0  0]
 [ 0  0  6  1 23  0]
 [ 0  0  0  0  0 20]]
Epoch: [7]
       [Avg Loss]          0.529972
       [Training]   Prec@1 81.500000 Max 81.500000
       [Avg Loss]          1.514415
       [Validation] Prec@1 58.333333 Max 63.888889
Confusion matrix:
[[14  0  5  0 11 10]
 [ 0 17  4  9  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 19  0 11  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  1  0 19]]
Epoch: [8]
       [Avg Loss]          0.582359
       [Training]   Prec@1 79.666667 Max 81.500000
       [Avg Loss]          1.882101
       [Validation] Prec@1 61.666667 Max 63.888889
Confusion matrix:
[[14  0 11  3  2 10]
 [ 0 23  3  2  0  2]
 [ 0  0 30  0  0  0]
 [ 0  2 23  2  3  0]
 [ 0  0  5  0 25  0]
 [ 0  0  3  0  0 17]]
Epoch: [9]
       [Avg Loss]          0.481371
       [Training]   Prec@1 83.000000 Max 83.000000
       [Avg Loss]          1.537087
       [Validation] Prec@1 70.555556 Max 70.555556
Confusion matrix:
[[29  0  1  0  0 10]
 [ 1 26  3  0  0  0]
 [ 0  0 30  0  0  0]
 [ 6  1 22  0  1  0]
 [ 3  0  5  0 22  0]
 [ 0  0  0  0  0 20]]
Epoch: [10]
       [Avg Loss]          0.431130
       [Training]   Prec@1 85.500000 Max 85.500000
       [Avg Loss]          1.815870
       [Validation] Prec@1 51.666667 Max 70.555556
Confusion matrix:
[[10  0  8  9  3 10]
 [ 0 10  5 14  1  0]
 [ 0  0 30  0  0  0]
 [ 0  0 22  0  8  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  2  0 18]]
Epoch: [11]
       [Avg Loss]          0.424373
       [Training]   Prec@1 85.333333 Max 85.500000
       [Avg Loss]          1.563076
       [Validation] Prec@1 65.000000 Max 70.555556
Confusion matrix:
[[19  0 11  0  0 10]
 [ 0 29  0  1  0  0]
 [ 0  2 28  0  0  0]
 [ 0  6 22  0  2  0]
 [ 0  0  7  0 23  0]
 [ 0  0  2  0  0 18]]
Epoch: [12]
       [Avg Loss]          0.403158
       [Training]   Prec@1 86.333333 Max 86.333333
       [Avg Loss]          1.497188
       [Validation] Prec@1 66.111111 Max 70.555556
Confusion matrix:
[[16  0  8  6  0 10]
 [ 0 28  1  1  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 23  4  2  0]
 [ 0  0  5  0 25  0]
 [ 0  0  2  2  0 16]]
Epoch: [13]
       [Avg Loss]          0.417956
       [Training]   Prec@1 86.166667 Max 86.333333
       [Avg Loss]          2.130580
       [Validation] Prec@1 65.000000 Max 70.555556
Confusion matrix:
[[29  0  1  0  0 10]
 [ 0 16 13  1  0  0]
 [ 0  0 30  0  0  0]
 [ 3  0 27  0  0  0]
 [ 1  0  7  0 22  0]
 [ 0  0  0  0  0 20]]
Epoch: [14]
       [Avg Loss]          0.451059
       [Training]   Prec@1 83.500000 Max 86.333333
       [Avg Loss]          1.992353
       [Validation] Prec@1 48.888889 Max 70.555556
Confusion matrix:
[[ 2  0  1  3 25  9]
 [ 0 11  0 19  0  0]
 [ 0  0 27  3  0  0]
 [ 0  0 10  5 15  0]
 [ 0  0  3  0 27  0]
 [ 0  0  0  4  0 16]]
Fold "0" complete, final accuracy: 70.55555555555556
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.676179
       [Training]   Prec@1 32.941176 Max 32.941176
       [Avg Loss]          1.753695
       [Validation] Prec@1 20.000000 Max 20.000000
Confusion matrix:
[[ 0 30  0  0  0  0]
 [ 0 35  0  0  0  0]
 [ 0 30  0  0  0  0]
 [ 1 29  0  0  0  0]
 [ 0 30  0  0  0  0]
 [ 0 28  0  0  0  2]]
Epoch: [1]
       [Avg Loss]          1.159265
       [Training]   Prec@1 56.806723 Max 56.806723
       [Avg Loss]          1.414370
       [Validation] Prec@1 61.081081 Max 61.081081
Confusion matrix:
[[22  4  1  0  3  0]
 [ 1 26  7  1  0  0]
 [ 1  1 27  0  1  0]
 [ 5  0  7  5 13  0]
 [ 0  0  6  1 23  0]
 [13  3  1  3  0 10]]
Epoch: [2]
       [Avg Loss]          0.891276
       [Training]   Prec@1 71.092437 Max 71.092437
       [Avg Loss]          1.485351
       [Validation] Prec@1 34.054054 Max 61.081081
Confusion matrix:
[[28  0  0  0  0  2]
 [15 12  0  1  0  7]
 [29  0  1  0  0  0]
 [30  0  0  0  0  0]
 [25  0  0  0  5  0]
 [13  0  0  0  0 17]]
Epoch: [3]
       [Avg Loss]          0.793594
       [Training]   Prec@1 72.605042 Max 72.605042
       [Avg Loss]          1.176824
       [Validation] Prec@1 56.756757 Max 61.081081
Confusion matrix:
[[25  0  3  1  0  1]
 [ 2  7 26  0  0  0]
 [ 0  0 30  0  0  0]
 [ 6  0 11 12  0  1]
 [ 9  0  2  9 10  0]
 [ 6  0  2  1  0 21]]
Epoch: [4]
       [Avg Loss]          0.677392
       [Training]   Prec@1 77.142857 Max 77.142857
       [Avg Loss]          0.833436
       [Validation] Prec@1 69.729730 Max 69.729730
Confusion matrix:
[[14  7  9  0  0  0]
 [ 0 32  3  0  0  0]
 [ 0  4 26  0  0  0]
 [ 1  1 10  7  9  2]
 [ 2  0  0  0 28  0]
 [ 0  4  1  2  1 22]]
Epoch: [5]
       [Avg Loss]          0.669853
       [Training]   Prec@1 78.991597 Max 78.991597
       [Avg Loss]          1.089623
       [Validation] Prec@1 62.162162 Max 69.729730
Confusion matrix:
[[16  3  0  4  0  7]
 [ 0 33  1  0  0  1]
 [ 0 12  2 16  0  0]
 [ 0  2  0 23  1  4]
 [ 3  4  0  9 14  0]
 [ 1  2  0  0  0 27]]
Epoch: [6]
       [Avg Loss]          0.629277
       [Training]   Prec@1 77.647059 Max 78.991597
       [Avg Loss]          1.424478
       [Validation] Prec@1 56.756757 Max 69.729730
Confusion matrix:
[[29  0  0  1  0  0]
 [10  8 13  3  1  0]
 [13  0 17  0  0  0]
 [ 9  0  2  7 12  0]
 [ 1  0  0  0 29  0]
 [ 4  0  0  8  3 15]]
Epoch: [7]
       [Avg Loss]          0.566962
       [Training]   Prec@1 80.504202 Max 80.504202
       [Avg Loss]          0.917286
       [Validation] Prec@1 69.189189 Max 69.729730
Confusion matrix:
[[19  3  7  0  0  1]
 [ 0 30  5  0  0  0]
 [ 0  2 28  0  0  0]
 [ 1  1 10 11  0  7]
 [ 7  7  0  1 15  0]
 [ 1  3  1  0  0 25]]
Epoch: [8]
       [Avg Loss]          0.562054
       [Training]   Prec@1 81.344538 Max 81.344538
       [Avg Loss]          1.502778
       [Validation] Prec@1 63.243243 Max 69.729730
Confusion matrix:
[[13  5 11  0  0  1]
 [ 0 33  2  0  0  0]
 [ 0  6 24  0  0  0]
 [ 0  2 12  5 11  0]
 [ 0  8  0  0 22  0]
 [ 5  2  1  1  1 20]]
Epoch: [9]
       [Avg Loss]          0.566992
       [Training]   Prec@1 79.831933 Max 81.344538
       [Avg Loss]          0.736245
       [Validation] Prec@1 76.216216 Max 76.216216
Confusion matrix:
[[24  4  1  1  0  0]
 [ 1 33  1  0  0  0]
 [ 0  9 20  1  0  0]
 [ 2  2  6 13  7  0]
 [ 2  0  0  1 27  0]
 [ 1  2  1  2  0 24]]
Epoch: [10]
       [Avg Loss]          0.508734
       [Training]   Prec@1 81.848739 Max 81.848739
       [Avg Loss]          0.736851
       [Validation] Prec@1 76.216216 Max 76.216216
Confusion matrix:
[[24  4  0  1  0  1]
 [ 0 32  2  0  0  1]
 [ 0  5 24  1  0  0]
 [ 2  1  2 21  0  4]
 [ 2  7  0  5 16  0]
 [ 1  3  0  1  1 24]]
Epoch: [11]
       [Avg Loss]          0.406326
       [Training]   Prec@1 87.563025 Max 87.563025
       [Avg Loss]          0.826118
       [Validation] Prec@1 76.216216 Max 76.216216
Confusion matrix:
[[24  3  2  0  1  0]
 [ 5 27  3  0  0  0]
 [ 0  0 30  0  0  0]
 [11  0  5 14  0  0]
 [ 5  0  0  1 24  0]
 [ 3  2  0  2  1 22]]
Epoch: [12]
       [Avg Loss]          0.430562
       [Training]   Prec@1 84.537815 Max 87.563025
       [Avg Loss]          0.944771
       [Validation] Prec@1 74.054054 Max 76.216216
Confusion matrix:
[[23  3  0  1  0  3]
 [ 1 34  0  0  0  0]
 [ 1  7 22  0  0  0]
 [ 4  1  0 19  2  4]
 [ 4  8  0  4 14  0]
 [ 3  2  0  0  0 25]]
Epoch: [13]
       [Avg Loss]          0.329686
       [Training]   Prec@1 89.915966 Max 89.915966
       [Avg Loss]          1.028477
       [Validation] Prec@1 75.135135 Max 76.216216
Confusion matrix:
[[23  4  2  1  0  0]
 [ 1 34  0  0  0  0]
 [ 0  8 19  3  0  0]
 [ 0  4  2 21  1  2]
 [ 3  8  0  1 18  0]
 [ 2  3  0  1  0 24]]
Epoch: [14]
       [Avg Loss]          0.349191
       [Training]   Prec@1 88.235294 Max 89.915966
       [Avg Loss]          1.105040
       [Validation] Prec@1 70.270270 Max 76.216216
Confusion matrix:
[[26  0  4  0  0  0]
 [11 20  3  1  0  0]
 [ 0  0 30  0  0  0]
 [11  0  6 11  1  1]
 [ 9  0  0  0 21  0]
 [ 7  0  0  1  0 22]]
Fold "1" complete, final accuracy: 76.21621621621621
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.642488
       [Training]   Prec@1 33.949580 Max 33.949580
       [Avg Loss]          1.730586
       [Validation] Prec@1 16.756757 Max 16.756757
Confusion matrix:
[[ 0  0  0  0 30  0]
 [ 0  0  0  0 35  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 29  1]]
Epoch: [1]
       [Avg Loss]          1.099872
       [Training]   Prec@1 59.831933 Max 59.831933
       [Avg Loss]          1.440335
       [Validation] Prec@1 53.513514 Max 53.513514
Confusion matrix:
[[10  1  0  1 18  0]
 [ 0 29  0  0  5  1]
 [ 4  0  5  4 17  0]
 [ 0  1  0  5 24  0]
 [ 0  0  0  0 30  0]
 [ 0  9  0  0  1 20]]
Epoch: [2]
       [Avg Loss]          0.946016
       [Training]   Prec@1 66.554622 Max 66.554622
       [Avg Loss]          1.188986
       [Validation] Prec@1 58.378378 Max 58.378378
Confusion matrix:
[[21  0  0  0  9  0]
 [ 3 21  0  1 10  0]
 [ 7  0  4  6 13  0]
 [ 1  0  0  4 21  4]
 [ 0  0  0  0 30  0]
 [ 0  2  0  0  0 28]]
Epoch: [3]
       [Avg Loss]          0.808885
       [Training]   Prec@1 70.420168 Max 70.420168
       [Avg Loss]          1.220568
       [Validation] Prec@1 51.351351 Max 58.378378
Confusion matrix:
[[ 8  7  0  0  0 15]
 [ 0 29  0  0  0  6]
 [ 0 10  0  8  0 12]
 [ 0 16  0  8  6  0]
 [ 0  6  0  4 20  0]
 [ 0  0  0  0  0 30]]
Epoch: [4]
       [Avg Loss]          0.757873
       [Training]   Prec@1 73.949580 Max 73.949580
       [Avg Loss]          2.150982
       [Validation] Prec@1 36.216216 Max 58.378378
Confusion matrix:
[[ 9  1  0  2 18  0]
 [ 1  7  0  0 27  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  2 27  1]
 [ 0  0  0  0 30  0]
 [ 3 13  0  0  0 14]]
Epoch: [5]
       [Avg Loss]          0.714985
       [Training]   Prec@1 74.957983 Max 74.957983
       [Avg Loss]          1.899755
       [Validation] Prec@1 35.675676 Max 58.378378
Confusion matrix:
[[30  0  0  0  0  0]
 [35  0  0  0  0  0]
 [30  0  0  0  0  0]
 [21  0  0  6  0  3]
 [23  0  0  0  7  0]
 [ 7  0  0  0  0 23]]
Epoch: [6]
       [Avg Loss]          0.625193
       [Training]   Prec@1 79.663866 Max 79.663866
       [Avg Loss]          1.026593
       [Validation] Prec@1 69.729730 Max 69.729730
Confusion matrix:
[[16  5  0  5  4  0]
 [ 0 32  0  0  0  3]
 [ 0  0 10 20  0  0]
 [ 0  6  1 21  2  0]
 [ 0  0  0 10 20  0]
 [ 0  0  0  0  0 30]]
Epoch: [7]
       [Avg Loss]          0.573843
       [Training]   Prec@1 80.336134 Max 80.336134
       [Avg Loss]          1.541699
       [Validation] Prec@1 54.594595 Max 69.729730
Confusion matrix:
[[27  0  0  0  3  0]
 [25  3  0  6  0  1]
 [15  0  0 15  0  0]
 [ 2  0  0 27  1  0]
 [10  0  0  1 19  0]
 [ 5  0  0  0  0 25]]
Epoch: [8]
       [Avg Loss]          0.532328
       [Training]   Prec@1 82.184874 Max 82.184874
       [Avg Loss]          0.896235
       [Validation] Prec@1 76.756757 Max 76.756757
Confusion matrix:
[[18  4  0  1  7  0]
 [ 0 34  0  0  0  1]
 [ 0  0 18  5  7  0]
 [ 0  3  0 16 11  0]
 [ 0  0  0  0 30  0]
 [ 1  3  0  0  0 26]]
Epoch: [9]
       [Avg Loss]          0.506475
       [Training]   Prec@1 83.529412 Max 83.529412
       [Avg Loss]          0.622096
       [Validation] Prec@1 80.540541 Max 80.540541
Confusion matrix:
[[22  6  1  0  1  0]
 [ 0 33  0  1  0  1]
 [ 0  0 20  9  0  1]
 [ 0  0  1 27  0  2]
 [ 7  0  0  4 19  0]
 [ 2  0  0  0  0 28]]
Epoch: [10]
       [Avg Loss]          0.443691
       [Training]   Prec@1 84.537815 Max 84.537815
       [Avg Loss]          0.605377
       [Validation] Prec@1 84.864865 Max 84.864865
Confusion matrix:
[[19  3  1  1  6  0]
 [ 0 33  0  1  0  1]
 [ 0  0 24  6  0  0]
 [ 0  0  3 27  0  0]
 [ 0  0  1  5 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [11]
       [Avg Loss]          0.437156
       [Training]   Prec@1 83.865546 Max 84.537815
       [Avg Loss]          1.235010
       [Validation] Prec@1 68.648649 Max 84.864865
Confusion matrix:
[[25  1  0  0  3  1]
 [ 3 21  0  1  0 10]
 [ 1  1  9 14  1  4]
 [ 0  2  0 18  7  3]
 [ 3  0  0  3 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [12]
       [Avg Loss]          0.391388
       [Training]   Prec@1 85.882353 Max 85.882353
       [Avg Loss]          0.739905
       [Validation] Prec@1 76.756757 Max 84.864865
Confusion matrix:
[[22  3  0  0  5  0]
 [ 3 32  0  0  0  0]
 [ 0  2 22  6  0  0]
 [ 0  0  0 20 10  0]
 [ 1  0  0  0 29  0]
 [ 5  8  0  0  0 17]]
Epoch: [13]
       [Avg Loss]          0.419199
       [Training]   Prec@1 86.386555 Max 86.386555
       [Avg Loss]          0.697819
       [Validation] Prec@1 77.837838 Max 84.864865
Confusion matrix:
[[22  1  0  4  3  0]
 [ 8 21  0  1  0  5]
 [ 0  0 20 10  0  0]
 [ 0  0  1 29  0  0]
 [ 4  0  0  4 22  0]
 [ 0  0  0  0  0 30]]
Epoch: [14]
       [Avg Loss]          0.366322
       [Training]   Prec@1 88.067227 Max 88.067227
       [Avg Loss]          0.946606
       [Validation] Prec@1 74.594595 Max 84.864865
Confusion matrix:
[[15 10  1  0  4  0]
 [ 0 35  0  0  0  0]
 [ 0  0 29  1  0  0]
 [ 4  4  2 15  5  0]
 [ 1  0  0  1 28  0]
 [ 7  7  0  0  0 16]]
Fold "2" complete, final accuracy: 84.86486486486487
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.608062
       [Training]   Prec@1 37.121212 Max 37.121212
       [Avg Loss]          1.717739
       [Validation] Prec@1 20.000000 Max 20.000000
Confusion matrix:
[[20  0  0  0  0  0]
 [19  0  0  1  0  0]
 [19  0  1  0  0  0]
 [17  0  0  3  0  0]
 [10  0  3  7  0  0]
 [20  0  0  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.080915
       [Training]   Prec@1 61.969697 Max 61.969697
       [Avg Loss]          1.275152
       [Validation] Prec@1 67.500000 Max 67.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 17  0  1  1  1]
 [ 8  3  1  4  4  0]
 [12  0  0  7  0  1]
 [ 0  0  0  0 20  0]
 [ 1  2  0  1  0 16]]
Epoch: [2]
       [Avg Loss]          0.894759
       [Training]   Prec@1 67.727273 Max 67.727273
       [Avg Loss]          1.094704
       [Validation] Prec@1 60.833333 Max 67.500000
Confusion matrix:
[[15  0  5  0  0  0]
 [ 4  2 12  1  0  1]
 [ 0  0 19  1  0  0]
 [ 2  0  5 12  0  1]
 [ 0  0  5  6  9  0]
 [ 3  0  1  0  0 16]]
Epoch: [3]
       [Avg Loss]          0.777725
       [Training]   Prec@1 73.787879 Max 73.787879
       [Avg Loss]          1.156790
       [Validation] Prec@1 56.666667 Max 67.500000
Confusion matrix:
[[15  0  5  0  0  0]
 [ 0  4  0 16  0  0]
 [ 0  0  9 11  0  0]
 [ 2  0  1 16  1  0]
 [ 0  0  0  9 11  0]
 [ 0  2  0  4  1 13]]
Epoch: [4]
       [Avg Loss]          0.752768
       [Training]   Prec@1 74.393939 Max 74.393939
       [Avg Loss]          1.226859
       [Validation] Prec@1 60.833333 Max 67.500000
Confusion matrix:
[[ 8  0 10  2  0  0]
 [ 0 15  1  4  0  0]
 [ 0  0 12  8  0  0]
 [ 0  0  3 17  0  0]
 [ 0  0  0 15  5  0]
 [ 0  3  0  1  0 16]]
Epoch: [5]
       [Avg Loss]          0.675727
       [Training]   Prec@1 77.575758 Max 77.575758
       [Avg Loss]          1.608342
       [Validation] Prec@1 51.666667 Max 67.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 12  1  1  6  0]
 [ 2  0  4  0 14  0]
 [11  0  0  1  8  0]
 [ 0  0  0  0 20  0]
 [12  2  0  1  0  5]]
Epoch: [6]
       [Avg Loss]          0.709121
       [Training]   Prec@1 75.303030 Max 77.575758
       [Avg Loss]          0.958699
       [Validation] Prec@1 65.833333 Max 67.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 15  0  4  0  1]
 [ 1  3  2 14  0  0]
 [ 1  2  0 15  1  1]
 [ 0  6  0  1 13  0]
 [ 0  5  0  1  0 14]]
Epoch: [7]
       [Avg Loss]          0.683284
       [Training]   Prec@1 76.666667 Max 77.575758
       [Avg Loss]          0.955390
       [Validation] Prec@1 73.333333 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 13  2  5  0  0]
 [ 0  0 14  6  0  0]
 [ 1  0  2 17  0  0]
 [ 0  0  4  7  9  0]
 [ 0  3  0  2  0 15]]
Epoch: [8]
       [Avg Loss]          0.586592
       [Training]   Prec@1 80.454545 Max 80.454545
       [Avg Loss]          1.416524
       [Validation] Prec@1 51.666667 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [12  3  4  1  0  0]
 [ 7  0 10  3  0  0]
 [15  0  0  4  0  1]
 [ 0  0  0  0 20  0]
 [14  0  1  0  0  5]]
Epoch: [9]
       [Avg Loss]          0.549949
       [Training]   Prec@1 80.606061 Max 80.606061
       [Avg Loss]          0.854927
       [Validation] Prec@1 73.333333 Max 73.333333
Confusion matrix:
[[11  0  8  1  0  0]
 [ 0 17  1  2  0  0]
 [ 0  1 13  5  1  0]
 [ 1  1  0 18  0  0]
 [ 0  0  0  3 17  0]
 [ 0  6  1  1  0 12]]
Epoch: [10]
       [Avg Loss]          0.501787
       [Training]   Prec@1 83.333333 Max 83.333333
       [Avg Loss]          1.028382
       [Validation] Prec@1 65.833333 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 12  0  5  0  3]
 [ 3  0  1 16  0  0]
 [ 5  0  0 13  0  2]
 [ 0  0  0  3 17  0]
 [ 0  4  0  0  0 16]]
Epoch: [11]
       [Avg Loss]          0.498957
       [Training]   Prec@1 83.333333 Max 83.333333
       [Avg Loss]          0.962758
       [Validation] Prec@1 66.666667 Max 73.333333
Confusion matrix:
[[ 9  0 10  1  0  0]
 [ 0 17  2  1  0  0]
 [ 0  0 13  7  0  0]
 [ 0  1  5 12  0  2]
 [ 0  0  0  7 13  0]
 [ 0  4  0  0  0 16]]
Epoch: [12]
       [Avg Loss]          0.464005
       [Training]   Prec@1 84.545455 Max 84.545455
       [Avg Loss]          1.714180
       [Validation] Prec@1 57.500000 Max 73.333333
Confusion matrix:
[[ 3  0  8  3  6  0]
 [ 0 17  1  1  1  0]
 [ 0  0  8  8  4  0]
 [ 0  1  0 16  3  0]
 [ 0  0  0  0 20  0]
 [ 0  7  0  8  0  5]]
Epoch: [13]
       [Avg Loss]          0.471503
       [Training]   Prec@1 84.848485 Max 84.848485
       [Avg Loss]          0.728269
       [Validation] Prec@1 74.166667 Max 74.166667
Confusion matrix:
[[19  0  0  1  0  0]
 [ 1 13  0  1  0  5]
 [ 3  0  8  9  0  0]
 [ 5  0  0 13  0  2]
 [ 0  0  0  0 20  0]
 [ 2  2  0  0  0 16]]
Epoch: [14]
       [Avg Loss]          0.423365
       [Training]   Prec@1 85.606061 Max 85.606061
       [Avg Loss]          0.681707
       [Validation] Prec@1 82.500000 Max 82.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 19  0  1  0  0]
 [ 1  0 12  7  0  0]
 [ 5  1  0 14  0  0]
 [ 0  0  0  0 20  0]
 [ 0  6  0  0  0 14]]
Fold "3" complete, final accuracy: 82.5
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.532327
       [Training]   Prec@1 38.358209 Max 38.358209
       [Avg Loss]          1.725250
       [Validation] Prec@1 16.363636 Max 16.363636
Confusion matrix:
[[ 0  3 17  0  0  0]
 [ 0  0 20  0  0  0]
 [ 0  2 18  0  0  0]
 [ 0  0 20  0  0  0]
 [ 0  0  8  2  0  0]
 [ 0 12  8  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.073112
       [Training]   Prec@1 60.746269 Max 60.746269
       [Avg Loss]          1.620463
       [Validation] Prec@1 42.727273 Max 42.727273
Confusion matrix:
[[20  0  0  0  0  0]
 [10  0  4  6  0  0]
 [10  0 10  0  0  0]
 [ 0  0  5 15  0  0]
 [ 7  0  0  1  2  0]
 [20  0  0  0  0  0]]
Epoch: [2]
       [Avg Loss]          0.780917
       [Training]   Prec@1 72.686567 Max 72.686567
       [Avg Loss]          2.044475
       [Validation] Prec@1 30.909091 Max 42.727273
Confusion matrix:
[[20  0  0  0  0  0]
 [12  0  0  0  5  3]
 [15  0  0  0  5  0]
 [17  2  0  0  0  1]
 [ 0  0  0  0 10  0]
 [16  0  0  0  0  4]]
Epoch: [3]
       [Avg Loss]          0.680794
       [Training]   Prec@1 74.179104 Max 74.179104
       [Avg Loss]          1.521553
       [Validation] Prec@1 47.272727 Max 47.272727
Confusion matrix:
[[ 4  3  9  2  2  0]
 [ 0  9 11  0  0  0]
 [ 3  1 16  0  0  0]
 [ 0  5 10  5  0  0]
 [ 0  0  1  0  9  0]
 [ 0  8  2  1  0  9]]
Epoch: [4]
       [Avg Loss]          0.625125
       [Training]   Prec@1 78.805970 Max 78.805970
       [Avg Loss]          1.344295
       [Validation] Prec@1 66.363636 Max 66.363636
Confusion matrix:
[[16  1  1  0  1  1]
 [ 3 10  1  1  5  0]
 [ 6  1  6  0  5  2]
 [ 0  8  1 11  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.548711
       [Training]   Prec@1 80.746269 Max 80.746269
       [Avg Loss]          1.967011
       [Validation] Prec@1 57.272727 Max 66.363636
Confusion matrix:
[[17  0  0  0  0  3]
 [ 9  6  0  2  1  2]
 [ 9  1  0  7  2  1]
 [ 0  4  0 10  0  6]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [6]
       [Avg Loss]          0.533454
       [Training]   Prec@1 81.641791 Max 81.641791
       [Avg Loss]          2.282758
       [Validation] Prec@1 41.818182 Max 66.363636
Confusion matrix:
[[ 0  5  0  1 14  0]
 [ 0 10  0  1  9  0]
 [ 0  3  8  3  6  0]
 [ 0  5  0 15  0  0]
 [ 0  0  0  0 10  0]
 [ 0  5  0 11  1  3]]
Epoch: [7]
       [Avg Loss]          0.453605
       [Training]   Prec@1 83.731343 Max 83.731343
       [Avg Loss]          1.970974
       [Validation] Prec@1 50.000000 Max 66.363636
Confusion matrix:
[[16  0  3  1  0  0]
 [ 9  1  3  7  0  0]
 [ 7  0 11  2  0  0]
 [ 0  2  8 10  0  0]
 [ 0  0  0  1  9  0]
 [11  0  0  1  0  8]]
Epoch: [8]
       [Avg Loss]          0.458323
       [Training]   Prec@1 83.283582 Max 83.731343
       [Avg Loss]          1.090888
       [Validation] Prec@1 70.909091 Max 70.909091
Confusion matrix:
[[12  3  4  1  0  0]
 [ 0 15  1  1  3  0]
 [ 3  0 15  0  0  2]
 [ 0  6  1 13  0  0]
 [ 0  0  0  5  5  0]
 [ 0  1  0  1  0 18]]
Epoch: [9]
       [Avg Loss]          0.442325
       [Training]   Prec@1 84.477612 Max 84.477612
       [Avg Loss]          1.965454
       [Validation] Prec@1 55.454545 Max 70.909091
Confusion matrix:
[[16  0  1  0  3  0]
 [ 7  6  1  0  6  0]
 [10  0  5  0  5  0]
 [ 0  2  1 17  0  0]
 [ 0  0  0  0 10  0]
 [11  0  0  2  0  7]]
Epoch: [10]
       [Avg Loss]          0.458080
       [Training]   Prec@1 85.074627 Max 85.074627
       [Avg Loss]          1.597407
       [Validation] Prec@1 61.818182 Max 70.909091
Confusion matrix:
[[11  7  0  0  1  1]
 [ 2 16  1  0  1  0]
 [ 5  7  6  0  0  2]
 [ 0 15  0  5  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [11]
       [Avg Loss]          0.383453
       [Training]   Prec@1 85.970149 Max 85.970149
       [Avg Loss]          3.159012
       [Validation] Prec@1 35.454545 Max 70.909091
Confusion matrix:
[[ 4  0  0  3 13  0]
 [ 0  1  0  2 17  0]
 [ 4  0  6  3  7  0]
 [ 0  0  0 18  2  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0 20  0  0]]
Epoch: [12]
       [Avg Loss]          0.409953
       [Training]   Prec@1 86.119403 Max 86.119403
       [Avg Loss]          1.419708
       [Validation] Prec@1 67.272727 Max 70.909091
Confusion matrix:
[[17  1  2  0  0  0]
 [10  7  1  1  1  0]
 [ 6  0 13  0  0  1]
 [ 0  5  4 11  0  0]
 [ 0  0  0  1  9  0]
 [ 3  0  0  0  0 17]]
Epoch: [13]
       [Avg Loss]          0.333965
       [Training]   Prec@1 88.656716 Max 88.656716
       [Avg Loss]          1.340949
       [Validation] Prec@1 60.909091 Max 70.909091
Confusion matrix:
[[12  1  4  3  0  0]
 [ 3  8  5  3  1  0]
 [ 5  0 12  0  0  3]
 [ 0  3  1 14  0  2]
 [ 0  0  0  9  1  0]
 [ 0  0  0  0  0 20]]
Epoch: [14]
       [Avg Loss]          0.407114
       [Training]   Prec@1 84.626866 Max 88.656716
       [Avg Loss]          1.907870
       [Validation] Prec@1 55.454545 Max 70.909091
Confusion matrix:
[[17  0  0  3  0  0]
 [10  5  0  4  1  0]
 [ 8  0 10  1  1  0]
 [ 0  4  0 16  0  0]
 [ 0  0  0  0 10  0]
 [10  0  0  7  0  3]]
Fold "4" complete, final accuracy: 70.9090909090909

-----------------------------------------------------------------------
Training for stage 3 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=18)")
Average accuracy is: 77.00914550914551


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 4-----
Evaluated preprocessing: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=18)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.510393
       [Training]   Prec@1 39.333333 Max 39.333333
       [Avg Loss]          1.690964
       [Validation] Prec@1 20.555556 Max 20.555556
Confusion matrix:
[[ 1 14  0 23  0  2]
 [ 0 30  0  0  0  0]
 [ 0 28  0  2  0  0]
 [ 0 30  0  0  0  0]
 [ 0 25  0  5  0  0]
 [ 0 14  0  0  0  6]]
Epoch: [1]
       [Avg Loss]          1.033896
       [Training]   Prec@1 62.666667 Max 62.666667
       [Avg Loss]          1.435681
       [Validation] Prec@1 49.444444 Max 49.444444
Confusion matrix:
[[30  0  0  0  1  9]
 [ 9 11  0  1  0  9]
 [21  1  8  0  0  0]
 [21  6  3  0  0  0]
 [ 9  0  0  0 21  0]
 [ 1  0  0  0  0 19]]
Epoch: [2]
       [Avg Loss]          0.871036
       [Training]   Prec@1 70.500000 Max 70.500000
       [Avg Loss]          1.999253
       [Validation] Prec@1 30.000000 Max 49.444444
Confusion matrix:
[[ 4  0  0  4  0 32]
 [ 0 30  0  0  0  0]
 [ 0 19  0  0  0 11]
 [ 0 21  0  0  0  9]
 [ 0  8  0 19  0  3]
 [ 0  0  0  0  0 20]]
Epoch: [3]
       [Avg Loss]          0.725692
       [Training]   Prec@1 75.666667 Max 75.666667
       [Avg Loss]          2.521858
       [Validation] Prec@1 35.555556 Max 49.444444
Confusion matrix:
[[ 6  0  0  0 24 10]
 [ 0 13  0  2 15  0]
 [ 0  0  1  0 29  0]
 [ 1  0  0  0 29  0]
 [ 0  0  0  0 30  0]
 [ 5  0  0  1  0 14]]
Epoch: [4]
       [Avg Loss]          0.614152
       [Training]   Prec@1 81.333333 Max 81.333333
       [Avg Loss]          2.415227
       [Validation] Prec@1 33.888889 Max 49.444444
Confusion matrix:
[[ 0  0  0 14  0 26]
 [ 0  6  0  9  0 15]
 [ 0  1  9 20  0  0]
 [ 0  2  2 26  0  0]
 [ 0  1  0 29  0  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.694155
       [Training]   Prec@1 76.166667 Max 81.333333
       [Avg Loss]          1.079383
       [Validation] Prec@1 72.777778 Max 72.777778
Confusion matrix:
[[30  0  0  0  0 10]
 [ 0 28  0  2  0  0]
 [ 0  0 30  0  0  0]
 [ 3  0 27  0  0  0]
 [ 7  0  0  0 23  0]
 [ 0  0  0  0  0 20]]
Epoch: [6]
       [Avg Loss]          0.608590
       [Training]   Prec@1 78.666667 Max 81.333333
       [Avg Loss]          1.661105
       [Validation] Prec@1 58.888889 Max 72.777778
Confusion matrix:
[[ 9  0 11 10  0 10]
 [ 0 23  0  7  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 29  0  1  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  1  0 19]]
Epoch: [7]
       [Avg Loss]          0.542950
       [Training]   Prec@1 81.500000 Max 81.500000
       [Avg Loss]          1.552624
       [Validation] Prec@1 72.222222 Max 72.777778
Confusion matrix:
[[27  0  3  0  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  2 26  0  2  0]
 [ 0  0  5  0 25  0]
 [ 0  1  1  0  0 18]]
Epoch: [8]
       [Avg Loss]          0.553271
       [Training]   Prec@1 82.166667 Max 82.166667
       [Avg Loss]          1.436438
       [Validation] Prec@1 67.222222 Max 72.777778
Confusion matrix:
[[25  0  3  2  0 10]
 [ 0 30  0  0  0  0]
 [ 0  3 27  0  0  0]
 [ 0  7 11  0 12  0]
 [ 0  4  0  0 26  0]
 [ 0  7  0  0  0 13]]
Epoch: [9]
       [Avg Loss]          0.479887
       [Training]   Prec@1 84.000000 Max 84.000000
       [Avg Loss]          1.861866
       [Validation] Prec@1 60.000000 Max 72.777778
Confusion matrix:
[[ 9  0  8 13  0 10]
 [ 0 27  1  2  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  3  0 17]]
Epoch: [10]
       [Avg Loss]          0.449370
       [Training]   Prec@1 85.666667 Max 85.666667
       [Avg Loss]          3.413213
       [Validation] Prec@1 38.333333 Max 72.777778
Confusion matrix:
[[13  0  0  0 17 10]
 [ 0  1  0  1 28  0]
 [ 0  0  9  0 21  0]
 [ 0  0  2  0 28  0]
 [ 0  0  0  0 30  0]
 [ 2  0  0  2  0 16]]
Epoch: [11]
       [Avg Loss]          0.446219
       [Training]   Prec@1 85.666667 Max 85.666667
       [Avg Loss]          2.098079
       [Validation] Prec@1 51.111111 Max 72.777778
Confusion matrix:
[[24  0  0  0  0 16]
 [ 0 28  0  0  0  2]
 [ 0 12 16  2  0  0]
 [ 0 25  1  4  0  0]
 [ 4 26  0  0  0  0]
 [ 0  0  0  0  0 20]]
Epoch: [12]
       [Avg Loss]          0.473501
       [Training]   Prec@1 84.666667 Max 85.666667
       [Avg Loss]          1.630200
       [Validation] Prec@1 60.000000 Max 72.777778
Confusion matrix:
[[12  0 12  6  0 10]
 [ 0 29  0  1  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 28  1  0  0]
 [ 0  0  5  0 25  0]
 [ 0  0  7  2  0 11]]
Epoch: [13]
       [Avg Loss]          0.448682
       [Training]   Prec@1 86.166667 Max 86.166667
       [Avg Loss]          1.568654
       [Validation] Prec@1 66.111111 Max 72.777778
Confusion matrix:
[[30  0  0  0  0 10]
 [ 3 24  0  3  0  0]
 [ 1  0 18  0 11  0]
 [ 2  1  2  1 24  0]
 [ 3  0  0  0 27  0]
 [ 1  0  0  0  0 19]]
Epoch: [14]
       [Avg Loss]          0.422496
       [Training]   Prec@1 85.500000 Max 86.166667
       [Avg Loss]          1.845118
       [Validation] Prec@1 70.000000 Max 72.777778
Confusion matrix:
[[27  0  2  1  0 10]
 [ 0 28  1  1  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0  4  0 26  0]
 [ 0  0  5  0  0 15]]
Fold "0" complete, final accuracy: 72.77777777777777
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.476889
       [Training]   Prec@1 42.016807 Max 42.016807
       [Avg Loss]          1.691989
       [Validation] Prec@1 40.540541 Max 40.540541
Confusion matrix:
[[ 0  6  0 20  0  4]
 [ 0 32  0  3  0  0]
 [ 0  6  0 24  0  0]
 [ 0  2  0 28  0  0]
 [ 0  3  0 27  0  0]
 [ 0  2  0 13  0 15]]
Epoch: [1]
       [Avg Loss]          1.012195
       [Training]   Prec@1 65.546218 Max 65.546218
       [Avg Loss]          1.340347
       [Validation] Prec@1 50.810811 Max 50.810811
Confusion matrix:
[[22  4  0  0  3  1]
 [ 1 18  1 15  0  0]
 [ 0  0  4 21  5  0]
 [ 6  0  0 11 13  0]
 [ 2  1  0  6 21  0]
 [ 4  1  0  6  1 18]]
Epoch: [2]
       [Avg Loss]          0.856486
       [Training]   Prec@1 71.596639 Max 71.596639
       [Avg Loss]          1.033499
       [Validation] Prec@1 61.621622 Max 61.621622
Confusion matrix:
[[15  4  9  1  0  1]
 [ 1 18  2 14  0  0]
 [ 0  0 24  6  0  0]
 [ 5  0  6 18  1  0]
 [ 3  0  0  8 19  0]
 [ 4  1  1  4  0 20]]
Epoch: [3]
       [Avg Loss]          0.728576
       [Training]   Prec@1 75.630252 Max 75.630252
       [Avg Loss]          1.131750
       [Validation] Prec@1 57.297297 Max 61.621622
Confusion matrix:
[[21  5  4  0  0  0]
 [ 1 14 20  0  0  0]
 [ 0  0 30  0  0  0]
 [ 6  0 13  8  2  1]
 [ 5  3  4  3 15  0]
 [ 1  1  2  8  0 18]]
Epoch: [4]
       [Avg Loss]          0.709236
       [Training]   Prec@1 77.815126 Max 77.815126
       [Avg Loss]          1.018424
       [Validation] Prec@1 69.729730 Max 69.729730
Confusion matrix:
[[21  3  1  0  0  5]
 [ 1 28  5  0  0  1]
 [ 2  0 28  0  0  0]
 [12  1  7  9  1  0]
 [ 7  1  1  3 18  0]
 [ 1  1  1  2  0 25]]
Epoch: [5]
       [Avg Loss]          0.680072
       [Training]   Prec@1 76.470588 Max 77.815126
       [Avg Loss]          0.919389
       [Validation] Prec@1 71.351351 Max 71.351351
Confusion matrix:
[[16  4  0  6  0  4]
 [ 1 32  2  0  0  0]
 [ 2  1 26  1  0  0]
 [ 2  1  6 17  3  1]
 [ 3  0  0  9 18  0]
 [ 2  1  0  4  0 23]]
Epoch: [6]
       [Avg Loss]          0.675187
       [Training]   Prec@1 76.302521 Max 77.815126
       [Avg Loss]          1.036791
       [Validation] Prec@1 67.027027 Max 71.351351
Confusion matrix:
[[24  4  1  1  0  0]
 [ 1  8 18  7  1  0]
 [ 0  0 30  0  0  0]
 [ 3  0  6 19  2  0]
 [ 3  0  0  5 22  0]
 [ 1  1  1  6  0 21]]
Epoch: [7]
       [Avg Loss]          0.519413
       [Training]   Prec@1 82.521008 Max 82.521008
       [Avg Loss]          1.050267
       [Validation] Prec@1 68.648649 Max 71.351351
Confusion matrix:
[[22  5  2  0  0  1]
 [ 1 33  1  0  0  0]
 [ 2  5 23  0  0  0]
 [ 9  2  5 13  0  1]
 [10  2  0  3 15  0]
 [ 0  3  1  5  0 21]]
Epoch: [8]
       [Avg Loss]          0.478300
       [Training]   Prec@1 84.705882 Max 84.705882
       [Avg Loss]          0.965574
       [Validation] Prec@1 71.351351 Max 71.351351
Confusion matrix:
[[23  4  3  0  0  0]
 [ 4 28  3  0  0  0]
 [ 2  2 26  0  0  0]
 [ 9  2  7 12  0  0]
 [ 8  0  0  0 22  0]
 [ 3  1  1  3  1 21]]
Epoch: [9]
       [Avg Loss]          0.510716
       [Training]   Prec@1 83.193277 Max 84.705882
       [Avg Loss]          1.179493
       [Validation] Prec@1 65.945946 Max 71.351351
Confusion matrix:
[[25  5  0  0  0  0]
 [ 3 31  0  1  0  0]
 [ 7  5 18  0  0  0]
 [14  1  2 12  1  0]
 [ 7  3  0  1 19  0]
 [ 6  2  0  4  1 17]]
Epoch: [10]
       [Avg Loss]          0.493782
       [Training]   Prec@1 82.857143 Max 84.705882
       [Avg Loss]          0.823937
       [Validation] Prec@1 75.135135 Max 75.135135
Confusion matrix:
[[23  4  3  0  0  0]
 [ 1 33  1  0  0  0]
 [ 0  5 25  0  0  0]
 [ 3  1  5 21  0  0]
 [ 6  2  0  9 13  0]
 [ 1  2  1  2  0 24]]
Epoch: [11]
       [Avg Loss]          0.484682
       [Training]   Prec@1 83.193277 Max 84.705882
       [Avg Loss]          1.316808
       [Validation] Prec@1 63.243243 Max 75.135135
Confusion matrix:
[[22  5  3  0  0  0]
 [ 2 30  3  0  0  0]
 [ 0  0 30  0  0  0]
 [ 2  2  9  7 10  0]
 [ 3  8  1  0 18  0]
 [ 0  5  1 13  1 10]]
Epoch: [12]
       [Avg Loss]          0.547138
       [Training]   Prec@1 81.680672 Max 84.705882
       [Avg Loss]          1.366286
       [Validation] Prec@1 68.108108 Max 75.135135
Confusion matrix:
[[24  2  1  0  0  3]
 [ 3 27  1  0  0  4]
 [ 3  4 22  0  0  1]
 [17  1  4  4  1  3]
 [ 6  0  0  1 23  0]
 [ 3  0  1  0  0 26]]
Epoch: [13]
       [Avg Loss]          0.525546
       [Training]   Prec@1 81.848739 Max 84.705882
       [Avg Loss]          0.927641
       [Validation] Prec@1 76.216216 Max 76.216216
Confusion matrix:
[[23  5  2  0  0  0]
 [ 1 33  1  0  0  0]
 [ 0  4 26  0  0  0]
 [ 7  1  8 14  0  0]
 [ 7  0  0  3 20  0]
 [ 1  3  1  0  0 25]]
Epoch: [14]
       [Avg Loss]          0.524904
       [Training]   Prec@1 81.512605 Max 84.705882
       [Avg Loss]          1.180148
       [Validation] Prec@1 65.405405 Max 76.216216
Confusion matrix:
[[26  4  0  0  0  0]
 [ 4 27  4  0  0  0]
 [ 1  0 29  0  0  0]
 [10  1  7 12  0  0]
 [ 6  7  3  0 14  0]
 [ 7  1  0  9  0 13]]
Fold "1" complete, final accuracy: 76.21621621621621
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.528454
       [Training]   Prec@1 37.647059 Max 37.647059
       [Avg Loss]          1.702949
       [Validation] Prec@1 30.270270 Max 30.270270
Confusion matrix:
[[ 2  1  0  0 27  0]
 [ 0  9  0  0 26  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0 30  0]
 [ 0 12  0  0  3 15]]
Epoch: [1]
       [Avg Loss]          1.060729
       [Training]   Prec@1 62.016807 Max 62.016807
       [Avg Loss]          1.252275
       [Validation] Prec@1 66.486486 Max 66.486486
Confusion matrix:
[[ 7  5 18  0  0  0]
 [ 0 28  6  0  0  1]
 [ 0  0 30  0  0  0]
 [ 0  5  8  7  8  2]
 [ 0  0  9  0 21  0]
 [ 0  0  0  0  0 30]]
Epoch: [2]
       [Avg Loss]          0.920490
       [Training]   Prec@1 69.915966 Max 69.915966
       [Avg Loss]          0.993987
       [Validation] Prec@1 69.189189 Max 69.189189
Confusion matrix:
[[21  4  0  3  2  0]
 [ 0 27  1  4  0  3]
 [ 0  0 15 15  0  0]
 [ 0 12  0 15  0  3]
 [ 0  0  0 10 20  0]
 [ 0  0  0  0  0 30]]
Epoch: [3]
       [Avg Loss]          0.804391
       [Training]   Prec@1 71.932773 Max 71.932773
       [Avg Loss]          1.801653
       [Validation] Prec@1 39.459459 Max 69.189189
Confusion matrix:
[[29  0  0  0  1  0]
 [25  2  0  0  0  8]
 [25  0  2  3  0  0]
 [27  1  0  2  0  0]
 [21  0  0  0  9  0]
 [ 1  0  0  0  0 29]]
Epoch: [4]
       [Avg Loss]          0.815399
       [Training]   Prec@1 75.126050 Max 75.126050
       [Avg Loss]          1.181856
       [Validation] Prec@1 57.297297 Max 69.189189
Confusion matrix:
[[10  1  1 11  7  0]
 [ 0 32  0  2  0  1]
 [ 0  0  7 22  1  0]
 [ 0 12  3  9  4  2]
 [ 0  0  0  8 22  0]
 [ 0  4  0  0  0 26]]
Epoch: [5]
       [Avg Loss]          0.771278
       [Training]   Prec@1 73.277311 Max 75.126050
       [Avg Loss]          1.091276
       [Validation] Prec@1 70.810811 Max 70.810811
Confusion matrix:
[[23  0  0  0  7  0]
 [ 1 32  1  0  1  0]
 [ 0  0 14  6 10  0]
 [ 0  4  0 15 11  0]
 [ 6  0  0  0 24  0]
 [ 1  5  0  1  0 23]]
Epoch: [6]
       [Avg Loss]          0.634433
       [Training]   Prec@1 77.647059 Max 77.647059
       [Avg Loss]          0.898304
       [Validation] Prec@1 73.513514 Max 73.513514
Confusion matrix:
[[21  0  2  3  4  0]
 [ 2 21  8  4  0  0]
 [ 0  0 24  6  0  0]
 [ 0  3  6 20  1  0]
 [ 0  0  0 10 20  0]
 [ 0  0  0  0  0 30]]
Epoch: [7]
       [Avg Loss]          0.628755
       [Training]   Prec@1 81.848739 Max 81.848739
       [Avg Loss]          0.676089
       [Validation] Prec@1 76.216216 Max 76.216216
Confusion matrix:
[[23  0  0  1  6  0]
 [ 4 29  0  1  0  1]
 [ 0  0 19 11  0  0]
 [ 0  9  0 16  3  2]
 [ 0  0  0  3 27  0]
 [ 1  2  0  0  0 27]]
Epoch: [8]
       [Avg Loss]          0.585223
       [Training]   Prec@1 79.663866 Max 81.848739
       [Avg Loss]          1.338194
       [Validation] Prec@1 58.918919 Max 76.216216
Confusion matrix:
[[24  0  0  2  4  0]
 [ 4 15  0 12  2  2]
 [ 3  0  7 15  5  0]
 [ 1  0  0 12 17  0]
 [ 7  0  0  0 23  0]
 [ 1  0  0  1  0 28]]
Epoch: [9]
       [Avg Loss]          0.532145
       [Training]   Prec@1 82.857143 Max 82.857143
       [Avg Loss]          0.855564
       [Validation] Prec@1 75.135135 Max 76.216216
Confusion matrix:
[[20  1  4  1  4  0]
 [ 1 23  0  7  0  4]
 [ 0  0 23  7  0  0]
 [ 0  0  1 26  1  2]
 [ 1  0  0 10 19  0]
 [ 2  0  0  0  0 28]]
Epoch: [10]
       [Avg Loss]          0.522320
       [Training]   Prec@1 83.865546 Max 83.865546
       [Avg Loss]          1.010722
       [Validation] Prec@1 72.972973 Max 76.216216
Confusion matrix:
[[11  1  4 10  4  0]
 [ 0 34  0  0  0  1]
 [ 0  0 28  2  0  0]
 [ 0  3  6 16  5  0]
 [ 0  0  4  2 24  0]
 [ 4  4  0  0  0 22]]
Epoch: [11]
       [Avg Loss]          0.527757
       [Training]   Prec@1 81.680672 Max 83.865546
       [Avg Loss]          0.934873
       [Validation] Prec@1 74.594595 Max 76.216216
Confusion matrix:
[[21  2  3  0  4  0]
 [ 5 26  0  1  0  3]
 [ 0  0 18 12  0  0]
 [ 0  4  1 19  5  1]
 [ 0  0  0  6 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [12]
       [Avg Loss]          0.467133
       [Training]   Prec@1 84.033613 Max 84.033613
       [Avg Loss]          1.087793
       [Validation] Prec@1 68.648649 Max 76.216216
Confusion matrix:
[[22  4  0  1  3  0]
 [ 1 32  0  0  0  2]
 [ 0  4 11 15  0  0]
 [ 0 10  0 17  1  2]
 [ 0  2  0 11 17  0]
 [ 2  0  0  0  0 28]]
Epoch: [13]
       [Avg Loss]          0.470331
       [Training]   Prec@1 84.369748 Max 84.369748
       [Avg Loss]          0.980893
       [Validation] Prec@1 68.648649 Max 76.216216
Confusion matrix:
[[17  1  4  4  4  0]
 [ 2 20  7  3  0  3]
 [ 0  0 23  7  0  0]
 [ 0  1  6 20  2  1]
 [ 0  0  1 10 19  0]
 [ 2  0  0  0  0 28]]
Epoch: [14]
       [Avg Loss]          0.473561
       [Training]   Prec@1 85.546218 Max 85.546218
       [Avg Loss]          0.839036
       [Validation] Prec@1 74.594595 Max 76.216216
Confusion matrix:
[[21  0  4  0  5  0]
 [ 5 23  1  4  2  0]
 [ 0  0 24  6  0  0]
 [ 0  0  2 23  4  1]
 [ 6  0  0  0 24  0]
 [ 6  1  0  0  0 23]]
Fold "2" complete, final accuracy: 76.21621621621621
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.482586
       [Training]   Prec@1 43.030303 Max 43.030303
       [Avg Loss]          1.694662
       [Validation] Prec@1 40.833333 Max 40.833333
Confusion matrix:
[[ 0  0  9  0 11  0]
 [ 0 20  0  0  0  0]
 [ 0  9  8  0  3  0]
 [ 0  6  5  5  4  0]
 [ 0  5  0  0 15  0]
 [ 0 17  2  0  0  1]]
Epoch: [1]
       [Avg Loss]          1.076821
       [Training]   Prec@1 60.757576 Max 60.757576
       [Avg Loss]          1.478006
       [Validation] Prec@1 48.333333 Max 48.333333
Confusion matrix:
[[17  0  0  0  0  3]
 [ 0 13  0  1  0  6]
 [ 0  9  5  1  0  5]
 [ 1  0  1  5  0 13]
 [ 0  1  7 12  0  0]
 [ 0  2  0  0  0 18]]
Epoch: [2]
       [Avg Loss]          0.920442
       [Training]   Prec@1 70.909091 Max 70.909091
       [Avg Loss]          0.822801
       [Validation] Prec@1 73.333333 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 1 15  1  3  0  0]
 [ 0  2  9  8  1  0]
 [ 7  0  1 11  0  1]
 [ 0  0  0  3 17  0]
 [ 3  0  0  1  0 16]]
Epoch: [3]
       [Avg Loss]          0.799323
       [Training]   Prec@1 71.969697 Max 71.969697
       [Avg Loss]          1.014127
       [Validation] Prec@1 69.166667 Max 73.333333
Confusion matrix:
[[19  0  0  1  0  0]
 [ 3  9  0  8  0  0]
 [ 0  0  4 14  2  0]
 [ 1  0  1 18  0  0]
 [ 0  0  0  3 17  0]
 [ 1  2  0  1  0 16]]
Epoch: [4]
       [Avg Loss]          0.747705
       [Training]   Prec@1 76.515152 Max 76.515152
       [Avg Loss]          0.922055
       [Validation] Prec@1 65.000000 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0  7  0  5  0  8]
 [ 0  0 16  4  0  0]
 [ 4  0  4  5  0  7]
 [ 0  0  8  0 12  0]
 [ 0  2  0  0  0 18]]
Epoch: [5]
       [Avg Loss]          0.675235
       [Training]   Prec@1 78.333333 Max 78.333333
       [Avg Loss]          1.484779
       [Validation] Prec@1 57.500000 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 4 12  1  2  1  0]
 [ 0  2 10  4  4  0]
 [ 9  0  3  3  5  0]
 [ 0  0  0  0 20  0]
 [14  0  2  0  0  4]]
Epoch: [6]
       [Avg Loss]          0.747755
       [Training]   Prec@1 73.181818 Max 78.333333
       [Avg Loss]          1.459566
       [Validation] Prec@1 66.666667 Max 73.333333
Confusion matrix:
[[13  0  7  0  0  0]
 [ 0 20  0  0  0  0]
 [ 0 12  4  3  1  0]
 [ 1  5  3  9  2  0]
 [ 0  0  0  0 20  0]
 [ 0  6  0  0  0 14]]
Epoch: [7]
       [Avg Loss]          0.700300
       [Training]   Prec@1 76.818182 Max 78.333333
       [Avg Loss]          0.913963
       [Validation] Prec@1 66.666667 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 2 10  0  4  0  4]
 [ 1  0 14  5  0  0]
 [10  0  1  6  0  3]
 [ 0  0  2  6 12  0]
 [ 2  0  0  0  0 18]]
Epoch: [8]
       [Avg Loss]          0.654050
       [Training]   Prec@1 76.969697 Max 78.333333
       [Avg Loss]          0.918505
       [Validation] Prec@1 69.166667 Max 73.333333
Confusion matrix:
[[19  0  0  1  0  0]
 [ 2  6  2  9  0  1]
 [ 0  0  5 14  1  0]
 [ 0  0  1 19  0  0]
 [ 0  0  0  0 20  0]
 [ 3  1  0  2  0 14]]
Epoch: [9]
       [Avg Loss]          0.624566
       [Training]   Prec@1 78.030303 Max 78.333333
       [Avg Loss]          1.537851
       [Validation] Prec@1 55.833333 Max 73.333333
Confusion matrix:
[[14  0  0  6  0  0]
 [ 0 19  0  1  0  0]
 [ 0  9  6  5  0  0]
 [ 0  4  1 15  0  0]
 [ 0 17  0  0  3  0]
 [ 0 10  0  0  0 10]]
Epoch: [10]
       [Avg Loss]          0.549033
       [Training]   Prec@1 82.272727 Max 82.272727
       [Avg Loss]          1.150006
       [Validation] Prec@1 60.833333 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [12  8  0  0  0  0]
 [ 0  0 15  5  0  0]
 [16  0  0  4  0  0]
 [ 0  0  0  0 20  0]
 [14  0  0  0  0  6]]
Epoch: [11]
       [Avg Loss]          0.544924
       [Training]   Prec@1 81.060606 Max 82.272727
       [Avg Loss]          0.685542
       [Validation] Prec@1 79.166667 Max 79.166667
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 18  0  2  0  0]
 [ 0  0 14  6  0  0]
 [ 6  1  1 12  0  0]
 [ 0  0  0  0 20  0]
 [ 5  3  0  1  0 11]]
Epoch: [12]
       [Avg Loss]          0.498536
       [Training]   Prec@1 83.787879 Max 83.787879
       [Avg Loss]          0.925469
       [Validation] Prec@1 65.000000 Max 79.166667
Confusion matrix:
[[11  0  0  9  0  0]
 [ 0 10  0  2  0  8]
 [ 0  0  6 14  0  0]
 [ 0  0  0 19  0  1]
 [ 0  4  0  1 15  0]
 [ 0  3  0  0  0 17]]
Epoch: [13]
       [Avg Loss]          0.543910
       [Training]   Prec@1 82.272727 Max 83.787879
       [Avg Loss]          1.353175
       [Validation] Prec@1 55.000000 Max 79.166667
Confusion matrix:
[[20  0  0  0  0  0]
 [10  9  0  1  0  0]
 [ 1  0 15  4  0  0]
 [16  1  1  2  0  0]
 [ 0  0  0  0 20  0]
 [20  0  0  0  0  0]]
Epoch: [14]
       [Avg Loss]          0.529594
       [Training]   Prec@1 82.575758 Max 83.787879
       [Avg Loss]          0.806323
       [Validation] Prec@1 74.166667 Max 79.166667
Confusion matrix:
[[15  0  0  5  0  0]
 [ 0 12  0  8  0  0]
 [ 0  0  6 14  0  0]
 [ 0  0  0 20  0  0]
 [ 0  0  0  0 20  0]
 [ 0  2  0  2  0 16]]
Fold "3" complete, final accuracy: 79.16666666666667
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.417763
       [Training]   Prec@1 44.626866 Max 44.626866
       [Avg Loss]          1.711492
       [Validation] Prec@1 20.909091 Max 20.909091
Confusion matrix:
[[ 0  0  0 20  0  0]
 [ 0  0  0 20  0  0]
 [ 2  0  0 18  0  0]
 [ 0  0  0 20  0  0]
 [ 0  0  0 10  0  0]
 [ 9  0  0  8  0  3]]
Epoch: [1]
       [Avg Loss]          0.968833
       [Training]   Prec@1 68.059701 Max 68.059701
       [Avg Loss]          1.469973
       [Validation] Prec@1 52.727273 Max 52.727273
Confusion matrix:
[[19  1  0  0  0  0]
 [11  6  0  3  0  0]
 [10  0  5  5  0  0]
 [ 1 11  0  7  0  1]
 [ 0  0  0  3  7  0]
 [ 6  0  0  0  0 14]]
Epoch: [2]
       [Avg Loss]          0.806105
       [Training]   Prec@1 72.835821 Max 72.835821
       [Avg Loss]          1.523394
       [Validation] Prec@1 51.818182 Max 52.727273
Confusion matrix:
[[17  3  0  0  0  0]
 [10  9  1  0  0  0]
 [ 9  0 10  0  0  1]
 [ 0 17  0  1  0  2]
 [ 5  0  0  5  0  0]
 [ 0  0  0  0  0 20]]
Epoch: [3]
       [Avg Loss]          0.715021
       [Training]   Prec@1 75.373134 Max 75.373134
       [Avg Loss]          1.648668
       [Validation] Prec@1 58.181818 Max 58.181818
Confusion matrix:
[[17  2  0  0  0  1]
 [10  9  1  0  0  0]
 [ 9  3  6  0  0  2]
 [ 0 13  0  7  0  0]
 [ 0  0  0  5  5  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          0.638558
       [Training]   Prec@1 76.119403 Max 76.119403
       [Avg Loss]          1.720049
       [Validation] Prec@1 56.363636 Max 58.181818
Confusion matrix:
[[ 7  2  1 10  0  0]
 [ 0  5  0  9  6  0]
 [ 0  0  3 10  5  2]
 [ 0  1  0 19  0  0]
 [ 0  0  0  0 10  0]
 [ 0  2  0  0  0 18]]
Epoch: [5]
       [Avg Loss]          0.538109
       [Training]   Prec@1 80.597015 Max 80.597015
       [Avg Loss]          1.692494
       [Validation] Prec@1 57.272727 Max 58.181818
Confusion matrix:
[[11  1  0  2  5  1]
 [ 3  5  1  3  8  0]
 [ 6  0  4  6  3  1]
 [ 0  0  0 20  0  0]
 [ 0  0  0  0 10  0]
 [ 7  0  0  0  0 13]]
Epoch: [6]
       [Avg Loss]          0.558181
       [Training]   Prec@1 80.447761 Max 80.597015
       [Avg Loss]          2.078650
       [Validation] Prec@1 50.909091 Max 58.181818
Confusion matrix:
[[ 7  2  0  2  0  9]
 [ 0 11  5  0  0  4]
 [ 2  0 14  0  0  4]
 [ 0 10  0  4  0  6]
 [ 0  0  3  7  0  0]
 [ 0  0  0  0  0 20]]
Epoch: [7]
       [Avg Loss]          0.517747
       [Training]   Prec@1 81.791045 Max 81.791045
       [Avg Loss]          1.344876
       [Validation] Prec@1 63.636364 Max 63.636364
Confusion matrix:
[[18  0  1  1  0  0]
 [ 8  7  1  2  2  0]
 [ 8  0 11  1  0  0]
 [ 0  5  0 15  0  0]
 [ 0  0  0  0 10  0]
 [10  1  0  0  0  9]]
Epoch: [8]
       [Avg Loss]          0.544151
       [Training]   Prec@1 79.701493 Max 81.791045
       [Avg Loss]          1.147877
       [Validation] Prec@1 70.000000 Max 70.000000
Confusion matrix:
[[11  1  1  4  3  0]
 [ 1 13  2  0  4  0]
 [ 4  1 11  2  0  2]
 [ 0  7  0 13  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [9]
       [Avg Loss]          0.441507
       [Training]   Prec@1 85.373134 Max 85.373134
       [Avg Loss]          1.751729
       [Validation] Prec@1 69.090909 Max 70.000000
Confusion matrix:
[[15  2  3  0  0  0]
 [ 4  5  3  2  5  1]
 [ 7  0 12  0  1  0]
 [ 0  0  1 19  0  0]
 [ 0  0  0  0 10  0]
 [ 5  0  0  0  0 15]]
Epoch: [10]
       [Avg Loss]          0.410665
       [Training]   Prec@1 85.671642 Max 85.671642
       [Avg Loss]          1.426304
       [Validation] Prec@1 54.545455 Max 70.000000
Confusion matrix:
[[15  1  0  3  0  1]
 [ 6  4  0  8  1  1]
 [ 5  0  0 13  0  2]
 [ 0  0  0 18  0  2]
 [ 0  0  0  7  3  0]
 [ 0  0  0  0  0 20]]
Epoch: [11]
       [Avg Loss]          0.434228
       [Training]   Prec@1 85.970149 Max 85.970149
       [Avg Loss]          1.835323
       [Validation] Prec@1 56.363636 Max 70.000000
Confusion matrix:
[[ 5  1  4  6  4  0]
 [ 1  6  7  3  3  0]
 [ 5  0 13  1  0  1]
 [ 0  0  6 14  0  0]
 [ 0  0  0  0 10  0]
 [ 5  1  0  0  0 14]]
Epoch: [12]
       [Avg Loss]          0.408033
       [Training]   Prec@1 84.925373 Max 85.970149
       [Avg Loss]          1.718942
       [Validation] Prec@1 65.454545 Max 70.000000
Confusion matrix:
[[16  4  0  0  0  0]
 [ 9  9  1  1  0  0]
 [10  0  8  1  1  0]
 [ 0  5  0 14  0  1]
 [ 0  0  0  0 10  0]
 [ 5  0  0  0  0 15]]
Epoch: [13]
       [Avg Loss]          0.401187
       [Training]   Prec@1 85.820896 Max 85.970149
       [Avg Loss]          1.626415
       [Validation] Prec@1 69.090909 Max 70.000000
Confusion matrix:
[[17  0  3  0  0  0]
 [ 2  7  2  1  8  0]
 [ 7  0 13  0  0  0]
 [ 0  2  0 18  0  0]
 [ 0  0  0  0 10  0]
 [ 8  1  0  0  0 11]]
Epoch: [14]
       [Avg Loss]          0.392453
       [Training]   Prec@1 85.522388 Max 85.970149
       [Avg Loss]          1.050674
       [Validation] Prec@1 66.363636 Max 70.000000
Confusion matrix:
[[14  4  0  2  0  0]
 [ 8 10  1  1  0  0]
 [ 6  0 12  0  0  2]
 [ 0  5  0 15  0  0]
 [ 0  0  0  7  3  0]
 [ 1  0  0  0  0 19]]
Fold "4" complete, final accuracy: 70.0

-----------------------------------------------------------------------
Training for stage 4 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=18)")
Average accuracy is: 74.87537537537537


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 5-----
Evaluated preprocessing: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=12)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.401225
       [Training]   Prec@1 44.000000 Max 44.000000
       [Avg Loss]          1.558788
       [Validation] Prec@1 52.777778 Max 52.777778
Confusion matrix:
[[25  0  4  0  1 10]
 [17  8  1  0  2  2]
 [ 0  0 29  0  1  0]
 [ 1  1 17  0 11  0]
 [ 3  0  7  0 20  0]
 [ 7  0  0  0  0 13]]
Epoch: [1]
       [Avg Loss]          0.860088
       [Training]   Prec@1 72.500000 Max 72.500000
       [Avg Loss]          1.157405
       [Validation] Prec@1 66.666667 Max 66.666667
Confusion matrix:
[[29  0  0  0  1 10]
 [ 0 23  0  0  0  7]
 [ 2  3 23  0  2  0]
 [ 3  7 11  1  8  0]
 [ 6  0  0  0 24  0]
 [ 0  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          0.622347
       [Training]   Prec@1 79.166667 Max 79.166667
       [Avg Loss]          1.069322
       [Validation] Prec@1 70.555556 Max 70.555556
Confusion matrix:
[[25  0  4  1  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 25  1  4  0]
 [ 2  0  4  0 24  0]
 [ 0  0  0  3  0 17]]
Epoch: [3]
       [Avg Loss]          0.516607
       [Training]   Prec@1 83.833333 Max 83.833333
       [Avg Loss]          1.794607
       [Validation] Prec@1 65.555556 Max 70.555556
Confusion matrix:
[[16  0 10  1  2 11]
 [ 0 26  2  0  0  2]
 [ 0  0 30  0  0  0]
 [ 0  0 25  0  5  0]
 [ 0  0  4  0 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          0.491095
       [Training]   Prec@1 83.666667 Max 83.833333
       [Avg Loss]          1.532304
       [Validation] Prec@1 68.333333 Max 70.555556
Confusion matrix:
[[19  0  9  2  0 10]
 [ 0 30  0  0  0  0]
 [ 0  1 29  0  0  0]
 [ 0  8 19  1  2  0]
 [ 1  2  2  0 25  0]
 [ 0  1  0  0  0 19]]
Epoch: [5]
       [Avg Loss]          0.457147
       [Training]   Prec@1 85.166667 Max 85.166667
       [Avg Loss]          1.056717
       [Validation] Prec@1 74.444444 Max 74.444444
Confusion matrix:
[[22  0  7  0  1 10]
 [ 0 29  0  0  0  1]
 [ 0  0 28  2  0  0]
 [ 0  1 15 13  1  0]
 [ 0  0  4  0 26  0]
 [ 0  3  1  0  0 16]]
Epoch: [6]
       [Avg Loss]          0.419707
       [Training]   Prec@1 87.166667 Max 87.166667
       [Avg Loss]          1.477607
       [Validation] Prec@1 66.111111 Max 74.444444
Confusion matrix:
[[19  0 10  1  0 10]
 [ 0 28  0  0  0  2]
 [ 0  2 27  1  0  0]
 [ 0  3 21  6  0  0]
 [ 4  5  2  0 19  0]
 [ 0  0  0  0  0 20]]
Epoch: [7]
       [Avg Loss]          0.436065
       [Training]   Prec@1 86.000000 Max 87.166667
       [Avg Loss]          1.289933
       [Validation] Prec@1 69.444444 Max 74.444444
Confusion matrix:
[[22  0  7  1  0 10]
 [ 0 26  3  0  0  1]
 [ 0  0 29  1  0  0]
 [ 1  0 23  6  0  0]
 [ 0  1  4  0 25  0]
 [ 3  0  0  0  0 17]]
Epoch: [8]
       [Avg Loss]          0.321096
       [Training]   Prec@1 89.333333 Max 89.333333
       [Avg Loss]          1.370769
       [Validation] Prec@1 70.000000 Max 74.444444
Confusion matrix:
[[23  1  5  1  0 10]
 [ 0 30  0  0  0  0]
 [ 0  2 27  1  0  0]
 [ 1  0 23  6  0  0]
 [ 3  5  0  0 22  0]
 [ 0  2  0  0  0 18]]
Epoch: [9]
       [Avg Loss]          0.320297
       [Training]   Prec@1 89.833333 Max 89.833333
       [Avg Loss]          1.403018
       [Validation] Prec@1 72.222222 Max 74.444444
Confusion matrix:
[[20  1  8  1  0 10]
 [ 0 29  0  0  0  1]
 [ 0  0 29  1  0  0]
 [ 1  0 22  7  0  0]
 [ 0  1  4  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [10]
       [Avg Loss]          0.242306
       [Training]   Prec@1 92.500000 Max 92.500000
       [Avg Loss]          1.214802
       [Validation] Prec@1 76.111111 Max 76.111111
Confusion matrix:
[[23  1  5  1  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 28  2  0  0]
 [ 0  2 14 13  1  0]
 [ 1  2  2  0 25  0]
 [ 0  0  0  2  0 18]]
Epoch: [11]
       [Avg Loss]          0.245037
       [Training]   Prec@1 92.666667 Max 92.666667
       [Avg Loss]          1.398279
       [Validation] Prec@1 68.888889 Max 76.111111
Confusion matrix:
[[20  1  9  0  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 29  1  0  0]
 [ 0  0 24  6  0  0]
 [ 0  5  3  0 22  0]
 [ 0  3  0  0  0 17]]
Epoch: [12]
       [Avg Loss]          0.242953
       [Training]   Prec@1 93.166667 Max 93.166667
       [Avg Loss]          1.420140
       [Validation] Prec@1 69.444444 Max 76.111111
Confusion matrix:
[[21  1  8  0  0 10]
 [ 0 26  0  0  0  4]
 [ 0  0 29  1  0  0]
 [ 2  0 20  4  4  0]
 [ 0  2  3  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [13]
       [Avg Loss]          0.225939
       [Training]   Prec@1 92.000000 Max 93.166667
       [Avg Loss]          1.391948
       [Validation] Prec@1 72.222222 Max 76.111111
Confusion matrix:
[[17  1 11  1  0 10]
 [ 0 29  0  0  0  1]
 [ 0  0 29  1  0  0]
 [ 1  2 17 10  0  0]
 [ 1  3  1  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [14]
       [Avg Loss]          0.185111
       [Training]   Prec@1 94.500000 Max 94.500000
       [Avg Loss]          1.606118
       [Validation] Prec@1 72.222222 Max 76.111111
Confusion matrix:
[[20  1  8  1  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 29  1  0  0]
 [ 1  1 21  6  1  0]
 [ 0  1  4  0 25  0]
 [ 0  0  0  0  0 20]]
Fold "0" complete, final accuracy: 76.11111111111111
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.432507
       [Training]   Prec@1 44.369748 Max 44.369748
       [Avg Loss]          1.532540
       [Validation] Prec@1 40.540541 Max 40.540541
Confusion matrix:
[[30  0  0  0  0  0]
 [28  7  0  0  0  0]
 [23  0  7  0  0  0]
 [24  0  0  0  6  0]
 [17  0  1  0 12  0]
 [11  0  0  0  0 19]]
Epoch: [1]
       [Avg Loss]          0.990260
       [Training]   Prec@1 65.210084 Max 65.210084
       [Avg Loss]          1.048346
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[28  1  1  0  0  0]
 [ 9 25  1  0  0  0]
 [ 1  6 23  0  0  0]
 [19  1  4  1  5  0]
 [13  0  0  0 17  0]
 [12  1  0  0  0 17]]
Epoch: [2]
       [Avg Loss]          0.759322
       [Training]   Prec@1 73.613445 Max 73.613445
       [Avg Loss]          1.004875
       [Validation] Prec@1 68.108108 Max 68.108108
Confusion matrix:
[[25  1  0  0  0  4]
 [ 5 28  1  1  0  0]
 [ 1  7 22  0  0  0]
 [15  1  0  4  9  1]
 [ 9  2  0  0 19  0]
 [ 2  0  0  0  0 28]]
Epoch: [3]
       [Avg Loss]          0.643131
       [Training]   Prec@1 77.647059 Max 77.647059
       [Avg Loss]          0.776727
       [Validation] Prec@1 74.054054 Max 74.054054
Confusion matrix:
[[23  6  1  0  0  0]
 [ 0 35  0  0  0  0]
 [ 0  5 25  0  0  0]
 [ 8  4  0  9  9  0]
 [ 1  7  0  1 21  0]
 [ 4  2  0  0  0 24]]
Epoch: [4]
       [Avg Loss]          0.568724
       [Training]   Prec@1 81.008403 Max 81.008403
       [Avg Loss]          0.840066
       [Validation] Prec@1 76.756757 Max 76.756757
Confusion matrix:
[[27  2  0  0  0  1]
 [ 1 25  7  2  0  0]
 [ 1  1 27  1  0  0]
 [ 9  0  3 12  6  0]
 [ 0  4  0  1 25  0]
 [ 1  2  1  0  0 26]]
Epoch: [5]
       [Avg Loss]          0.495034
       [Training]   Prec@1 84.705882 Max 84.705882
       [Avg Loss]          1.271195
       [Validation] Prec@1 68.648649 Max 76.756757
Confusion matrix:
[[24  6  0  0  0  0]
 [ 0 35  0  0  0  0]
 [ 1  7 21  1  0  0]
 [13  0  3 14  0  0]
 [18  3  0  0  9  0]
 [ 3  2  0  1  0 24]]
Epoch: [6]
       [Avg Loss]          0.477374
       [Training]   Prec@1 83.865546 Max 84.705882
       [Avg Loss]          0.841051
       [Validation] Prec@1 73.513514 Max 76.756757
Confusion matrix:
[[24  1  0  0  1  4]
 [ 7 26  2  0  0  0]
 [ 3  0 26  1  0  0]
 [ 9  0  3  8  9  1]
 [ 3  0  0  0 27  0]
 [ 3  1  0  1  0 25]]
Epoch: [7]
       [Avg Loss]          0.418569
       [Training]   Prec@1 87.563025 Max 87.563025
       [Avg Loss]          0.877047
       [Validation] Prec@1 75.135135 Max 76.756757
Confusion matrix:
[[21  6  1  2  0  0]
 [ 1 34  0  0  0  0]
 [ 0  4 25  1  0  0]
 [ 3  0  6 19  1  1]
 [ 3  4  0  6 17  0]
 [ 3  2  1  1  0 23]]
Epoch: [8]
       [Avg Loss]          0.375969
       [Training]   Prec@1 87.394958 Max 87.563025
       [Avg Loss]          0.638961
       [Validation] Prec@1 80.540541 Max 80.540541
Confusion matrix:
[[24  4  1  0  0  1]
 [ 1 33  0  1  0  0]
 [ 1  2 27  0  0  0]
 [ 6  0  4 16  3  1]
 [ 6  1  0  0 23  0]
 [ 2  1  0  1  0 26]]
Epoch: [9]
       [Avg Loss]          0.319295
       [Training]   Prec@1 89.579832 Max 89.579832
       [Avg Loss]          0.916250
       [Validation] Prec@1 78.918919 Max 80.540541
Confusion matrix:
[[24  4  1  1  0  0]
 [ 1 34  0  0  0  0]
 [ 0  7 23  0  0  0]
 [ 6  0  4 19  1  0]
 [ 7  0  0  0 23  0]
 [ 2  2  0  3  0 23]]
Epoch: [10]
       [Avg Loss]          0.244991
       [Training]   Prec@1 92.941176 Max 92.941176
       [Avg Loss]          0.933400
       [Validation] Prec@1 72.972973 Max 80.540541
Confusion matrix:
[[24  4  0  1  0  1]
 [ 6 24  1  4  0  0]
 [ 0  0 28  2  0  0]
 [ 6  0  3 11  8  2]
 [ 4  3  0  0 23  0]
 [ 2  2  0  1  0 25]]
Epoch: [11]
       [Avg Loss]          0.265290
       [Training]   Prec@1 92.100840 Max 92.941176
       [Avg Loss]          0.854303
       [Validation] Prec@1 75.675676 Max 80.540541
Confusion matrix:
[[23  4  1  1  0  1]
 [ 4 30  0  0  0  1]
 [ 0  4 26  0  0  0]
 [ 5  0  5 13  6  1]
 [ 4  4  0  0 22  0]
 [ 2  2  0  0  0 26]]
Epoch: [12]
       [Avg Loss]          0.194827
       [Training]   Prec@1 92.436975 Max 92.941176
       [Avg Loss]          0.873100
       [Validation] Prec@1 76.756757 Max 80.540541
Confusion matrix:
[[21  5  0  4  0  0]
 [ 3 32  0  0  0  0]
 [ 0  5 21  4  0  0]
 [ 7  0  2 20  1  0]
 [ 2  4  0  1 23  0]
 [ 2  2  0  1  0 25]]
Epoch: [13]
       [Avg Loss]          0.210591
       [Training]   Prec@1 92.436975 Max 92.941176
       [Avg Loss]          0.847926
       [Validation] Prec@1 76.216216 Max 80.540541
Confusion matrix:
[[25  4  1  0  0  0]
 [ 5 30  0  0  0  0]
 [ 1  3 26  0  0  0]
 [ 8  0  5 15  1  1]
 [ 6  3  0  0 21  0]
 [ 3  2  0  1  0 24]]
Epoch: [14]
       [Avg Loss]          0.182979
       [Training]   Prec@1 94.789916 Max 94.789916
       [Avg Loss]          0.678014
       [Validation] Prec@1 81.621622 Max 81.621622
Confusion matrix:
[[25  4  0  1  0  0]
 [ 2 32  0  1  0  0]
 [ 0  2 27  1  0  0]
 [ 7  0  2 20  1  0]
 [ 6  3  0  0 21  0]
 [ 2  2  0  0  0 26]]
Fold "1" complete, final accuracy: 81.62162162162163
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.641659
       [Training]   Prec@1 35.798319 Max 35.798319
       [Avg Loss]          1.489690
       [Validation] Prec@1 62.162162 Max 62.162162
Confusion matrix:
[[17  6  0  0  4  3]
 [ 2 26  0  0  1  6]
 [ 8  4 10  1  7  0]
 [ 4  2  0  2 22  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  0  0 30]]
Epoch: [1]
       [Avg Loss]          1.066120
       [Training]   Prec@1 62.857143 Max 62.857143
       [Avg Loss]          1.029321
       [Validation] Prec@1 68.648649 Max 68.648649
Confusion matrix:
[[20  3  0  0  6  1]
 [ 2 30  0  0  0  3]
 [ 9  0 19  0  2  0]
 [ 4  6  2  4  8  6]
 [ 6  0  0  0 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [2]
       [Avg Loss]          0.820378
       [Training]   Prec@1 72.941176 Max 72.941176
       [Avg Loss]          1.057424
       [Validation] Prec@1 59.459459 Max 68.648649
Confusion matrix:
[[25  2  0  0  3  0]
 [10 19  0  1  0  5]
 [ 5  0 18  4  3  0]
 [11  1  0  3  9  6]
 [ 7  0  0  0 23  0]
 [ 8  0  0  0  0 22]]
Epoch: [3]
       [Avg Loss]          0.650130
       [Training]   Prec@1 76.302521 Max 76.302521
       [Avg Loss]          0.600115
       [Validation] Prec@1 83.243243 Max 83.243243
Confusion matrix:
[[21  1  1  0  7  0]
 [ 2 26  1  0  2  4]
 [ 0  0 30  0  0  0]
 [ 0  2  2 24  2  0]
 [ 2  0  0  3 25  0]
 [ 2  0  0  0  0 28]]
Epoch: [4]
       [Avg Loss]          0.546118
       [Training]   Prec@1 83.025210 Max 83.025210
       [Avg Loss]          1.193500
       [Validation] Prec@1 71.891892 Max 83.243243
Confusion matrix:
[[21  5  0  0  4  0]
 [ 6 26  1  0  0  2]
 [ 0  0 27  1  2  0]
 [ 0  8  3  9 10  0]
 [ 0  4  0  0 26  0]
 [ 1  1  4  0  0 24]]
Epoch: [5]
       [Avg Loss]          0.566510
       [Training]   Prec@1 80.504202 Max 83.025210
       [Avg Loss]          0.847783
       [Validation] Prec@1 76.756757 Max 83.243243
Confusion matrix:
[[22  1  0  0  7  0]
 [ 9 20  0  2  0  4]
 [ 0  0 28  2  0  0]
 [ 0  0  3 24  1  2]
 [ 4  0  0  5 21  0]
 [ 3  0  0  0  0 27]]
Epoch: [6]
       [Avg Loss]          0.490198
       [Training]   Prec@1 84.033613 Max 84.033613
       [Avg Loss]          0.764368
       [Validation] Prec@1 77.837838 Max 83.243243
Confusion matrix:
[[20  2  0  2  6  0]
 [ 3 25  1  3  1  2]
 [ 0  0 28  1  1  0]
 [ 4  0  1 20  5  0]
 [ 0  0  0  3 27  0]
 [ 5  1  0  0  0 24]]
Epoch: [7]
       [Avg Loss]          0.384669
       [Training]   Prec@1 88.907563 Max 88.907563
       [Avg Loss]          0.826095
       [Validation] Prec@1 80.000000 Max 83.243243
Confusion matrix:
[[20  2  0  1  6  1]
 [ 5 22  0  4  1  3]
 [ 0  0 30  0  0  0]
 [ 0  0  5 24  0  1]
 [ 0  0  2  3 25  0]
 [ 3  0  0  0  0 27]]
Epoch: [8]
       [Avg Loss]          0.340875
       [Training]   Prec@1 89.579832 Max 89.579832
       [Avg Loss]          0.701339
       [Validation] Prec@1 84.864865 Max 84.864865
Confusion matrix:
[[21  2  0  0  7  0]
 [ 3 29  0  0  0  3]
 [ 0  0 30  0  0  0]
 [ 1  3  2 23  1  0]
 [ 0  0  0  2 28  0]
 [ 4  0  0  0  0 26]]
Epoch: [9]
       [Avg Loss]          0.363719
       [Training]   Prec@1 89.915966 Max 89.915966
       [Avg Loss]          1.019656
       [Validation] Prec@1 76.756757 Max 84.864865
Confusion matrix:
[[19  0  0  0  9  2]
 [ 4 21  0  2  3  5]
 [ 0  0 28  2  0  0]
 [ 1  0  2 18  8  1]
 [ 0  0  0  2 28  0]
 [ 2  0  0  0  0 28]]
Epoch: [10]
       [Avg Loss]          0.356190
       [Training]   Prec@1 88.067227 Max 89.915966
       [Avg Loss]          0.858817
       [Validation] Prec@1 75.675676 Max 84.864865
Confusion matrix:
[[15 10  0  0  5  0]
 [ 6 24  0  3  0  2]
 [ 0  0 30  0  0  0]
 [ 0  1  5 24  0  0]
 [ 0  5  0  2 23  0]
 [ 5  1  0  0  0 24]]
Epoch: [11]
       [Avg Loss]          0.272808
       [Training]   Prec@1 91.932773 Max 91.932773
       [Avg Loss]          0.996122
       [Validation] Prec@1 76.216216 Max 84.864865
Confusion matrix:
[[21  0  0  0  9  0]
 [ 7 18  0  5  3  2]
 [ 0  0 28  0  2  0]
 [ 0  0  6 19  5  0]
 [ 0  0  0  0 30  0]
 [ 5  0  0  0  0 25]]
Epoch: [12]
       [Avg Loss]          0.272592
       [Training]   Prec@1 91.092437 Max 91.932773
       [Avg Loss]          0.759608
       [Validation] Prec@1 78.918919 Max 84.864865
Confusion matrix:
[[17  8  0  0  4  1]
 [ 4 28  1  1  0  1]
 [ 0  0 30  0  0  0]
 [ 0  0  2 28  0  0]
 [ 0  4  0  5 21  0]
 [ 5  3  0  0  0 22]]
Epoch: [13]
       [Avg Loss]          0.231937
       [Training]   Prec@1 92.773109 Max 92.773109
       [Avg Loss]          0.977938
       [Validation] Prec@1 76.756757 Max 84.864865
Confusion matrix:
[[20  4  0  0  5  1]
 [ 6 25  0  1  1  2]
 [ 0  0 30  0  0  0]
 [ 3  3  4 19  0  1]
 [ 0  3  0  4 23  0]
 [ 5  0  0  0  0 25]]
Epoch: [14]
       [Avg Loss]          0.206165
       [Training]   Prec@1 92.605042 Max 92.773109
       [Avg Loss]          0.981987
       [Validation] Prec@1 73.513514 Max 84.864865
Confusion matrix:
[[17  2  0  3  7  1]
 [ 5 17  1  6  1  5]
 [ 0  0 30  0  0  0]
 [ 0  0  1 26  3  0]
 [ 0  1  0  6 23  0]
 [ 7  0  0  0  0 23]]
Fold "2" complete, final accuracy: 84.86486486486487
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.451114
       [Training]   Prec@1 43.181818 Max 43.181818
       [Avg Loss]          1.344077
       [Validation] Prec@1 63.333333 Max 63.333333
Confusion matrix:
[[12  0  0  8  0  0]
 [ 0 13  0  2  2  3]
 [ 0  1  2  4 13  0]
 [ 0  0  0 14  5  1]
 [ 0  0  0  0 20  0]
 [ 0  2  0  3  0 15]]
Epoch: [1]
       [Avg Loss]          0.916620
       [Training]   Prec@1 67.878788 Max 67.878788
       [Avg Loss]          0.876290
       [Validation] Prec@1 72.500000 Max 72.500000
Confusion matrix:
[[17  0  0  3  0  0]
 [ 0 14  0  2  0  4]
 [ 1  1  5  6  7  0]
 [ 1  1  0 14  2  2]
 [ 0  0  0  0 20  0]
 [ 2  0  0  1  0 17]]
Epoch: [2]
       [Avg Loss]          0.725726
       [Training]   Prec@1 76.969697 Max 76.969697
       [Avg Loss]          0.658502
       [Validation] Prec@1 80.833333 Max 80.833333
Confusion matrix:
[[18  0  0  2  0  0]
 [ 0 18  1  1  0  0]
 [ 0  0 13  7  0  0]
 [ 1  0  1 16  1  1]
 [ 0  0  0  6 14  0]
 [ 0  2  0  0  0 18]]
Epoch: [3]
       [Avg Loss]          0.663338
       [Training]   Prec@1 78.181818 Max 78.181818
       [Avg Loss]          0.922158
       [Validation] Prec@1 69.166667 Max 80.833333
Confusion matrix:
[[ 9  0  0 11  0  0]
 [ 0 16  0  2  0  2]
 [ 0  1  8 11  0  0]
 [ 0  1  0 16  2  1]
 [ 0  0  0  0 20  0]
 [ 2  1  0  3  0 14]]
Epoch: [4]
       [Avg Loss]          0.547837
       [Training]   Prec@1 82.424242 Max 82.424242
       [Avg Loss]          0.709277
       [Validation] Prec@1 77.500000 Max 80.833333
Confusion matrix:
[[14  0  4  0  2  0]
 [ 0 18  0  2  0  0]
 [ 0  0 16  2  2  0]
 [ 1  0  5 12  1  1]
 [ 0  0  0  0 20  0]
 [ 0  5  0  2  0 13]]
Epoch: [5]
       [Avg Loss]          0.556177
       [Training]   Prec@1 81.060606 Max 82.424242
       [Avg Loss]          0.971578
       [Validation] Prec@1 65.833333 Max 80.833333
Confusion matrix:
[[13  0  0  7  0  0]
 [ 0 19  0  1  0  0]
 [ 2  0 11  6  1  0]
 [ 1  0  1 18  0  0]
 [ 0  0  0  9 11  0]
 [ 1  5  0  7  0  7]]
Epoch: [6]
       [Avg Loss]          0.492742
       [Training]   Prec@1 83.636364 Max 83.636364
       [Avg Loss]          0.459640
       [Validation] Prec@1 87.500000 Max 87.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 1 19  0  0  0  0]
 [ 0  1 16  2  1  0]
 [ 5  0  2 12  0  1]
 [ 0  0  0  0 20  0]
 [ 1  1  0  0  0 18]]
Epoch: [7]
       [Avg Loss]          0.377940
       [Training]   Prec@1 86.515152 Max 86.515152
       [Avg Loss]          0.929670
       [Validation] Prec@1 71.666667 Max 87.500000
Confusion matrix:
[[ 9  0  0 11  0  0]
 [ 0 19  0  1  0  0]
 [ 0  2 13  5  0  0]
 [ 0  1  1 18  0  0]
 [ 1  0  0  2 17  0]
 [ 0  3  0  7  0 10]]
Epoch: [8]
       [Avg Loss]          0.349039
       [Training]   Prec@1 88.030303 Max 88.030303
       [Avg Loss]          0.714123
       [Validation] Prec@1 80.000000 Max 87.500000
Confusion matrix:
[[13  0  0  6  0  1]
 [ 0 19  0  0  0  1]
 [ 3  0 13  4  0  0]
 [ 3  0  1 15  0  1]
 [ 0  0  0  0 20  0]
 [ 3  1  0  0  0 16]]
Epoch: [9]
       [Avg Loss]          0.311757
       [Training]   Prec@1 89.848485 Max 89.848485
       [Avg Loss]          0.891447
       [Validation] Prec@1 73.333333 Max 87.500000
Confusion matrix:
[[ 5  0  1 14  0  0]
 [ 0 18  1  1  0  0]
 [ 0  0 14  6  0  0]
 [ 0  0  3 16  0  1]
 [ 0  0  0  0 20  0]
 [ 0  2  0  3  0 15]]
Epoch: [10]
       [Avg Loss]          0.379371
       [Training]   Prec@1 88.333333 Max 89.848485
       [Avg Loss]          0.872746
       [Validation] Prec@1 70.000000 Max 87.500000
Confusion matrix:
[[ 7  0  0 12  1  0]
 [ 1 18  0  1  0  0]
 [ 0  2  7 11  0  0]
 [ 0  2  0 17  0  1]
 [ 0  0  0  0 20  0]
 [ 3  1  0  1  0 15]]
Epoch: [11]
       [Avg Loss]          0.275374
       [Training]   Prec@1 90.757576 Max 90.757576
       [Avg Loss]          0.917916
       [Validation] Prec@1 72.500000 Max 87.500000
Confusion matrix:
[[ 9  0  0 11  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 16  3  1  0]
 [ 0  0  2 17  0  1]
 [ 0  0  0  9 11  0]
 [ 0  4  0  1  0 15]]
Epoch: [12]
       [Avg Loss]          0.262496
       [Training]   Prec@1 92.121212 Max 92.121212
       [Avg Loss]          0.930477
       [Validation] Prec@1 80.000000 Max 87.500000
Confusion matrix:
[[10  0  0  9  1  0]
 [ 0 19  0  1  0  0]
 [ 0  0 14  6  0  0]
 [ 0  2  0 17  0  1]
 [ 0  0  0  0 20  0]
 [ 2  2  0  0  0 16]]
Epoch: [13]
       [Avg Loss]          0.207614
       [Training]   Prec@1 93.787879 Max 93.787879
       [Avg Loss]          0.855483
       [Validation] Prec@1 79.166667 Max 87.500000
Confusion matrix:
[[13  0  0  7  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 14  6  0  0]
 [ 1  2  0 16  0  1]
 [ 0  0  0  0 20  0]
 [ 3  4  0  0  0 13]]
Epoch: [14]
       [Avg Loss]          0.203106
       [Training]   Prec@1 93.181818 Max 93.787879
       [Avg Loss]          0.932554
       [Validation] Prec@1 80.833333 Max 87.500000
Confusion matrix:
[[11  0  0  9  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 14  5  1  0]
 [ 0  0  0 19  0  1]
 [ 0  0  0  0 20  0]
 [ 1  3  0  2  0 14]]
Fold "3" complete, final accuracy: 87.5
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.410692
       [Training]   Prec@1 46.119403 Max 46.119403
       [Avg Loss]          1.521446
       [Validation] Prec@1 56.363636 Max 56.363636
Confusion matrix:
[[17  0  1  0  2  0]
 [ 8  9  3  0  0  0]
 [ 8  1 11  0  0  0]
 [ 8  6  4  2  0  0]
 [ 0  0  0  0 10  0]
 [ 5  2  0  0  0 13]]
Epoch: [1]
       [Avg Loss]          0.788717
       [Training]   Prec@1 73.582090 Max 73.582090
       [Avg Loss]          1.466455
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[16  0  1  0  3  0]
 [ 3  8  2  0  7  0]
 [ 7  0 11  1  0  1]
 [ 0  6 12  1  0  1]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          0.610715
       [Training]   Prec@1 80.000000 Max 80.000000
       [Avg Loss]          1.149958
       [Validation] Prec@1 65.454545 Max 65.454545
Confusion matrix:
[[17  2  1  0  0  0]
 [ 1  7 10  0  2  0]
 [ 6  0 13  0  0  1]
 [ 0  5  7  8  0  0]
 [ 0  0  3  0  7  0]
 [ 0  0  0  0  0 20]]
Epoch: [3]
       [Avg Loss]          0.581732
       [Training]   Prec@1 82.985075 Max 82.985075
       [Avg Loss]          1.360975
       [Validation] Prec@1 67.272727 Max 67.272727
Confusion matrix:
[[16  0  1  2  1  0]
 [ 1  7  3  3  6  0]
 [ 6  0 10  1  2  1]
 [ 0  5  3 12  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  1  0 19]]
Epoch: [4]
       [Avg Loss]          0.526008
       [Training]   Prec@1 82.089552 Max 82.985075
       [Avg Loss]          1.414985
       [Validation] Prec@1 58.181818 Max 67.272727
Confusion matrix:
[[12  1  0  5  1  1]
 [ 1  2  4  4  9  0]
 [ 6  0  8  5  0  1]
 [ 0  5  3 12  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.474282
       [Training]   Prec@1 85.671642 Max 85.671642
       [Avg Loss]          1.115245
       [Validation] Prec@1 73.636364 Max 73.636364
Confusion matrix:
[[18  2  0  0  0  0]
 [ 5 13  0  2  0  0]
 [ 6  0 13  0  0  1]
 [ 0  5  5 10  0  0]
 [ 0  0  0  2  8  0]
 [ 0  0  0  1  0 19]]
Epoch: [6]
       [Avg Loss]          0.456065
       [Training]   Prec@1 86.268657 Max 86.268657
       [Avg Loss]          1.375620
       [Validation] Prec@1 67.272727 Max 73.636364
Confusion matrix:
[[17  1  0  1  0  1]
 [ 2 13  0  2  3  0]
 [ 6  0 13  0  0  1]
 [ 0  2 12  2  0  4]
 [ 0  0  0  0 10  0]
 [ 0  0  0  1  0 19]]
Epoch: [7]
       [Avg Loss]          0.357616
       [Training]   Prec@1 87.761194 Max 87.761194
       [Avg Loss]          1.245411
       [Validation] Prec@1 65.454545 Max 73.636364
Confusion matrix:
[[13  0  0  2  4  1]
 [ 6  9  0  3  2  0]
 [ 6  0 11  2  0  1]
 [ 0  3  6 11  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  2  0 18]]
Epoch: [8]
       [Avg Loss]          0.321984
       [Training]   Prec@1 88.656716 Max 88.656716
       [Avg Loss]          0.967362
       [Validation] Prec@1 72.727273 Max 73.636364
Confusion matrix:
[[17  0  0  3  0  0]
 [ 0 12  0  4  4  0]
 [ 6  0  8  6  0  0]
 [ 0  2  2 14  0  2]
 [ 0  0  0  0 10  0]
 [ 0  0  0  1  0 19]]
Epoch: [9]
       [Avg Loss]          0.263833
       [Training]   Prec@1 92.238806 Max 92.238806
       [Avg Loss]          1.258294
       [Validation] Prec@1 60.000000 Max 73.636364
Confusion matrix:
[[14  0  0  5  1  0]
 [ 3 10  0  4  3  0]
 [ 5  0  6  8  0  1]
 [ 0  5  6  9  0  0]
 [ 0  0  0  1  9  0]
 [ 0  0  0  2  0 18]]
Epoch: [10]
       [Avg Loss]          0.264100
       [Training]   Prec@1 92.089552 Max 92.238806
       [Avg Loss]          1.300796
       [Validation] Prec@1 65.454545 Max 73.636364
Confusion matrix:
[[14  0  0  4  0  2]
 [ 0 11  0  5  3  1]
 [ 5  0  3 10  0  2]
 [ 0  1  2 16  0  1]
 [ 0  0  0  0 10  0]
 [ 0  0  0  2  0 18]]
Epoch: [11]
       [Avg Loss]          0.217150
       [Training]   Prec@1 93.134328 Max 93.134328
       [Avg Loss]          1.386833
       [Validation] Prec@1 66.363636 Max 73.636364
Confusion matrix:
[[13  0  0  3  4  0]
 [ 1 12  0  3  4  0]
 [ 6  0  6  7  0  1]
 [ 0  1  2 14  0  3]
 [ 0  0  0  0 10  0]
 [ 0  0  0  2  0 18]]
Epoch: [12]
       [Avg Loss]          0.262794
       [Training]   Prec@1 91.940299 Max 93.134328
       [Avg Loss]          1.538897
       [Validation] Prec@1 65.454545 Max 73.636364
Confusion matrix:
[[12  0  0  5  3  0]
 [ 0 15  0  2  3  0]
 [ 3  0  7  9  0  1]
 [ 1  3  4  9  0  3]
 [ 0  0  0  0 10  0]
 [ 0  0  0  1  0 19]]
Epoch: [13]
       [Avg Loss]          0.198076
       [Training]   Prec@1 94.179104 Max 94.179104
       [Avg Loss]          1.584739
       [Validation] Prec@1 62.727273 Max 73.636364
Confusion matrix:
[[16  0  0  4  0  0]
 [ 3  8  0  3  6  0]
 [ 6  0  6  8  0  0]
 [ 0  1  7 12  0  0]
 [ 0  0  0  0 10  0]
 [ 1  0  0  2  0 17]]
Epoch: [14]
       [Avg Loss]          0.196765
       [Training]   Prec@1 94.179104 Max 94.179104
       [Avg Loss]          1.384643
       [Validation] Prec@1 64.545455 Max 73.636364
Confusion matrix:
[[17  0  1  2  0  0]
 [ 0  5  0  5 10  0]
 [ 5  0  9  4  0  2]
 [ 0  1  6 10  0  3]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Fold "4" complete, final accuracy: 73.63636363636364

-----------------------------------------------------------------------
Training for stage 5 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=12)")
Average accuracy is: 80.74679224679225


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 6-----
Evaluated preprocessing: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=12)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.346937
       [Training]   Prec@1 50.166667 Max 50.166667
       [Avg Loss]          1.474119
       [Validation] Prec@1 72.222222 Max 72.222222
Confusion matrix:
[[26  0  0  0  4 10]
 [ 0 29  0  1  0  0]
 [ 0  0 30  0  0  0]
 [ 1  0 24  0  5  0]
 [ 3  0  1  0 26  0]
 [ 0  1  0  0  0 19]]
Epoch: [1]
       [Avg Loss]          0.801279
       [Training]   Prec@1 73.500000 Max 73.500000
       [Avg Loss]          1.072889
       [Validation] Prec@1 73.888889 Max 73.888889
Confusion matrix:
[[28  0  2  0  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 29  0  0  0]
 [ 3  0  2  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          0.669667
       [Training]   Prec@1 77.666667 Max 77.666667
       [Avg Loss]          1.188418
       [Validation] Prec@1 70.000000 Max 73.888889
Confusion matrix:
[[21  0  4  0  5 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 29  0  0  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [3]
       [Avg Loss]          0.563356
       [Training]   Prec@1 82.000000 Max 82.000000
       [Avg Loss]          1.406228
       [Validation] Prec@1 69.444444 Max 73.888889
Confusion matrix:
[[20  0  0  1  9 10]
 [ 0 28  0  1  0  1]
 [ 0  0 30  0  0  0]
 [ 0  0 28  1  1  0]
 [ 4  0  0  0 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          0.496102
       [Training]   Prec@1 84.333333 Max 84.333333
       [Avg Loss]          1.321399
       [Validation] Prec@1 72.222222 Max 73.888889
Confusion matrix:
[[25  0  0  4  1 10]
 [ 0 30  0  0  0  0]
 [ 0  0 28  0  2  0]
 [ 1  0 14  2 13  0]
 [ 2  0  2  0 26  0]
 [ 0  1  0  0  0 19]]
Epoch: [5]
       [Avg Loss]          0.494348
       [Training]   Prec@1 83.166667 Max 84.333333
       [Avg Loss]          1.467620
       [Validation] Prec@1 68.888889 Max 73.888889
Confusion matrix:
[[28  0  1  1  0 10]
 [ 0 20  4  6  0  0]
 [ 0  0 30  0  0  0]
 [ 1  0 25  4  0  0]
 [ 4  0  2  0 24  0]
 [ 0  0  0  2  0 18]]
Epoch: [6]
       [Avg Loss]          0.506268
       [Training]   Prec@1 84.500000 Max 84.500000
       [Avg Loss]          1.811576
       [Validation] Prec@1 70.555556 Max 73.888889
Confusion matrix:
[[24  0  6  0  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 29  1  0  0]
 [ 0  0  7  0 23  0]
 [ 0  0  0  1  0 19]]
Epoch: [7]
       [Avg Loss]          0.464701
       [Training]   Prec@1 86.166667 Max 86.166667
       [Avg Loss]          1.419056
       [Validation] Prec@1 74.444444 Max 74.444444
Confusion matrix:
[[29  0  0  1  0 10]
 [ 0 28  2  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 27  3  0  0]
 [ 4  0  1  0 25  0]
 [ 0  0  0  1  0 19]]
Epoch: [8]
       [Avg Loss]          0.460462
       [Training]   Prec@1 85.000000 Max 86.166667
       [Avg Loss]          1.268924
       [Validation] Prec@1 73.888889 Max 74.444444
Confusion matrix:
[[23  0  1  2  4 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  2 20  1  6  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  1  0 19]]
Epoch: [9]
       [Avg Loss]          0.316451
       [Training]   Prec@1 90.666667 Max 90.666667
       [Avg Loss]          1.170429
       [Validation] Prec@1 72.777778 Max 74.444444
Confusion matrix:
[[24  0  3  1  2 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 27  3  0  0]
 [ 1  0  4  0 25  0]
 [ 0  0  0  1  0 19]]
Epoch: [10]
       [Avg Loss]          0.371678
       [Training]   Prec@1 87.500000 Max 90.666667
       [Avg Loss]          1.629811
       [Validation] Prec@1 67.777778 Max 74.444444
Confusion matrix:
[[15  0  6  9  0 10]
 [ 0 29  1  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 27  3  0  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [11]
       [Avg Loss]          0.307342
       [Training]   Prec@1 91.000000 Max 91.000000
       [Avg Loss]          0.974736
       [Validation] Prec@1 77.222222 Max 77.222222
Confusion matrix:
[[29  0  0  1  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  1  7  4 17  0]
 [ 4  0  0  0 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [12]
       [Avg Loss]          0.287783
       [Training]   Prec@1 91.833333 Max 91.833333
       [Avg Loss]          1.283095
       [Validation] Prec@1 75.555556 Max 77.222222
Confusion matrix:
[[27  0  2  1  0 10]
 [ 0 27  1  0  0  2]
 [ 0  0 30  0  0  0]
 [ 0  0 23  6  1  0]
 [ 1  0  3  0 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [13]
       [Avg Loss]          0.223210
       [Training]   Prec@1 93.166667 Max 93.166667
       [Avg Loss]          1.276684
       [Validation] Prec@1 73.333333 Max 77.222222
Confusion matrix:
[[22  0  7  1  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 23  6  0  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  1  0 19]]
Epoch: [14]
       [Avg Loss]          0.184214
       [Training]   Prec@1 94.333333 Max 94.333333
       [Avg Loss]          1.447724
       [Validation] Prec@1 73.333333 Max 77.222222
Confusion matrix:
[[22  0  0  1  7 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1  8  3 18  0]
 [ 2  1  0  0 27  0]
 [ 0  0  0  0  0 20]]
Fold "0" complete, final accuracy: 77.22222222222223
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.349377
       [Training]   Prec@1 51.260504 Max 51.260504
       [Avg Loss]          1.499262
       [Validation] Prec@1 54.054054 Max 54.054054
Confusion matrix:
[[24  6  0  0  0  0]
 [ 1 34  0  0  0  0]
 [ 9  5 16  0  0  0]
 [24  2  3  1  0  0]
 [13  4  0  0 13  0]
 [16  2  0  0  0 12]]
Epoch: [1]
       [Avg Loss]          0.925178
       [Training]   Prec@1 70.756303 Max 70.756303
       [Avg Loss]          0.948609
       [Validation] Prec@1 67.567568 Max 67.567568
Confusion matrix:
[[23  6  0  0  0  1]
 [ 1 34  0  0  0  0]
 [ 0  8 21  1  0  0]
 [18  3  6  2  0  1]
 [ 5  2  0  0 23  0]
 [ 5  2  1  0  0 22]]
Epoch: [2]
       [Avg Loss]          0.735427
       [Training]   Prec@1 73.781513 Max 73.781513
       [Avg Loss]          1.177361
       [Validation] Prec@1 62.162162 Max 67.567568
Confusion matrix:
[[24  2  0  0  0  4]
 [ 4 29  1  0  0  1]
 [ 8  2 20  0  0  0]
 [14  2  5  7  1  1]
 [19  1  0  0 10  0]
 [ 2  1  0  2  0 25]]
Epoch: [3]
       [Avg Loss]          0.732259
       [Training]   Prec@1 73.445378 Max 73.781513
       [Avg Loss]          0.848616
       [Validation] Prec@1 72.432432 Max 72.432432
Confusion matrix:
[[19  9  2  0  0  0]
 [ 0 34  1  0  0  0]
 [ 0  2 28  0  0  0]
 [ 5  4  4 15  2  0]
 [ 3  5  0  5 17  0]
 [ 2  3  1  3  0 21]]
Epoch: [4]
       [Avg Loss]          0.627589
       [Training]   Prec@1 76.302521 Max 76.302521
       [Avg Loss]          0.944671
       [Validation] Prec@1 67.027027 Max 72.432432
Confusion matrix:
[[21  9  0  0  0  0]
 [ 0 22 12  1  0  0]
 [ 1  2 27  0  0  0]
 [10  0  6 12  2  0]
 [ 2  6  0  1 21  0]
 [ 1  3  1  4  0 21]]
Epoch: [5]
       [Avg Loss]          0.525216
       [Training]   Prec@1 82.689076 Max 82.689076
       [Avg Loss]          0.804523
       [Validation] Prec@1 79.459459 Max 79.459459
Confusion matrix:
[[26  4  0  0  0  0]
 [ 1 32  2  0  0  0]
 [ 2  2 26  0  0  0]
 [ 7  2  1 19  1  0]
 [ 5  0  0  1 24  0]
 [ 3  1  1  5  0 20]]
Epoch: [6]
       [Avg Loss]          0.491052
       [Training]   Prec@1 81.512605 Max 82.689076
       [Avg Loss]          0.965662
       [Validation] Prec@1 65.405405 Max 79.459459
Confusion matrix:
[[15  5  5  0  0  5]
 [ 1 33  0  0  0  1]
 [ 1  5 24  0  0  0]
 [ 8  2  6 14  0  0]
 [ 9  1  0  5 13  2]
 [ 2  2  1  3  0 22]]
Epoch: [7]
       [Avg Loss]          0.477479
       [Training]   Prec@1 84.705882 Max 84.705882
       [Avg Loss]          0.698336
       [Validation] Prec@1 78.378378 Max 79.459459
Confusion matrix:
[[24  4  1  1  0  0]
 [ 1 32  2  0  0  0]
 [ 0  2 26  2  0  0]
 [ 8  2  1 17  1  1]
 [ 5  0  0  0 25  0]
 [ 1  2  1  5  0 21]]
Epoch: [8]
       [Avg Loss]          0.388278
       [Training]   Prec@1 86.218487 Max 86.218487
       [Avg Loss]          1.044852
       [Validation] Prec@1 72.432432 Max 79.459459
Confusion matrix:
[[22  7  0  1  0  0]
 [ 1 34  0  0  0  0]
 [ 0  5 24  1  0  0]
 [14  2  1 11  2  0]
 [ 3  3  0  2 22  0]
 [ 1  2  1  5  0 21]]
Epoch: [9]
       [Avg Loss]          0.371652
       [Training]   Prec@1 85.378151 Max 86.218487
       [Avg Loss]          0.992562
       [Validation] Prec@1 75.675676 Max 79.459459
Confusion matrix:
[[25  3  2  0  0  0]
 [ 3 32  0  0  0  0]
 [ 1  4 25  0  0  0]
 [13  0  3 13  1  0]
 [ 5  0  0  0 25  0]
 [ 5  1  0  4  0 20]]
Epoch: [10]
       [Avg Loss]          0.393219
       [Training]   Prec@1 86.554622 Max 86.554622
       [Avg Loss]          1.035634
       [Validation] Prec@1 72.972973 Max 79.459459
Confusion matrix:
[[24  4  0  0  1  1]
 [ 3 32  0  0  0  0]
 [ 1  6 21  0  2  0]
 [11  2  1 10  5  1]
 [ 4  0  0  0 26  0]
 [ 2  3  0  3  0 22]]
Epoch: [11]
       [Avg Loss]          0.340088
       [Training]   Prec@1 89.075630 Max 89.075630
       [Avg Loss]          0.854826
       [Validation] Prec@1 76.756757 Max 79.459459
Confusion matrix:
[[25  4  1  0  0  0]
 [ 1 34  0  0  0  0]
 [ 0  6 24  0  0  0]
 [ 8  2  0 18  1  1]
 [11  0  0  0 19  0]
 [ 2  2  0  4  0 22]]
Epoch: [12]
       [Avg Loss]          0.220716
       [Training]   Prec@1 92.941176 Max 92.941176
       [Avg Loss]          1.080993
       [Validation] Prec@1 70.810811 Max 79.459459
Confusion matrix:
[[26  4  0  0  0  0]
 [ 1 34  0  0  0  0]
 [ 3  6 19  2  0  0]
 [11  1  1 15  1  1]
 [10  0  0  4 16  0]
 [ 2  2  0  5  0 21]]
Epoch: [13]
       [Avg Loss]          0.210940
       [Training]   Prec@1 93.949580 Max 93.949580
       [Avg Loss]          1.235020
       [Validation] Prec@1 71.351351 Max 79.459459
Confusion matrix:
[[25  2  1  0  2  0]
 [ 3 31  0  1  0  0]
 [ 2  1 21  5  1  0]
 [13  0  1 11  5  0]
 [ 9  0  0  0 21  0]
 [ 2  1  0  4  0 23]]
Epoch: [14]
       [Avg Loss]          0.225603
       [Training]   Prec@1 93.277311 Max 93.949580
       [Avg Loss]          1.140997
       [Validation] Prec@1 72.432432 Max 79.459459
Confusion matrix:
[[22  5  0  0  0  3]
 [ 1 34  0  0  0  0]
 [ 0  3 26  0  1  0]
 [13  1  2 13  1  0]
 [ 4  2  0  3 21  0]
 [ 5  2  1  4  0 18]]
Fold "1" complete, final accuracy: 79.45945945945945
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.423774
       [Training]   Prec@1 46.218487 Max 46.218487
       [Avg Loss]          1.406475
       [Validation] Prec@1 63.243243 Max 63.243243
Confusion matrix:
[[ 8  2  8  3  9  0]
 [ 1 28  6  0  0  0]
 [ 0  0 24  0  6  0]
 [ 2  6  6  7  9  0]
 [ 0  0  5  0 25  0]
 [ 0  5  0  0  0 25]]
Epoch: [1]
       [Avg Loss]          0.966834
       [Training]   Prec@1 65.714286 Max 65.714286
       [Avg Loss]          1.038561
       [Validation] Prec@1 67.027027 Max 67.027027
Confusion matrix:
[[22  0  0  0  8  0]
 [ 0 21 10  0  0  4]
 [ 4  0 24  2  0  0]
 [ 4  2  9 13  1  1]
 [11  0  5  0 14  0]
 [ 0  0  0  0  0 30]]
Epoch: [2]
       [Avg Loss]          0.770855
       [Training]   Prec@1 73.949580 Max 73.949580
       [Avg Loss]          0.763381
       [Validation] Prec@1 70.270270 Max 70.270270
Confusion matrix:
[[21  2  1  0  6  0]
 [ 3 17 10  0  0  5]
 [ 2  0 26  2  0  0]
 [ 0  0 10 16  0  4]
 [ 1  0  8  1 20  0]
 [ 0  0  0  0  0 30]]
Epoch: [3]
       [Avg Loss]          0.655031
       [Training]   Prec@1 76.470588 Max 76.470588
       [Avg Loss]          1.027546
       [Validation] Prec@1 66.486486 Max 70.270270
Confusion matrix:
[[21  0  0  0  9  0]
 [ 8 17  5  2  3  0]
 [ 9  0  9  0 12  0]
 [ 1  1  5 21  2  0]
 [ 1  0  0  0 29  0]
 [ 4  0  0  0  0 26]]
Epoch: [4]
       [Avg Loss]          0.689719
       [Training]   Prec@1 75.798319 Max 76.470588
       [Avg Loss]          0.931179
       [Validation] Prec@1 71.891892 Max 71.891892
Confusion matrix:
[[20  0  0  1  9  0]
 [ 2 30  1  0  0  2]
 [ 2  0  7  8 13  0]
 [ 0  6  1 19  2  2]
 [ 1  0  0  2 27  0]
 [ 0  0  0  0  0 30]]
Epoch: [5]
       [Avg Loss]          0.502002
       [Training]   Prec@1 82.521008 Max 82.521008
       [Avg Loss]          1.128692
       [Validation] Prec@1 70.810811 Max 71.891892
Confusion matrix:
[[21  0  1  0  8  0]
 [ 6 26  0  0  2  1]
 [ 2  0 13  8  7  0]
 [ 0  5  0 17  7  1]
 [ 0  0  1  5 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [6]
       [Avg Loss]          0.488505
       [Training]   Prec@1 83.865546 Max 83.865546
       [Avg Loss]          1.219807
       [Validation] Prec@1 71.891892 Max 71.891892
Confusion matrix:
[[18  0  0  2 10  0]
 [ 5 27  0  0  2  1]
 [ 1  0  8  2 19  0]
 [ 0  2  2 23  2  1]
 [ 0  0  0  1 29  0]
 [ 2  0  0  0  0 28]]
Epoch: [7]
       [Avg Loss]          0.412497
       [Training]   Prec@1 86.218487 Max 86.218487
       [Avg Loss]          1.089670
       [Validation] Prec@1 71.351351 Max 71.891892
Confusion matrix:
[[16  0  1  5  8  0]
 [ 6 25  0  1  0  3]
 [ 0  0 20  9  1  0]
 [ 0  4  2 23  0  1]
 [ 0  0  0 10 20  0]
 [ 2  0  0  0  0 28]]
Epoch: [8]
       [Avg Loss]          0.440774
       [Training]   Prec@1 84.705882 Max 86.218487
       [Avg Loss]          1.010985
       [Validation] Prec@1 71.891892 Max 71.891892
Confusion matrix:
[[15  0  4  1  5  5]
 [ 5 28  1  0  0  1]
 [ 1  0 21  6  2  0]
 [ 0  8  1 19  0  2]
 [ 2  0  4  1 23  0]
 [ 3  0  0  0  0 27]]
Epoch: [9]
       [Avg Loss]          0.435615
       [Training]   Prec@1 84.873950 Max 86.218487
       [Avg Loss]          1.141518
       [Validation] Prec@1 72.972973 Max 72.972973
Confusion matrix:
[[21  2  0  0  7  0]
 [ 6 27  0  0  1  1]
 [ 2  0 14 14  0  0]
 [ 0  5  0 18  6  1]
 [ 0  0  1  2 27  0]
 [ 2  0  0  0  0 28]]
Epoch: [10]
       [Avg Loss]          0.386031
       [Training]   Prec@1 88.067227 Max 88.067227
       [Avg Loss]          0.975532
       [Validation] Prec@1 77.837838 Max 77.837838
Confusion matrix:
[[19  0  2  2  7  0]
 [ 6 24  1  3  0  1]
 [ 0  0 22  7  1  0]
 [ 0  0  2 27  0  1]
 [ 0  0  0  6 24  0]
 [ 2  0  0  0  0 28]]
Epoch: [11]
       [Avg Loss]          0.314544
       [Training]   Prec@1 88.571429 Max 88.571429
       [Avg Loss]          0.910269
       [Validation] Prec@1 75.135135 Max 77.837838
Confusion matrix:
[[20  0  0  2  8  0]
 [ 8 22  1  0  1  3]
 [ 1  0 20  2  7  0]
 [ 0  2  2 24  2  0]
 [ 0  0  0  3 27  0]
 [ 3  0  0  1  0 26]]
Epoch: [12]
       [Avg Loss]          0.411681
       [Training]   Prec@1 86.050420 Max 88.571429
       [Avg Loss]          1.184272
       [Validation] Prec@1 63.243243 Max 77.837838
Confusion matrix:
[[19  2  0  2  7  0]
 [ 4 20  7  0  0  4]
 [ 0  0 12 17  1  0]
 [ 0  2  4 22  0  2]
 [ 0  0  0 14 16  0]
 [ 2  0  0  0  0 28]]
Epoch: [13]
       [Avg Loss]          0.371555
       [Training]   Prec@1 89.915966 Max 89.915966
       [Avg Loss]          0.852591
       [Validation] Prec@1 77.837838 Max 77.837838
Confusion matrix:
[[19  4  0  1  6  0]
 [ 3 30  0  1  0  1]
 [ 0  0 17  1 12  0]
 [ 0  2  0 24  3  1]
 [ 0  0  0  2 28  0]
 [ 4  0  0  0  0 26]]
Epoch: [14]
       [Avg Loss]          0.294140
       [Training]   Prec@1 89.747899 Max 89.915966
       [Avg Loss]          1.393685
       [Validation] Prec@1 70.270270 Max 77.837838
Confusion matrix:
[[20  0  0  0  9  1]
 [ 7 22  3  2  0  1]
 [ 2  0 16  9  3  0]
 [ 0  0  0 26  0  4]
 [ 0  0  0 11 19  0]
 [ 3  0  0  0  0 27]]
Fold "2" complete, final accuracy: 77.83783783783784
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.360801
       [Training]   Prec@1 50.151515 Max 50.151515
       [Avg Loss]          1.321510
       [Validation] Prec@1 61.666667 Max 61.666667
Confusion matrix:
[[13  0  5  0  2  0]
 [ 0 18  0  0  2  0]
 [ 0  2  2  2 14  0]
 [ 1  3  3  7  6  0]
 [ 0  0  0  0 20  0]
 [ 0  5  0  0  1 14]]
Epoch: [1]
       [Avg Loss]          0.927662
       [Training]   Prec@1 70.909091 Max 70.909091
       [Avg Loss]          0.800855
       [Validation] Prec@1 70.833333 Max 70.833333
Confusion matrix:
[[15  0  0  0  0  5]
 [ 0 17  1  2  0  0]
 [ 1  0  6 13  0  0]
 [ 1  1  0 12  1  5]
 [ 0  0  0  1 19  0]
 [ 0  3  0  1  0 16]]
Epoch: [2]
       [Avg Loss]          0.733510
       [Training]   Prec@1 74.848485 Max 74.848485
       [Avg Loss]          0.768705
       [Validation] Prec@1 73.333333 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 18  0  1  0  1]
 [ 0  4  6 10  0  0]
 [ 8  2  0  8  1  1]
 [ 0  0  0  0 20  0]
 [ 0  3  0  1  0 16]]
Epoch: [3]
       [Avg Loss]          0.721220
       [Training]   Prec@1 76.060606 Max 76.060606
       [Avg Loss]          1.040478
       [Validation] Prec@1 64.166667 Max 73.333333
Confusion matrix:
[[15  0  0  5  0  0]
 [ 0 17  0  3  0  0]
 [ 0  1  6 13  0  0]
 [ 2  0  2 16  0  0]
 [ 0  0  0  7 13  0]
 [ 6  0  0  3  1 10]]
Epoch: [4]
       [Avg Loss]          0.649854
       [Training]   Prec@1 79.242424 Max 79.242424
       [Avg Loss]          0.567431
       [Validation] Prec@1 82.500000 Max 82.500000
Confusion matrix:
[[19  0  1  0  0  0]
 [ 0 16  1  2  0  1]
 [ 0  1 18  1  0  0]
 [ 5  1  0 14  0  0]
 [ 0  1  1  1 17  0]
 [ 0  2  0  3  0 15]]
Epoch: [5]
       [Avg Loss]          0.499008
       [Training]   Prec@1 82.272727 Max 82.272727
       [Avg Loss]          0.643508
       [Validation] Prec@1 76.666667 Max 82.500000
Confusion matrix:
[[17  0  0  3  0  0]
 [ 0 19  0  1  0  0]
 [ 0  2  8 10  0  0]
 [ 1  2  0 16  1  0]
 [ 0  0  0  3 17  0]
 [ 1  2  0  2  0 15]]
Epoch: [6]
       [Avg Loss]          0.441762
       [Training]   Prec@1 84.696970 Max 84.696970
       [Avg Loss]          0.649770
       [Validation] Prec@1 75.000000 Max 82.500000
Confusion matrix:
[[15  0  5  0  0  0]
 [ 0 13  0  3  0  4]
 [ 0  0 15  5  0  0]
 [ 3  0  3 12  1  1]
 [ 0  0  0  2 18  0]
 [ 0  2  0  1  0 17]]
Epoch: [7]
       [Avg Loss]          0.399820
       [Training]   Prec@1 86.515152 Max 86.515152
       [Avg Loss]          0.763196
       [Validation] Prec@1 75.000000 Max 82.500000
Confusion matrix:
[[13  0  2  5  0  0]
 [ 0 18  0  2  0  0]
 [ 0  1 12  6  1  0]
 [ 3  0  0 17  0  0]
 [ 0  0  0  5 15  0]
 [ 2  1  0  2  0 15]]
Epoch: [8]
       [Avg Loss]          0.399799
       [Training]   Prec@1 86.060606 Max 86.515152
       [Avg Loss]          0.653102
       [Validation] Prec@1 79.166667 Max 82.500000
Confusion matrix:
[[16  0  0  4  0  0]
 [ 0 18  0  2  0  0]
 [ 0  0 14  5  1  0]
 [ 1  0  2 17  0  0]
 [ 0  0  0  0 20  0]
 [ 5  4  0  1  0 10]]
Epoch: [9]
       [Avg Loss]          0.303232
       [Training]   Prec@1 91.212121 Max 91.212121
       [Avg Loss]          0.501695
       [Validation] Prec@1 85.000000 Max 85.000000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 18  0  1  0  1]
 [ 0  1 17  2  0  0]
 [ 6  0  0 14  0  0]
 [ 0  0  0  0 20  0]
 [ 1  3  0  3  0 13]]
Epoch: [10]
       [Avg Loss]          0.306552
       [Training]   Prec@1 91.666667 Max 91.666667
       [Avg Loss]          0.509989
       [Validation] Prec@1 84.166667 Max 85.000000
Confusion matrix:
[[15  0  0  5  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 18  2  0  0]
 [ 1  1  2 15  0  1]
 [ 0  0  0  0 20  0]
 [ 1  2  0  3  0 14]]
Epoch: [11]
       [Avg Loss]          0.225768
       [Training]   Prec@1 92.272727 Max 92.272727
       [Avg Loss]          0.811759
       [Validation] Prec@1 75.833333 Max 85.000000
Confusion matrix:
[[19  0  1  0  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 15  5  0  0]
 [ 2  3  2 13  0  0]
 [ 0  0  0  8 12  0]
 [ 0  7  0  0  0 13]]
Epoch: [12]
       [Avg Loss]          0.231352
       [Training]   Prec@1 91.969697 Max 92.272727
       [Avg Loss]          0.723610
       [Validation] Prec@1 82.500000 Max 85.000000
Confusion matrix:
[[18  0  0  0  2  0]
 [ 0 19  0  1  0  0]
 [ 0  2 15  3  0  0]
 [ 1  2  2 15  0  0]
 [ 0  0  0  0 20  0]
 [ 1  6  0  1  0 12]]
Epoch: [13]
       [Avg Loss]          0.274024
       [Training]   Prec@1 91.818182 Max 92.272727
       [Avg Loss]          0.616369
       [Validation] Prec@1 85.000000 Max 85.000000
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0 19  0  1  0  0]
 [ 0  2 14  4  0  0]
 [ 3  1  0 16  0  0]
 [ 0  0  0  2 18  0]
 [ 0  2  0  2  0 16]]
Epoch: [14]
       [Avg Loss]          0.244973
       [Training]   Prec@1 91.515152 Max 92.272727
       [Avg Loss]          0.716710
       [Validation] Prec@1 83.333333 Max 85.000000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 19  0  1  0  0]
 [ 0  1 16  3  0  0]
 [ 6  0  0 14  0  0]
 [ 0  0  0  0 20  0]
 [ 2  6  0  1  0 11]]
Fold "3" complete, final accuracy: 85.0
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.288673
       [Training]   Prec@1 49.104478 Max 49.104478
       [Avg Loss]          1.413959
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[17  2  1  0  0  0]
 [ 6  7  3  0  4  0]
 [ 9  0  9  0  1  1]
 [ 0 10  2  3  5  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [1]
       [Avg Loss]          0.797784
       [Training]   Prec@1 74.477612 Max 74.477612
       [Avg Loss]          1.613794
       [Validation] Prec@1 57.272727 Max 60.000000
Confusion matrix:
[[10  4  0  0  4  2]
 [ 2  8  4  0  6  0]
 [ 6  1  8  0  4  1]
 [ 1 11  0  7  0  1]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          0.719698
       [Training]   Prec@1 74.626866 Max 74.626866
       [Avg Loss]          1.398957
       [Validation] Prec@1 68.181818 Max 68.181818
Confusion matrix:
[[13  4  2  0  1  0]
 [ 2 11  3  0  4  0]
 [ 6  1 11  1  0  1]
 [ 0  9  0 11  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  1  0  0 19]]
Epoch: [3]
       [Avg Loss]          0.645970
       [Training]   Prec@1 76.865672 Max 76.865672
       [Avg Loss]          1.105501
       [Validation] Prec@1 70.909091 Max 70.909091
Confusion matrix:
[[14  2  1  3  0  0]
 [ 1  8  6  2  3  0]
 [ 5  1 10  3  0  1]
 [ 0  4  0 16  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          0.566929
       [Training]   Prec@1 80.149254 Max 80.149254
       [Avg Loss]          1.398909
       [Validation] Prec@1 70.000000 Max 70.909091
Confusion matrix:
[[12  4  2  2  0  0]
 [ 0 11  5  4  0  0]
 [ 6  1 10  2  0  1]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.501585
       [Training]   Prec@1 82.089552 Max 82.089552
       [Avg Loss]          1.329266
       [Validation] Prec@1 65.454545 Max 70.909091
Confusion matrix:
[[14  2  0  2  2  0]
 [ 0 12  2  2  4  0]
 [ 6  0  3 10  0  1]
 [ 0  6  0 13  0  1]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [6]
       [Avg Loss]          0.511727
       [Training]   Prec@1 82.835821 Max 82.835821
       [Avg Loss]          1.136348
       [Validation] Prec@1 66.363636 Max 70.909091
Confusion matrix:
[[16  1  1  2  0  0]
 [ 7  3  1  7  2  0]
 [ 7  0  9  3  0  1]
 [ 0  4  0 15  0  1]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [7]
       [Avg Loss]          0.365464
       [Training]   Prec@1 88.507463 Max 88.507463
       [Avg Loss]          1.748064
       [Validation] Prec@1 65.454545 Max 70.909091
Confusion matrix:
[[10  4  1  1  4  0]
 [ 0  8  1  2  9  0]
 [ 6  0  8  3  2  1]
 [ 0  4  0 16  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [8]
       [Avg Loss]          0.381770
       [Training]   Prec@1 86.417910 Max 88.507463
       [Avg Loss]          1.530015
       [Validation] Prec@1 69.090909 Max 70.909091
Confusion matrix:
[[17  1  1  1  0  0]
 [ 0  7  2  3  8  0]
 [ 6  0  8  5  0  1]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [9]
       [Avg Loss]          0.330892
       [Training]   Prec@1 89.402985 Max 89.402985
       [Avg Loss]          1.456043
       [Validation] Prec@1 66.363636 Max 70.909091
Confusion matrix:
[[15  1  1  1  2  0]
 [ 1  6  1  7  5  0]
 [ 6  0 11  2  0  1]
 [ 0  4  1 15  0  0]
 [ 0  0  0  0 10  0]
 [ 4  0  0  0  0 16]]
Epoch: [10]
       [Avg Loss]          0.304416
       [Training]   Prec@1 89.552239 Max 89.552239
       [Avg Loss]          1.637499
       [Validation] Prec@1 58.181818 Max 70.909091
Confusion matrix:
[[16  1  1  2  0  0]
 [ 1  9  1  3  6  0]
 [ 7  0  5  7  0  1]
 [ 0  6  0 13  0  1]
 [ 0  0  0  0 10  0]
 [ 9  0  0  0  0 11]]
Epoch: [11]
       [Avg Loss]          0.227934
       [Training]   Prec@1 93.134328 Max 93.134328
       [Avg Loss]          1.579521
       [Validation] Prec@1 64.545455 Max 70.909091
Confusion matrix:
[[14  1  1  3  1  0]
 [ 0  8  1  4  7  0]
 [ 6  0  3 10  0  1]
 [ 0  3  0 17  0  0]
 [ 0  0  0  0 10  0]
 [ 1  0  0  0  0 19]]
Epoch: [12]
       [Avg Loss]          0.179653
       [Training]   Prec@1 94.328358 Max 94.328358
       [Avg Loss]          1.673989
       [Validation] Prec@1 65.454545 Max 70.909091
Confusion matrix:
[[14  1  1  3  1  0]
 [ 0  8  1  8  3  0]
 [ 6  0 10  3  0  1]
 [ 0  3  1 16  0  0]
 [ 0  0  0  0 10  0]
 [ 5  1  0  0  0 14]]
Epoch: [13]
       [Avg Loss]          0.196916
       [Training]   Prec@1 94.179104 Max 94.328358
       [Avg Loss]          1.515268
       [Validation] Prec@1 70.000000 Max 70.909091
Confusion matrix:
[[16  1  1  1  1  0]
 [ 0 13  1  2  4  0]
 [ 5  0  5  8  0  2]
 [ 0  4  1 15  0  0]
 [ 0  0  0  0 10  0]
 [ 2  0  0  0  0 18]]
Epoch: [14]
       [Avg Loss]          0.185302
       [Training]   Prec@1 94.328358 Max 94.328358
       [Avg Loss]          1.930605
       [Validation] Prec@1 60.909091 Max 70.909091
Confusion matrix:
[[15  1  1  2  1  0]
 [ 2 12  0  5  1  0]
 [ 6  0  0 12  0  2]
 [ 0  5  0 15  0  0]
 [ 0  0  0  0 10  0]
 [ 5  0  0  0  0 15]]
Fold "4" complete, final accuracy: 70.9090909090909

-----------------------------------------------------------------------
Training for stage 6 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=12)")
Average accuracy is: 78.0857220857221


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 7-----
Evaluated preprocessing: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=12)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.531459
       [Training]   Prec@1 38.833333 Max 38.833333
       [Avg Loss]          1.733344
       [Validation] Prec@1 27.777778 Max 27.777778
Confusion matrix:
[[ 1 10 29  0  0  0]
 [ 0  7 23  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 28  0  2  0]
 [ 0  0 24  0  6  0]
 [ 0 12  2  0  0  6]]
Epoch: [1]
       [Avg Loss]          1.003813
       [Training]   Prec@1 61.833333 Max 61.833333
       [Avg Loss]          1.578266
       [Validation] Prec@1 28.333333 Max 28.333333
Confusion matrix:
[[33  0  0  0  0  7]
 [28  0  0  0  0  2]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [ 2  0  0  0  0 18]]
Epoch: [2]
       [Avg Loss]          0.842766
       [Training]   Prec@1 67.166667 Max 67.166667
       [Avg Loss]          1.581854
       [Validation] Prec@1 35.555556 Max 35.555556
Confusion matrix:
[[ 1  2 24  4  3  6]
 [ 0  2 26  2  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0  6  0 24  0]
 [ 0  9  2  2  0  7]]
Epoch: [3]
       [Avg Loss]          0.727683
       [Training]   Prec@1 75.000000 Max 75.000000
       [Avg Loss]          1.594460
       [Validation] Prec@1 45.555556 Max 45.555556
Confusion matrix:
[[30  0  0  0  0 10]
 [ 1 22  0  1  0  6]
 [18  3  9  0  0  0]
 [25  0  5  0  0  0]
 [29  0  0  0  1  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          0.773179
       [Training]   Prec@1 72.500000 Max 75.000000
       [Avg Loss]          2.163815
       [Validation] Prec@1 42.777778 Max 45.555556
Confusion matrix:
[[ 0  0  4 26  0 10]
 [ 0 17  0 13  0  0]
 [ 0  0 28  2  0  0]
 [ 0  0 19 11  0  0]
 [ 0  0  5 18  7  0]
 [ 0  4  0  2  0 14]]
Epoch: [5]
       [Avg Loss]          0.699132
       [Training]   Prec@1 76.166667 Max 76.166667
       [Avg Loss]          1.398705
       [Validation] Prec@1 58.888889 Max 58.888889
Confusion matrix:
[[16  0 13  1  0 10]
 [ 0 14  9  7  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 26  3  0  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  2  0 18]]
Epoch: [6]
       [Avg Loss]          0.620883
       [Training]   Prec@1 78.500000 Max 78.500000
       [Avg Loss]          1.806899
       [Validation] Prec@1 57.777778 Max 58.888889
Confusion matrix:
[[30  0  0  0  0 10]
 [15 10  3  2  0  0]
 [ 3  0 27  0  0  0]
 [13  0 15  0  2  0]
 [10  0  0  0 20  0]
 [ 3  0  0  0  0 17]]
Epoch: [7]
       [Avg Loss]          0.578537
       [Training]   Prec@1 80.000000 Max 80.000000
       [Avg Loss]          2.036794
       [Validation] Prec@1 52.777778 Max 58.888889
Confusion matrix:
[[13  0 15  2  0 10]
 [ 0 18  6  4  0  2]
 [ 0  0 30  0  0  0]
 [ 0  0 28  2  0  0]
 [ 0  0 16  2 12  0]
 [ 0  0  0  0  0 20]]
Epoch: [8]
       [Avg Loss]          0.578237
       [Training]   Prec@1 80.500000 Max 80.500000
       [Avg Loss]          1.957054
       [Validation] Prec@1 61.111111 Max 61.111111
Confusion matrix:
[[13  0 11  5  1 10]
 [ 0 26  0  0  0  4]
 [ 0  5 24  1  0  0]
 [ 0 11 10  3  6  0]
 [ 0  1  4  1 24  0]
 [ 0  0  0  0  0 20]]
Epoch: [9]
       [Avg Loss]          0.596943
       [Training]   Prec@1 80.833333 Max 80.833333
       [Avg Loss]          1.356771
       [Validation] Prec@1 73.888889 Max 73.888889
Confusion matrix:
[[28  0  1  0  1 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  0 23  0  6  0]
 [ 2  0  3  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [10]
       [Avg Loss]          0.442640
       [Training]   Prec@1 85.500000 Max 85.500000
       [Avg Loss]          1.802792
       [Validation] Prec@1 61.666667 Max 73.888889
Confusion matrix:
[[17  0  8  5  0 10]
 [ 0 24  0  3  0  3]
 [ 0  0 28  2  0  0]
 [ 0  2 23  5  0  0]
 [ 0  0  5  4 21  0]
 [ 0  1  0  3  0 16]]
Epoch: [11]
       [Avg Loss]          0.465989
       [Training]   Prec@1 84.000000 Max 85.500000
       [Avg Loss]          1.846900
       [Validation] Prec@1 67.222222 Max 73.888889
Confusion matrix:
[[19  0  4  7  0 10]
 [ 0 22  3  2  0  3]
 [ 0  0 30  0  0  0]
 [ 0  0 23  5  2  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [12]
       [Avg Loss]          0.449932
       [Training]   Prec@1 85.000000 Max 85.500000
       [Avg Loss]          2.048792
       [Validation] Prec@1 61.111111 Max 73.888889
Confusion matrix:
[[18  1 11  0  0 10]
 [ 0 30  0  0  0  0]
 [ 0  2 28  0  0  0]
 [ 0  4 19  0  7  0]
 [ 4  0  6  0 20  0]
 [ 0  5  0  1  0 14]]
Epoch: [13]
       [Avg Loss]          0.466374
       [Training]   Prec@1 84.666667 Max 85.500000
       [Avg Loss]          1.830329
       [Validation] Prec@1 58.333333 Max 73.888889
Confusion matrix:
[[24  0  4  2  0 10]
 [11  4 12  3  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 25  4  1  0]
 [ 1  0  4  0 25  0]
 [ 2  0  0  0  0 18]]
Epoch: [14]
       [Avg Loss]          0.468532
       [Training]   Prec@1 84.666667 Max 85.500000
       [Avg Loss]          1.900122
       [Validation] Prec@1 62.222222 Max 73.888889
Confusion matrix:
[[13  0  6 10  1 10]
 [ 0 24  4  2  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 21  0  9  0]
 [ 0  0  4  0 26  0]
 [ 0  0  0  1  0 19]]
Fold "0" complete, final accuracy: 73.88888888888889
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.491818
       [Training]   Prec@1 43.865546 Max 43.865546
       [Avg Loss]          1.727415
       [Validation] Prec@1 16.756757 Max 16.756757
Confusion matrix:
[[30  0  0  0  0  0]
 [34  1  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.150833
       [Training]   Prec@1 57.647059 Max 57.647059
       [Avg Loss]          1.550577
       [Validation] Prec@1 39.459459 Max 39.459459
Confusion matrix:
[[30  0  0  0  0  0]
 [18  0 17  0  0  0]
 [ 4  0 26  0  0  0]
 [28  0  2  0  0  0]
 [18  0  5  0  7  0]
 [20  0  0  0  0 10]]
Epoch: [2]
       [Avg Loss]          0.977725
       [Training]   Prec@1 65.882353 Max 65.882353
       [Avg Loss]          1.211901
       [Validation] Prec@1 46.486486 Max 46.486486
Confusion matrix:
[[27  0  0  0  0  3]
 [17 13  1  2  0  2]
 [25  0  3  1  1  0]
 [12  0  0  8 10  0]
 [ 3  0  1  4 22  0]
 [14  0  0  3  0 13]]
Epoch: [3]
       [Avg Loss]          0.853133
       [Training]   Prec@1 70.756303 Max 70.756303
       [Avg Loss]          1.124262
       [Validation] Prec@1 56.216216 Max 56.216216
Confusion matrix:
[[22  0  0  0  0  8]
 [ 3 26  0  0  0  6]
 [17  6  4  0  3  0]
 [18  1  0  4  6  1]
 [ 8  0  0  0 22  0]
 [ 4  0  0  0  0 26]]
Epoch: [4]
       [Avg Loss]          0.808327
       [Training]   Prec@1 73.445378 Max 73.445378
       [Avg Loss]          0.919672
       [Validation] Prec@1 70.270270 Max 70.270270
Confusion matrix:
[[14 11  5  0  0  0]
 [ 0 33  2  0  0  0]
 [ 0  3 27  0  0  0]
 [ 3  3  8  5  9  2]
 [ 0  3  0  0 27  0]
 [ 0  4  1  0  1 24]]
Epoch: [5]
       [Avg Loss]          0.804372
       [Training]   Prec@1 71.260504 Max 73.445378
       [Avg Loss]          1.680168
       [Validation] Prec@1 42.702703 Max 70.270270
Confusion matrix:
[[ 3  4 23  0  0  0]
 [ 0  8 25  2  0  0]
 [ 0  0 30  0  0  0]
 [ 1  0 20  9  0  0]
 [ 0  0 17  2 11  0]
 [ 4  0  7  1  0 18]]
Epoch: [6]
       [Avg Loss]          0.738490
       [Training]   Prec@1 73.781513 Max 73.781513
       [Avg Loss]          1.100586
       [Validation] Prec@1 64.864865 Max 70.270270
Confusion matrix:
[[23  3  0  2  0  2]
 [ 0 31  0  0  0  4]
 [ 0 18 12  0  0  0]
 [ 2  5  4  7 10  2]
 [ 0  5  0  1 24  0]
 [ 2  3  0  2  0 23]]
Epoch: [7]
       [Avg Loss]          0.671107
       [Training]   Prec@1 76.974790 Max 76.974790
       [Avg Loss]          1.110035
       [Validation] Prec@1 61.621622 Max 70.270270
Confusion matrix:
[[20  2  3  1  0  4]
 [ 1 32  0  0  0  2]
 [ 0 15 14  1  0  0]
 [10  2  3  7  0  8]
 [11  3  0  1 15  0]
 [ 2  2  0  0  0 26]]
Epoch: [8]
       [Avg Loss]          0.606808
       [Training]   Prec@1 78.151261 Max 78.151261
       [Avg Loss]          1.237098
       [Validation] Prec@1 63.243243 Max 70.270270
Confusion matrix:
[[25  5  0  0  0  0]
 [ 1 33  1  0  0  0]
 [11  8  6  0  5  0]
 [10  1  0  7 12  0]
 [ 1  0  0  0 29  0]
 [ 3  2  0  7  1 17]]
Epoch: [9]
       [Avg Loss]          0.600715
       [Training]   Prec@1 80.504202 Max 80.504202
       [Avg Loss]          1.330726
       [Validation] Prec@1 60.000000 Max 70.270270
Confusion matrix:
[[15  2  5  0  0  8]
 [ 0 30  3  0  0  2]
 [ 0  4 26  0  0  0]
 [11  0 12  3  0  4]
 [11  6  0  2 11  0]
 [ 1  2  1  0  0 26]]
Epoch: [10]
       [Avg Loss]          0.620016
       [Training]   Prec@1 79.159664 Max 80.504202
       [Avg Loss]          0.894536
       [Validation] Prec@1 69.189189 Max 70.270270
Confusion matrix:
[[25  0  0  2  1  2]
 [11 14  6  4  0  0]
 [ 2  0 23  0  5  0]
 [ 2  0  3 17  7  1]
 [ 0  0  0  3 27  0]
 [ 2  1  0  4  1 22]]
Epoch: [11]
       [Avg Loss]          0.599319
       [Training]   Prec@1 78.487395 Max 80.504202
       [Avg Loss]          1.158211
       [Validation] Prec@1 64.864865 Max 70.270270
Confusion matrix:
[[19  2  0  1  0  8]
 [ 0 34  0  0  0  1]
 [ 0 16 12  1  1  0]
 [ 1  5  3 12  7  2]
 [ 1  7  0  1 21  0]
 [ 2  4  0  2  0 22]]
Epoch: [12]
       [Avg Loss]          0.510318
       [Training]   Prec@1 82.184874 Max 82.184874
       [Avg Loss]          0.863091
       [Validation] Prec@1 72.972973 Max 72.972973
Confusion matrix:
[[24  5  0  1  0  0]
 [ 3 31  1  0  0  0]
 [ 2  6 22  0  0  0]
 [ 7  1  2 19  0  1]
 [ 5  7  0  4 14  0]
 [ 3  2  0  0  0 25]]
Epoch: [13]
       [Avg Loss]          0.480778
       [Training]   Prec@1 84.033613 Max 84.033613
       [Avg Loss]          0.948919
       [Validation] Prec@1 70.810811 Max 72.972973
Confusion matrix:
[[29  0  1  0  0  0]
 [ 8 25  1  1  0  0]
 [ 2  0 28  0  0  0]
 [10  0  5 11  4  0]
 [ 6  0  0  3 21  0]
 [10  1  1  1  0 17]]
Epoch: [14]
       [Avg Loss]          0.486958
       [Training]   Prec@1 84.537815 Max 84.537815
       [Avg Loss]          0.899165
       [Validation] Prec@1 69.189189 Max 72.972973
Confusion matrix:
[[18  5  4  2  0  1]
 [ 3 32  0  0  0  0]
 [ 0  9 20  1  0  0]
 [ 0  1  6 21  0  2]
 [10  0  0  6 14  0]
 [ 2  2  1  2  0 23]]
Fold "1" complete, final accuracy: 72.97297297297297
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.704503
       [Training]   Prec@1 33.781513 Max 33.781513
       [Avg Loss]          1.718030
       [Validation] Prec@1 34.054054 Max 34.054054
Confusion matrix:
[[26  0  2  0  0  2]
 [18  0  8  0  0  9]
 [23  0  7  0  0  0]
 [24  0  0  0  0  6]
 [30  0  0  0  0  0]
 [ 0  0  0  0  0 30]]
Epoch: [1]
       [Avg Loss]          1.215480
       [Training]   Prec@1 53.949580 Max 53.949580
       [Avg Loss]          1.435926
       [Validation] Prec@1 65.945946 Max 65.945946
Confusion matrix:
[[21  1  0  5  3  0]
 [ 2 29  1  2  0  1]
 [10  0  9 11  0  0]
 [15  0  0 14  1  0]
 [ 8  0  0  3 19  0]
 [ 0  0  0  0  0 30]]
Epoch: [2]
       [Avg Loss]          0.925243
       [Training]   Prec@1 68.571429 Max 68.571429
       [Avg Loss]          1.254484
       [Validation] Prec@1 60.540541 Max 65.945946
Confusion matrix:
[[24  5  0  1  0  0]
 [ 7 21  0  1  0  6]
 [15  0  0 15  0  0]
 [ 3  3  0 20  0  4]
 [10  0  0  0 20  0]
 [ 3  0  0  0  0 27]]
Epoch: [3]
       [Avg Loss]          0.784696
       [Training]   Prec@1 72.605042 Max 72.605042
       [Avg Loss]          0.950639
       [Validation] Prec@1 74.054054 Max 74.054054
Confusion matrix:
[[21  0  2  2  5  0]
 [ 4 20  4  0  0  7]
 [ 0  0 23  7  0  0]
 [ 0  1  5 23  0  1]
 [ 0  0  2  8 20  0]
 [ 0  0  0  0  0 30]]
Epoch: [4]
       [Avg Loss]          0.736727
       [Training]   Prec@1 74.789916 Max 74.789916
       [Avg Loss]          1.570636
       [Validation] Prec@1 62.162162 Max 74.054054
Confusion matrix:
[[21  4  0  0  5  0]
 [ 3 31  0  0  0  1]
 [ 3 10  5  5  7  0]
 [ 0 14  0  3 12  1]
 [ 0  2  0  0 28  0]
 [ 2  1  0  0  0 27]]
Epoch: [5]
       [Avg Loss]          0.668992
       [Training]   Prec@1 75.630252 Max 75.630252
       [Avg Loss]          0.809333
       [Validation] Prec@1 75.675676 Max 75.675676
Confusion matrix:
[[13  3  7  4  3  0]
 [ 0 33  0  1  0  1]
 [ 0  1 19 10  0  0]
 [ 0  1  1 28  0  0]
 [ 0  0  1 11 18  0]
 [ 0  1  0  0  0 29]]
Epoch: [6]
       [Avg Loss]          0.660411
       [Training]   Prec@1 77.142857 Max 77.142857
       [Avg Loss]          0.998015
       [Validation] Prec@1 69.729730 Max 75.675676
Confusion matrix:
[[23  0  0  0  7  0]
 [ 5 27  0  0  0  3]
 [ 2  2 11  6  9  0]
 [ 0  1  0 14 15  0]
 [ 4  0  0  2 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [7]
       [Avg Loss]          0.617481
       [Training]   Prec@1 81.512605 Max 81.512605
       [Avg Loss]          1.182221
       [Validation] Prec@1 64.864865 Max 75.675676
Confusion matrix:
[[ 9  4  2  8  5  2]
 [ 0 33  0  0  0  2]
 [ 0  9 14  7  0  0]
 [ 0 14  2 11  0  3]
 [ 0  3  0  4 23  0]
 [ 0  0  0  0  0 30]]
Epoch: [8]
       [Avg Loss]          0.640833
       [Training]   Prec@1 78.991597 Max 81.512605
       [Avg Loss]          0.903515
       [Validation] Prec@1 71.891892 Max 75.675676
Confusion matrix:
[[22  4  1  0  3  0]
 [ 9 25  0  0  0  1]
 [ 2  0 17 11  0  0]
 [ 3  2  1 21  0  3]
 [10  0  0  0 20  0]
 [ 2  0  0  0  0 28]]
Epoch: [9]
       [Avg Loss]          0.623111
       [Training]   Prec@1 78.319328 Max 81.512605
       [Avg Loss]          1.228006
       [Validation] Prec@1 72.972973 Max 75.675676
Confusion matrix:
[[21  1  0  0  8  0]
 [ 0 33  0  0  1  1]
 [ 0  0 13  1 16  0]
 [ 0  0  1 11 18  0]
 [ 0  0  0  0 30  0]
 [ 2  1  0  0  0 27]]
Epoch: [10]
       [Avg Loss]          0.564449
       [Training]   Prec@1 80.672269 Max 81.512605
       [Avg Loss]          0.918387
       [Validation] Prec@1 72.432432 Max 75.675676
Confusion matrix:
[[17  2  5  1  5  0]
 [ 7 22  0  5  0  1]
 [ 0  0 18 12  0  0]
 [ 0  0  0 28  0  2]
 [ 3  0  0  6 21  0]
 [ 2  0  0  0  0 28]]
Epoch: [11]
       [Avg Loss]          0.485312
       [Training]   Prec@1 82.184874 Max 82.184874
       [Avg Loss]          0.939893
       [Validation] Prec@1 71.891892 Max 75.675676
Confusion matrix:
[[22  5  0  0  3  0]
 [ 5 28  0  1  0  1]
 [ 0  4 13  8  5  0]
 [ 0  2  1 21  6  0]
 [ 7  0  0  0 23  0]
 [ 3  1  0  0  0 26]]
Epoch: [12]
       [Avg Loss]          0.495997
       [Training]   Prec@1 83.025210 Max 83.025210
       [Avg Loss]          1.063130
       [Validation] Prec@1 72.432432 Max 75.675676
Confusion matrix:
[[18  1  0  4  6  1]
 [ 2 16  0 11  0  6]
 [ 0  0 20 10  0  0]
 [ 0  0  0 30  0  0]
 [ 0  0  0 10 20  0]
 [ 0  0  0  0  0 30]]
Epoch: [13]
       [Avg Loss]          0.524498
       [Training]   Prec@1 83.025210 Max 83.025210
       [Avg Loss]          1.064988
       [Validation] Prec@1 72.972973 Max 75.675676
Confusion matrix:
[[14  7  1  3  2  3]
 [ 0 34  0  0  0  1]
 [ 0  6 11 13  0  0]
 [ 0  4  0 24  0  2]
 [ 0  4  0  3 23  0]
 [ 0  1  0  0  0 29]]
Epoch: [14]
       [Avg Loss]          0.472122
       [Training]   Prec@1 83.025210 Max 83.025210
       [Avg Loss]          1.133672
       [Validation] Prec@1 58.918919 Max 75.675676
Confusion matrix:
[[25  0  0  0  5  0]
 [25  5  0  3  0  2]
 [10  0  3 17  0  0]
 [ 0  0  0 28  0  2]
 [ 7  0  0  1 22  0]
 [ 4  0  0  0  0 26]]
Fold "2" complete, final accuracy: 75.67567567567568
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.536651
       [Training]   Prec@1 37.727273 Max 37.727273
       [Avg Loss]          1.698282
       [Validation] Prec@1 27.500000 Max 27.500000
Confusion matrix:
[[ 5 15  0  0  0  0]
 [ 0 20  0  0  0  0]
 [ 0 15  5  0  0  0]
 [ 9  9  0  1  1  0]
 [ 0 10  8  0  2  0]
 [ 0 20  0  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.149287
       [Training]   Prec@1 58.636364 Max 58.636364
       [Avg Loss]          1.333431
       [Validation] Prec@1 53.333333 Max 53.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [11  4  0  2  0  3]
 [ 8  0  0  0 12  0]
 [15  0  0  4  0  1]
 [ 0  0  0  0 20  0]
 [ 4  0  0  0  0 16]]
Epoch: [2]
       [Avg Loss]          0.881274
       [Training]   Prec@1 68.787879 Max 68.787879
       [Avg Loss]          1.256604
       [Validation] Prec@1 42.500000 Max 53.333333
Confusion matrix:
[[ 2  0  0 14  0  4]
 [ 0 10  0  4  0  6]
 [ 0  4  0 14  0  2]
 [ 0  0  0 16  0  4]
 [ 0  4  0 10  6  0]
 [ 0  2  0  1  0 17]]
Epoch: [3]
       [Avg Loss]          0.853008
       [Training]   Prec@1 72.121212 Max 72.121212
       [Avg Loss]          1.104061
       [Validation] Prec@1 55.000000 Max 55.000000
Confusion matrix:
[[16  0  0  4  0  0]
 [ 2  5  4  7  0  2]
 [ 0  0  9 11  0  0]
 [ 1  0  1 17  1  0]
 [ 0  0  3  8  9  0]
 [ 5  0  0  5  0 10]]
Epoch: [4]
       [Avg Loss]          0.722015
       [Training]   Prec@1 78.787879 Max 78.787879
       [Avg Loss]          1.216271
       [Validation] Prec@1 55.833333 Max 55.833333
Confusion matrix:
[[11  0  9  0  0  0]
 [ 0 16  2  2  0  0]
 [ 0  0 16  4  0  0]
 [ 1  0 14  5  0  0]
 [ 0  0  8  2 10  0]
 [ 2  3  0  6  0  9]]
Epoch: [5]
       [Avg Loss]          0.745897
       [Training]   Prec@1 73.787879 Max 78.787879
       [Avg Loss]          1.604595
       [Validation] Prec@1 50.833333 Max 55.833333
Confusion matrix:
[[10  0  0 10  0  0]
 [ 0 19  0  1  0  0]
 [ 0 10  0 10  0  0]
 [ 0  1  0 18  0  1]
 [ 0 10  0  7  3  0]
 [ 0  7  0  2  0 11]]
Epoch: [6]
       [Avg Loss]          0.640714
       [Training]   Prec@1 78.030303 Max 78.787879
       [Avg Loss]          1.062745
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 3 15  0  1  0  1]
 [ 2  2  3 13  0  0]
 [ 6  1  0  7  0  6]
 [ 0  0  1  6 13  0]
 [ 6  0  0  0  0 14]]
Epoch: [7]
       [Avg Loss]          0.639784
       [Training]   Prec@1 77.727273 Max 78.787879
       [Avg Loss]          1.094578
       [Validation] Prec@1 67.500000 Max 67.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 4 11  0  4  0  1]
 [ 3  0  3 10  4  0]
 [ 4  0  0 14  0  2]
 [ 0  0  0  0 20  0]
 [ 5  0  0  2  0 13]]
Epoch: [8]
       [Avg Loss]          0.642223
       [Training]   Prec@1 78.333333 Max 78.787879
       [Avg Loss]          0.853343
       [Validation] Prec@1 66.666667 Max 67.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 1 19  0  0  0  0]
 [ 2  1  5 10  2  0]
 [10  1  0  8  0  1]
 [ 0  0  0  3 17  0]
 [ 1  7  0  1  0 11]]
Epoch: [9]
       [Avg Loss]          0.515163
       [Training]   Prec@1 83.181818 Max 83.181818
       [Avg Loss]          0.748009
       [Validation] Prec@1 78.333333 Max 78.333333
Confusion matrix:
[[19  0  0  0  0  1]
 [ 2 16  0  0  0  2]
 [ 0  3  8  8  1  0]
 [ 5  1  0 13  0  1]
 [ 0  0  0  0 20  0]
 [ 1  1  0  0  0 18]]
Epoch: [10]
       [Avg Loss]          0.520197
       [Training]   Prec@1 82.727273 Max 83.181818
       [Avg Loss]          1.208440
       [Validation] Prec@1 65.000000 Max 78.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 1 14  1  1  0  3]
 [ 3  0  1 13  3  0]
 [13  0  0  6  0  1]
 [ 0  0  0  0 20  0]
 [ 0  2  0  1  0 17]]
Epoch: [11]
       [Avg Loss]          0.506125
       [Training]   Prec@1 82.272727 Max 83.181818
       [Avg Loss]          1.133821
       [Validation] Prec@1 75.000000 Max 78.333333
Confusion matrix:
[[15  0  1  4  0  0]
 [ 0 18  1  1  0  0]
 [ 0  4 10  5  1  0]
 [ 0  1  0 18  0  1]
 [ 0  3  0  0 17  0]
 [ 0  7  0  1  0 12]]
Epoch: [12]
       [Avg Loss]          0.506754
       [Training]   Prec@1 80.909091 Max 83.181818
       [Avg Loss]          0.741509
       [Validation] Prec@1 71.666667 Max 78.333333
Confusion matrix:
[[14  0  0  6  0  0]
 [ 0 15  1  1  0  3]
 [ 0  0 10 10  0  0]
 [ 0  0  1 18  0  1]
 [ 0  0  6  1 13  0]
 [ 1  2  0  1  0 16]]
Epoch: [13]
       [Avg Loss]          0.488173
       [Training]   Prec@1 82.878788 Max 83.181818
       [Avg Loss]          0.742048
       [Validation] Prec@1 76.666667 Max 78.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 1 18  0  0  0  1]
 [ 1  1  8 10  0  0]
 [ 3  1  1 14  0  1]
 [ 0  1  0  0 19  0]
 [ 1  5  0  1  0 13]]
Epoch: [14]
       [Avg Loss]          0.450845
       [Training]   Prec@1 85.757576 Max 85.757576
       [Avg Loss]          0.725894
       [Validation] Prec@1 75.833333 Max 78.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 1 15  0  0  0  4]
 [ 0  3  8  8  1  0]
 [ 3  1  0 15  0  1]
 [ 0  1  0  3 16  0]
 [ 2  1  0  0  0 17]]
Fold "3" complete, final accuracy: 78.33333333333333
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.481865
       [Training]   Prec@1 41.492537 Max 41.492537
       [Avg Loss]          1.671524
       [Validation] Prec@1 41.818182 Max 41.818182
Confusion matrix:
[[13  7  0  0  0  0]
 [ 0 19  1  0  0  0]
 [ 6  4 10  0  0  0]
 [ 3 16  1  0  0  0]
 [ 2  8  0  0  0  0]
 [ 9  7  0  0  0  4]]
Epoch: [1]
       [Avg Loss]          0.982590
       [Training]   Prec@1 64.179104 Max 64.179104
       [Avg Loss]          1.438778
       [Validation] Prec@1 53.636364 Max 53.636364
Confusion matrix:
[[19  0  0  0  0  1]
 [ 9  9  2  0  0  0]
 [ 9  0 10  0  0  1]
 [ 8  6  5  1  0  0]
 [ 3  0  0  0  7  0]
 [ 7  0  0  0  0 13]]
Epoch: [2]
       [Avg Loss]          0.771963
       [Training]   Prec@1 74.776119 Max 74.776119
       [Avg Loss]          1.831242
       [Validation] Prec@1 44.545455 Max 53.636364
Confusion matrix:
[[20  0  0  0  0  0]
 [14  4  2  0  0  0]
 [10  0  5  2  3  0]
 [ 0  3  2 13  0  2]
 [ 3  0  0  0  7  0]
 [20  0  0  0  0  0]]
Epoch: [3]
       [Avg Loss]          0.764831
       [Training]   Prec@1 74.179104 Max 74.776119
       [Avg Loss]          1.318318
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[11  7  0  0  2  0]
 [ 0 13  1  0  6  0]
 [ 4  1 10  2  2  1]
 [ 0  8  4  8  0  0]
 [ 0  0  0  0 10  0]
 [ 0  6  0  0  0 14]]
Epoch: [4]
       [Avg Loss]          0.717004
       [Training]   Prec@1 75.970149 Max 75.970149
       [Avg Loss]          2.216960
       [Validation] Prec@1 40.909091 Max 60.000000
Confusion matrix:
[[ 2  0  5  0 13  0]
 [ 0  5  6  1  8  0]
 [ 5  0 13  2  0  0]
 [ 0  5  4 11  0  0]
 [ 0  0  0  0 10  0]
 [ 8  0  3  5  0  4]]
Epoch: [5]
       [Avg Loss]          0.683782
       [Training]   Prec@1 76.119403 Max 76.119403
       [Avg Loss]          1.914374
       [Validation] Prec@1 56.363636 Max 60.000000
Confusion matrix:
[[15  2  0  1  2  0]
 [ 2  7  1  1  9  0]
 [ 9  0 11  0  0  0]
 [ 0  6  4 10  0  0]
 [ 0  0  0  0 10  0]
 [10  0  0  1  0  9]]
Epoch: [6]
       [Avg Loss]          0.648520
       [Training]   Prec@1 77.014925 Max 77.014925
       [Avg Loss]          1.802435
       [Validation] Prec@1 62.727273 Max 62.727273
Confusion matrix:
[[ 9  8  0  0  3  0]
 [ 0 17  1  0  2  0]
 [ 6  3 10  0  0  1]
 [ 0 15  1  4  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [7]
       [Avg Loss]          0.606328
       [Training]   Prec@1 77.462687 Max 77.462687
       [Avg Loss]          2.166554
       [Validation] Prec@1 40.909091 Max 62.727273
Confusion matrix:
[[ 8  0  0  0  5  7]
 [ 5  6  0  1  7  1]
 [13  0  0  0  5  2]
 [ 0  3  0  1  4 12]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [8]
       [Avg Loss]          0.554304
       [Training]   Prec@1 80.746269 Max 80.746269
       [Avg Loss]          1.461323
       [Validation] Prec@1 65.454545 Max 65.454545
Confusion matrix:
[[13  7  0  0  0  0]
 [ 4 15  1  0  0  0]
 [ 6  1 12  0  0  1]
 [ 0 10  6  3  0  1]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [9]
       [Avg Loss]          0.481008
       [Training]   Prec@1 83.880597 Max 83.880597
       [Avg Loss]          1.501817
       [Validation] Prec@1 60.000000 Max 65.454545
Confusion matrix:
[[14  0  4  0  2  0]
 [ 6  4  3  3  4  0]
 [ 7  0 13  0  0  0]
 [ 0  1 12  7  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  1  1  0 18]]
Epoch: [10]
       [Avg Loss]          0.471144
       [Training]   Prec@1 82.985075 Max 83.880597
       [Avg Loss]          2.050368
       [Validation] Prec@1 42.727273 Max 65.454545
Confusion matrix:
[[ 5  0  0 15  0  0]
 [ 4  6  1  7  2  0]
 [ 3  0  1 15  0  1]
 [ 0  3  0 17  0  0]
 [ 0  0  0  9  1  0]
 [ 0  0  0  3  0 17]]
Epoch: [11]
       [Avg Loss]          0.402099
       [Training]   Prec@1 87.313433 Max 87.313433
       [Avg Loss]          2.207709
       [Validation] Prec@1 48.181818 Max 65.454545
Confusion matrix:
[[ 7  0  2  1 10  0]
 [ 0  5  2  2 11  0]
 [ 6  0 13  1  0  0]
 [ 0  2  7 11  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0 13  0  7]]
Epoch: [12]
       [Avg Loss]          0.401060
       [Training]   Prec@1 86.268657 Max 87.313433
       [Avg Loss]          1.330124
       [Validation] Prec@1 70.909091 Max 70.909091
Confusion matrix:
[[15  1  1  1  0  2]
 [ 9  7  1  3  0  0]
 [ 8  0 11  1  0  0]
 [ 0  5  0 15  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [13]
       [Avg Loss]          0.411305
       [Training]   Prec@1 85.671642 Max 87.313433
       [Avg Loss]          1.707514
       [Validation] Prec@1 50.000000 Max 70.909091
Confusion matrix:
[[10  0  2  4  4  0]
 [ 1  5  2  0 12  0]
 [ 4  0 10  3  3  0]
 [ 0  2  3 14  1  0]
 [ 0  0  0  0 10  0]
 [ 2  0  0 12  0  6]]
Epoch: [14]
       [Avg Loss]          0.407564
       [Training]   Prec@1 86.268657 Max 87.313433
       [Avg Loss]          1.463831
       [Validation] Prec@1 64.545455 Max 70.909091
Confusion matrix:
[[18  1  0  0  1  0]
 [ 9  8  0  2  1  0]
 [ 8  0  6  6  0  0]
 [ 0  4  2 13  0  1]
 [ 0  0  0  0 10  0]
 [ 3  0  0  1  0 16]]
Fold "4" complete, final accuracy: 70.9090909090909

-----------------------------------------------------------------------
Training for stage 7 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=12)")
Average accuracy is: 74.35599235599236


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 8-----
Evaluated preprocessing: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=12)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.454455
       [Training]   Prec@1 42.500000 Max 42.500000
       [Avg Loss]          1.727025
       [Validation] Prec@1 26.666667 Max 26.666667
Confusion matrix:
[[ 3 27 10  0  0  0]
 [ 0 30  0  0  0  0]
 [ 0 15 15  0  0  0]
 [ 0 23  7  0  0  0]
 [ 0 14 16  0  0  0]
 [ 0 20  0  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.022526
       [Training]   Prec@1 63.166667 Max 63.166667
       [Avg Loss]          1.464045
       [Validation] Prec@1 36.666667 Max 36.666667
Confusion matrix:
[[33  0  0  0  0  7]
 [24  1  5  0  0  0]
 [18  0 12  0  0  0]
 [25  0  5  0  0  0]
 [20  0  0  0 10  0]
 [10  0  0  0  0 10]]
Epoch: [2]
       [Avg Loss]          0.878723
       [Training]   Prec@1 71.833333 Max 71.833333
       [Avg Loss]          1.595698
       [Validation] Prec@1 53.333333 Max 53.333333
Confusion matrix:
[[ 0  0 23  0  7 10]
 [ 0 29  0  0  0  1]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 12  0 18  0]
 [ 0  1  0  0  0 19]]
Epoch: [3]
       [Avg Loss]          0.709583
       [Training]   Prec@1 76.333333 Max 76.333333
       [Avg Loss]          1.039301
       [Validation] Prec@1 63.333333 Max 63.333333
Confusion matrix:
[[20  0  0  0 10 10]
 [ 1 21  0  8  0  0]
 [ 1  0 26  0  3  0]
 [ 0  0  9  1 20  0]
 [ 3  0  0  0 27  0]
 [ 0  1  0  0  0 19]]
Epoch: [4]
       [Avg Loss]          0.683551
       [Training]   Prec@1 77.000000 Max 77.000000
       [Avg Loss]          1.460032
       [Validation] Prec@1 52.777778 Max 63.333333
Confusion matrix:
[[12  0  0 18  0 10]
 [ 0 12  0 18  0  0]
 [ 1  0 12 16  1  0]
 [ 2  0  1 19  8  0]
 [ 1  0  0  8 21  0]
 [ 0  0  0  1  0 19]]
Epoch: [5]
       [Avg Loss]          0.605443
       [Training]   Prec@1 80.833333 Max 80.833333
       [Avg Loss]          2.063386
       [Validation] Prec@1 57.222222 Max 63.333333
Confusion matrix:
[[13  0 17  0  0 10]
 [ 0 19 10  1  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0  7  0 23  0]
 [ 0  1  1  0  0 18]]
Epoch: [6]
       [Avg Loss]          0.615098
       [Training]   Prec@1 80.500000 Max 80.833333
       [Avg Loss]          1.278505
       [Validation] Prec@1 72.222222 Max 72.222222
Confusion matrix:
[[30  0  0  0  0 10]
 [ 0 28  0  2  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 16  0 14  0]
 [ 1  0  4  0 25  0]
 [ 0  0  2  1  0 17]]
Epoch: [7]
       [Avg Loss]          0.608874
       [Training]   Prec@1 80.500000 Max 80.833333
       [Avg Loss]          1.755768
       [Validation] Prec@1 52.222222 Max 72.222222
Confusion matrix:
[[ 3  0  4 23  0 10]
 [ 0 27  0  3  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 27  3  0  0]
 [ 0  0  7 12 11  0]
 [ 0  0  0  0  0 20]]
Epoch: [8]
       [Avg Loss]          0.582290
       [Training]   Prec@1 81.000000 Max 81.000000
       [Avg Loss]          1.489909
       [Validation] Prec@1 70.555556 Max 72.222222
Confusion matrix:
[[28  0  0  2  0 10]
 [ 0 27  0  3  0  0]
 [ 0  0 30  0  0  0]
 [ 0  3 27  0  0  0]
 [ 2  0  3  3 22  0]
 [ 0  0  0  0  0 20]]
Epoch: [9]
       [Avg Loss]          0.563331
       [Training]   Prec@1 81.333333 Max 81.333333
       [Avg Loss]          1.228575
       [Validation] Prec@1 70.555556 Max 72.222222
Confusion matrix:
[[25  0  5  0  0 10]
 [ 0 29  0  1  0  0]
 [ 0  0 30  0  0  0]
 [ 1  4 23  0  2  0]
 [ 2  0  3  0 25  0]
 [ 0  0  1  1  0 18]]
Epoch: [10]
       [Avg Loss]          0.436979
       [Training]   Prec@1 86.666667 Max 86.666667
       [Avg Loss]          1.745268
       [Validation] Prec@1 67.222222 Max 72.222222
Confusion matrix:
[[17  0  8  5  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  3 27  0  0  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  1  0 19]]
Epoch: [11]
       [Avg Loss]          0.522820
       [Training]   Prec@1 83.333333 Max 86.666667
       [Avg Loss]          1.286918
       [Validation] Prec@1 66.666667 Max 72.222222
Confusion matrix:
[[30  0  0  0  0 10]
 [ 0  4  0 26  0  0]
 [ 0  0 29  1  0  0]
 [ 2  0 15 13  0  0]
 [ 5  0  0  0 25  0]
 [ 0  0  0  1  0 19]]
Epoch: [12]
       [Avg Loss]          0.494569
       [Training]   Prec@1 82.166667 Max 86.666667
       [Avg Loss]          1.646849
       [Validation] Prec@1 68.888889 Max 72.222222
Confusion matrix:
[[21  0  9  0  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  4 25  0  0  0]
 [ 0  0  5  0 25  0]
 [ 0  0  1  1  0 18]]
Epoch: [13]
       [Avg Loss]          0.524005
       [Training]   Prec@1 82.000000 Max 86.666667
       [Avg Loss]          1.263880
       [Validation] Prec@1 63.333333 Max 72.222222
Confusion matrix:
[[14  0  1 10  5 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 15  5  9  0]
 [ 1  1  1  1 26  0]
 [ 0  0 10  1  0  9]]
Epoch: [14]
       [Avg Loss]          0.460227
       [Training]   Prec@1 85.000000 Max 86.666667
       [Avg Loss]          1.875328
       [Validation] Prec@1 63.333333 Max 72.222222
Confusion matrix:
[[29  0  0  1  0 10]
 [ 0 12  0 17  0  1]
 [ 0  0 30  0  0  0]
 [ 1  1 27  1  0  0]
 [ 4  0  3  1 22  0]
 [ 0  0  0  0  0 20]]
Fold "0" complete, final accuracy: 72.22222222222223
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.507348
       [Training]   Prec@1 43.529412 Max 43.529412
       [Avg Loss]          1.720615
       [Validation] Prec@1 27.567568 Max 27.567568
Confusion matrix:
[[15 13  2  0  0  0]
 [ 0 35  0  0  0  0]
 [ 0 29  1  0  0  0]
 [ 3 27  0  0  0  0]
 [ 0 27  3  0  0  0]
 [11 19  0  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.023591
       [Training]   Prec@1 63.361345 Max 63.361345
       [Avg Loss]          1.583050
       [Validation] Prec@1 31.351351 Max 31.351351
Confusion matrix:
[[23  0  0  0  0  7]
 [28  5  1  0  0  1]
 [26  0  4  0  0  0]
 [26  0  1  1  0  2]
 [22  0  6  2  0  0]
 [ 5  0  0  0  0 25]]
Epoch: [2]
       [Avg Loss]          0.835688
       [Training]   Prec@1 70.420168 Max 70.420168
       [Avg Loss]          1.044579
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[23  5  0  1  0  1]
 [ 1 34  0  0  0  0]
 [ 0 14  2 10  4  0]
 [ 3  4  0 11 11  1]
 [ 3  4  0  3 20  0]
 [ 2  4  0  3  0 21]]
Epoch: [3]
       [Avg Loss]          0.788484
       [Training]   Prec@1 74.789916 Max 74.789916
       [Avg Loss]          1.106876
       [Validation] Prec@1 57.837838 Max 60.000000
Confusion matrix:
[[26  2  0  0  0  2]
 [ 3 16  6  1  0  9]
 [ 1  0 28  1  0  0]
 [17  0  5  8  0  0]
 [11  0  2  6 11  0]
 [ 9  0  1  2  0 18]]
Epoch: [4]
       [Avg Loss]          0.718926
       [Training]   Prec@1 75.294118 Max 75.294118
       [Avg Loss]          1.504605
       [Validation] Prec@1 60.540541 Max 60.540541
Confusion matrix:
[[13  8  5  0  0  4]
 [ 0 35  0  0  0  0]
 [ 0 15 15  0  0  0]
 [ 3  8  3 12  0  4]
 [ 3  8  6  1 12  0]
 [ 2  3  0  0  0 25]]
Epoch: [5]
       [Avg Loss]          0.649876
       [Training]   Prec@1 78.991597 Max 78.991597
       [Avg Loss]          1.351217
       [Validation] Prec@1 56.216216 Max 60.540541
Confusion matrix:
[[27  2  0  0  0  1]
 [ 4  6 20  5  0  0]
 [ 4  0 26  0  0  0]
 [15  0  6  7  0  2]
 [16  0  2  0 12  0]
 [ 3  0  1  0  0 26]]
Epoch: [6]
       [Avg Loss]          0.708412
       [Training]   Prec@1 72.773109 Max 78.991597
       [Avg Loss]          1.327054
       [Validation] Prec@1 60.540541 Max 60.540541
Confusion matrix:
[[23  3  2  0  0  2]
 [ 1 19 15  0  0  0]
 [ 0  0 30  0  0  0]
 [ 3  0 13  3 11  0]
 [ 5  1  3  1 20  0]
 [ 6  1  3  3  0 17]]
Epoch: [7]
       [Avg Loss]          0.618345
       [Training]   Prec@1 79.159664 Max 79.159664
       [Avg Loss]          1.130192
       [Validation] Prec@1 67.567568 Max 67.567568
Confusion matrix:
[[17  2  7  0  0  4]
 [ 3 30  1  0  0  1]
 [ 2  0 28  0  0  0]
 [ 0  1 12 14  0  3]
 [ 8  2  1  8 11  0]
 [ 2  0  2  1  0 25]]
Epoch: [8]
       [Avg Loss]          0.552316
       [Training]   Prec@1 80.672269 Max 80.672269
       [Avg Loss]          1.617304
       [Validation] Prec@1 56.216216 Max 67.567568
Confusion matrix:
[[23  6  0  0  0  1]
 [ 1 34  0  0  0  0]
 [ 7 15  4  2  2  0]
 [17  5  0  8  0  0]
 [ 9  9  0  0 12  0]
 [ 2  4  0  1  0 23]]
Epoch: [9]
       [Avg Loss]          0.547870
       [Training]   Prec@1 82.016807 Max 82.016807
       [Avg Loss]          1.171715
       [Validation] Prec@1 70.810811 Max 70.810811
Confusion matrix:
[[15  5  8  0  0  2]
 [ 1 34  0  0  0  0]
 [ 0  6 24  0  0  0]
 [ 1  4  7 17  0  1]
 [ 7  7  0  1 15  0]
 [ 1  2  1  0  0 26]]
Epoch: [10]
       [Avg Loss]          0.523179
       [Training]   Prec@1 81.176471 Max 82.016807
       [Avg Loss]          1.165217
       [Validation] Prec@1 63.243243 Max 70.810811
Confusion matrix:
[[20  2  3  0  0  5]
 [ 1 24  2  0  0  8]
 [ 2  0 28  0  0  0]
 [ 6  1  9 10  0  4]
 [14  3  0  2 11  0]
 [ 3  0  1  2  0 24]]
Epoch: [11]
       [Avg Loss]          0.510603
       [Training]   Prec@1 82.857143 Max 82.857143
       [Avg Loss]          1.010300
       [Validation] Prec@1 69.189189 Max 70.810811
Confusion matrix:
[[21  4  2  0  0  3]
 [ 3 32  0  0  0  0]
 [ 3  2 25  0  0  0]
 [ 1  1  5 11 10  2]
 [ 9  1  1  1 18  0]
 [ 3  2  0  4  0 21]]
Epoch: [12]
       [Avg Loss]          0.496391
       [Training]   Prec@1 81.680672 Max 82.857143
       [Avg Loss]          1.228566
       [Validation] Prec@1 68.108108 Max 70.810811
Confusion matrix:
[[22  4  4  0  0  0]
 [ 1 30  4  0  0  0]
 [ 3  0 27  0  0  0]
 [13  3  6  8  0  0]
 [15  1  0  0 14  0]
 [ 1  2  2  0  0 25]]
Epoch: [13]
       [Avg Loss]          0.468503
       [Training]   Prec@1 83.865546 Max 83.865546
       [Avg Loss]          1.011189
       [Validation] Prec@1 73.513514 Max 73.513514
Confusion matrix:
[[21  2  0  2  0  5]
 [ 2 28  1  2  0  2]
 [ 2  0 27  1  0  0]
 [ 4  0  2 21  0  3]
 [ 8  1  0  8 13  0]
 [ 2  1  0  1  0 26]]
Epoch: [14]
       [Avg Loss]          0.449920
       [Training]   Prec@1 85.714286 Max 85.714286
       [Avg Loss]          1.190407
       [Validation] Prec@1 63.783784 Max 73.513514
Confusion matrix:
[[23  4  3  0  0  0]
 [ 3 25  3  4  0  0]
 [ 2  0 28  0  0  0]
 [ 8  0 10 12  0  0]
 [15  1  0  0 14  0]
 [ 9  0  1  4  0 16]]
Fold "1" complete, final accuracy: 73.51351351351352
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.627928
       [Training]   Prec@1 36.470588 Max 36.470588
       [Avg Loss]          1.691414
       [Validation] Prec@1 40.000000 Max 40.000000
Confusion matrix:
[[16  1  8  5  0  0]
 [ 0  3 13 19  0  0]
 [ 0  0 26  4  0  0]
 [ 5  0  8 17  0  0]
 [15  0 15  0  0  0]
 [11  0  0  7  0 12]]
Epoch: [1]
       [Avg Loss]          1.141381
       [Training]   Prec@1 59.327731 Max 59.327731
       [Avg Loss]          1.386330
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[20  4  2  4  0  0]
 [ 2 19  8  6  0  0]
 [ 0  0 13 17  0  0]
 [ 3  3  1 23  0  0]
 [ 2  0  1 11 16  0]
 [10  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          0.967954
       [Training]   Prec@1 68.067227 Max 68.067227
       [Avg Loss]          1.712386
       [Validation] Prec@1 28.108108 Max 60.000000
Confusion matrix:
[[18  1  0  0  0 11]
 [ 0  1  0  0  0 34]
 [ 9  0  1  0  0 20]
 [ 5  0  0  2  0 23]
 [28  0  0  2  0  0]
 [ 0  0  0  0  0 30]]
Epoch: [3]
       [Avg Loss]          0.825272
       [Training]   Prec@1 72.773109 Max 72.773109
       [Avg Loss]          1.237661
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[19  0  0  2  9  0]
 [ 1 18  0  8  6  2]
 [ 0  0  0 14 16  0]
 [ 0  2  0 15 13  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  1  0 29]]
Epoch: [4]
       [Avg Loss]          0.782201
       [Training]   Prec@1 72.941176 Max 72.941176
       [Avg Loss]          0.947427
       [Validation] Prec@1 69.729730 Max 69.729730
Confusion matrix:
[[11  1  6  7  5  0]
 [ 0 31  2  1  0  1]
 [ 0  0 25  5  0  0]
 [ 0 11  5  9  4  1]
 [ 0  0  2  4 24  0]
 [ 0  1  0  0  0 29]]
Epoch: [5]
       [Avg Loss]          0.692461
       [Training]   Prec@1 77.983193 Max 77.983193
       [Avg Loss]          0.895254
       [Validation] Prec@1 77.297297 Max 77.297297
Confusion matrix:
[[21  2  2  0  5  0]
 [ 1 30  0  2  0  2]
 [ 0  0 20  4  6  0]
 [ 0 10  0 13  7  0]
 [ 0  0  0  0 30  0]
 [ 1  0  0  0  0 29]]
Epoch: [6]
       [Avg Loss]          0.687266
       [Training]   Prec@1 76.302521 Max 77.983193
       [Avg Loss]          1.251681
       [Validation] Prec@1 64.864865 Max 77.297297
Confusion matrix:
[[21  1  1  0  7  0]
 [ 5 10  5 10  0  5]
 [ 3  0 20  6  1  0]
 [ 1  0  4 17  8  0]
 [ 4  0  0  2 24  0]
 [ 1  0  0  1  0 28]]
Epoch: [7]
       [Avg Loss]          0.587721
       [Training]   Prec@1 80.168067 Max 80.168067
       [Avg Loss]          1.755705
       [Validation] Prec@1 63.243243 Max 77.297297
Confusion matrix:
[[15  0  0  0 15  0]
 [ 0 34  0  0  0  1]
 [ 0  5 14  0 11  0]
 [ 1 17  0  1 11  0]
 [ 0  0  0  0 30  0]
 [ 4  3  0  0  0 23]]
Epoch: [8]
       [Avg Loss]          0.600237
       [Training]   Prec@1 79.495798 Max 80.168067
       [Avg Loss]          0.891176
       [Validation] Prec@1 71.891892 Max 77.297297
Confusion matrix:
[[21  1  2  3  3  0]
 [ 0 30  1  1  0  3]
 [ 0  0 24  6  0  0]
 [ 1  8  5 15  0  1]
 [ 5  0  0  6 19  0]
 [ 0  6  0  0  0 24]]
Epoch: [9]
       [Avg Loss]          0.621981
       [Training]   Prec@1 80.336134 Max 80.336134
       [Avg Loss]          1.133114
       [Validation] Prec@1 60.540541 Max 77.297297
Confusion matrix:
[[22  0  1  0  7  0]
 [11  9  4 10  0  1]
 [ 0  0 16 12  2  0]
 [ 1  0  2 18  9  0]
 [ 2  0  0  4 24  0]
 [ 7  0  0  0  0 23]]
Epoch: [10]
       [Avg Loss]          0.615670
       [Training]   Prec@1 77.983193 Max 80.336134
       [Avg Loss]          1.206929
       [Validation] Prec@1 66.486486 Max 77.297297
Confusion matrix:
[[14  3  1  6  6  0]
 [ 0 34  0  0  0  1]
 [ 0  2 21  7  0  0]
 [ 1 11  1  8  9  0]
 [ 0  0  0  4 26  0]
 [ 3  7  0  0  0 20]]
Epoch: [11]
       [Avg Loss]          0.570394
       [Training]   Prec@1 80.000000 Max 80.336134
       [Avg Loss]          1.023154
       [Validation] Prec@1 70.270270 Max 77.297297
Confusion matrix:
[[14  0  1  7  8  0]
 [ 0 23  0  6  0  6]
 [ 0  0 13 16  1  0]
 [ 0  3  0 25  0  2]
 [ 0  0  0  5 25  0]
 [ 0  0  0  0  0 30]]
Epoch: [12]
       [Avg Loss]          0.508474
       [Training]   Prec@1 81.008403 Max 81.008403
       [Avg Loss]          1.014782
       [Validation] Prec@1 63.783784 Max 77.297297
Confusion matrix:
[[24  2  2  0  2  0]
 [ 9 24  0  0  0  2]
 [ 2  2 13 13  0  0]
 [ 1 13  0 16  0  0]
 [10  0  0  6 14  0]
 [ 3  0  0  0  0 27]]
Epoch: [13]
       [Avg Loss]          0.485032
       [Training]   Prec@1 84.705882 Max 84.705882
       [Avg Loss]          1.078019
       [Validation] Prec@1 76.756757 Max 77.297297
Confusion matrix:
[[21  0  0  0  9  0]
 [ 3 31  0  0  0  1]
 [ 1  0 13  9  7  0]
 [ 0  7  0 20  2  1]
 [ 0  0  0  0 30  0]
 [ 2  1  0  0  0 27]]
Epoch: [14]
       [Avg Loss]          0.492276
       [Training]   Prec@1 83.529412 Max 84.705882
       [Avg Loss]          1.106949
       [Validation] Prec@1 71.891892 Max 77.297297
Confusion matrix:
[[19  2  0  0  9  0]
 [ 6 28  0  0  0  1]
 [ 0  0 22  4  4  0]
 [ 1  4  1 13 11  0]
 [ 0  0  0  2 28  0]
 [ 6  1  0  0  0 23]]
Fold "2" complete, final accuracy: 77.29729729729729
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.490413
       [Training]   Prec@1 39.696970 Max 39.696970
       [Avg Loss]          1.731526
       [Validation] Prec@1 30.833333 Max 30.833333
Confusion matrix:
[[ 0  0 10  0 10  0]
 [ 0 10  9  0  1  0]
 [ 0  0 20  0  0  0]
 [ 0  0 20  0  0  0]
 [ 0  0 13  0  7  0]
 [ 0 15  5  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.155195
       [Training]   Prec@1 59.242424 Max 59.242424
       [Avg Loss]          1.155916
       [Validation] Prec@1 64.166667 Max 64.166667
Confusion matrix:
[[ 5  0  3 10  0  2]
 [ 0 17  1  1  0  1]
 [ 0  5 13  1  1  0]
 [ 0  1  2 13  0  4]
 [ 0  0  1  7 12  0]
 [ 0  3  0  0  0 17]]
Epoch: [2]
       [Avg Loss]          0.885414
       [Training]   Prec@1 71.969697 Max 71.969697
       [Avg Loss]          1.109558
       [Validation] Prec@1 60.000000 Max 64.166667
Confusion matrix:
[[15  0  5  0  0  0]
 [ 0 19  0  1  0  0]
 [ 0 10  9  1  0  0]
 [ 3  2  6  9  0  0]
 [ 0 10  0  6  4  0]
 [ 0  3  0  1  0 16]]
Epoch: [3]
       [Avg Loss]          0.797827
       [Training]   Prec@1 73.484848 Max 73.484848
       [Avg Loss]          1.166441
       [Validation] Prec@1 54.166667 Max 64.166667
Confusion matrix:
[[14  0  0  6  0  0]
 [ 2  8  0  8  0  2]
 [ 0  0  0 20  0  0]
 [ 2  0  0 18  0  0]
 [ 0  0  0 11  9  0]
 [ 1  2  0  1  0 16]]
Epoch: [4]
       [Avg Loss]          0.746473
       [Training]   Prec@1 76.212121 Max 76.212121
       [Avg Loss]          1.004526
       [Validation] Prec@1 66.666667 Max 66.666667
Confusion matrix:
[[12  0  7  0  1  0]
 [ 0 16  2  2  0  0]
 [ 0  0 18  0  2  0]
 [ 4  1  6  8  1  0]
 [ 0  0  2  0 18  0]
 [ 1  8  0  3  0  8]]
Epoch: [5]
       [Avg Loss]          0.745795
       [Training]   Prec@1 74.242424 Max 76.212121
       [Avg Loss]          1.042471
       [Validation] Prec@1 67.500000 Max 67.500000
Confusion matrix:
[[17  0  0  3  0  0]
 [ 0 12  0  3  0  5]
 [ 0  3 15  2  0  0]
 [ 1  0  0 19  0  0]
 [ 0  0  0 20  0  0]
 [ 0  1  0  1  0 18]]
Epoch: [6]
       [Avg Loss]          0.710012
       [Training]   Prec@1 76.515152 Max 76.515152
       [Avg Loss]          0.711542
       [Validation] Prec@1 76.666667 Max 76.666667
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 13  1  6  0  0]
 [ 0  0 14  5  1  0]
 [ 5  0  3 10  2  0]
 [ 0  0  0  0 20  0]
 [ 2  2  0  1  0 15]]
Epoch: [7]
       [Avg Loss]          0.662347
       [Training]   Prec@1 77.575758 Max 77.575758
       [Avg Loss]          0.749542
       [Validation] Prec@1 72.500000 Max 76.666667
Confusion matrix:
[[17  0  3  0  0  0]
 [ 1 10  1  4  0  4]
 [ 0  0 17  3  0  0]
 [ 2  0  4 10  0  4]
 [ 0  0  0  4 16  0]
 [ 0  2  0  1  0 17]]
Epoch: [8]
       [Avg Loss]          0.688319
       [Training]   Prec@1 76.818182 Max 77.575758
       [Avg Loss]          0.722805
       [Validation] Prec@1 73.333333 Max 76.666667
Confusion matrix:
[[17  0  0  3  0  0]
 [ 0 17  0  3  0  0]
 [ 0  1  2 16  1  0]
 [ 3  0  0 15  1  1]
 [ 0  0  0  0 20  0]
 [ 0  2  0  1  0 17]]
Epoch: [9]
       [Avg Loss]          0.594577
       [Training]   Prec@1 80.303030 Max 80.303030
       [Avg Loss]          0.674403
       [Validation] Prec@1 70.833333 Max 76.666667
Confusion matrix:
[[20  0  0  0  0  0]
 [ 3 12  0  5  0  0]
 [ 0  1 13  6  0  0]
 [ 9  0  0 11  0  0]
 [ 0  0  0  7 13  0]
 [ 3  0  0  1  0 16]]
Epoch: [10]
       [Avg Loss]          0.561488
       [Training]   Prec@1 80.606061 Max 80.606061
       [Avg Loss]          0.803019
       [Validation] Prec@1 74.166667 Max 76.666667
Confusion matrix:
[[18  0  2  0  0  0]
 [ 0 16  0  4  0  0]
 [ 0  0 16  4  0  0]
 [ 6  0  4  8  2  0]
 [ 0  0  3  0 17  0]
 [ 1  4  0  1  0 14]]
Epoch: [11]
       [Avg Loss]          0.562424
       [Training]   Prec@1 80.000000 Max 80.606061
       [Avg Loss]          0.809470
       [Validation] Prec@1 77.500000 Max 77.500000
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0 19  0  1  0  0]
 [ 0  3  9  5  3  0]
 [ 2  3  0 13  2  0]
 [ 0  0  0  0 20  0]
 [ 0  7  0  0  0 13]]
Epoch: [12]
       [Avg Loss]          0.561784
       [Training]   Prec@1 79.242424 Max 80.606061
       [Avg Loss]          0.894533
       [Validation] Prec@1 66.666667 Max 77.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 4  4  1  8  0  3]
 [ 0  0 15  1  4  0]
 [10  0  2  8  0  0]
 [ 0  0  0  0 20  0]
 [ 6  0  0  1  0 13]]
Epoch: [13]
       [Avg Loss]          0.608242
       [Training]   Prec@1 78.787879 Max 80.606061
       [Avg Loss]          0.685577
       [Validation] Prec@1 83.333333 Max 83.333333
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0 19  0  1  0  0]
 [ 0  2  8  9  1  0]
 [ 1  1  0 18  0  0]
 [ 0  0  0  0 20  0]
 [ 1  3  0  0  0 16]]
Epoch: [14]
       [Avg Loss]          0.492293
       [Training]   Prec@1 83.636364 Max 83.636364
       [Avg Loss]          0.563165
       [Validation] Prec@1 84.166667 Max 84.166667
Confusion matrix:
[[20  0  0  0  0  0]
 [ 2 15  0  3  0  0]
 [ 0  0 15  5  0  0]
 [ 3  0  0 17  0  0]
 [ 0  0  0  0 20  0]
 [ 2  1  0  3  0 14]]
Fold "3" complete, final accuracy: 84.16666666666667
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.443525
       [Training]   Prec@1 44.477612 Max 44.477612
       [Avg Loss]          1.630474
       [Validation] Prec@1 39.090909 Max 39.090909
Confusion matrix:
[[13  5  2  0  0  0]
 [ 7  7  6  0  0  0]
 [ 6  0 13  0  0  1]
 [ 0 11  9  0  0  0]
 [ 2  0  8  0  0  0]
 [ 1  9  0  0  0 10]]
Epoch: [1]
       [Avg Loss]          1.000211
       [Training]   Prec@1 65.223881 Max 65.223881
       [Avg Loss]          1.204241
       [Validation] Prec@1 66.363636 Max 66.363636
Confusion matrix:
[[13  3  2  0  0  2]
 [ 0 13  3  1  3  0]
 [ 6  0 13  0  0  1]
 [ 0 14  1  5  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [2]
       [Avg Loss]          0.792838
       [Training]   Prec@1 73.582090 Max 73.582090
       [Avg Loss]          2.038660
       [Validation] Prec@1 49.090909 Max 66.363636
Confusion matrix:
[[15  0  1  0  4  0]
 [ 0  6  0  1 13  0]
 [ 8  0  0  0 12  0]
 [ 0  6  1 11  2  0]
 [ 0  0  0  0 10  0]
 [ 8  0  0  0  0 12]]
Epoch: [3]
       [Avg Loss]          0.793958
       [Training]   Prec@1 73.134328 Max 73.582090
       [Avg Loss]          1.864520
       [Validation] Prec@1 44.545455 Max 66.363636
Confusion matrix:
[[ 6  9  0  5  0  0]
 [ 0 17  0  0  3  0]
 [ 4  9  0  2  5  0]
 [ 0 15  0  5  0  0]
 [ 0  0  0  0 10  0]
 [ 0  9  0  0  0 11]]
Epoch: [4]
       [Avg Loss]          0.700211
       [Training]   Prec@1 74.477612 Max 74.477612
       [Avg Loss]          1.884605
       [Validation] Prec@1 54.545455 Max 66.363636
Confusion matrix:
[[10  0  2  1  7  0]
 [ 1  1  7  0 11  0]
 [ 6  0 12  0  1  1]
 [ 0  5  2 12  1  0]
 [ 0  0  0  0 10  0]
 [ 5  0  0  0  0 15]]
Epoch: [5]
       [Avg Loss]          0.633865
       [Training]   Prec@1 77.313433 Max 77.313433
       [Avg Loss]          1.937584
       [Validation] Prec@1 50.000000 Max 66.363636
Confusion matrix:
[[ 5  2  1  6  6  0]
 [ 0  9  2  3  6  0]
 [ 6  0 11  0  2  1]
 [ 0  6  1 13  0  0]
 [ 0  0  0  0 10  0]
 [10  3  0  0  0  7]]
Epoch: [6]
       [Avg Loss]          0.650685
       [Training]   Prec@1 78.805970 Max 78.805970
       [Avg Loss]          1.504322
       [Validation] Prec@1 54.545455 Max 66.363636
Confusion matrix:
[[15  0  0  1  0  4]
 [ 6  0  1  4  0  9]
 [ 5  0  9  3  0  3]
 [ 0  0  0 10  0 10]
 [ 4  0  0  0  6  0]
 [ 0  0  0  0  0 20]]
Epoch: [7]
       [Avg Loss]          0.597227
       [Training]   Prec@1 80.000000 Max 80.000000
       [Avg Loss]          1.548652
       [Validation] Prec@1 62.727273 Max 66.363636
Confusion matrix:
[[16  1  1  0  2  0]
 [ 1  9  1  0  9  0]
 [ 8  0 11  0  1  0]
 [ 0  7  0 13  0  0]
 [ 0  0  0  0 10  0]
 [ 8  2  0  0  0 10]]
Epoch: [8]
       [Avg Loss]          0.536335
       [Training]   Prec@1 80.298507 Max 80.298507
       [Avg Loss]          1.248094
       [Validation] Prec@1 67.272727 Max 67.272727
Confusion matrix:
[[15  3  0  1  0  1]
 [ 0 14  0  3  3  0]
 [ 5  1  2  8  2  2]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [9]
       [Avg Loss]          0.529077
       [Training]   Prec@1 81.791045 Max 81.791045
       [Avg Loss]          1.405516
       [Validation] Prec@1 72.727273 Max 72.727273
Confusion matrix:
[[16  0  2  2  0  0]
 [ 0  8  4  5  3  0]
 [ 6  0 13  0  0  1]
 [ 0  6  0 14  0  0]
 [ 0  0  1  0  9  0]
 [ 0  0  0  0  0 20]]
Epoch: [10]
       [Avg Loss]          0.497918
       [Training]   Prec@1 81.940299 Max 81.940299
       [Avg Loss]          1.195763
       [Validation] Prec@1 69.090909 Max 72.727273
Confusion matrix:
[[ 9  4  0  6  0  1]
 [ 0 12  2  4  2  0]
 [ 5  0 11  2  0  2]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [11]
       [Avg Loss]          0.457930
       [Training]   Prec@1 84.328358 Max 84.328358
       [Avg Loss]          1.620986
       [Validation] Prec@1 70.909091 Max 72.727273
Confusion matrix:
[[17  0  1  1  1  0]
 [ 1  5  2  2 10  0]
 [ 7  0 10  0  2  1]
 [ 0  2  0 18  0  0]
 [ 0  0  0  0 10  0]
 [ 1  1  0  0  0 18]]
Epoch: [12]
       [Avg Loss]          0.415961
       [Training]   Prec@1 85.820896 Max 85.820896
       [Avg Loss]          1.646453
       [Validation] Prec@1 70.000000 Max 72.727273
Confusion matrix:
[[15  2  0  3  0  0]
 [ 0  8  3  6  3  0]
 [ 7  0 10  2  0  1]
 [ 0  5  0 15  0  0]
 [ 0  0  1  0  9  0]
 [ 0  0  0  0  0 20]]
Epoch: [13]
       [Avg Loss]          0.533986
       [Training]   Prec@1 82.686567 Max 85.820896
       [Avg Loss]          1.113422
       [Validation] Prec@1 67.272727 Max 72.727273
Confusion matrix:
[[15  1  0  4  0  0]
 [ 4  7  1  3  5  0]
 [ 6  0  5  6  1  2]
 [ 0  2  0 18  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [14]
       [Avg Loss]          0.429998
       [Training]   Prec@1 83.731343 Max 85.820896
       [Avg Loss]          1.405680
       [Validation] Prec@1 67.272727 Max 72.727273
Confusion matrix:
[[16  0  1  2  0  1]
 [ 9  5  2  4  0  0]
 [ 8  0 10  1  0  1]
 [ 1  3  0 16  0  0]
 [ 0  0  0  3  7  0]
 [ 0  0  0  0  0 20]]
Fold "4" complete, final accuracy: 72.72727272727273

-----------------------------------------------------------------------
Training for stage 8 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=12)")
Average accuracy is: 75.9853944853945


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 9-----
Evaluated preprocessing: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=11)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.509524
       [Training]   Prec@1 41.833333 Max 41.833333
       [Avg Loss]          1.623580
       [Validation] Prec@1 50.555556 Max 50.555556
Confusion matrix:
[[15  0 14  0  1 10]
 [ 3 16  8  0  0  3]
 [ 0  0 30  0  0  0]
 [ 0  1 19  0 10  0]
 [ 0  0 15  0 15  0]
 [ 2  1  2  0  0 15]]
Epoch: [1]
       [Avg Loss]          0.868478
       [Training]   Prec@1 69.833333 Max 69.833333
       [Avg Loss]          1.152005
       [Validation] Prec@1 67.777778 Max 67.777778
Confusion matrix:
[[29  0  0  0  1 10]
 [ 0 28  0  1  0  1]
 [ 0  3 19  0  8  0]
 [ 1  6  6  0 17  0]
 [ 3  0  0  0 27  0]
 [ 0  1  0  0  0 19]]
Epoch: [2]
       [Avg Loss]          0.647010
       [Training]   Prec@1 77.833333 Max 77.833333
       [Avg Loss]          1.483492
       [Validation] Prec@1 60.000000 Max 67.777778
Confusion matrix:
[[20  0  8  2  0 10]
 [ 0 28  0  0  0  2]
 [ 0  3 27  0  0  0]
 [ 1 13 16  0  0  0]
 [ 9  0  5  0 16  0]
 [ 0  3  0  0  0 17]]
Epoch: [3]
       [Avg Loss]          0.565603
       [Training]   Prec@1 80.500000 Max 80.500000
       [Avg Loss]          1.465700
       [Validation] Prec@1 63.333333 Max 67.777778
Confusion matrix:
[[13  0  7  9  1 10]
 [ 0 29  0  0  0  1]
 [ 0  4 26  0  0  0]
 [ 0  3 13  0 14  0]
 [ 0  0  3  0 27  0]
 [ 0  0  0  1  0 19]]
Epoch: [4]
       [Avg Loss]          0.535433
       [Training]   Prec@1 81.833333 Max 81.833333
       [Avg Loss]          1.575170
       [Validation] Prec@1 67.222222 Max 67.777778
Confusion matrix:
[[23  0  6  1  0 10]
 [ 0 21  0  0  0  9]
 [ 0  2 28  0  0  0]
 [ 1  1 22  4  2  0]
 [ 1  0  4  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.452209
       [Training]   Prec@1 84.166667 Max 84.166667
       [Avg Loss]          1.140616
       [Validation] Prec@1 71.111111 Max 71.111111
Confusion matrix:
[[19  0  6  5  0 10]
 [ 0 24  0  0  0  6]
 [ 0  0 28  2  0  0]
 [ 1  1 12 16  0  0]
 [ 3  0  5  0 22  0]
 [ 0  0  0  1  0 19]]
Epoch: [6]
       [Avg Loss]          0.394169
       [Training]   Prec@1 86.666667 Max 86.666667
       [Avg Loss]          1.393249
       [Validation] Prec@1 66.666667 Max 71.111111
Confusion matrix:
[[16  0  9  1  0 14]
 [ 0 25  3  0  0  2]
 [ 0  0 28  2  0  0]
 [ 1  1 17 11  0  0]
 [ 0  0  5  2 23  0]
 [ 0  2  1  0  0 17]]
Epoch: [7]
       [Avg Loss]          0.313278
       [Training]   Prec@1 90.500000 Max 90.500000
       [Avg Loss]          1.420850
       [Validation] Prec@1 66.111111 Max 71.111111
Confusion matrix:
[[23  1  5  2  0  9]
 [ 0 30  0  0  0  0]
 [ 0  6 24  0  0  0]
 [ 2 13  8  1  6  0]
 [ 3  1  4  0 22  0]
 [ 0  1  0  0  0 19]]
Epoch: [8]
       [Avg Loss]          0.262920
       [Training]   Prec@1 91.500000 Max 91.500000
       [Avg Loss]          1.585877
       [Validation] Prec@1 68.888889 Max 71.111111
Confusion matrix:
[[23  0  7  0  0 10]
 [ 0 29  0  0  0  1]
 [ 0  0 29  1  0  0]
 [ 2  1 20  1  6  0]
 [ 0  1  4  0 25  0]
 [ 2  0  1  0  0 17]]
Epoch: [9]
       [Avg Loss]          0.291485
       [Training]   Prec@1 89.666667 Max 91.500000
       [Avg Loss]          1.363711
       [Validation] Prec@1 70.555556 Max 71.111111
Confusion matrix:
[[21  1  4  2  2 10]
 [ 0 30  0  0  0  0]
 [ 0  2 26  2  0  0]
 [ 0  5 11 11  3  0]
 [ 1  4  0  1 24  0]
 [ 0  4  1  0  0 15]]
Epoch: [10]
       [Avg Loss]          0.317485
       [Training]   Prec@1 89.166667 Max 91.500000
       [Avg Loss]          1.597234
       [Validation] Prec@1 70.000000 Max 71.111111
Confusion matrix:
[[21  0  8  0  0 11]
 [ 0 28  0  1  0  1]
 [ 0  0 28  2  0  0]
 [ 1  0 21  8  0  0]
 [ 3  1  5  0 21  0]
 [ 0  0  0  0  0 20]]
Epoch: [11]
       [Avg Loss]          0.187683
       [Training]   Prec@1 94.000000 Max 94.000000
       [Avg Loss]          1.230843
       [Validation] Prec@1 75.555556 Max 75.555556
Confusion matrix:
[[21  0  5  4  0 10]
 [ 0 30  0  0  0  0]
 [ 0  2 27  1  0  0]
 [ 0  5 12 13  0  0]
 [ 1  3  1  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [12]
       [Avg Loss]          0.174262
       [Training]   Prec@1 94.666667 Max 94.666667
       [Avg Loss]          1.478674
       [Validation] Prec@1 78.333333 Max 78.333333
Confusion matrix:
[[23  0  7  0  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 28  2  0  0]
 [ 0  1 13 16  0  0]
 [ 1  1  3  0 25  0]
 [ 0  0  1  0  0 19]]
Epoch: [13]
       [Avg Loss]          0.192610
       [Training]   Prec@1 94.000000 Max 94.666667
       [Avg Loss]          1.433739
       [Validation] Prec@1 74.444444 Max 78.333333
Confusion matrix:
[[20  0  5  5  0 10]
 [ 0 30  0  0  0  0]
 [ 0  1 29  0  0  0]
 [ 1  7 12 10  0  0]
 [ 1  1  3  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [14]
       [Avg Loss]          0.272781
       [Training]   Prec@1 91.500000 Max 94.666667
       [Avg Loss]          1.538881
       [Validation] Prec@1 73.333333 Max 78.333333
Confusion matrix:
[[21  1  5  3  0 10]
 [ 0 29  0  0  0  1]
 [ 0  1 29  0  0  0]
 [ 1  8 13  8  0  0]
 [ 1  2  2  0 25  0]
 [ 0  0  0  0  0 20]]
Fold "0" complete, final accuracy: 78.33333333333333
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.432824
       [Training]   Prec@1 44.033613 Max 44.033613
       [Avg Loss]          1.522719
       [Validation] Prec@1 59.459459 Max 59.459459
Confusion matrix:
[[29  1  0  0  0  0]
 [ 3 32  0  0  0  0]
 [14  7  9  0  0  0]
 [21  3  0  0  6  0]
 [ 2  5  0  0 23  0]
 [12  1  0  0  0 17]]
Epoch: [1]
       [Avg Loss]          0.950675
       [Training]   Prec@1 69.579832 Max 69.579832
       [Avg Loss]          1.047535
       [Validation] Prec@1 63.243243 Max 63.243243
Confusion matrix:
[[26  4  0  0  0  0]
 [ 5 30  0  0  0  0]
 [ 2 14 14  0  0  0]
 [23  2  2  0  2  1]
 [ 7  0  0  0 23  0]
 [ 5  1  0  0  0 24]]
Epoch: [2]
       [Avg Loss]          0.731088
       [Training]   Prec@1 74.285714 Max 74.285714
       [Avg Loss]          0.805393
       [Validation] Prec@1 75.135135 Max 75.135135
Confusion matrix:
[[25  4  0  0  1  0]
 [ 1 34  0  0  0  0]
 [ 1  5 24  0  0  0]
 [10  4  0  9  7  0]
 [ 0  4  0  0 26  0]
 [ 2  5  0  2  0 21]]
Epoch: [3]
       [Avg Loss]          0.584863
       [Training]   Prec@1 81.344538 Max 81.344538
       [Avg Loss]          0.954521
       [Validation] Prec@1 76.216216 Max 76.216216
Confusion matrix:
[[25  2  0  0  3  0]
 [ 3 32  0  0  0  0]
 [ 0  5 22  1  2  0]
 [ 7  3  1  7 12  0]
 [ 0  0  0  0 30  0]
 [ 2  1  0  1  1 25]]
Epoch: [4]
       [Avg Loss]          0.495581
       [Training]   Prec@1 83.193277 Max 83.193277
       [Avg Loss]          1.191645
       [Validation] Prec@1 71.891892 Max 76.216216
Confusion matrix:
[[26  4  0  0  0  0]
 [ 0 35  0  0  0  0]
 [ 1 10 19  0  0  0]
 [10  1  2 17  0  0]
 [ 6  8  1  4 11  0]
 [ 2  2  0  1  0 25]]
Epoch: [5]
       [Avg Loss]          0.471673
       [Training]   Prec@1 83.361345 Max 83.361345
       [Avg Loss]          0.790837
       [Validation] Prec@1 77.297297 Max 77.297297
Confusion matrix:
[[23  4  0  2  1  0]
 [ 4 29  1  0  1  0]
 [ 3  2 25  0  0  0]
 [ 6  0  2 12 10  0]
 [ 1  0  0  1 28  0]
 [ 1  2  0  0  1 26]]
Epoch: [6]
       [Avg Loss]          0.455146
       [Training]   Prec@1 85.546218 Max 85.546218
       [Avg Loss]          0.927282
       [Validation] Prec@1 76.216216 Max 77.297297
Confusion matrix:
[[26  4  0  0  0  0]
 [ 3 29  3  0  0  0]
 [ 0  5 23  2  0  0]
 [ 8  1  2 18  1  0]
 [ 8  0  0  3 19  0]
 [ 2  2  0  0  0 26]]
Epoch: [7]
       [Avg Loss]          0.427569
       [Training]   Prec@1 88.235294 Max 88.235294
       [Avg Loss]          0.815404
       [Validation] Prec@1 82.702703 Max 82.702703
Confusion matrix:
[[22  7  1  0  0  0]
 [ 0 35  0  0  0  0]
 [ 0  5 25  0  0  0]
 [ 6  0  2 19  2  1]
 [ 1  0  0  1 28  0]
 [ 1  2  0  2  1 24]]
Epoch: [8]
       [Avg Loss]          0.296019
       [Training]   Prec@1 89.579832 Max 89.579832
       [Avg Loss]          0.897301
       [Validation] Prec@1 74.594595 Max 82.702703
Confusion matrix:
[[27  2  0  1  0  0]
 [ 8 26  0  0  1  0]
 [ 0  6 22  1  1  0]
 [ 8  0  2 18  2  0]
 [ 3  2  0  1 24  0]
 [ 1  3  2  1  2 21]]
Epoch: [9]
       [Avg Loss]          0.312837
       [Training]   Prec@1 89.411765 Max 89.579832
       [Avg Loss]          1.007478
       [Validation] Prec@1 72.972973 Max 82.702703
Confusion matrix:
[[18 11  1  0  0  0]
 [ 0 34  1  0  0  0]
 [ 1  5 24  0  0  0]
 [ 9  0  3 13  4  1]
 [ 3  7  0  0 20  0]
 [ 2  1  0  1  0 26]]
Epoch: [10]
       [Avg Loss]          0.298441
       [Training]   Prec@1 91.932773 Max 91.932773
       [Avg Loss]          0.907657
       [Validation] Prec@1 77.297297 Max 82.702703
Confusion matrix:
[[27  2  0  1  0  0]
 [ 4 28  2  0  1  0]
 [ 0  2 25  2  1  0]
 [ 7  0  3 19  1  0]
 [ 9  0  0  2 19  0]
 [ 2  2  0  1  0 25]]
Epoch: [11]
       [Avg Loss]          0.263783
       [Training]   Prec@1 91.596639 Max 91.932773
       [Avg Loss]          0.818258
       [Validation] Prec@1 82.162162 Max 82.702703
Confusion matrix:
[[25  4  1  0  0  0]
 [ 1 34  0  0  0  0]
 [ 0  4 25  1  0  0]
 [ 9  0  3 16  2  0]
 [ 1  1  0  1 27  0]
 [ 2  2  0  0  1 25]]
Epoch: [12]
       [Avg Loss]          0.262900
       [Training]   Prec@1 92.268908 Max 92.268908
       [Avg Loss]          1.154943
       [Validation] Prec@1 75.675676 Max 82.702703
Confusion matrix:
[[25  5  0  0  0  0]
 [ 1 34  0  0  0  0]
 [ 1  3 26  0  0  0]
 [13  0  3 11  3  0]
 [ 8  3  0  0 19  0]
 [ 2  2  0  1  0 25]]
Epoch: [13]
       [Avg Loss]          0.303999
       [Training]   Prec@1 91.428571 Max 92.268908
       [Avg Loss]          0.998452
       [Validation] Prec@1 74.054054 Max 82.702703
Confusion matrix:
[[25  4  1  0  0  0]
 [ 6 28  0  0  1  0]
 [ 0  5 23  1  1  0]
 [12  0  3  9  6  0]
 [ 3  0  0  0 27  0]
 [ 3  1  0  0  1 25]]
Epoch: [14]
       [Avg Loss]          0.238493
       [Training]   Prec@1 92.100840 Max 92.268908
       [Avg Loss]          1.139350
       [Validation] Prec@1 69.189189 Max 82.702703
Confusion matrix:
[[20  6  4  0  0  0]
 [ 0 34  0  1  0  0]
 [ 0  4 24  2  0  0]
 [12  0  6  7  4  1]
 [ 8  6  0  0 16  0]
 [ 2  1  0  0  0 27]]
Fold "1" complete, final accuracy: 82.70270270270271
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.522610
       [Training]   Prec@1 41.176471 Max 41.176471
       [Avg Loss]          1.524252
       [Validation] Prec@1 50.270270 Max 50.270270
Confusion matrix:
[[13  9  0  0  0  8]
 [ 0 26  0  0  0  9]
 [10  3  1 16  0  0]
 [11  5  0  7  2  5]
 [ 6  1  0  7 16  0]
 [ 0  0  0  0  0 30]]
Epoch: [1]
       [Avg Loss]          0.967448
       [Training]   Prec@1 64.705882 Max 64.705882
       [Avg Loss]          1.075895
       [Validation] Prec@1 63.243243 Max 63.243243
Confusion matrix:
[[22  4  0  0  3  1]
 [ 2 27  0  0  0  6]
 [ 6  1 18  3  2  0]
 [ 1  4  2  3 14  6]
 [ 9  0  0  0 21  0]
 [ 4  0  0  0  0 26]]
Epoch: [2]
       [Avg Loss]          0.805327
       [Training]   Prec@1 72.605042 Max 72.605042
       [Avg Loss]          0.963786
       [Validation] Prec@1 69.189189 Max 69.189189
Confusion matrix:
[[22  2  0  0  4  2]
 [ 5 21  0  0  0  9]
 [ 2  0 27  1  0  0]
 [ 1  3  1 10  4 11]
 [ 5  0  0  0 20  5]
 [ 2  0  0  0  0 28]]
Epoch: [3]
       [Avg Loss]          0.629792
       [Training]   Prec@1 78.319328 Max 78.319328
       [Avg Loss]          0.899139
       [Validation] Prec@1 76.756757 Max 76.756757
Confusion matrix:
[[21  1  0  0  8  0]
 [ 5 28  0  0  0  2]
 [ 0  0 28  0  2  0]
 [ 0 10  4 11  5  0]
 [ 0  0  0  0 30  0]
 [ 5  1  0  0  0 24]]
Epoch: [4]
       [Avg Loss]          0.550370
       [Training]   Prec@1 82.352941 Max 82.352941
       [Avg Loss]          0.770882
       [Validation] Prec@1 77.297297 Max 77.297297
Confusion matrix:
[[22  2  0  1  5  0]
 [ 6 21  1  3  1  3]
 [ 0  0 30  0  0  0]
 [ 1  0  4 22  3  0]
 [ 5  0  0  1 24  0]
 [ 4  1  1  0  0 24]]
Epoch: [5]
       [Avg Loss]          0.476281
       [Training]   Prec@1 83.865546 Max 83.865546
       [Avg Loss]          0.916222
       [Validation] Prec@1 75.135135 Max 77.297297
Confusion matrix:
[[21  1  0  0  8  0]
 [ 8 24  0  1  1  1]
 [ 0  0 29  1  0  0]
 [ 0  2  5 19  2  2]
 [ 2  0  0  5 23  0]
 [ 6  1  0  0  0 23]]
Epoch: [6]
       [Avg Loss]          0.398798
       [Training]   Prec@1 86.890756 Max 86.890756
       [Avg Loss]          0.750496
       [Validation] Prec@1 78.918919 Max 78.918919
Confusion matrix:
[[20  2  1  1  6  0]
 [ 4 30  0  0  0  1]
 [ 0  0 28  0  2  0]
 [ 1  1  2 23  0  3]
 [ 0  1  0  8 21  0]
 [ 5  1  0  0  0 24]]
Epoch: [7]
       [Avg Loss]          0.473411
       [Training]   Prec@1 84.369748 Max 86.890756
       [Avg Loss]          1.053547
       [Validation] Prec@1 72.972973 Max 78.918919
Confusion matrix:
[[21  1  0  0  8  0]
 [ 8 17  0  5  2  3]
 [ 3  0 25  0  2  0]
 [ 0  0  4 17  9  0]
 [ 0  0  0  0 30  0]
 [ 4  1  0  0  0 25]]
Epoch: [8]
       [Avg Loss]          0.421171
       [Training]   Prec@1 85.882353 Max 86.890756
       [Avg Loss]          0.929404
       [Validation] Prec@1 76.216216 Max 78.918919
Confusion matrix:
[[19  1  1  0  8  1]
 [ 3 19  4  2  6  1]
 [ 0  0 30  0  0  0]
 [ 0  1  2 22  4  1]
 [ 0  1  0  3 26  0]
 [ 2  0  3  0  0 25]]
Epoch: [9]
       [Avg Loss]          0.344660
       [Training]   Prec@1 89.243697 Max 89.243697
       [Avg Loss]          0.857887
       [Validation] Prec@1 80.540541 Max 80.540541
Confusion matrix:
[[18  8  0  0  4  0]
 [ 2 25  0  2  0  6]
 [ 0  0 30  0  0  0]
 [ 0  0  4 26  0  0]
 [ 0  1  0  7 22  0]
 [ 2  0  0  0  0 28]]
Epoch: [10]
       [Avg Loss]          0.304224
       [Training]   Prec@1 89.075630 Max 89.243697
       [Avg Loss]          0.787814
       [Validation] Prec@1 80.540541 Max 80.540541
Confusion matrix:
[[20  2  0  0  7  1]
 [ 7 23  1  2  0  2]
 [ 0  0 30  0  0  0]
 [ 2  2  3 22  1  0]
 [ 0  0  0  2 28  0]
 [ 2  2  0  0  0 26]]
Epoch: [11]
       [Avg Loss]          0.263869
       [Training]   Prec@1 91.428571 Max 91.428571
       [Avg Loss]          0.868829
       [Validation] Prec@1 82.702703 Max 82.702703
Confusion matrix:
[[20  1  0  1  7  1]
 [ 3 26  0  0  0  6]
 [ 0  0 30  0  0  0]
 [ 0  4  1 24  0  1]
 [ 0  3  0  4 23  0]
 [ 0  0  0  0  0 30]]
Epoch: [12]
       [Avg Loss]          0.216297
       [Training]   Prec@1 92.773109 Max 92.773109
       [Avg Loss]          0.691281
       [Validation] Prec@1 82.162162 Max 82.702703
Confusion matrix:
[[20  6  0  2  2  0]
 [ 4 26  0  4  0  1]
 [ 0  0 30  0  0  0]
 [ 1  0  2 27  0  0]
 [ 0  4  0  1 25  0]
 [ 4  1  0  1  0 24]]
Epoch: [13]
       [Avg Loss]          0.236461
       [Training]   Prec@1 92.100840 Max 92.773109
       [Avg Loss]          1.198246
       [Validation] Prec@1 78.918919 Max 82.702703
Confusion matrix:
[[21  0  0  1  8  0]
 [ 7 18  1  6  0  3]
 [ 0  0 30  0  0  0]
 [ 0  0  5 23  0  2]
 [ 0  0  0  6 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [14]
       [Avg Loss]          0.190217
       [Training]   Prec@1 94.453782 Max 94.453782
       [Avg Loss]          1.055601
       [Validation] Prec@1 79.459459 Max 82.702703
Confusion matrix:
[[16  6  0  1  7  0]
 [ 6 26  0  1  1  1]
 [ 0  0 28  2  0  0]
 [ 0  4  1 24  1  0]
 [ 0  2  0  0 28  0]
 [ 2  3  0  0  0 25]]
Fold "2" complete, final accuracy: 82.70270270270271
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.488536
       [Training]   Prec@1 43.181818 Max 43.181818
       [Avg Loss]          1.405646
       [Validation] Prec@1 56.666667 Max 56.666667
Confusion matrix:
[[20  0  0  0  0  0]
 [ 7  8  0  0  0  5]
 [13  1  0  0  6  0]
 [13  0  0  4  2  1]
 [ 0  0  0  0 20  0]
 [ 3  1  0  0  0 16]]
Epoch: [1]
       [Avg Loss]          0.973071
       [Training]   Prec@1 65.303030 Max 65.303030
       [Avg Loss]          0.921468
       [Validation] Prec@1 75.833333 Max 75.833333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 1 18  0  0  0  1]
 [ 5  4  3  4  4  0]
 [ 5  0  0 13  1  1]
 [ 0  0  0  0 20  0]
 [ 3  0  0  0  0 17]]
Epoch: [2]
       [Avg Loss]          0.641891
       [Training]   Prec@1 79.242424 Max 79.242424
       [Avg Loss]          0.756684
       [Validation] Prec@1 77.500000 Max 77.500000
Confusion matrix:
[[18  0  0  1  1  0]
 [ 0 19  0  1  0  0]
 [ 0  1 13  5  1  0]
 [ 2  0  2 13  3  0]
 [ 0  0  0  0 20  0]
 [ 5  2  0  3  0 10]]
Epoch: [3]
       [Avg Loss]          0.537413
       [Training]   Prec@1 81.969697 Max 81.969697
       [Avg Loss]          0.786092
       [Validation] Prec@1 75.833333 Max 77.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 1 19  0  0  0  0]
 [ 0  2 11  7  0  0]
 [ 5  1  0 10  3  1]
 [ 0  0  0  0 20  0]
 [ 4  4  0  1  0 11]]
Epoch: [4]
       [Avg Loss]          0.505194
       [Training]   Prec@1 84.090909 Max 84.090909
       [Avg Loss]          0.678323
       [Validation] Prec@1 75.833333 Max 77.500000
Confusion matrix:
[[ 9  0  0  3  0  8]
 [ 1 18  0  1  0  0]
 [ 0  2 13  5  0  0]
 [ 1  1  0 16  0  2]
 [ 0  0  0  0 20  0]
 [ 4  0  0  1  0 15]]
Epoch: [5]
       [Avg Loss]          0.468786
       [Training]   Prec@1 84.242424 Max 84.242424
       [Avg Loss]          0.859099
       [Validation] Prec@1 70.833333 Max 77.500000
Confusion matrix:
[[10  0  0  3  7  0]
 [ 0 19  0  0  1  0]
 [ 5  0 12  3  0  0]
 [ 1  1  0 13  4  1]
 [ 0  0  0  0 20  0]
 [ 5  3  0  1  0 11]]
Epoch: [6]
       [Avg Loss]          0.452282
       [Training]   Prec@1 85.151515 Max 85.151515
       [Avg Loss]          0.841832
       [Validation] Prec@1 77.500000 Max 77.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 1 19  0  0  0  0]
 [ 1  2  8  7  2  0]
 [ 2  1  0 13  3  1]
 [ 0  1  0  0 19  0]
 [ 2  3  0  1  0 14]]
Epoch: [7]
       [Avg Loss]          0.396033
       [Training]   Prec@1 86.060606 Max 86.060606
       [Avg Loss]          0.507023
       [Validation] Prec@1 85.833333 Max 85.833333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 17  2  1  0]
 [ 3  0  0 14  2  1]
 [ 0  0  0  0 20  0]
 [ 0  7  0  0  0 13]]
Epoch: [8]
       [Avg Loss]          0.330716
       [Training]   Prec@1 90.757576 Max 90.757576
       [Avg Loss]          0.733552
       [Validation] Prec@1 73.333333 Max 85.833333
Confusion matrix:
[[12  0  1  7  0  0]
 [ 0 19  0  1  0  0]
 [ 2  1 14  3  0  0]
 [ 0  0  3 15  1  1]
 [ 0  0  0  6 14  0]
 [ 1  3  0  2  0 14]]
Epoch: [9]
       [Avg Loss]          0.284749
       [Training]   Prec@1 91.818182 Max 91.818182
       [Avg Loss]          0.622982
       [Validation] Prec@1 82.500000 Max 85.833333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 2 17  0  0  1  0]
 [ 1  0 17  2  0  0]
 [ 5  1  0 11  2  1]
 [ 0  0  0  0 20  0]
 [ 2  3  0  1  0 14]]
Epoch: [10]
       [Avg Loss]          0.245255
       [Training]   Prec@1 92.272727 Max 92.272727
       [Avg Loss]          0.937760
       [Validation] Prec@1 75.000000 Max 85.833333
Confusion matrix:
[[ 9  0  0 11  0  0]
 [ 0 19  0  1  0  0]
 [ 2  1 11  6  0  0]
 [ 1  1  0 17  0  1]
 [ 1  0  0  0 19  0]
 [ 1  3  0  1  0 15]]
Epoch: [11]
       [Avg Loss]          0.232945
       [Training]   Prec@1 92.121212 Max 92.272727
       [Avg Loss]          0.643332
       [Validation] Prec@1 78.333333 Max 85.833333
Confusion matrix:
[[19  0  0  1  0  0]
 [ 2 18  0  0  0  0]
 [ 3  1 14  1  1  0]
 [ 4  2  0 12  1  1]
 [ 0  0  0  0 20  0]
 [ 5  4  0  0  0 11]]
Epoch: [12]
       [Avg Loss]          0.171991
       [Training]   Prec@1 95.454545 Max 95.454545
       [Avg Loss]          0.719486
       [Validation] Prec@1 77.500000 Max 85.833333
Confusion matrix:
[[12  0  0  8  0  0]
 [ 1 18  0  1  0  0]
 [ 3  0 12  5  0  0]
 [ 2  0  0 17  0  1]
 [ 0  0  0  0 20  0]
 [ 2  3  0  1  0 14]]
Epoch: [13]
       [Avg Loss]          0.174181
       [Training]   Prec@1 94.545455 Max 95.454545
       [Avg Loss]          0.853416
       [Validation] Prec@1 75.833333 Max 85.833333
Confusion matrix:
[[10  3  0  7  0  0]
 [ 0 17  0  1  0  2]
 [ 3  1 12  4  0  0]
 [ 2  0  0 17  0  1]
 [ 0  0  0  0 20  0]
 [ 1  3  0  1  0 15]]
Epoch: [14]
       [Avg Loss]          0.176018
       [Training]   Prec@1 94.545455 Max 95.454545
       [Avg Loss]          1.281398
       [Validation] Prec@1 70.000000 Max 85.833333
Confusion matrix:
[[ 8  0  0 12  0  0]
 [ 2 15  0  1  1  1]
 [ 0  1 15  3  0  1]
 [ 0  0  2 16  1  1]
 [ 0  0  0  0 20  0]
 [ 7  2  0  1  0 10]]
Fold "3" complete, final accuracy: 85.83333333333333
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.437794
       [Training]   Prec@1 43.731343 Max 43.731343
       [Avg Loss]          1.540246
       [Validation] Prec@1 55.454545 Max 55.454545
Confusion matrix:
[[19  0  1  0  0  0]
 [ 5  8  0  0  7  0]
 [ 9  1  5  0  5  0]
 [11  7  0  0  0  2]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [1]
       [Avg Loss]          0.905339
       [Training]   Prec@1 68.656716 Max 68.656716
       [Avg Loss]          1.197473
       [Validation] Prec@1 62.727273 Max 62.727273
Confusion matrix:
[[13  5  2  0  0  0]
 [ 0  9 11  0  0  0]
 [ 6  0 14  0  0  0]
 [ 0  7  6  6  0  1]
 [ 0  0  2  0  8  0]
 [ 0  1  0  0  0 19]]
Epoch: [2]
       [Avg Loss]          0.712449
       [Training]   Prec@1 76.567164 Max 76.567164
       [Avg Loss]          0.928755
       [Validation] Prec@1 73.636364 Max 73.636364
Confusion matrix:
[[18  1  1  0  0  0]
 [ 1 12  1  3  3  0]
 [ 7  0 13  0  0  0]
 [ 0  4  7  8  0  1]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [3]
       [Avg Loss]          0.539098
       [Training]   Prec@1 82.537313 Max 82.537313
       [Avg Loss]          1.347892
       [Validation] Prec@1 60.000000 Max 73.636364
Confusion matrix:
[[13  2  1  2  1  1]
 [ 0 16  4  0  0  0]
 [ 7  0 13  0  0  0]
 [ 0  5  6  9  0  0]
 [ 0  0  1  4  5  0]
 [ 9  0  0  1  0 10]]
Epoch: [4]
       [Avg Loss]          0.543183
       [Training]   Prec@1 81.641791 Max 82.537313
       [Avg Loss]          0.988081
       [Validation] Prec@1 70.909091 Max 73.636364
Confusion matrix:
[[15  2  2  0  0  1]
 [ 1 15  0  1  3  0]
 [ 5  0 11  3  0  1]
 [ 0  6  0  8  0  6]
 [ 0  0  0  1  9  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.455675
       [Training]   Prec@1 83.880597 Max 83.880597
       [Avg Loss]          1.277556
       [Validation] Prec@1 54.545455 Max 73.636364
Confusion matrix:
[[14  1  1  1  2  1]
 [ 9  1  1  9  0  0]
 [ 6  0 14  0  0  0]
 [ 0  3 10  7  0  0]
 [ 0  0  0  0 10  0]
 [ 5  0  0  1  0 14]]
Epoch: [6]
       [Avg Loss]          0.372650
       [Training]   Prec@1 87.313433 Max 87.313433
       [Avg Loss]          1.249793
       [Validation] Prec@1 70.909091 Max 73.636364
Confusion matrix:
[[15  1  1  2  1  0]
 [ 1 13  1  2  3  0]
 [ 6  0  9  4  1  0]
 [ 0  6  2 12  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  1  0 19]]
Epoch: [7]
       [Avg Loss]          0.367114
       [Training]   Prec@1 88.507463 Max 88.507463
       [Avg Loss]          1.199311
       [Validation] Prec@1 66.363636 Max 73.636364
Confusion matrix:
[[16  1  0  3  0  0]
 [ 1  6  1  9  3  0]
 [ 6  0  5  9  0  0]
 [ 0  1  1 18  0  0]
 [ 0  0  0  0 10  0]
 [ 1  0  0  1  0 18]]
Epoch: [8]
       [Avg Loss]          0.293197
       [Training]   Prec@1 89.253731 Max 89.253731
       [Avg Loss]          1.324371
       [Validation] Prec@1 67.272727 Max 73.636364
Confusion matrix:
[[15  1  1  2  1  0]
 [ 0 14  0  2  4  0]
 [ 6  0  6  8  0  0]
 [ 0  6  4 10  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  1  0 19]]
Epoch: [9]
       [Avg Loss]          0.284390
       [Training]   Prec@1 90.597015 Max 90.597015
       [Avg Loss]          1.463034
       [Validation] Prec@1 63.636364 Max 73.636364
Confusion matrix:
[[16  2  0  2  0  0]
 [ 5  6  0  5  4  0]
 [ 6  0  4 10  0  0]
 [ 0  1  2 16  0  1]
 [ 0  0  0  0 10  0]
 [ 1  0  0  1  0 18]]
Epoch: [10]
       [Avg Loss]          0.253251
       [Training]   Prec@1 91.044776 Max 91.044776
       [Avg Loss]          1.071559
       [Validation] Prec@1 69.090909 Max 73.636364
Confusion matrix:
[[16  3  0  1  0  0]
 [ 1 15  0  2  2  0]
 [ 6  0 11  2  0  1]
 [ 0  5  8  6  0  1]
 [ 0  0  0  0 10  0]
 [ 1  0  0  1  0 18]]
Epoch: [11]
       [Avg Loss]          0.216784
       [Training]   Prec@1 91.940299 Max 91.940299
       [Avg Loss]          1.467477
       [Validation] Prec@1 65.454545 Max 73.636364
Confusion matrix:
[[15  2  0  2  0  1]
 [ 0 11  0  6  3  0]
 [ 6  0  1 13  0  0]
 [ 0  2  2 16  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  1  0 19]]
Epoch: [12]
       [Avg Loss]          0.236641
       [Training]   Prec@1 91.044776 Max 91.940299
       [Avg Loss]          1.678663
       [Validation] Prec@1 54.545455 Max 73.636364
Confusion matrix:
[[15  0  0  4  1  0]
 [ 1 11  0  4  4  0]
 [ 6  0  5  9  0  0]
 [ 0  1  5 13  0  1]
 [ 0  0  2  0  8  0]
 [ 8  0  0  4  0  8]]
Epoch: [13]
       [Avg Loss]          0.238827
       [Training]   Prec@1 91.940299 Max 91.940299
       [Avg Loss]          1.313427
       [Validation] Prec@1 64.545455 Max 73.636364
Confusion matrix:
[[16  1  0  2  0  1]
 [ 1 12  3  2  2  0]
 [ 6  0 10  4  0  0]
 [ 0  1  4 15  0  0]
 [ 0  0  0  2  8  0]
 [ 9  0  0  1  0 10]]
Epoch: [14]
       [Avg Loss]          0.209816
       [Training]   Prec@1 93.432836 Max 93.432836
       [Avg Loss]          1.806222
       [Validation] Prec@1 55.454545 Max 73.636364
Confusion matrix:
[[ 8  1  0 10  1  0]
 [ 0  3  0 12  5  0]
 [ 6  0  9  5  0  0]
 [ 0  2  6 12  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  1  0 19]]
Fold "4" complete, final accuracy: 73.63636363636364

-----------------------------------------------------------------------
Training for stage 9 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "StandardScaler()", pca: "PCA(n_components=11)")
Average accuracy is: 80.64168714168713


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 10-----
Evaluated preprocessing: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=11)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.402702
       [Training]   Prec@1 44.166667 Max 44.166667
       [Avg Loss]          1.507219
       [Validation] Prec@1 58.888889 Max 58.888889
Confusion matrix:
[[14  0 11  0  5 10]
 [ 0 29  1  0  0  0]
 [ 0  3 27  0  0  0]
 [ 0  5 15  0 10  0]
 [ 0  0 13  0 17  0]
 [ 0  0  1  0  0 19]]
Epoch: [1]
       [Avg Loss]          0.847231
       [Training]   Prec@1 72.333333 Max 72.333333
       [Avg Loss]          1.201333
       [Validation] Prec@1 68.888889 Max 68.888889
Confusion matrix:
[[23  0  1  2  4 10]
 [ 0 29  0  1  0  0]
 [ 0  0 26  0  4  0]
 [ 0  0 16  0 14  0]
 [ 0  0  4  0 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          0.683698
       [Training]   Prec@1 75.833333 Max 75.833333
       [Avg Loss]          1.164408
       [Validation] Prec@1 66.111111 Max 68.888889
Confusion matrix:
[[19  0  3  8  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 29  0  0  0]
 [ 0  0  4  2 24  0]
 [ 0  0  4  0  0 16]]
Epoch: [3]
       [Avg Loss]          0.620421
       [Training]   Prec@1 80.166667 Max 80.166667
       [Avg Loss]          1.406683
       [Validation] Prec@1 67.222222 Max 68.888889
Confusion matrix:
[[18  0  4  2  6 10]
 [ 0 27  0  3  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 29  0  1  0]
 [ 0  0  4  0 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [4]
       [Avg Loss]          0.484783
       [Training]   Prec@1 83.500000 Max 83.500000
       [Avg Loss]          1.144337
       [Validation] Prec@1 71.111111 Max 71.111111
Confusion matrix:
[[23  0  3  1  3 10]
 [ 0 30  0  0  0  0]
 [ 0  2 28  0  0  0]
 [ 1  2 26  1  0  0]
 [ 0  0  4  0 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.423364
       [Training]   Prec@1 85.000000 Max 85.000000
       [Avg Loss]          1.483068
       [Validation] Prec@1 70.555556 Max 71.111111
Confusion matrix:
[[23  0  3  4  0 10]
 [ 0 29  0  0  0  1]
 [ 0  0 30  0  0  0]
 [ 0  0 29  1  0  0]
 [ 2  0  4  0 24  0]
 [ 0  0  0  0  0 20]]
Epoch: [6]
       [Avg Loss]          0.393882
       [Training]   Prec@1 87.166667 Max 87.166667
       [Avg Loss]          1.199886
       [Validation] Prec@1 71.666667 Max 71.666667
Confusion matrix:
[[21  0  5  4  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 26  4  0  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  1  0 19]]
Epoch: [7]
       [Avg Loss]          0.327498
       [Training]   Prec@1 89.666667 Max 89.666667
       [Avg Loss]          1.479158
       [Validation] Prec@1 73.333333 Max 73.333333
Confusion matrix:
[[22  0  6  2  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  0 24  4  1  0]
 [ 0  0  4  0 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [8]
       [Avg Loss]          0.280686
       [Training]   Prec@1 91.833333 Max 91.833333
       [Avg Loss]          1.421014
       [Validation] Prec@1 71.666667 Max 73.333333
Confusion matrix:
[[25  0  1  4  0 10]
 [ 0 28  2  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 28  0  1  0]
 [ 0  0  4  0 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [9]
       [Avg Loss]          0.301255
       [Training]   Prec@1 90.500000 Max 91.833333
       [Avg Loss]          1.392832
       [Validation] Prec@1 70.000000 Max 73.333333
Confusion matrix:
[[22  0  3  3  2 10]
 [ 0 26  4  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  1 20  4  4  0]
 [ 0  0  4  0 26  0]
 [ 0  0  2  0  0 18]]
Epoch: [10]
       [Avg Loss]          0.339372
       [Training]   Prec@1 88.500000 Max 91.833333
       [Avg Loss]          1.299546
       [Validation] Prec@1 75.555556 Max 75.555556
Confusion matrix:
[[28  0  2  0  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  3 22  4  0  0]
 [ 3  1  2  0 24  0]
 [ 0  0  0  0  0 20]]
Epoch: [11]
       [Avg Loss]          0.272290
       [Training]   Prec@1 91.500000 Max 91.833333
       [Avg Loss]          1.733984
       [Validation] Prec@1 63.333333 Max 75.555556
Confusion matrix:
[[ 7  0 14  3  6 10]
 [ 0 30  0  0  0  0]
 [ 0  0 29  0  1  0]
 [ 0  1 12  1 16  0]
 [ 0  0  3  0 27  0]
 [ 0  0  0  0  0 20]]
Epoch: [12]
       [Avg Loss]          0.257554
       [Training]   Prec@1 92.166667 Max 92.166667
       [Avg Loss]          1.349964
       [Validation] Prec@1 71.666667 Max 75.555556
Confusion matrix:
[[21  0  6  3  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 26  3  0  0]
 [ 1  2  2  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [13]
       [Avg Loss]          0.248472
       [Training]   Prec@1 91.500000 Max 92.166667
       [Avg Loss]          1.383920
       [Validation] Prec@1 69.444444 Max 75.555556
Confusion matrix:
[[21  0  5  4  0 10]
 [ 0 24  2  1  0  3]
 [ 0  0 30  0  0  0]
 [ 1  2 15  4  8  0]
 [ 0  0  4  0 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [14]
       [Avg Loss]          0.264802
       [Training]   Prec@1 91.000000 Max 92.166667
       [Avg Loss]          1.348529
       [Validation] Prec@1 72.777778 Max 75.555556
Confusion matrix:
[[21  0  2  5  2 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  1 13  3 12  0]
 [ 0  0  3  0 27  0]
 [ 0  0  0  0  0 20]]
Fold "0" complete, final accuracy: 75.55555555555556
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.308664
       [Training]   Prec@1 49.579832 Max 49.579832
       [Avg Loss]          1.377258
       [Validation] Prec@1 59.459459 Max 59.459459
Confusion matrix:
[[24  4  0  0  0  2]
 [ 1 28  6  0  0  0]
 [ 8  2 16  0  4  0]
 [24  2  3  0  1  0]
 [ 7  0  4  0 19  0]
 [ 5  2  0  0  0 23]]
Epoch: [1]
       [Avg Loss]          0.904880
       [Training]   Prec@1 71.092437 Max 71.092437
       [Avg Loss]          0.845501
       [Validation] Prec@1 74.594595 Max 74.594595
Confusion matrix:
[[26  3  0  0  0  1]
 [ 2 30  2  0  0  1]
 [ 0  3 27  0  0  0]
 [16  1  5  7  0  1]
 [ 8  0  0  0 22  0]
 [ 4  0  0  0  0 26]]
Epoch: [2]
       [Avg Loss]          0.812900
       [Training]   Prec@1 70.420168 Max 71.092437
       [Avg Loss]          0.863066
       [Validation] Prec@1 67.027027 Max 74.594595
Confusion matrix:
[[26  4  0  0  0  0]
 [ 2 29  2  0  0  2]
 [ 0  3 27  0  0  0]
 [ 9  1  9 11  0  0]
 [20  0  0  0 10  0]
 [ 3  1  0  4  1 21]]
Epoch: [3]
       [Avg Loss]          0.746991
       [Training]   Prec@1 74.117647 Max 74.117647
       [Avg Loss]          0.986354
       [Validation] Prec@1 69.729730 Max 74.594595
Confusion matrix:
[[23  3  0  0  3  1]
 [ 3 23  2  0  0  7]
 [ 3  1 26  0  0  0]
 [13  0  5  7  4  1]
 [ 1  0  0  0 29  0]
 [ 2  0  0  5  2 21]]
Epoch: [4]
       [Avg Loss]          0.672889
       [Training]   Prec@1 76.974790 Max 76.974790
       [Avg Loss]          0.837363
       [Validation] Prec@1 70.810811 Max 74.594595
Confusion matrix:
[[27  1  1  0  0  1]
 [ 3 27  3  1  0  1]
 [ 0  2 28  0  0  0]
 [11  0  6 12  0  1]
 [10  0  4  1 15  0]
 [ 2  0  1  5  0 22]]
Epoch: [5]
       [Avg Loss]          0.571824
       [Training]   Prec@1 79.663866 Max 79.663866
       [Avg Loss]          1.007979
       [Validation] Prec@1 74.594595 Max 74.594595
Confusion matrix:
[[25  5  0  0  0  0]
 [ 1 33  0  0  0  1]
 [ 0  8 22  0  0  0]
 [15  1  2  9  2  1]
 [ 5  0  0  0 25  0]
 [ 2  0  1  3  0 24]]
Epoch: [6]
       [Avg Loss]          0.515657
       [Training]   Prec@1 82.521008 Max 82.521008
       [Avg Loss]          0.877876
       [Validation] Prec@1 72.972973 Max 74.594595
Confusion matrix:
[[26  4  0  0  0  0]
 [ 2 31  0  2  0  0]
 [ 0  2 20  8  0  0]
 [12  0  1 16  1  0]
 [ 7  0  0  0 23  0]
 [ 2  1  0  7  1 19]]
Epoch: [7]
       [Avg Loss]          0.480679
       [Training]   Prec@1 83.697479 Max 83.697479
       [Avg Loss]          0.952085
       [Validation] Prec@1 72.432432 Max 74.594595
Confusion matrix:
[[25  3  2  0  0  0]
 [ 2 33  0  0  0  0]
 [ 0  8 22  0  0  0]
 [11  1  2 14  1  1]
 [ 4  0  0  6 20  0]
 [ 2  1  1  5  1 20]]
Epoch: [8]
       [Avg Loss]          0.369359
       [Training]   Prec@1 88.067227 Max 88.067227
       [Avg Loss]          1.036310
       [Validation] Prec@1 70.810811 Max 74.594595
Confusion matrix:
[[28  2  0  0  0  0]
 [ 3 32  0  0  0  0]
 [ 3  6 17  4  0  0]
 [14  3  0 11  1  1]
 [ 6  0  0  1 23  0]
 [ 3  2  0  4  1 20]]
Epoch: [9]
       [Avg Loss]          0.324578
       [Training]   Prec@1 89.747899 Max 89.747899
       [Avg Loss]          0.951688
       [Validation] Prec@1 68.648649 Max 74.594595
Confusion matrix:
[[17  8  2  1  0  2]
 [ 0 34  1  0  0  0]
 [ 2  2 22  4  0  0]
 [ 9  1  1 17  0  2]
 [ 6  1  0  3 20  0]
 [ 2  1  4  6  0 17]]
Epoch: [10]
       [Avg Loss]          0.368425
       [Training]   Prec@1 87.394958 Max 89.747899
       [Avg Loss]          0.841709
       [Validation] Prec@1 71.891892 Max 74.594595
Confusion matrix:
[[23  4  0  3  0  0]
 [ 2 33  0  0  0  0]
 [ 0  6 13 11  0  0]
 [ 1  4  1 22  1  1]
 [ 8  0  0  0 22  0]
 [ 1  2  0  7  0 20]]
Epoch: [11]
       [Avg Loss]          0.300262
       [Training]   Prec@1 90.588235 Max 90.588235
       [Avg Loss]          0.935208
       [Validation] Prec@1 75.135135 Max 75.135135
Confusion matrix:
[[24  3  3  0  0  0]
 [ 2 33  0  0  0  0]
 [ 0  5 24  1  0  0]
 [ 9  1  6 12  1  1]
 [ 7  0  0  0 23  0]
 [ 1  2  0  3  1 23]]
Epoch: [12]
       [Avg Loss]          0.313337
       [Training]   Prec@1 89.915966 Max 90.588235
       [Avg Loss]          0.783723
       [Validation] Prec@1 77.297297 Max 77.297297
Confusion matrix:
[[27  3  0  0  0  0]
 [ 1 34  0  0  0  0]
 [ 3  3 21  3  0  0]
 [ 9  1  1 18  1  0]
 [ 7  0  0  0 23  0]
 [ 1  3  1  5  0 20]]
Epoch: [13]
       [Avg Loss]          0.228234
       [Training]   Prec@1 93.277311 Max 93.277311
       [Avg Loss]          0.825285
       [Validation] Prec@1 78.918919 Max 78.918919
Confusion matrix:
[[27  3  0  0  0  0]
 [ 1 32  1  1  0  0]
 [ 2  1 26  1  0  0]
 [10  3  2 13  2  0]
 [ 3  0  0  0 27  0]
 [ 1  3  0  5  0 21]]
Epoch: [14]
       [Avg Loss]          0.237416
       [Training]   Prec@1 92.605042 Max 93.277311
       [Avg Loss]          1.160974
       [Validation] Prec@1 70.270270 Max 78.918919
Confusion matrix:
[[23  4  3  0  0  0]
 [ 1 34  0  0  0  0]
 [ 1  3 23  3  0  0]
 [16  3  1  9  1  0]
 [10  0  0  0 20  0]
 [ 1  3  1  4  0 21]]
Fold "1" complete, final accuracy: 78.91891891891892
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.377383
       [Training]   Prec@1 47.058824 Max 47.058824
       [Avg Loss]          1.382055
       [Validation] Prec@1 68.108108 Max 68.108108
Confusion matrix:
[[16  4  3  0  1  6]
 [ 0 26  1  0  0  8]
 [ 4  0 20  4  2  0]
 [ 6  9  0  7  5  3]
 [ 3  0  0  0 27  0]
 [ 0  0  0  0  0 30]]
Epoch: [1]
       [Avg Loss]          0.934937
       [Training]   Prec@1 68.739496 Max 68.739496
       [Avg Loss]          0.995317
       [Validation] Prec@1 75.135135 Max 75.135135
Confusion matrix:
[[21  0  0  0  9  0]
 [ 2 31  1  0  0  1]
 [ 1  0 19  3  7  0]
 [ 0  7  1 14  5  3]
 [ 3  0  2  1 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [2]
       [Avg Loss]          0.763432
       [Training]   Prec@1 76.302521 Max 76.302521
       [Avg Loss]          0.773443
       [Validation] Prec@1 76.756757 Max 76.756757
Confusion matrix:
[[21  4  0  0  5  0]
 [ 4 26  1  0  0  4]
 [ 2  1 23  3  1  0]
 [ 0  3  4 18  4  1]
 [ 0  0  6  0 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [3]
       [Avg Loss]          0.793038
       [Training]   Prec@1 71.428571 Max 76.302521
       [Avg Loss]          1.027018
       [Validation] Prec@1 71.891892 Max 76.756757
Confusion matrix:
[[21  2  0  0  7  0]
 [ 6 27  0  1  0  1]
 [ 2  1 13 13  1  0]
 [ 0 10  0 19  0  1]
 [ 1  0  0  6 23  0]
 [ 0  0  0  0  0 30]]
Epoch: [4]
       [Avg Loss]          0.636201
       [Training]   Prec@1 79.831933 Max 79.831933
       [Avg Loss]          0.748668
       [Validation] Prec@1 72.432432 Max 76.756757
Confusion matrix:
[[21  7  0  0  2  0]
 [ 2 23  6  0  0  4]
 [ 1  0 21  7  1  0]
 [ 1  0  5 21  2  1]
 [ 3  0  3  5 19  0]
 [ 1  0  0  0  0 29]]
Epoch: [5]
       [Avg Loss]          0.606219
       [Training]   Prec@1 80.840336 Max 80.840336
       [Avg Loss]          0.960527
       [Validation] Prec@1 70.270270 Max 76.756757
Confusion matrix:
[[21  1  0  0  8  0]
 [ 5 28  2  0  0  0]
 [ 1  0 13 15  1  0]
 [ 0  2  2 25  0  1]
 [ 2  0  5  2 21  0]
 [ 3  5  0  0  0 22]]
Epoch: [6]
       [Avg Loss]          0.493908
       [Training]   Prec@1 83.697479 Max 83.697479
       [Avg Loss]          1.119615
       [Validation] Prec@1 60.540541 Max 76.756757
Confusion matrix:
[[12  2  0  7  6  3]
 [ 6 22  0  0  0  7]
 [ 1  0  6 19  4  0]
 [ 0  8  0 18  0  4]
 [ 0  0  0  6 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [7]
       [Avg Loss]          0.491770
       [Training]   Prec@1 83.865546 Max 83.865546
       [Avg Loss]          1.034052
       [Validation] Prec@1 75.135135 Max 76.756757
Confusion matrix:
[[20  0  0  0 10  0]
 [ 2 30  0  1  0  2]
 [ 2  3 10 12  3  0]
 [ 0  7  0 23  0  0]
 [ 1  0  0  3 26  0]
 [ 0  0  0  0  0 30]]
Epoch: [8]
       [Avg Loss]          0.432325
       [Training]   Prec@1 85.210084 Max 85.210084
       [Avg Loss]          1.075952
       [Validation] Prec@1 70.270270 Max 76.756757
Confusion matrix:
[[25  1  0  0  4  0]
 [14 18  0  1  0  2]
 [ 4  0 14  4  8  0]
 [ 0  0  3 22  4  1]
 [ 1  0  0  4 25  0]
 [ 4  0  0  0  0 26]]
Epoch: [9]
       [Avg Loss]          0.388570
       [Training]   Prec@1 86.890756 Max 86.890756
       [Avg Loss]          1.152057
       [Validation] Prec@1 71.891892 Max 76.756757
Confusion matrix:
[[18  0  0  3  9  0]
 [ 5 24  1  1  3  1]
 [ 1  0 20  9  0  0]
 [ 0  1  0 25  0  4]
 [ 0  0  0 11 19  0]
 [ 3  0  0  0  0 27]]
Epoch: [10]
       [Avg Loss]          0.338462
       [Training]   Prec@1 88.739496 Max 88.739496
       [Avg Loss]          0.800722
       [Validation] Prec@1 74.594595 Max 76.756757
Confusion matrix:
[[20  3  0  1  6  0]
 [ 4 28  0  0  0  3]
 [ 1  0 19  5  5  0]
 [ 0  4  2 21  2  1]
 [ 1  2  0  3 24  0]
 [ 2  0  0  2  0 26]]
Epoch: [11]
       [Avg Loss]          0.299609
       [Training]   Prec@1 90.588235 Max 90.588235
       [Avg Loss]          1.443570
       [Validation] Prec@1 61.621622 Max 76.756757
Confusion matrix:
[[18  0  0  2  9  1]
 [ 4 27  0  0  0  4]
 [ 0  3  3 20  4  0]
 [ 0  5  0 18  2  5]
 [ 0  2  0  7 21  0]
 [ 3  0  0  0  0 27]]
Epoch: [12]
       [Avg Loss]          0.343019
       [Training]   Prec@1 91.092437 Max 91.092437
       [Avg Loss]          0.915849
       [Validation] Prec@1 74.594595 Max 76.756757
Confusion matrix:
[[17  0  0  5  8  0]
 [11 21  3  0  0  0]
 [ 0  0 26  4  0  0]
 [ 0  1  4 24  0  1]
 [ 2  0  0  4 24  0]
 [ 4  0  0  0  0 26]]
Epoch: [13]
       [Avg Loss]          0.310084
       [Training]   Prec@1 89.579832 Max 91.092437
       [Avg Loss]          0.781060
       [Validation] Prec@1 76.216216 Max 76.756757
Confusion matrix:
[[15  7  2  1  5  0]
 [ 1 27  0  0  0  7]
 [ 0  0 23  3  4  0]
 [ 0  2  5 20  1  2]
 [ 0  3  0  1 26  0]
 [ 0  0  0  0  0 30]]
Epoch: [14]
       [Avg Loss]          0.303925
       [Training]   Prec@1 90.924370 Max 91.092437
       [Avg Loss]          0.815217
       [Validation] Prec@1 82.702703 Max 82.702703
Confusion matrix:
[[19  0  0  2  9  0]
 [ 1 32  0  1  0  1]
 [ 1  0 24  5  0  0]
 [ 0  0  2 26  0  2]
 [ 0  0  0  5 25  0]
 [ 2  1  0  0  0 27]]
Fold "2" complete, final accuracy: 82.70270270270271
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.452613
       [Training]   Prec@1 43.333333 Max 43.333333
       [Avg Loss]          1.371425
       [Validation] Prec@1 67.500000 Max 67.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 3 13  3  0  0  1]
 [ 1  0 18  0  1  0]
 [15  0  3  0  1  1]
 [ 0  0  4  0 16  0]
 [ 6  0  0  0  0 14]]
Epoch: [1]
       [Avg Loss]          0.904172
       [Training]   Prec@1 70.909091 Max 70.909091
       [Avg Loss]          0.810700
       [Validation] Prec@1 75.000000 Max 75.000000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 18  0  1  0  1]
 [ 0  4  8  5  3  0]
 [ 8  0  0 10  1  1]
 [ 0  0  0  3 17  0]
 [ 3  0  0  0  0 17]]
Epoch: [2]
       [Avg Loss]          0.761985
       [Training]   Prec@1 74.696970 Max 74.696970
       [Avg Loss]          1.097585
       [Validation] Prec@1 55.833333 Max 75.000000
Confusion matrix:
[[12  0  3  2  3  0]
 [ 1 12  0  5  0  2]
 [ 0  0  7 13  0  0]
 [ 2  0  1 13  3  1]
 [ 0  0  0 10 10  0]
 [ 4  1  0  2  0 13]]
Epoch: [3]
       [Avg Loss]          0.725291
       [Training]   Prec@1 77.121212 Max 77.121212
       [Avg Loss]          0.881612
       [Validation] Prec@1 76.666667 Max 76.666667
Confusion matrix:
[[19  0  0  1  0  0]
 [ 0 18  0  2  0  0]
 [ 0  1 11  8  0  0]
 [ 2  0  0 18  0  0]
 [ 0  0  0  9 11  0]
 [ 1  1  0  3  0 15]]
Epoch: [4]
       [Avg Loss]          0.646288
       [Training]   Prec@1 79.393939 Max 79.393939
       [Avg Loss]          0.642916
       [Validation] Prec@1 76.666667 Max 76.666667
Confusion matrix:
[[16  0  0  4  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 12  8  0  0]
 [ 0  0  1 18  0  1]
 [ 0  0  0  8 12  0]
 [ 2  0  0  3  0 15]]
Epoch: [5]
       [Avg Loss]          0.603180
       [Training]   Prec@1 80.151515 Max 80.151515
       [Avg Loss]          0.706345
       [Validation] Prec@1 70.833333 Max 76.666667
Confusion matrix:
[[14  0  1  5  0  0]
 [ 0 11  0  4  0  5]
 [ 0  1  9 10  0  0]
 [ 0  0  3 16  0  1]
 [ 0  0  0  1 19  0]
 [ 2  0  0  2  0 16]]
Epoch: [6]
       [Avg Loss]          0.538968
       [Training]   Prec@1 82.575758 Max 82.575758
       [Avg Loss]          0.919555
       [Validation] Prec@1 70.000000 Max 76.666667
Confusion matrix:
[[17  0  1  2  0  0]
 [ 1 19  0  0  0  0]
 [ 0  1  6 13  0  0]
 [ 3  0  3 13  0  1]
 [ 0  0  0  7 13  0]
 [ 1  2  0  1  0 16]]
Epoch: [7]
       [Avg Loss]          0.391244
       [Training]   Prec@1 86.818182 Max 86.818182
       [Avg Loss]          0.806949
       [Validation] Prec@1 73.333333 Max 76.666667
Confusion matrix:
[[12  0  2  6  0  0]
 [ 0 19  0  1  0  0]
 [ 0  2  6 12  0  0]
 [ 0  0  2 17  1  0]
 [ 0  0  0  0 20  0]
 [ 0  3  0  3  0 14]]
Epoch: [8]
       [Avg Loss]          0.376744
       [Training]   Prec@1 88.030303 Max 88.030303
       [Avg Loss]          0.597483
       [Validation] Prec@1 79.166667 Max 79.166667
Confusion matrix:
[[17  0  0  3  0  0]
 [ 2 18  0  0  0  0]
 [ 0  2 14  4  0  0]
 [ 1  0  4 15  0  0]
 [ 0  0  0  5 15  0]
 [ 1  2  0  1  0 16]]
Epoch: [9]
       [Avg Loss]          0.332214
       [Training]   Prec@1 88.484848 Max 88.484848
       [Avg Loss]          0.891085
       [Validation] Prec@1 71.666667 Max 79.166667
Confusion matrix:
[[14  0  2  4  0  0]
 [ 0 14  0  6  0  0]
 [ 0  0 13  7  0  0]
 [ 0  0  0 20  0  0]
 [ 0  0  0  9 11  0]
 [ 1  2  0  3  0 14]]
Epoch: [10]
       [Avg Loss]          0.331090
       [Training]   Prec@1 89.242424 Max 89.242424
       [Avg Loss]          0.504773
       [Validation] Prec@1 82.500000 Max 82.500000
Confusion matrix:
[[17  0  2  1  0  0]
 [ 1 19  0  0  0  0]
 [ 0  0 20  0  0  0]
 [ 1  1  3 15  0  0]
 [ 0  0  1  4 15  0]
 [ 3  3  0  1  0 13]]
Epoch: [11]
       [Avg Loss]          0.274444
       [Training]   Prec@1 92.272727 Max 92.272727
       [Avg Loss]          0.907794
       [Validation] Prec@1 70.833333 Max 82.500000
Confusion matrix:
[[13  0  1  6  0  0]
 [ 0 15  0  5  0  0]
 [ 0  0 14  6  0  0]
 [ 1  0  2 17  0  0]
 [ 0  0  0  3 17  0]
 [ 4  2  0  5  0  9]]
Epoch: [12]
       [Avg Loss]          0.279234
       [Training]   Prec@1 91.818182 Max 92.272727
       [Avg Loss]          0.465486
       [Validation] Prec@1 83.333333 Max 83.333333
Confusion matrix:
[[18  0  0  2  0  0]
 [ 1 18  0  0  0  1]
 [ 0  0 13  7  0  0]
 [ 3  1  1 14  0  1]
 [ 0  0  0  0 20  0]
 [ 0  2  0  1  0 17]]
Epoch: [13]
       [Avg Loss]          0.286833
       [Training]   Prec@1 91.212121 Max 92.272727
       [Avg Loss]          0.558031
       [Validation] Prec@1 85.833333 Max 85.833333
Confusion matrix:
[[15  0  0  5  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 19  1  0  0]
 [ 1  0  2 17  0  0]
 [ 0  0  0  0 20  0]
 [ 1  3  0  3  0 13]]
Epoch: [14]
       [Avg Loss]          0.287909
       [Training]   Prec@1 91.515152 Max 92.272727
       [Avg Loss]          0.554506
       [Validation] Prec@1 85.833333 Max 85.833333
Confusion matrix:
[[18  0  0  2  0  0]
 [ 1 18  0  1  0  0]
 [ 0  1 18  1  0  0]
 [ 0  0  2 17  0  1]
 [ 0  0  0  0 20  0]
 [ 4  2  0  2  0 12]]
Fold "3" complete, final accuracy: 85.83333333333333
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.262829
       [Training]   Prec@1 54.179104 Max 54.179104
       [Avg Loss]          1.446211
       [Validation] Prec@1 41.818182 Max 41.818182
Confusion matrix:
[[14  4  1  0  1  0]
 [ 8  2  6  0  4  0]
 [ 8  0  0  0 10  2]
 [ 0  5  8  2  5  0]
 [ 1  0  0  0  9  0]
 [ 0  1  0  0  0 19]]
Epoch: [1]
       [Avg Loss]          0.887018
       [Training]   Prec@1 70.746269 Max 70.746269
       [Avg Loss]          1.431936
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[ 9  5  2  0  3  1]
 [ 2  9  3  0  6  0]
 [ 7  0  8  0  4  1]
 [ 0  6  3 10  0  1]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          0.610126
       [Training]   Prec@1 78.656716 Max 78.656716
       [Avg Loss]          1.235505
       [Validation] Prec@1 70.000000 Max 70.000000
Confusion matrix:
[[17  1  2  0  0  0]
 [ 4  7  6  1  1  1]
 [ 6  0 12  0  0  2]
 [ 0  6  1 12  0  1]
 [ 0  0  1  0  9  0]
 [ 0  0  0  0  0 20]]
Epoch: [3]
       [Avg Loss]          0.647662
       [Training]   Prec@1 79.104478 Max 79.104478
       [Avg Loss]          1.627450
       [Validation] Prec@1 60.000000 Max 70.000000
Confusion matrix:
[[10  4  1  1  3  1]
 [ 0  5  4  4  5  2]
 [ 6  0 11  2  0  1]
 [ 0  6  1 11  0  2]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [4]
       [Avg Loss]          0.625996
       [Training]   Prec@1 78.656716 Max 79.104478
       [Avg Loss]          1.608452
       [Validation] Prec@1 65.454545 Max 70.000000
Confusion matrix:
[[14  1  1  1  3  0]
 [ 1  7  2  1  9  0]
 [ 8  0  7  1  3  1]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.522376
       [Training]   Prec@1 82.537313 Max 82.537313
       [Avg Loss]          1.470949
       [Validation] Prec@1 65.454545 Max 70.000000
Confusion matrix:
[[14  1  0  4  0  1]
 [ 3  4  2  3  5  3]
 [ 7  0 11  1  0  1]
 [ 1  5  0 13  0  1]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [6]
       [Avg Loss]          0.479375
       [Training]   Prec@1 82.537313 Max 82.537313
       [Avg Loss]          1.404969
       [Validation] Prec@1 73.636364 Max 73.636364
Confusion matrix:
[[16  2  2  0  0  0]
 [ 0 14  2  1  3  0]
 [ 6  0  9  4  0  1]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 1  1  0  0  0 18]]
Epoch: [7]
       [Avg Loss]          0.439678
       [Training]   Prec@1 83.731343 Max 83.731343
       [Avg Loss]          1.353007
       [Validation] Prec@1 70.000000 Max 73.636364
Confusion matrix:
[[15  1  0  2  2  0]
 [ 0 12  1  3  4  0]
 [ 6  0  6  7  0  1]
 [ 0  6  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [8]
       [Avg Loss]          0.370301
       [Training]   Prec@1 87.164179 Max 87.164179
       [Avg Loss]          1.401687
       [Validation] Prec@1 68.181818 Max 73.636364
Confusion matrix:
[[10  3  3  1  3  0]
 [ 0  8  3  6  3  0]
 [ 6  0 11  2  0  1]
 [ 0  1  0 19  0  0]
 [ 0  0  1  0  9  0]
 [ 1  1  0  0  0 18]]
Epoch: [9]
       [Avg Loss]          0.350869
       [Training]   Prec@1 87.611940 Max 87.611940
       [Avg Loss]          1.266153
       [Validation] Prec@1 73.636364 Max 73.636364
Confusion matrix:
[[15  1  1  2  1  0]
 [ 0 14  1  3  2  0]
 [ 6  0 10  3  0  1]
 [ 0  6  0 13  0  1]
 [ 0  0  0  0 10  0]
 [ 1  0  0  0  0 19]]
Epoch: [10]
       [Avg Loss]          0.347074
       [Training]   Prec@1 86.865672 Max 87.611940
       [Avg Loss]          1.465992
       [Validation] Prec@1 66.363636 Max 73.636364
Confusion matrix:
[[15  1  0  4  0  0]
 [ 0 10  1  3  5  1]
 [ 5  0  4  8  0  3]
 [ 0  5  0 14  0  1]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [11]
       [Avg Loss]          0.331378
       [Training]   Prec@1 89.402985 Max 89.402985
       [Avg Loss]          1.458981
       [Validation] Prec@1 66.363636 Max 73.636364
Confusion matrix:
[[13  4  1  2  0  0]
 [ 0 12  1  4  3  0]
 [ 7  0  6  6  0  1]
 [ 1  5  0 14  0  0]
 [ 0  0  0  0 10  0]
 [ 1  1  0  0  0 18]]
Epoch: [12]
       [Avg Loss]          0.305833
       [Training]   Prec@1 90.597015 Max 90.597015
       [Avg Loss]          1.575888
       [Validation] Prec@1 64.545455 Max 73.636364
Confusion matrix:
[[12  2  1  4  1  0]
 [ 0 12  2  2  4  0]
 [ 6  0  5  8  0  1]
 [ 0  6  0 13  0  1]
 [ 0  0  0  0 10  0]
 [ 1  0  0  0  0 19]]
Epoch: [13]
       [Avg Loss]          0.267668
       [Training]   Prec@1 91.641791 Max 91.641791
       [Avg Loss]          1.562781
       [Validation] Prec@1 58.181818 Max 73.636364
Confusion matrix:
[[16  1  1  2  0  0]
 [ 0  7  1 10  1  1]
 [ 6  0  5  6  2  1]
 [ 0  4  1 15  0  0]
 [ 0  0  0  0 10  0]
 [ 9  0  0  0  0 11]]
Epoch: [14]
       [Avg Loss]          0.224111
       [Training]   Prec@1 92.238806 Max 92.238806
       [Avg Loss]          1.482971
       [Validation] Prec@1 58.181818 Max 73.636364
Confusion matrix:
[[10  2  2  3  3  0]
 [ 0  5  3  7  3  2]
 [ 6  0  4  9  0  1]
 [ 0  5  0 15  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Fold "4" complete, final accuracy: 73.63636363636364

-----------------------------------------------------------------------
Training for stage 10 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "StandardScaler()", pca: "PCA(n_components=11)")
Average accuracy is: 79.32937482937483


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 11-----
Evaluated preprocessing: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=11)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.533786
       [Training]   Prec@1 38.666667 Max 38.666667
       [Avg Loss]          1.744965
       [Validation] Prec@1 19.444444 Max 19.444444
Confusion matrix:
[[ 0  0 40  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 15  0  0  5]]
Epoch: [1]
       [Avg Loss]          1.000958
       [Training]   Prec@1 63.500000 Max 63.500000
       [Avg Loss]          1.495895
       [Validation] Prec@1 36.111111 Max 36.111111
Confusion matrix:
[[14  0 18  4  0  4]
 [ 0  3 26  1  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 22  0  8  0]
 [ 0  0 20  0 10  0]
 [ 9  0  2  1  0  8]]
Epoch: [2]
       [Avg Loss]          0.815776
       [Training]   Prec@1 70.833333 Max 70.833333
       [Avg Loss]          1.638983
       [Validation] Prec@1 32.777778 Max 36.111111
Confusion matrix:
[[13  4  0 13  0 10]
 [ 0 26  0  0  0  4]
 [ 0 28  2  0  0  0]
 [ 0 30  0  0  0  0]
 [ 0 14  0 16  0  0]
 [ 0  2  0  0  0 18]]
Epoch: [3]
       [Avg Loss]          0.753512
       [Training]   Prec@1 73.333333 Max 73.333333
       [Avg Loss]          1.367914
       [Validation] Prec@1 61.666667 Max 61.666667
Confusion matrix:
[[30  0  0  0  0 10]
 [17 10  1  2  0  0]
 [ 1  0 29  0  0  0]
 [17  0 10  0  3  0]
 [ 3  0  3  0 24  0]
 [ 0  2  0  0  0 18]]
Epoch: [4]
       [Avg Loss]          0.703978
       [Training]   Prec@1 75.333333 Max 75.333333
       [Avg Loss]          1.971898
       [Validation] Prec@1 46.111111 Max 61.666667
Confusion matrix:
[[ 9  0 18  3  0 10]
 [ 0 25  0  3  0  2]
 [ 0  0 30  0  0  0]
 [ 0  0 28  2  0  0]
 [ 0  0 22  7  1  0]
 [ 0  4  0  0  0 16]]
Epoch: [5]
       [Avg Loss]          0.559580
       [Training]   Prec@1 82.166667 Max 82.166667
       [Avg Loss]          1.681493
       [Validation] Prec@1 70.000000 Max 70.000000
Confusion matrix:
[[30  0  0  0  0 10]
 [ 0 28  0  2  0  0]
 [ 0  0 24  0  6  0]
 [ 0  0 12  0 18  0]
 [ 0  0  4  0 26  0]
 [ 0  2  0  0  0 18]]
Epoch: [6]
       [Avg Loss]          0.545640
       [Training]   Prec@1 81.500000 Max 82.166667
       [Avg Loss]          1.745159
       [Validation] Prec@1 65.000000 Max 70.000000
Confusion matrix:
[[29  0  1  0  0 10]
 [ 0 29  0  0  0  1]
 [ 0 12 17  1  0  0]
 [ 0 10  6  0 14  0]
 [ 0  3  1  0 26  0]
 [ 0  4  0  0  0 16]]
Epoch: [7]
       [Avg Loss]          0.537126
       [Training]   Prec@1 82.333333 Max 82.333333
       [Avg Loss]          1.846125
       [Validation] Prec@1 57.222222 Max 70.000000
Confusion matrix:
[[ 7  0  9 14  0 10]
 [ 0 26  0  2  2  0]
 [ 0  0 25  0  5  0]
 [ 0  0  9  0 21  0]
 [ 0  0  5  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [8]
       [Avg Loss]          0.522786
       [Training]   Prec@1 81.000000 Max 82.333333
       [Avg Loss]          1.988840
       [Validation] Prec@1 56.666667 Max 70.000000
Confusion matrix:
[[16  1  9  5  0  9]
 [ 0 30  0  0  0  0]
 [ 0  0 29  1  0  0]
 [ 0  4 22  4  0  0]
 [ 1  8  7  5  9  0]
 [ 0  6  0  0  0 14]]
Epoch: [9]
       [Avg Loss]          0.497854
       [Training]   Prec@1 81.833333 Max 82.333333
       [Avg Loss]          1.655995
       [Validation] Prec@1 68.333333 Max 70.000000
Confusion matrix:
[[26  0  3  1  0 10]
 [ 0 19  0  3  0  8]
 [ 0  0 28  2  0  0]
 [ 0  0 22  5  3  0]
 [ 1  0  4  0 25  0]
 [ 0  0  0  0  0 20]]
Epoch: [10]
       [Avg Loss]          0.549855
       [Training]   Prec@1 82.333333 Max 82.333333
       [Avg Loss]          2.052838
       [Validation] Prec@1 66.666667 Max 70.000000
Confusion matrix:
[[25  1  5  0  0  9]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  4 24  0  2  0]
 [ 0  0  5  0 25  0]
 [ 0 10  0  0  0 10]]
Epoch: [11]
       [Avg Loss]          0.459461
       [Training]   Prec@1 86.333333 Max 86.333333
       [Avg Loss]          1.723326
       [Validation] Prec@1 61.666667 Max 70.000000
Confusion matrix:
[[14  2  3  2  9 10]
 [ 0 30  0  0  0  0]
 [ 0  3 25  1  1  0]
 [ 0  7 11  0 12  0]
 [ 0  7  0  0 23  0]
 [ 0  0  0  1  0 19]]
Epoch: [12]
       [Avg Loss]          0.456513
       [Training]   Prec@1 86.000000 Max 86.333333
       [Avg Loss]          1.870437
       [Validation] Prec@1 58.888889 Max 70.000000
Confusion matrix:
[[27  0  3  0  0 10]
 [ 1 10  7  5  0  7]
 [ 0  0 30  0  0  0]
 [ 0  0 25  5  0  0]
 [11  0  5  0 14  0]
 [ 0  0  0  0  0 20]]
Epoch: [13]
       [Avg Loss]          0.459937
       [Training]   Prec@1 85.000000 Max 86.333333
       [Avg Loss]          1.837619
       [Validation] Prec@1 65.000000 Max 70.000000
Confusion matrix:
[[17  2  7  5  0  9]
 [ 0 27  3  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 25  5  0  0]
 [ 0  0  5  1 24  0]
 [ 0  5  0  1  0 14]]
Epoch: [14]
       [Avg Loss]          0.394274
       [Training]   Prec@1 86.166667 Max 86.333333
       [Avg Loss]          1.532465
       [Validation] Prec@1 71.111111 Max 71.111111
Confusion matrix:
[[30  0  0  0  0 10]
 [ 0 30  0  0  0  0]
 [ 0  0 23  0  7  0]
 [ 1  0  7  0 22  0]
 [ 5  0  0  0 25  0]
 [ 0  0  0  0  0 20]]
Fold "0" complete, final accuracy: 71.11111111111111
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.561265
       [Training]   Prec@1 38.823529 Max 38.823529
       [Avg Loss]          1.745621
       [Validation] Prec@1 16.216216 Max 16.216216
Confusion matrix:
[[30  0  0  0  0  0]
 [35  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]
 [30  0  0  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.234030
       [Training]   Prec@1 51.596639 Max 51.596639
       [Avg Loss]          1.513608
       [Validation] Prec@1 42.162162 Max 42.162162
Confusion matrix:
[[30  0  0  0  0  0]
 [ 4  9 22  0  0  0]
 [ 2  0 28  0  0  0]
 [24  0  4  0  2  0]
 [10  0  9  0 11  0]
 [29  0  1  0  0  0]]
Epoch: [2]
       [Avg Loss]          1.084027
       [Training]   Prec@1 60.672269 Max 60.672269
       [Avg Loss]          1.284740
       [Validation] Prec@1 47.027027 Max 47.027027
Confusion matrix:
[[30  0  0  0  0  0]
 [ 9 16 10  0  0  0]
 [ 9  0 20  0  1  0]
 [27  0  0  0  3  0]
 [13  0  1  0 16  0]
 [24  1  0  0  0  5]]
Epoch: [3]
       [Avg Loss]          0.894851
       [Training]   Prec@1 69.411765 Max 69.411765
       [Avg Loss]          1.114729
       [Validation] Prec@1 58.378378 Max 58.378378
Confusion matrix:
[[10 11  9  0  0  0]
 [ 0 33  2  0  0  0]
 [ 0  7 23  0  0  0]
 [12  3  8  6  0  1]
 [ 8  3  4  0 15  0]
 [ 1  5  1  2  0 21]]
Epoch: [4]
       [Avg Loss]          0.777660
       [Training]   Prec@1 74.453782 Max 74.453782
       [Avg Loss]          0.883378
       [Validation] Prec@1 66.486486 Max 66.486486
Confusion matrix:
[[24  2  0  1  0  3]
 [ 2 33  0  0  0  0]
 [ 0  9 15  6  0  0]
 [ 8  3  1 16  0  2]
 [10  2  0  6 12  0]
 [ 5  1  0  1  0 23]]
Epoch: [5]
       [Avg Loss]          0.748681
       [Training]   Prec@1 71.428571 Max 74.453782
       [Avg Loss]          1.024270
       [Validation] Prec@1 63.243243 Max 66.486486
Confusion matrix:
[[19  6  1  1  3  0]
 [ 0 32  1  1  1  0]
 [ 0 10 13  1  6  0]
 [ 2  1  5  9 13  0]
 [ 0  0  0  1 29  0]
 [ 1  3  1  9  1 15]]
Epoch: [6]
       [Avg Loss]          0.634109
       [Training]   Prec@1 77.478992 Max 77.478992
       [Avg Loss]          1.747070
       [Validation] Prec@1 52.432432 Max 66.486486
Confusion matrix:
[[ 5  6 10  0  0  9]
 [ 0 35  0  0  0  0]
 [ 0 18 12  0  0  0]
 [ 0  6  4 16  0  4]
 [ 0 13  1 13  3  0]
 [ 0  2  1  1  0 26]]
Epoch: [7]
       [Avg Loss]          0.681564
       [Training]   Prec@1 76.974790 Max 77.478992
       [Avg Loss]          1.627589
       [Validation] Prec@1 58.918919 Max 66.486486
Confusion matrix:
[[17 11  0  0  2  0]
 [ 0 35  0  0  0  0]
 [ 0 19  4  1  6  0]
 [ 5  5  0  9 10  1]
 [ 0  6  0  1 23  0]
 [ 2  4  0  2  1 21]]
Epoch: [8]
       [Avg Loss]          0.549257
       [Training]   Prec@1 81.680672 Max 81.680672
       [Avg Loss]          1.404157
       [Validation] Prec@1 54.594595 Max 66.486486
Confusion matrix:
[[23  0  1  0  6  0]
 [ 3 25  0  0  7  0]
 [ 0  4 14  0 12  0]
 [ 3  0  3  6 18  0]
 [ 0  0  0  0 30  0]
 [17  1  0  6  3  3]]
Epoch: [9]
       [Avg Loss]          0.544614
       [Training]   Prec@1 83.025210 Max 83.025210
       [Avg Loss]          0.825539
       [Validation] Prec@1 67.567568 Max 67.567568
Confusion matrix:
[[18  2  4  0  0  6]
 [ 1 30  1  2  0  1]
 [ 0  5 25  0  0  0]
 [ 5  0 11 12  1  1]
 [ 6  1  2  5 16  0]
 [ 2  2  1  1  0 24]]
Epoch: [10]
       [Avg Loss]          0.516342
       [Training]   Prec@1 81.848739 Max 83.025210
       [Avg Loss]          1.314092
       [Validation] Prec@1 58.918919 Max 67.567568
Confusion matrix:
[[11  3  0  1  0 15]
 [ 0 34  0  0  0  1]
 [ 0  9 13  8  0  0]
 [ 0  2  2 17  0  9]
 [ 1 10  0 11  8  0]
 [ 1  2  1  0  0 26]]
Epoch: [11]
       [Avg Loss]          0.552973
       [Training]   Prec@1 80.504202 Max 83.025210
       [Avg Loss]          1.041665
       [Validation] Prec@1 65.945946 Max 67.567568
Confusion matrix:
[[26  0  3  0  0  1]
 [ 7 22  3  3  0  0]
 [ 0  0 30  0  0  0]
 [ 6  0 11  6  7  0]
 [11  0  0  0 19  0]
 [ 8  0  1  1  1 19]]
Epoch: [12]
       [Avg Loss]          0.563149
       [Training]   Prec@1 80.336134 Max 83.025210
       [Avg Loss]          0.891245
       [Validation] Prec@1 72.432432 Max 72.432432
Confusion matrix:
[[23  4  1  1  1  0]
 [ 1 34  0  0  0  0]
 [ 0 12 18  0  0  0]
 [ 7  2  2 17  1  1]
 [ 2  5  0  5 18  0]
 [ 3  2  0  0  1 24]]
Epoch: [13]
       [Avg Loss]          0.505860
       [Training]   Prec@1 83.025210 Max 83.025210
       [Avg Loss]          0.989967
       [Validation] Prec@1 71.891892 Max 72.432432
Confusion matrix:
[[21  5  1  0  3  0]
 [ 1 34  0  0  0  0]
 [ 0 13 17  0  0  0]
 [ 2  3  3 15  6  1]
 [ 0  4  0  1 25  0]
 [ 0  3  1  4  1 21]]
Epoch: [14]
       [Avg Loss]          0.451977
       [Training]   Prec@1 84.033613 Max 84.033613
       [Avg Loss]          1.017051
       [Validation] Prec@1 68.648649 Max 72.432432
Confusion matrix:
[[15  3 12  0  0  0]
 [ 0 28  7  0  0  0]
 [ 0  4 26  0  0  0]
 [ 4  0 13  7  6  0]
 [ 2  0  0  0 28  0]
 [ 2  1  3  0  1 23]]
Fold "1" complete, final accuracy: 72.43243243243244
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.669781
       [Training]   Prec@1 33.277311 Max 33.277311
       [Avg Loss]          1.717522
       [Validation] Prec@1 25.405405 Max 25.405405
Confusion matrix:
[[17  0  0  0  0 13]
 [ 0  0  0  0  0 35]
 [28  0  0  0  0  2]
 [25  0  0  0  0  5]
 [30  0  0  0  0  0]
 [ 0  0  0  0  0 30]]
Epoch: [1]
       [Avg Loss]          1.131685
       [Training]   Prec@1 58.319328 Max 58.319328
       [Avg Loss]          1.476973
       [Validation] Prec@1 49.729730 Max 49.729730
Confusion matrix:
[[25  4  0  1  0  0]
 [11 22  0  0  0  2]
 [14  1  8  7  0  0]
 [15  0  0 10  0  5]
 [18  0  0  5  7  0]
 [10  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          0.885673
       [Training]   Prec@1 70.756303 Max 70.756303
       [Avg Loss]          1.160725
       [Validation] Prec@1 55.675676 Max 55.675676
Confusion matrix:
[[ 4  1 20  0  5  0]
 [ 0 28  7  0  0  0]
 [ 0  0 27  3  0  0]
 [ 1  0 13  7  9  0]
 [ 0  0  8  1 21  0]
 [ 0 14  0  0  0 16]]
Epoch: [3]
       [Avg Loss]          0.854952
       [Training]   Prec@1 70.084034 Max 70.756303
       [Avg Loss]          1.067700
       [Validation] Prec@1 65.405405 Max 65.405405
Confusion matrix:
[[23  1  0  3  3  0]
 [ 4  6  9 12  0  4]
 [ 1  0 20  9  0  0]
 [ 0  2  0 27  0  1]
 [10  0  0  0 20  0]
 [ 5  0  0  0  0 25]]
Epoch: [4]
       [Avg Loss]          0.722691
       [Training]   Prec@1 73.109244 Max 73.109244
       [Avg Loss]          1.257316
       [Validation] Prec@1 67.027027 Max 67.027027
Confusion matrix:
[[14  0  5  0 11  0]
 [ 1 26  1  0  5  2]
 [ 1  0 16  1 12  0]
 [ 0  5  1 11 12  1]
 [ 0  0  1  0 29  0]
 [ 0  2  0  0  0 28]]
Epoch: [5]
       [Avg Loss]          0.669154
       [Training]   Prec@1 76.974790 Max 76.974790
       [Avg Loss]          1.061244
       [Validation] Prec@1 77.297297 Max 77.297297
Confusion matrix:
[[18  7  3  0  2  0]
 [ 0 34  0  0  0  1]
 [ 0  2 19  4  5  0]
 [ 0  7  0 20  3  0]
 [ 2  1  1  4 22  0]
 [ 0  0  0  0  0 30]]
Epoch: [6]
       [Avg Loss]          0.633644
       [Training]   Prec@1 78.823529 Max 78.823529
       [Avg Loss]          1.036941
       [Validation] Prec@1 70.810811 Max 77.297297
Confusion matrix:
[[19  1  3  0  7  0]
 [10 24  0  1  0  0]
 [ 0  0 18 12  0  0]
 [ 0  1  0 27  2  0]
 [ 2  0  0  7 21  0]
 [ 8  0  0  0  0 22]]
Epoch: [7]
       [Avg Loss]          0.642253
       [Training]   Prec@1 77.142857 Max 78.823529
       [Avg Loss]          1.628559
       [Validation] Prec@1 55.135135 Max 77.297297
Confusion matrix:
[[ 5  7  6  0  0 12]
 [ 0 28  0  0  0  7]
 [ 0 10 12  7  0  1]
 [ 0 16  0 10  0  4]
 [ 1  7  0  4 18  0]
 [ 0  1  0  0  0 29]]
Epoch: [8]
       [Avg Loss]          0.624529
       [Training]   Prec@1 77.647059 Max 78.823529
       [Avg Loss]          2.518736
       [Validation] Prec@1 48.108108 Max 77.297297
Confusion matrix:
[[21  0  0  0  9  0]
 [ 9  1  0 11 11  3]
 [ 1  0  2  8 19  0]
 [ 0  0  0  9 21  0]
 [ 0  0  0  0 30  0]
 [ 4  0  0  0  0 26]]
Epoch: [9]
       [Avg Loss]          0.691643
       [Training]   Prec@1 76.302521 Max 78.823529
       [Avg Loss]          1.013869
       [Validation] Prec@1 71.351351 Max 77.297297
Confusion matrix:
[[13  5  8  0  4  0]
 [ 0 34  0  0  0  1]
 [ 0  0 29  0  1  0]
 [ 0  5 13  5  7  0]
 [ 0  0  2  1 27  0]
 [ 3  3  0  0  0 24]]
Epoch: [10]
       [Avg Loss]          0.571038
       [Training]   Prec@1 80.168067 Max 80.168067
       [Avg Loss]          1.115016
       [Validation] Prec@1 67.027027 Max 77.297297
Confusion matrix:
[[16  8  5  0  0  1]
 [ 0 31  0  0  0  4]
 [ 2  1 19  8  0  0]
 [ 0  3  0 17  0 10]
 [ 9  0  4  6 11  0]
 [ 0  0  0  0  0 30]]
Epoch: [11]
       [Avg Loss]          0.553334
       [Training]   Prec@1 79.831933 Max 80.168067
       [Avg Loss]          0.824916
       [Validation] Prec@1 71.351351 Max 77.297297
Confusion matrix:
[[19  3  0  3  3  2]
 [ 1 31  0  0  0  3]
 [ 0  1  8 21  0  0]
 [ 0  2  0 23  5  0]
 [ 0  0  0  8 22  0]
 [ 0  1  0  0  0 29]]
Epoch: [12]
       [Avg Loss]          0.526660
       [Training]   Prec@1 83.193277 Max 83.193277
       [Avg Loss]          1.008116
       [Validation] Prec@1 76.216216 Max 77.297297
Confusion matrix:
[[16  4  3  2  5  0]
 [ 0 34  0  0  0  1]
 [ 0  1 15 14  0  0]
 [ 0  2  1 25  2  0]
 [ 0  1  0  5 24  0]
 [ 2  1  0  0  0 27]]
Epoch: [13]
       [Avg Loss]          0.545331
       [Training]   Prec@1 82.016807 Max 83.193277
       [Avg Loss]          1.461469
       [Validation] Prec@1 56.216216 Max 77.297297
Confusion matrix:
[[21  0  4  0  5  0]
 [19  1  5  7  2  1]
 [ 5  0 17  8  0  0]
 [ 1  0  2 19  8  0]
 [10  0  0  0 20  0]
 [ 4  0  0  0  0 26]]
Epoch: [14]
       [Avg Loss]          0.542129
       [Training]   Prec@1 79.663866 Max 83.193277
       [Avg Loss]          0.795819
       [Validation] Prec@1 75.135135 Max 77.297297
Confusion matrix:
[[13  3  3  6  5  0]
 [ 0 32  2  0  0  1]
 [ 0  0 29  1  0  0]
 [ 0  1  7 22  0  0]
 [ 0  0  3  8 19  0]
 [ 4  2  0  0  0 24]]
Fold "2" complete, final accuracy: 77.29729729729729
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.633860
       [Training]   Prec@1 33.939394 Max 33.939394
       [Avg Loss]          1.713892
       [Validation] Prec@1 18.333333 Max 18.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [19  1  0  0  0  0]
 [20  0  0  0  0  0]
 [19  0  0  1  0  0]
 [20  0  0  0  0  0]
 [20  0  0  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.209308
       [Training]   Prec@1 53.030303 Max 53.030303
       [Avg Loss]          1.488102
       [Validation] Prec@1 50.833333 Max 50.833333
Confusion matrix:
[[19  0  0  0  0  1]
 [12  0  0  0  0  8]
 [20  0  0  0  0  0]
 [ 9  0  0  8  0  3]
 [ 4  0  0  0 16  0]
 [ 2  0  0  0  0 18]]
Epoch: [2]
       [Avg Loss]          0.948325
       [Training]   Prec@1 68.030303 Max 68.030303
       [Avg Loss]          1.071519
       [Validation] Prec@1 59.166667 Max 59.166667
Confusion matrix:
[[20  0  0  0  0  0]
 [ 6  9  0  3  0  2]
 [ 2  0 12  3  3  0]
 [10  0  0 10  0  0]
 [ 0  0  0  7 13  0]
 [ 9  1  0  2  1  7]]
Epoch: [3]
       [Avg Loss]          0.829028
       [Training]   Prec@1 72.121212 Max 72.121212
       [Avg Loss]          1.040626
       [Validation] Prec@1 59.166667 Max 59.166667
Confusion matrix:
[[17  0  0  2  0  1]
 [ 0 14  1  0  0  5]
 [ 0  9  6  5  0  0]
 [ 1  1  0 15  0  3]
 [ 0  9  0 10  1  0]
 [ 0  2  0  0  0 18]]
Epoch: [4]
       [Avg Loss]          0.813621
       [Training]   Prec@1 71.363636 Max 72.121212
       [Avg Loss]          0.865709
       [Validation] Prec@1 70.000000 Max 70.000000
Confusion matrix:
[[18  0  0  0  0  2]
 [ 4 14  0  1  0  1]
 [ 0  5  8  7  0  0]
 [ 2  0  0 15  0  3]
 [ 0  2  0  7 11  0]
 [ 1  1  0  0  0 18]]
Epoch: [5]
       [Avg Loss]          0.703634
       [Training]   Prec@1 74.696970 Max 74.696970
       [Avg Loss]          1.266904
       [Validation] Prec@1 50.833333 Max 70.000000
Confusion matrix:
[[13  0  0  2  5  0]
 [ 4  9  0  3  4  0]
 [ 0  0  5  9  6  0]
 [ 0  0  1 12  7  0]
 [ 0  0  0  0 20  0]
 [ 6  1  0 10  1  2]]
Epoch: [6]
       [Avg Loss]          0.654952
       [Training]   Prec@1 78.181818 Max 78.181818
       [Avg Loss]          1.105994
       [Validation] Prec@1 69.166667 Max 70.000000
Confusion matrix:
[[19  0  1  0  0  0]
 [ 1 12  3  1  0  3]
 [ 0  0 18  2  0  0]
 [ 8  0  5  6  0  1]
 [ 0  0  8  2 10  0]
 [ 0  2  0  0  0 18]]
Epoch: [7]
       [Avg Loss]          0.615723
       [Training]   Prec@1 78.939394 Max 78.939394
       [Avg Loss]          0.675550
       [Validation] Prec@1 80.000000 Max 80.000000
Confusion matrix:
[[16  0  3  1  0  0]
 [ 0 19  0  1  0  0]
 [ 0  4  9  7  0  0]
 [ 1  0  0 18  0  1]
 [ 0  0  0  1 19  0]
 [ 0  3  0  2  0 15]]
Epoch: [8]
       [Avg Loss]          0.561463
       [Training]   Prec@1 80.757576 Max 80.757576
       [Avg Loss]          0.667875
       [Validation] Prec@1 75.000000 Max 80.000000
Confusion matrix:
[[18  0  0  2  0  0]
 [ 0 18  0  1  0  1]
 [ 2  0  9  8  1  0]
 [ 1  1  1 16  1  0]
 [ 0  0  0  5 15  0]
 [ 3  3  0  0  0 14]]
Epoch: [9]
       [Avg Loss]          0.534739
       [Training]   Prec@1 83.030303 Max 83.030303
       [Avg Loss]          0.890540
       [Validation] Prec@1 70.833333 Max 80.000000
Confusion matrix:
[[ 6  0  0 14  0  0]
 [ 0 18  1  1  0  0]
 [ 0  0  7 10  3  0]
 [ 0  0  0 19  0  1]
 [ 0  0  0  0 20  0]
 [ 1  3  0  1  0 15]]
Epoch: [10]
       [Avg Loss]          0.552781
       [Training]   Prec@1 82.727273 Max 83.030303
       [Avg Loss]          0.751964
       [Validation] Prec@1 74.166667 Max 80.000000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 4 12  2  0  1  1]
 [ 2  0 14  3  1  0]
 [ 7  0  2  9  1  1]
 [ 0  0  0  0 20  0]
 [ 4  1  0  1  0 14]]
Epoch: [11]
       [Avg Loss]          0.550104
       [Training]   Prec@1 81.212121 Max 83.030303
       [Avg Loss]          0.795002
       [Validation] Prec@1 75.833333 Max 80.000000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 2 17  1  0  0  0]
 [ 2  0 13  3  2  0]
 [13  0  0  7  0  0]
 [ 0  0  0  0 20  0]
 [ 3  2  0  1  0 14]]
Epoch: [12]
       [Avg Loss]          0.509310
       [Training]   Prec@1 81.818182 Max 83.030303
       [Avg Loss]          0.831927
       [Validation] Prec@1 70.000000 Max 80.000000
Confusion matrix:
[[ 5  0  0 15  0  0]
 [ 0 18  0  1  0  1]
 [ 1  0 10  8  1  0]
 [ 0  0  0 20  0  0]
 [ 0  1  0  3 16  0]
 [ 2  2  0  1  0 15]]
Epoch: [13]
       [Avg Loss]          0.491499
       [Training]   Prec@1 83.030303 Max 83.030303
       [Avg Loss]          0.986058
       [Validation] Prec@1 65.000000 Max 80.000000
Confusion matrix:
[[11  0  0  3  6  0]
 [ 0 19  0  1  0  0]
 [ 1  0 10  7  2  0]
 [ 0  0  0 18  2  0]
 [ 0  0  0  0 20  0]
 [ 8  3  0  9  0  0]]
Epoch: [14]
       [Avg Loss]          0.430398
       [Training]   Prec@1 87.272727 Max 87.272727
       [Avg Loss]          0.802598
       [Validation] Prec@1 72.500000 Max 80.000000
Confusion matrix:
[[11  0  0  5  0  4]
 [ 1 19  0  0  0  0]
 [ 3  0 10  6  1  0]
 [ 2  1  0 14  0  3]
 [ 0  0  0  1 19  0]
 [ 1  5  0  0  0 14]]
Fold "3" complete, final accuracy: 80.0
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.561802
       [Training]   Prec@1 37.761194 Max 37.761194
       [Avg Loss]          1.723632
       [Validation] Prec@1 39.090909 Max 39.090909
Confusion matrix:
[[ 1  2  6  0 11  0]
 [ 0  0 10  0 10  0]
 [ 0  0 18  0  2  0]
 [ 0  0 10  0 10  0]
 [ 0  0  0  0 10  0]
 [ 0  0  6  0  0 14]]
Epoch: [1]
       [Avg Loss]          1.132611
       [Training]   Prec@1 57.910448 Max 57.910448
       [Avg Loss]          1.846664
       [Validation] Prec@1 27.272727 Max 39.090909
Confusion matrix:
[[20  0  0  0  0  0]
 [13  0  0  0  7  0]
 [14  0  0  0  6  0]
 [18  0  0  0  2  0]
 [ 0  0  0  0 10  0]
 [20  0  0  0  0  0]]
Epoch: [2]
       [Avg Loss]          0.845153
       [Training]   Prec@1 70.298507 Max 70.298507
       [Avg Loss]          1.691038
       [Validation] Prec@1 40.000000 Max 40.000000
Confusion matrix:
[[19  0  0  0  1  0]
 [ 7  0  0  1  7  5]
 [13  0  1  0  6  0]
 [ 1  0  1 12  4  2]
 [ 0  0  0  0 10  0]
 [18  0  0  0  0  2]]
Epoch: [3]
       [Avg Loss]          0.787917
       [Training]   Prec@1 72.835821 Max 72.835821
       [Avg Loss]          3.956469
       [Validation] Prec@1 14.545455 Max 40.000000
Confusion matrix:
[[ 0  0  0  0 20  0]
 [ 0  5  0  0 15  0]
 [ 2  0  0  0 18  0]
 [ 0  5  0  1 14  0]
 [ 0  0  0  0 10  0]
 [19  0  0  0  1  0]]
Epoch: [4]
       [Avg Loss]          0.702714
       [Training]   Prec@1 75.970149 Max 75.970149
       [Avg Loss]          1.268257
       [Validation] Prec@1 68.181818 Max 68.181818
Confusion matrix:
[[17  1  1  1  0  0]
 [ 6  7  4  1  2  0]
 [ 8  0 12  0  0  0]
 [ 0  5  4 11  0  0]
 [ 0  0  1  1  8  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.600208
       [Training]   Prec@1 79.402985 Max 79.402985
       [Avg Loss]          1.888143
       [Validation] Prec@1 56.363636 Max 68.181818
Confusion matrix:
[[12  0  1  5  0  2]
 [ 3  7  7  3  0  0]
 [ 4  0 12  2  0  2]
 [ 0  6  0 11  0  3]
 [ 0  0  1  9  0  0]
 [ 0  0  0  0  0 20]]
Epoch: [6]
       [Avg Loss]          0.614820
       [Training]   Prec@1 79.104478 Max 79.402985
       [Avg Loss]          1.768605
       [Validation] Prec@1 52.727273 Max 68.181818
Confusion matrix:
[[ 1  3  7  6  3  0]
 [ 0 10  8  1  1  0]
 [ 2  0 15  2  0  1]
 [ 0  5  8  7  0  0]
 [ 0  0  1  0  9  0]
 [ 0  0  2  2  0 16]]
Epoch: [7]
       [Avg Loss]          0.536941
       [Training]   Prec@1 82.835821 Max 82.835821
       [Avg Loss]          2.383037
       [Validation] Prec@1 48.181818 Max 68.181818
Confusion matrix:
[[17  0  1  0  2  0]
 [ 6  6  2  0  6  0]
 [ 9  0 11  0  0  0]
 [ 0  5  8  6  1  0]
 [ 0  0  0  0 10  0]
 [14  0  0  3  0  3]]
Epoch: [8]
       [Avg Loss]          0.489430
       [Training]   Prec@1 83.134328 Max 83.134328
       [Avg Loss]          1.363551
       [Validation] Prec@1 64.545455 Max 68.181818
Confusion matrix:
[[15  2  1  1  1  0]
 [ 4  4  2  6  4  0]
 [ 5  0 11  2  0  2]
 [ 0  0  5 15  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  3  0 16]]
Epoch: [9]
       [Avg Loss]          0.571290
       [Training]   Prec@1 81.044776 Max 83.134328
       [Avg Loss]          1.862808
       [Validation] Prec@1 59.090909 Max 68.181818
Confusion matrix:
[[14  0  5  1  0  0]
 [ 2 11  7  0  0  0]
 [ 3  0 15  0  0  2]
 [ 0  7  8  4  0  1]
 [ 0  0  8  1  1  0]
 [ 0  0  0  0  0 20]]
Epoch: [10]
       [Avg Loss]          0.510898
       [Training]   Prec@1 82.985075 Max 83.134328
       [Avg Loss]          1.970900
       [Validation] Prec@1 48.181818 Max 68.181818
Confusion matrix:
[[10  0  0 10  0  0]
 [ 7  0  0  9  4  0]
 [ 3  0  0 16  0  1]
 [ 0  0  0 20  0  0]
 [ 0  0  0  4  6  0]
 [ 0  0  0  3  0 17]]
Epoch: [11]
       [Avg Loss]          0.512650
       [Training]   Prec@1 81.044776 Max 83.134328
       [Avg Loss]          1.186275
       [Validation] Prec@1 69.090909 Max 69.090909
Confusion matrix:
[[11  5  0  0  4  0]
 [ 0 13  1  0  6  0]
 [ 6  0  8  3  1  2]
 [ 0  5  0 14  0  1]
 [ 0  0  0  0 10  0]
 [ 0  0  0  0  0 20]]
Epoch: [12]
       [Avg Loss]          0.430040
       [Training]   Prec@1 86.567164 Max 86.567164
       [Avg Loss]          1.593892
       [Validation] Prec@1 55.454545 Max 69.090909
Confusion matrix:
[[17  0  1  0  2  0]
 [ 6  6  1  0  7  0]
 [ 7  0 11  0  2  0]
 [ 0  3  4 13  0  0]
 [ 0  0  0  0 10  0]
 [ 9  0  3  4  0  4]]
Epoch: [13]
       [Avg Loss]          0.448180
       [Training]   Prec@1 84.925373 Max 86.567164
       [Avg Loss]          1.804172
       [Validation] Prec@1 59.090909 Max 69.090909
Confusion matrix:
[[11  4  5  0  0  0]
 [ 0 14  6  0  0  0]
 [ 2  0 16  0  0  2]
 [ 0  6  9  4  0  1]
 [ 0  0 10  0  0  0]
 [ 0  0  0  0  0 20]]
Epoch: [14]
       [Avg Loss]          0.417158
       [Training]   Prec@1 84.477612 Max 86.567164
       [Avg Loss]          2.952272
       [Validation] Prec@1 32.727273 Max 69.090909
Confusion matrix:
[[ 1  0  1  8 10  0]
 [ 0  5  1  2 12  0]
 [ 1  0  5 12  0  2]
 [ 0  1  6 13  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  9  9  0  2]]
Fold "4" complete, final accuracy: 69.0909090909091

-----------------------------------------------------------------------
Training for stage 11 complete!
Evaluated preprocessing is: (center-norm: "False", scaler: "MinMaxScaler()", pca: "PCA(n_components=11)")
Average accuracy is: 73.98634998634998


-----------------------------------------------------------------------
-----------------------------------------------------------------------
-----Stage 1-----
Evaluated preprocessing: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=11)")
Reading the 'LeapGestures' dataset...
Dataset: LeapGestures
Classes: {0: 'ask', 1: 'grasp', 2: 'move', 3: 'nothing', 4: 'ok', 5: 'point'}
Num samples: 960
Num synth: 0
Learning rate: 0.001
Batch size: 64
Weight decay: 0
Num epochs: 15

Random seed: 1570254494
Running fold "0"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.525817
       [Training]   Prec@1 38.000000 Max 38.000000
       [Avg Loss]          1.735691
       [Validation] Prec@1 23.333333 Max 23.333333
Confusion matrix:
[[ 0  0 31  0  0  9]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  0  8  0  0 12]]
Epoch: [1]
       [Avg Loss]          1.031270
       [Training]   Prec@1 63.166667 Max 63.166667
       [Avg Loss]          1.544111
       [Validation] Prec@1 58.333333 Max 58.333333
Confusion matrix:
[[30  0  0  0  0 10]
 [ 0 23  0  6  0  1]
 [ 0  0 30  0  0  0]
 [ 6  0 22  2  0  0]
 [ 6  0 16  8  0  0]
 [ 0  0  0  0  0 20]]
Epoch: [2]
       [Avg Loss]          0.904969
       [Training]   Prec@1 69.166667 Max 69.166667
       [Avg Loss]          1.788264
       [Validation] Prec@1 28.888889 Max 58.333333
Confusion matrix:
[[ 0  8  1 21  0 10]
 [ 0 30  0  0  0  0]
 [ 0 30  0  0  0  0]
 [ 0 30  0  0  0  0]
 [ 0  7 17  3  3  0]
 [ 0  1  0  0  0 19]]
Epoch: [3]
       [Avg Loss]          0.886889
       [Training]   Prec@1 68.666667 Max 69.166667
       [Avg Loss]          1.133648
       [Validation] Prec@1 61.111111 Max 61.111111
Confusion matrix:
[[29  0  0  0  2  9]
 [ 2 22  0  3  0  3]
 [ 8  0 18  4  0  0]
 [13  0  8  1  8  0]
 [ 6  0  0  0 24  0]
 [ 3  0  0  1  0 16]]
Epoch: [4]
       [Avg Loss]          0.763681
       [Training]   Prec@1 72.333333 Max 72.333333
       [Avg Loss]          1.932229
       [Validation] Prec@1 55.000000 Max 61.111111
Confusion matrix:
[[25  5  0  0  0 10]
 [ 0 30  0  0  0  0]
 [ 0 29  1  0  0  0]
 [ 0 30  0  0  0  0]
 [ 0  7  0  0 23  0]
 [ 0  0  0  0  0 20]]
Epoch: [5]
       [Avg Loss]          0.640730
       [Training]   Prec@1 79.500000 Max 79.500000
       [Avg Loss]          1.197285
       [Validation] Prec@1 61.111111 Max 61.111111
Confusion matrix:
[[19  0  0 11  0 10]
 [ 0 25  0  5  0  0]
 [ 0 10 15  5  0  0]
 [ 1  8  6  5 10  0]
 [ 2  0  0  2 26  0]
 [ 0  0  0  0  0 20]]
Epoch: [6]
       [Avg Loss]          0.632481
       [Training]   Prec@1 80.000000 Max 80.000000
       [Avg Loss]          1.469098
       [Validation] Prec@1 51.666667 Max 61.111111
Confusion matrix:
[[30  0  0  0  0 10]
 [ 0 30  0  0  0  0]
 [ 0 25  5  0  0  0]
 [ 1 27  2  0  0  0]
 [20  0  0  1  9  0]
 [ 0  1  0  0  0 19]]
Epoch: [7]
       [Avg Loss]          0.668485
       [Training]   Prec@1 78.666667 Max 80.000000
       [Avg Loss]          1.617572
       [Validation] Prec@1 52.777778 Max 61.111111
Confusion matrix:
[[11  0  0 19  0 10]
 [ 0 28  0  2  0  0]
 [18  3  2  7  0  0]
 [ 9  4  2 15  0  0]
 [ 6  0  0  5 19  0]
 [ 0  0  0  0  0 20]]
Epoch: [8]
       [Avg Loss]          0.595847
       [Training]   Prec@1 79.833333 Max 80.000000
       [Avg Loss]          1.991259
       [Validation] Prec@1 60.555556 Max 61.111111
Confusion matrix:
[[ 7  0 20  2  1 10]
 [ 0 28  0  2  0  0]
 [ 0  0 30  0  0  0]
 [ 0  2 28  0  0  0]
 [ 0  0  6  0 24  0]
 [ 0  0  0  0  0 20]]
Epoch: [9]
       [Avg Loss]          0.567910
       [Training]   Prec@1 81.000000 Max 81.000000
       [Avg Loss]          1.254881
       [Validation] Prec@1 57.222222 Max 61.111111
Confusion matrix:
[[27  0  0  3  0 10]
 [ 0 28  0  2  0  0]
 [ 2 20  4  4  0  0]
 [ 3 15  0 12  0  0]
 [12  0  0  6 12  0]
 [ 0  0  0  0  0 20]]
Epoch: [10]
       [Avg Loss]          0.572302
       [Training]   Prec@1 80.333333 Max 81.000000
       [Avg Loss]          1.441932
       [Validation] Prec@1 56.666667 Max 61.111111
Confusion matrix:
[[26  1  0  3  0 10]
 [ 0 30  0  0  0  0]
 [ 0 11 18  1  0  0]
 [ 1 17  5  7  0  0]
 [13  5  1 10  1  0]
 [ 0  0  0  0  0 20]]
Epoch: [11]
       [Avg Loss]          0.553648
       [Training]   Prec@1 81.333333 Max 81.333333
       [Avg Loss]          1.735287
       [Validation] Prec@1 63.888889 Max 63.888889
Confusion matrix:
[[13  0  1  0 16 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 0  1 14  0 15  0]
 [ 3  0  2  0 25  0]
 [ 0  0  1  2  0 17]]
Epoch: [12]
       [Avg Loss]          0.537724
       [Training]   Prec@1 81.333333 Max 81.333333
       [Avg Loss]          1.182834
       [Validation] Prec@1 73.888889 Max 73.888889
Confusion matrix:
[[28  0  0  2  0 10]
 [ 0 26  0  4  0  0]
 [ 0  0 30  0  0  0]
 [ 1  2 18  5  4  0]
 [ 3  0  2  0 25  0]
 [ 0  0  0  1  0 19]]
Epoch: [13]
       [Avg Loss]          0.475894
       [Training]   Prec@1 83.833333 Max 83.833333
       [Avg Loss]          1.076932
       [Validation] Prec@1 67.777778 Max 73.888889
Confusion matrix:
[[22  3  0  4  1 10]
 [ 0 30  0  0  0  0]
 [ 0  3 23  4  0  0]
 [ 0 10  8 11  1  0]
 [ 1  4  0  0 25  0]
 [ 0  9  0  0  0 11]]
Epoch: [14]
       [Avg Loss]          0.468091
       [Training]   Prec@1 83.666667 Max 83.833333
       [Avg Loss]          1.605198
       [Validation] Prec@1 71.666667 Max 73.888889
Confusion matrix:
[[24  0  0  0  6 10]
 [ 0 30  0  0  0  0]
 [ 0  0 30  0  0  0]
 [ 1  2 23  0  4  0]
 [ 5  0  0  0 25  0]
 [ 0  0  0  0  0 20]]
Fold "0" complete, final accuracy: 73.88888888888889
Running fold "1"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.503745
       [Training]   Prec@1 42.521008 Max 42.521008
       [Avg Loss]          1.733286
       [Validation] Prec@1 18.378378 Max 18.378378
Confusion matrix:
[[28  0  2  0  0  0]
 [27  4  4  0  0  0]
 [30  0  0  0  0  0]
 [27  0  3  0  0  0]
 [30  0  0  0  0  0]
 [26  0  2  0  0  2]]
Epoch: [1]
       [Avg Loss]          1.129438
       [Training]   Prec@1 59.495798 Max 59.495798
       [Avg Loss]          1.363702
       [Validation] Prec@1 52.972973 Max 52.972973
Confusion matrix:
[[ 6 10 14  0  0  0]
 [ 0 34  1  0  0  0]
 [ 0 16  8  4  2  0]
 [ 0  6  5 14  5  0]
 [ 0  3  1  9 17  0]
 [ 0  7  1  3  0 19]]
Epoch: [2]
       [Avg Loss]          1.035759
       [Training]   Prec@1 62.689076 Max 62.689076
       [Avg Loss]          1.297425
       [Validation] Prec@1 55.135135 Max 55.135135
Confusion matrix:
[[20  1  0  0  0  9]
 [ 2 24  3  0  0  6]
 [ 5  3 22  0  0  0]
 [21  0  5  0  0  4]
 [13  0  8  0  9  0]
 [ 3  0  0  0  0 27]]
Epoch: [3]
       [Avg Loss]          0.953281
       [Training]   Prec@1 67.899160 Max 67.899160
       [Avg Loss]          1.250892
       [Validation] Prec@1 60.000000 Max 60.000000
Confusion matrix:
[[27  2  0  0  0  1]
 [ 6 16 13  0  0  0]
 [ 4  0 26  0  0  0]
 [19  0  7  4  0  0]
 [14  0  0  0 16  0]
 [ 5  0  1  2  0 22]]
Epoch: [4]
       [Avg Loss]          0.838746
       [Training]   Prec@1 71.596639 Max 71.596639
       [Avg Loss]          1.068290
       [Validation] Prec@1 60.540541 Max 60.540541
Confusion matrix:
[[ 9  2  0 11  0  8]
 [ 0 33  0  0  0  2]
 [ 0 16  9  5  0  0]
 [ 0  4  1 21  1  3]
 [ 0  5  0 11 14  0]
 [ 0  1  0  3  0 26]]
Epoch: [5]
       [Avg Loss]          0.799977
       [Training]   Prec@1 72.268908 Max 72.268908
       [Avg Loss]          0.935724
       [Validation] Prec@1 64.324324 Max 64.324324
Confusion matrix:
[[25  3  1  1  0  0]
 [ 2 14 11  8  0  0]
 [ 0  1 26  3  0  0]
 [10  0  7 13  0  0]
 [ 6  0  0  2 22  0]
 [ 1  0  1  9  0 19]]
Epoch: [6]
       [Avg Loss]          0.707288
       [Training]   Prec@1 74.621849 Max 74.621849
       [Avg Loss]          1.015307
       [Validation] Prec@1 64.864865 Max 64.864865
Confusion matrix:
[[16  9  4  0  0  1]
 [ 1 34  0  0  0  0]
 [ 0 14 16  0  0  0]
 [ 6  5  7  6  4  2]
 [ 0  5  0  0 25  0]
 [ 1  4  0  2  0 23]]
Epoch: [7]
       [Avg Loss]          0.678166
       [Training]   Prec@1 75.630252 Max 75.630252
       [Avg Loss]          0.860141
       [Validation] Prec@1 70.270270 Max 70.270270
Confusion matrix:
[[25  4  1  0  0  0]
 [ 3 21  3  8  0  0]
 [ 1  2 21  6  0  0]
 [11  1  2 14  1  1]
 [ 1  0  0  2 27  0]
 [ 4  0  1  3  0 22]]
Epoch: [8]
       [Avg Loss]          0.626259
       [Training]   Prec@1 77.647059 Max 77.647059
       [Avg Loss]          0.809070
       [Validation] Prec@1 68.648649 Max 70.270270
Confusion matrix:
[[21  2  5  1  0  1]
 [ 1 23 11  0  0  0]
 [ 0  2 28  0  0  0]
 [ 5  1  9 13  0  2]
 [ 7  0  0  5 18  0]
 [ 1  0  2  3  0 24]]
Epoch: [9]
       [Avg Loss]          0.591494
       [Training]   Prec@1 77.310924 Max 77.647059
       [Avg Loss]          0.864160
       [Validation] Prec@1 74.594595 Max 74.594595
Confusion matrix:
[[18 10  0  1  1  0]
 [ 0 26  5  4  0  0]
 [ 0  2 28  0  0  0]
 [ 1  1  7 15  4  2]
 [ 2  1  0  0 27  0]
 [ 1  2  1  2  0 24]]
Epoch: [10]
       [Avg Loss]          0.683179
       [Training]   Prec@1 76.134454 Max 77.647059
       [Avg Loss]          0.995712
       [Validation] Prec@1 67.567568 Max 74.594595
Confusion matrix:
[[22  2  1  0  0  5]
 [ 2 31  1  0  0  1]
 [ 0  8 22  0  0  0]
 [ 9  2  6  9  3  1]
 [ 9  0  0  0 21  0]
 [ 4  0  2  4  0 20]]
Epoch: [11]
       [Avg Loss]          0.762097
       [Training]   Prec@1 72.436975 Max 77.647059
       [Avg Loss]          1.381574
       [Validation] Prec@1 61.081081 Max 74.594595
Confusion matrix:
[[22  1  0  0  0  7]
 [ 1 25  2  0  0  7]
 [ 9  6 15  0  0  0]
 [13  3  2  6  2  4]
 [11  0  0  0 19  0]
 [ 2  1  1  0  0 26]]
Epoch: [12]
       [Avg Loss]          0.674765
       [Training]   Prec@1 78.151261 Max 78.151261
       [Avg Loss]          0.834839
       [Validation] Prec@1 68.108108 Max 74.594595
Confusion matrix:
[[21  2  0  1  6  0]
 [ 3 31  0  0  1  0]
 [ 0  8 20  0  2  0]
 [ 5  4  4 13  4  0]
 [ 0  0  0  0 30  0]
 [ 9  2  0  7  1 11]]
Epoch: [13]
       [Avg Loss]          0.688824
       [Training]   Prec@1 74.789916 Max 78.151261
       [Avg Loss]          0.783166
       [Validation] Prec@1 77.297297 Max 77.297297
Confusion matrix:
[[24  4  1  0  0  1]
 [ 1 31  3  0  0  0]
 [ 0  2 28  0  0  0]
 [10  2  6 10  1  1]
 [ 2  0  0  0 28  0]
 [ 2  1  2  3  0 22]]
Epoch: [14]
       [Avg Loss]          0.542331
       [Training]   Prec@1 80.672269 Max 80.672269
       [Avg Loss]          1.138789
       [Validation] Prec@1 62.162162 Max 77.297297
Confusion matrix:
[[23  2  3  0  0  2]
 [ 5 30  0  0  0  0]
 [ 2 16 11  1  0  0]
 [ 8  5  3 13  0  1]
 [11  1  0  1 17  0]
 [ 3  2  0  4  0 21]]
Fold "1" complete, final accuracy: 77.29729729729729
Running fold "2"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.562274
       [Training]   Prec@1 41.512605 Max 41.512605
       [Avg Loss]          1.648229
       [Validation] Prec@1 45.405405 Max 45.405405
Confusion matrix:
[[17  1  0 12  0  0]
 [ 0 16  0 17  0  2]
 [ 0  0  0 30  0  0]
 [ 8  0  0 22  0  0]
 [20  0  0 10  0  0]
 [ 0  0  0  1  0 29]]
Epoch: [1]
       [Avg Loss]          1.138988
       [Training]   Prec@1 61.008403 Max 61.008403
       [Avg Loss]          1.544330
       [Validation] Prec@1 36.756757 Max 45.405405
Confusion matrix:
[[23  2  0  5  0  0]
 [ 3  2  0 12  0 18]
 [22  0  0  8  0  0]
 [ 9  0  0 13  0  8]
 [21  0  0  9  0  0]
 [ 0  0  0  0  0 30]]
Epoch: [2]
       [Avg Loss]          0.947463
       [Training]   Prec@1 66.722689 Max 66.722689
       [Avg Loss]          1.067214
       [Validation] Prec@1 60.540541 Max 60.540541
Confusion matrix:
[[ 4  4  3 17  2  0]
 [ 0 27  1  4  0  3]
 [ 0  1 16 12  1  0]
 [ 0  9  0 16  5  0]
 [ 0  0  0 10 20  0]
 [ 0  0  0  1  0 29]]
Epoch: [3]
       [Avg Loss]          0.847529
       [Training]   Prec@1 71.260504 Max 71.260504
       [Avg Loss]          1.059476
       [Validation] Prec@1 64.864865 Max 64.864865
Confusion matrix:
[[19  4  6  0  0  1]
 [ 0 18 11  1  0  5]
 [ 0  0 22  8  0  0]
 [ 0  3  7 14  0  6]
 [ 5  0  1  7 17  0]
 [ 0  0  0  0  0 30]]
Epoch: [4]
       [Avg Loss]          0.766936
       [Training]   Prec@1 75.966387 Max 75.966387
       [Avg Loss]          0.893319
       [Validation] Prec@1 69.729730 Max 69.729730
Confusion matrix:
[[24  2  1  0  3  0]
 [ 3 30  1  0  0  1]
 [ 3  3 16  8  0  0]
 [ 8  9  1 12  0  0]
 [ 4  0  0  2 24  0]
 [ 3  4  0  0  0 23]]
Epoch: [5]
       [Avg Loss]          0.743841
       [Training]   Prec@1 75.294118 Max 75.966387
       [Avg Loss]          1.274312
       [Validation] Prec@1 61.621622 Max 69.729730
Confusion matrix:
[[16  0  0  6  8  0]
 [ 4 15  1  6  8  1]
 [ 0  0  5 14 11  0]
 [ 0  0  0 25  5  0]
 [ 0  0  0  2 28  0]
 [ 4  0  0  1  0 25]]
Epoch: [6]
       [Avg Loss]          0.676662
       [Training]   Prec@1 76.974790 Max 76.974790
       [Avg Loss]          1.152606
       [Validation] Prec@1 67.027027 Max 69.729730
Confusion matrix:
[[22  2  0  0  6  0]
 [ 2 30  0  1  0  2]
 [ 1  5  0 23  1  0]
 [ 1  9  0 18  1  1]
 [ 2  0  0  4 24  0]
 [ 0  0  0  0  0 30]]
Epoch: [7]
       [Avg Loss]          0.628696
       [Training]   Prec@1 78.655462 Max 78.655462
       [Avg Loss]          1.135048
       [Validation] Prec@1 65.405405 Max 69.729730
Confusion matrix:
[[21  1  5  1  2  0]
 [ 2 23  4  0  0  6]
 [ 2  0 25  3  0  0]
 [ 3  5  2 11  0  9]
 [14  0  1  4 11  0]
 [ 0  0  0  0  0 30]]
Epoch: [8]
       [Avg Loss]          0.649034
       [Training]   Prec@1 77.310924 Max 78.655462
       [Avg Loss]          2.338143
       [Validation] Prec@1 51.351351 Max 69.729730
Confusion matrix:
[[21  0  0  2  7  0]
 [ 2  1  0 28  1  3]
 [ 2  0  0  9 19  0]
 [ 1  0  0 14 15  0]
 [ 0  0  0  0 30  0]
 [ 0  0  0  1  0 29]]
Epoch: [9]
       [Avg Loss]          0.633651
       [Training]   Prec@1 76.470588 Max 78.655462
       [Avg Loss]          1.245043
       [Validation] Prec@1 62.702703 Max 69.729730
Confusion matrix:
[[14  1  6  5  3  1]
 [ 1 22 10  1  0  1]
 [ 0  0 26  4  0  0]
 [ 0  8 10 10  0  2]
 [ 0  0 12  2 16  0]
 [ 0  2  0  0  0 28]]
Epoch: [10]
       [Avg Loss]          0.634847
       [Training]   Prec@1 76.638655 Max 78.655462
       [Avg Loss]          2.087727
       [Validation] Prec@1 47.027027 Max 69.729730
Confusion matrix:
[[21  0  0  0  9  0]
 [ 7  7  4  0 17  0]
 [ 1  0  5  0 24  0]
 [ 3  0  1  3 23  0]
 [ 1  0  0  0 29  0]
 [ 7  1  0  0  0 22]]
Epoch: [11]
       [Avg Loss]          0.638885
       [Training]   Prec@1 79.327731 Max 79.327731
       [Avg Loss]          1.025074
       [Validation] Prec@1 69.189189 Max 69.729730
Confusion matrix:
[[22  3  2  0  3  0]
 [ 7 25  1  0  0  2]
 [ 0  1  9 20  0  0]
 [ 0  9  0 20  0  1]
 [ 0  0  0  8 22  0]
 [ 0  0  0  0  0 30]]
Epoch: [12]
       [Avg Loss]          0.541046
       [Training]   Prec@1 82.521008 Max 82.521008
       [Avg Loss]          1.166029
       [Validation] Prec@1 64.324324 Max 69.729730
Confusion matrix:
[[11  2  4  9  3  1]
 [ 1 21  1  2  0 10]
 [ 0  0 19 11  0  0]
 [ 0  0  1 26  0  3]
 [ 2  0  5 11 12  0]
 [ 0  0  0  0  0 30]]
Epoch: [13]
       [Avg Loss]          0.542768
       [Training]   Prec@1 82.184874 Max 82.521008
       [Avg Loss]          1.343095
       [Validation] Prec@1 61.081081 Max 69.729730
Confusion matrix:
[[22  0  1  2  5  0]
 [ 4 10  0 19  0  2]
 [ 1  0  0 29  0  0]
 [ 0  0  0 30  0  0]
 [ 6  0  0  1 23  0]
 [ 1  0  0  1  0 28]]
Epoch: [14]
       [Avg Loss]          0.545967
       [Training]   Prec@1 81.344538 Max 82.521008
       [Avg Loss]          1.115954
       [Validation] Prec@1 71.351351 Max 71.351351
Confusion matrix:
[[17  1  3  3  6  0]
 [ 3 13  6 12  1  0]
 [ 0  0 23  6  1  0]
 [ 0  0  3 27  0  0]
 [ 0  0  1  3 26  0]
 [ 3  0  0  1  0 26]]
Fold "2" complete, final accuracy: 71.35135135135135
Running fold "3"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.523579
       [Training]   Prec@1 43.333333 Max 43.333333
       [Avg Loss]          1.689637
       [Validation] Prec@1 35.833333 Max 35.833333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 2 18  0  0  0  0]
 [14  6  0  0  0  0]
 [20  0  0  0  0  0]
 [10  5  0  0  5  0]
 [16  4  0  0  0  0]]
Epoch: [1]
       [Avg Loss]          1.102879
       [Training]   Prec@1 59.242424 Max 59.242424
       [Avg Loss]          1.213106
       [Validation] Prec@1 73.333333 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 2 16  0  1  0  1]
 [ 0  4 13  2  1  0]
 [12  1  0  7  0  0]
 [ 0  0  2  1 17  0]
 [ 3  2  0  0  0 15]]
Epoch: [2]
       [Avg Loss]          0.878111
       [Training]   Prec@1 70.909091 Max 70.909091
       [Avg Loss]          1.077081
       [Validation] Prec@1 55.000000 Max 73.333333
Confusion matrix:
[[16  0  0  4  0  0]
 [ 0  7  0  5  0  8]
 [ 0  1  0 19  0  0]
 [ 3  0  0 16  0  1]
 [ 0  0  0  9 11  0]
 [ 3  0  0  1  0 16]]
Epoch: [3]
       [Avg Loss]          0.788199
       [Training]   Prec@1 74.696970 Max 74.696970
       [Avg Loss]          0.871600
       [Validation] Prec@1 70.833333 Max 73.333333
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 16  0  4  0  0]
 [ 0  1  0 14  5  0]
 [ 4  1  0 13  2  0]
 [ 0  0  0  0 20  0]
 [ 2  1  0  1  0 16]]
Epoch: [4]
       [Avg Loss]          0.797602
       [Training]   Prec@1 74.545455 Max 74.696970
       [Avg Loss]          0.885968
       [Validation] Prec@1 70.833333 Max 73.333333
Confusion matrix:
[[ 6  3  0 11  0  0]
 [ 0 19  0  1  0  0]
 [ 0  4 16  0  0  0]
 [ 1  1  1 17  0  0]
 [ 0  0  7  2 11  0]
 [ 1  3  0  0  0 16]]
Epoch: [5]
       [Avg Loss]          0.802277
       [Training]   Prec@1 74.393939 Max 74.696970
       [Avg Loss]          0.818017
       [Validation] Prec@1 75.000000 Max 75.000000
Confusion matrix:
[[14  0  0  0  6  0]
 [ 0 20  0  0  0  0]
 [ 0  5 14  1  0  0]
 [ 3  3  1  8  5  0]
 [ 0  0  0  0 20  0]
 [ 2  3  0  1  0 14]]
Epoch: [6]
       [Avg Loss]          0.727370
       [Training]   Prec@1 76.060606 Max 76.060606
       [Avg Loss]          1.611759
       [Validation] Prec@1 42.500000 Max 75.000000
Confusion matrix:
[[ 5  0  4 11  0  0]
 [ 0  0  0  6  0 14]
 [ 0  0  6 14  0  0]
 [ 0  0  0 19  0  1]
 [ 0  0  1 15  4  0]
 [ 0  0  0  3  0 17]]
Epoch: [7]
       [Avg Loss]          0.723822
       [Training]   Prec@1 76.515152 Max 76.515152
       [Avg Loss]          1.174191
       [Validation] Prec@1 54.166667 Max 75.000000
Confusion matrix:
[[ 6  0  0 12  2  0]
 [ 0  0  0 19  0  1]
 [ 0  0  8 11  1  0]
 [ 0  0  0 19  1  0]
 [ 0  0  0  3 17  0]
 [ 2  0  0  3  0 15]]
Epoch: [8]
       [Avg Loss]          0.676335
       [Training]   Prec@1 76.212121 Max 76.515152
       [Avg Loss]          1.015646
       [Validation] Prec@1 60.000000 Max 75.000000
Confusion matrix:
[[11  0  0  9  0  0]
 [ 0 20  0  0  0  0]
 [ 0  3  4 13  0  0]
 [ 1  5  0 14  0  0]
 [ 0  0  0 14  6  0]
 [ 0  3  0  0  0 17]]
Epoch: [9]
       [Avg Loss]          0.707999
       [Training]   Prec@1 77.272727 Max 77.272727
       [Avg Loss]          1.553949
       [Validation] Prec@1 59.166667 Max 75.000000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 7 11  0  0  2  0]
 [ 0  0  4  0 16  0]
 [ 8  0  0  4  8  0]
 [ 0  0  0  0 20  0]
 [ 8  0  0  0  0 12]]
Epoch: [10]
       [Avg Loss]          0.644838
       [Training]   Prec@1 79.696970 Max 79.696970
       [Avg Loss]          0.682893
       [Validation] Prec@1 82.500000 Max 82.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 20  0  0  0  0]
 [ 0  7 13  0  0  0]
 [ 3  4  0 13  0  0]
 [ 0  0  3  0 17  0]
 [ 0  4  0  0  0 16]]
Epoch: [11]
       [Avg Loss]          0.659398
       [Training]   Prec@1 78.333333 Max 79.696970
       [Avg Loss]          0.577242
       [Validation] Prec@1 81.666667 Max 82.500000
Confusion matrix:
[[20  0  0  0  0  0]
 [ 0 16  0  3  0  1]
 [ 0  1 11  8  0  0]
 [ 1  0  0 19  0  0]
 [ 0  0  1  1 18  0]
 [ 3  2  0  1  0 14]]
Epoch: [12]
       [Avg Loss]          0.592413
       [Training]   Prec@1 80.303030 Max 80.303030
       [Avg Loss]          0.571707
       [Validation] Prec@1 80.000000 Max 82.500000
Confusion matrix:
[[17  0  1  2  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 14  6  0  0]
 [ 2  0  2 16  0  0]
 [ 0  0  3  0 17  0]
 [ 1  4  0  2  0 13]]
Epoch: [13]
       [Avg Loss]          0.596605
       [Training]   Prec@1 78.939394 Max 80.303030
       [Avg Loss]          0.908883
       [Validation] Prec@1 71.666667 Max 82.500000
Confusion matrix:
[[ 7  0  0 12  1  0]
 [ 0 16  0  4  0  0]
 [ 0  0  8 11  1  0]
 [ 0  0  0 19  1  0]
 [ 0  0  0  0 20  0]
 [ 0  2  0  2  0 16]]
Epoch: [14]
       [Avg Loss]          0.553309
       [Training]   Prec@1 82.272727 Max 82.272727
       [Avg Loss]          0.851371
       [Validation] Prec@1 74.166667 Max 82.500000
Confusion matrix:
[[10  1  2  7  0  0]
 [ 0 19  0  1  0  0]
 [ 0  0 16  4  0  0]
 [ 0  0  2 18  0  0]
 [ 0  0  8  1 11  0]
 [ 4  1  0  0  0 15]]
Fold "3" complete, final accuracy: 82.5
Running fold "4"...
Filling cache...
Epoch: [0]
       [Avg Loss]          1.490128
       [Training]   Prec@1 41.492537 Max 41.492537
       [Avg Loss]          1.693498
       [Validation] Prec@1 40.909091 Max 40.909091
Confusion matrix:
[[ 7  3 10  0  0  0]
 [ 8  1 11  0  0  0]
 [ 2  0 17  0  0  1]
 [ 0  3 17  0  0  0]
 [ 3  0  2  0  5  0]
 [ 0  0  5  0  0 15]]
Epoch: [1]
       [Avg Loss]          1.042312
       [Training]   Prec@1 64.328358 Max 64.328358
       [Avg Loss]          1.814639
       [Validation] Prec@1 26.363636 Max 40.909091
Confusion matrix:
[[ 1  2  4  0 13  0]
 [ 0  0  9  0 11  0]
 [ 3  0  5  0 12  0]
 [ 0  3  7  0 10  0]
 [ 0  0  0  0 10  0]
 [ 3  3  1  0  0 13]]
Epoch: [2]
       [Avg Loss]          0.830362
       [Training]   Prec@1 73.134328 Max 73.134328
       [Avg Loss]          1.820798
       [Validation] Prec@1 33.636364 Max 40.909091
Confusion matrix:
[[ 7  5  0  0  0  8]
 [ 0 12  0  0  0  8]
 [ 1 12  0  0  0  7]
 [ 0 16  0  0  0  4]
 [ 0  8  0  0  0  2]
 [ 0  2  0  0  0 18]]
Epoch: [3]
       [Avg Loss]          0.790331
       [Training]   Prec@1 73.731343 Max 73.731343
       [Avg Loss]          1.529347
       [Validation] Prec@1 59.090909 Max 59.090909
Confusion matrix:
[[14  0  2  0  4  0]
 [ 6  0  8  2  4  0]
 [ 7  0  6  0  6  1]
 [ 0  1  2 17  0  0]
 [ 0  0  0  0 10  0]
 [ 2  0  0  0  0 18]]
Epoch: [4]
       [Avg Loss]          0.686689
       [Training]   Prec@1 77.611940 Max 77.611940
       [Avg Loss]          1.891029
       [Validation] Prec@1 66.363636 Max 66.363636
Confusion matrix:
[[18  0  1  0  1  0]
 [ 9  6  3  0  2  0]
 [ 7  0 11  0  1  1]
 [ 0  6  1 10  3  0]
 [ 0  0  0  0 10  0]
 [ 0  2  0  0  0 18]]
Epoch: [5]
       [Avg Loss]          0.627299
       [Training]   Prec@1 76.567164 Max 77.611940
       [Avg Loss]          2.044210
       [Validation] Prec@1 64.545455 Max 66.363636
Confusion matrix:
[[15  0  2  2  1  0]
 [ 6  2  5  3  4  0]
 [ 7  0 10  2  0  1]
 [ 0  2  0 18  0  0]
 [ 0  0  0  0 10  0]
 [ 3  0  0  1  0 16]]
Epoch: [6]
       [Avg Loss]          0.636863
       [Training]   Prec@1 78.208955 Max 78.208955
       [Avg Loss]          2.100750
       [Validation] Prec@1 45.454545 Max 66.363636
Confusion matrix:
[[ 6  0  3  6  0  5]
 [ 0  2 11  7  0  0]
 [ 3  0 13  2  0  2]
 [ 0  5  6  9  0  0]
 [ 0  0  2  8  0  0]
 [ 0  0  0  0  0 20]]
Epoch: [7]
       [Avg Loss]          0.689780
       [Training]   Prec@1 76.567164 Max 78.208955
       [Avg Loss]          1.789769
       [Validation] Prec@1 43.636364 Max 66.363636
Confusion matrix:
[[17  0  2  0  1  0]
 [ 5  0  5  1  9  0]
 [ 8  0  5  0  7  0]
 [ 0  0  0  9 11  0]
 [ 0  0  0  0 10  0]
 [13  0  0  0  0  7]]
Epoch: [8]
       [Avg Loss]          0.606299
       [Training]   Prec@1 78.656716 Max 78.656716
       [Avg Loss]          1.595193
       [Validation] Prec@1 57.272727 Max 66.363636
Confusion matrix:
[[17  0  0  1  0  2]
 [ 9  7  1  2  0  1]
 [ 5  0 10  0  0  5]
 [ 0  6  0  7  0  7]
 [ 6  0  0  2  2  0]
 [ 0  0  0  0  0 20]]
Epoch: [9]
       [Avg Loss]          0.603284
       [Training]   Prec@1 79.253731 Max 79.253731
       [Avg Loss]          1.475021
       [Validation] Prec@1 64.545455 Max 66.363636
Confusion matrix:
[[16  0  1  3  0  0]
 [ 9  5  3  3  0  0]
 [ 8  0 11  1  0  0]
 [ 0  2  0 18  0  0]
 [ 0  0  0  0 10  0]
 [ 8  1  0  0  0 11]]
Epoch: [10]
       [Avg Loss]          0.557900
       [Training]   Prec@1 80.597015 Max 80.597015
       [Avg Loss]          1.431114
       [Validation] Prec@1 69.090909 Max 69.090909
Confusion matrix:
[[15  2  3  0  0  0]
 [ 6  7  5  1  1  0]
 [ 6  0 12  0  1  1]
 [ 0  6  1 13  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [11]
       [Avg Loss]          0.493233
       [Training]   Prec@1 83.582090 Max 83.582090
       [Avg Loss]          1.524730
       [Validation] Prec@1 70.000000 Max 70.000000
Confusion matrix:
[[17  1  2  0  0  0]
 [ 6  5  3  2  4  0]
 [ 7  0 11  0  1  1]
 [ 0  5  0 15  0  0]
 [ 0  0  0  0 10  0]
 [ 0  1  0  0  0 19]]
Epoch: [12]
       [Avg Loss]          0.516055
       [Training]   Prec@1 81.194030 Max 83.582090
       [Avg Loss]          1.631107
       [Validation] Prec@1 73.636364 Max 73.636364
Confusion matrix:
[[16  0  1  3  0  0]
 [ 0  5  3  8  4  0]
 [ 6  0 11  2  0  1]
 [ 0  0  0 20  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  0  1  0 19]]
Epoch: [13]
       [Avg Loss]          0.483484
       [Training]   Prec@1 83.134328 Max 83.582090
       [Avg Loss]          1.578667
       [Validation] Prec@1 60.000000 Max 73.636364
Confusion matrix:
[[11  3  2  4  0  0]
 [ 5  8  3  4  0  0]
 [ 5  0 13  0  0  2]
 [ 0  6  0 14  0  0]
 [ 0  0  2  6  2  0]
 [ 0  2  0  0  0 18]]
Epoch: [14]
       [Avg Loss]          0.545968
       [Training]   Prec@1 78.955224 Max 83.582090
       [Avg Loss]          1.139399
       [Validation] Prec@1 71.818182 Max 73.636364
Confusion matrix:
[[16  1  1  2  0  0]
 [ 2 10  3  3  1  1]
 [ 5  0 10  2  0  3]
 [ 0  3  0 15  0  2]
 [ 0  0  0  2  8  0]
 [ 0  0  0  0  0 20]]
Fold "4" complete, final accuracy: 73.63636363636364

-----------------------------------------------------------------------
Training for stage 1 complete!
Evaluated preprocessing is: (center-norm: "True", scaler: "MinMaxScaler()", pca: "PCA(n_components=11)")
Average accuracy is: 75.73478023478023


-----------------------------------------------------------------------
-----------------------------------------------------------------------